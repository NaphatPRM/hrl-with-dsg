Mon Jul 10 10:36:32 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:1A:00.0 Off |                  N/A |
| 17%   20C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  On   | 00000000:1B:00.0 Off |                  N/A |
| 16%   25C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  On   | 00000000:3D:00.0 Off |                  N/A |
| 16%   19C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  On   | 00000000:3E:00.0 Off |                  N/A |
| 16%   20C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  On   | 00000000:88:00.0 Off |                  N/A |
| 22%   42C    P2    67W / 250W |   9777MiB / 11178MiB |     14%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  On   | 00000000:89:00.0 Off |                  N/A |
| 17%   20C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  On   | 00000000:B1:00.0 Off |                  N/A |
| 22%   42C    P2    70W / 250W |   9447MiB / 11178MiB |     12%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  On   | 00000000:B2:00.0 Off |                  N/A |
| 16%   22C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    4   N/A  N/A    697444      C   python3                          9775MiB |
|    6   N/A  N/A    703857      C   python3                          9445MiB |
+-----------------------------------------------------------------------------+
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MiniGrid-MultiRoom-N4-S5-v0 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MiniGrid-MultiRoom-N4-S5-v0/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MiniGrid-MultiRoom-N4-S5-v0 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MiniGrid-MultiRoom-N4-S5-v0/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MiniGrid-MultiRoom-N4-S5-v0/18/initiation_set_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MiniGrid-MultiRoom-N4-S5-v0/18/value_function_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MiniGrid-MultiRoom-N4-S5-v0/18/accepted_events 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MiniGrid-MultiRoom-N4-S5-v0/18/rejected_events 
Creating classifier of type cnn
Creating rainbow with sigma=0.5
Created model-free option global-option with option_idx=0
[DSGTrainer] Adding new SalientEvent  SE([ 4 18])
[Seed=18] Device count: 1 Device Name: NVIDIA GeForce GTX 1080 Ti
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 0 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: 32.24438710231334
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.68488023430109
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 2 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -22.037777710473165
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 3 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -23.069377502659336
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 4 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -23.73651878896635
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 5 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -24.55134931035775
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 6 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -24.548186562606134
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 7 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -28.38450855296105
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 8 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -28.77176057640463
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 9 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -29.88993743591709
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 10 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -29.704754501290154
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 11 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -27.896683728438802
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 12 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -27.663995125563815
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 13 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -31.518884912133217
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 14 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -27.71533651810023
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 15 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -34.18835793621838
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 16 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -31.732683559974248
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 17 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -34.564766922965646
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 18 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -34.796647624112666
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 19 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -34.235854986240156
Accepted New Salient Event:  SE([10 15])
[DSGTrainer] Adding new SalientEvent  SE([10 15])
Took 3.877819538116455s to update distance table with 20040 states and events {SE([ 4 18]), None, SE([10 15])}
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 20 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -29.86775530705927
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 21 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -35.51581992348656
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 22 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -35.097193311259616
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 23 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.42079219222069
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 24 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -35.54109487426467
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 25 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -36.701380107784644
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 26 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -37.79927257215604
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 27 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -37.9329560212791
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 28 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.87240453995764
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 29 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.428463047370315
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 30 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.820697732269764
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 31 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.28111486695707
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 32 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.70906563248718
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 33 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -31.306031367217656
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 34 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -27.908886425720993
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 35 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -33.288227941753576
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 36 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.89423210080713
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 37 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -37.68618071638048
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 38 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.27076016133651
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 39 Step: 0
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.8172273254022
Accepted New Salient Event:  SE([10 16])
[DSGTrainer] Adding new SalientEvent  SE([10 16])
Took 4.279402256011963s to update distance table with 20040 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -34.19097547965066
Took 0.028565645217895508s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -22.31240238155806
Took 0.04474449157714844s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None, SE([10 15])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.11173876671819
Took 0.028348445892333984s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.84001311659813
Took 0.029191017150878906s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -35.953236060682684
Took 0.02761387825012207s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.79591692332178
Took 0.02791571617126465s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -37.24141462147236
Took 0.026053190231323242s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.281336914980784
Took 0.033780813217163086s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -36.35958127261256
Took 0.028467655181884766s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.57184033334488
Took 0.028889894485473633s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.5753866173327
Took 0.028530359268188477s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.911649361252785
Took 0.025680065155029297s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.77933848975226
Took 0.0298004150390625s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -42.64501065015793
Took 0.029898405075073242s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.20765842474066
Took 0.026381254196166992s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.6649710200727
Took 0.025354862213134766s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.79030868364498
Took 0.03232288360595703s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.53874057671055
Took 0.032975196838378906s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.5983622475178
Took 0.02657032012939453s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -42.40829785447568
Took 0.033360958099365234s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -18.023512572734035
Took 0.03733062744140625s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None, SE([10 15])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -36.30965849430504
Took 0.030974149703979492s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -44.4396175621514
Took 0.027979373931884766s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.44474821630865
Took 0.02697610855102539s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.70461924211122
Took 0.029130935668945312s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -35.816895660078444
Took 0.03084111213684082s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.064100672490895
Took 0.035504817962646484s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -41.32332715578377
Took 0.025476932525634766s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -41.22319374560175
Took 0.02857375144958496s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.644357555313036
Took 0.02679133415222168s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.58149711541864
Took 0.032257080078125s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None, SE([10 15])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -44.54909290606156
Took 0.031037569046020508s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -26.02870679051739
Took 0.027831315994262695s to update distance table with 1001 states and events {None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -44.651256291544996
Took 0.029767751693725586s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.9322747644037
Took 0.03461265563964844s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -34.27377702816739
Took 0.026960372924804688s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None, SE([10 15])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.52289720252156
Took 0.051955461502075195s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -44.12411502792747
Took 0.036138057708740234s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.91530161995615
Took 0.029572010040283203s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.82330185873434
Took 0.025422334671020508s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.19217145629227
Took 0.03790712356567383s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -41.99679442308843
Took 0.027792930603027344s to update distance table with 1001 states and events {SE([10 16]), SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.22864592121914
Took 0.035230159759521484s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -35.094964958036144
Took 0.026207447052001953s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.121177205001004
Took 0.037151336669921875s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.30603502690792
Took 0.018626689910888672s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.4350257711485
Took 0.025154829025268555s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -46.124441703315824
Took 0.04105663299560547s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -44.67876818496734
Took 0.03067612648010254s to update distance table with 1001 states and events {SE([ 4 18]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -46.365966144017875
Took 0.03732562065124512s to update distance table with 1001 states and events {SE([ 4 18]), None}
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 90 Step: 0
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[DeepSkillGraphsAgent] Creating chain from SE([ 4 18]) -> SE([10 16])
Creating classifier of type cnn
Created model-free option goal-option-1 with option_idx=1
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002961874008178711s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 91 Step: 120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002162933349609375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 92 Step: 240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002969980239868164s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 93 Step: 360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[DeepSkillGraphsAgent] Creating chain from SE([ 4 18]) -> SE([10 15])
Creating classifier of type cnn
Created model-free option goal-option-2 with option_idx=2
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.003061056137084961s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 94 Step: 480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0022749900817871094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 95 Step: 600
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0028219223022460938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 96 Step: 720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0035271644592285156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 97 Step: 840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0028352737426757812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 98 Step: 960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0028107166290283203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 99 Step: 1080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029680728912353516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 100 Step: 1200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003312826156616211s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 101 Step: 1320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0031032562255859375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 102 Step: 1440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0030028820037841797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 103 Step: 1560
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002788543701171875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 104 Step: 1680
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0030362606048583984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 105 Step: 1800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002474069595336914s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 106 Step: 1920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029342174530029297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 107 Step: 2040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029397010803222656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 108 Step: 2160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0022292137145996094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 109 Step: 2280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029020309448242188s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 110 Step: 2400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002974271774291992s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 111 Step: 2520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0022020339965820312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 112 Step: 2640
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029022693634033203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 113 Step: 2760
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002904176712036133s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 114 Step: 2880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003073453903198242s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 115 Step: 3000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0036039352416992188s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 116 Step: 3120
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002960205078125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 117 Step: 3240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0028977394104003906s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 118 Step: 3360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0028443336486816406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 119 Step: 3480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029528141021728516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 120 Step: 3600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0028603076934814453s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 121 Step: 3720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003009796142578125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 122 Step: 3840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029785633087158203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 123 Step: 3960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0030221939086914062s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 124 Step: 4080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029311180114746094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 125 Step: 4200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002946138381958008s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 126 Step: 4320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029497146606445312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 127 Step: 4440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029239654541015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 128 Step: 4560
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0032618045806884766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 129 Step: 4680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0034508705139160156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 130 Step: 4800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0033257007598876953s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 131 Step: 4920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0032682418823242188s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 132 Step: 5040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0033583641052246094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 133 Step: 5160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029189586639404297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 134 Step: 5280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0032536983489990234s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 135 Step: 5400
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003430604934692383s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 136 Step: 5520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003383636474609375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 137 Step: 5640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0031769275665283203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 138 Step: 5760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0032699108123779297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 139 Step: 5880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0035552978515625s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=140 Seed=18] Took 0.05522322654724121s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 140 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.462727033067495
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 141 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -42.91521046706475
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 142 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.05714778552647
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 143 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.08289906219579
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 144 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.21911549754441
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 145 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.94671299791662
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 146 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -38.895803071558475
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 147 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.58124022028642
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 148 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.1563408470829
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 149 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.88912860956043
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 150 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.768463503569365
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 151 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.67086638882756
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 152 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.98267505900003
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 153 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.98933614976704
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 154 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.76683370117098
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 155 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.629411708563566
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 156 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.25184680894017
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 157 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -46.409259243286215
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 158 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.72284411918372
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 159 Step: 6000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.29139907768695
Took 4.892225742340088s to update distance table with 20040 states and events {SE([10 16]), SE([ 4 18]), None}
[Episode=160 Seed=18] Took 0.06040835380554199s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 160 Step: 6000
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.002880096435546875s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 161 Step: 6120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0035915374755859375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 162 Step: 6240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003137826919555664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 163 Step: 6360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0023887157440185547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 164 Step: 6480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0033309459686279297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 165 Step: 6600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0032854080200195312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 166 Step: 6720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0025701522827148438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 167 Step: 6840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029501914978027344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 168 Step: 6960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.003213167190551758s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 169 Step: 7080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002245187759399414s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 170 Step: 7200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 120 transitions
Took 0.0029315948486328125s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.4836273193359375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 171 Step: 7320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002929210662841797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 172 Step: 7440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
goal-option-1 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.3685859291019313
Updated goal-option-1 on 88 transitions
Took 0.002465486526489258s to update distance table with 89 states and events {SE([10 16]), SE([ 4 18]), None}
DSG successfully reached SE([10 16])
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[DeepSkillGraphsAgent] Creating chain from SE([10 16]) -> SE([10 15])
Creating classifier of type cnn
Created model-free option goal-option-3 with option_idx=3
[Graph Consolidation] From (10, 16) to [10 15]
Revised planner goal vertex to SE([10 16]) and dsc goal vertex to SE([10 15])
Planner goal: SE([10 16]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [10 16] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 32 transitions
Took 0.0008442401885986328s to update distance table with 33 states and events {SE([10 16]), None}
================================================================================
[Consolidation] Episode: 173 Step: 7560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0031533241271972656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 174 Step: 7680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002360105514526367s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 175 Step: 7800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0033807754516601562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 176 Step: 7920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.710856251838246
Updated goal-option-1 on 120 transitions
Took 0.0029730796813964844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 177 Step: 8040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8193356915005188
Updated goal-option-1 on 120 transitions
Took 0.0031652450561523438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 178 Step: 8160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0030214786529541016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 179 Step: 8280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.8533890533221036
Updated goal-option-1 on 120 transitions
Took 0.0032050609588623047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 180 Step: 8400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0021953582763671875s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 181 Step: 8520
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0071972642089455
Updated goal-option-1 on 120 transitions
Took 0.0031180381774902344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 182 Step: 8640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002990245819091797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 183 Step: 8760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002465486526489258s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 184 Step: 8880
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.003326416015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 185 Step: 9000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.509337482390138
Updated goal-option-1 on 120 transitions
Took 0.0038080215454101562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 186 Step: 9120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002526998519897461s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 187 Step: 9240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.28515514969912
Updated goal-option-1 on 120 transitions
Took 0.0032188892364501953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 188 Step: 9360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3073627916420933
Updated goal-option-1 on 120 transitions
Took 0.0032160282135009766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 189 Step: 9480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002927064895629883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 190 Step: 9600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2006629673651443
Updated goal-option-1 on 120 transitions
Took 0.0034530162811279297s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.67572021484375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 191 Step: 9720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7925831785953479
Updated goal-option-1 on 120 transitions
Took 0.0034661293029785156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 192 Step: 9840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8655917716441213
Updated goal-option-1 on 120 transitions
Took 0.0034704208374023438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 193 Step: 9960
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8662434317804333
Updated goal-option-1 on 120 transitions
Took 0.003944873809814453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 194 Step: 10080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7347098429160255
Updated goal-option-1 on 120 transitions
Took 0.0032334327697753906s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 195 Step: 10200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029625892639160156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 196 Step: 10320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7945378364886204
Updated goal-option-1 on 120 transitions
Took 0.003159761428833008s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 197 Step: 10440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.823681759959704
Updated goal-option-1 on 120 transitions
Took 0.003122568130493164s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 198 Step: 10560
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.300123062212628
Updated goal-option-1 on 120 transitions
Took 0.003251791000366211s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 199 Step: 10680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.13818381591022
Updated goal-option-1 on 120 transitions
Took 0.005605220794677734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 200 Step: 10800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.5513999824964904
Updated goal-option-1 on 120 transitions
Took 0.0029611587524414062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 8.106231689453125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 201 Step: 10920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.651436507092842
Updated goal-option-1 on 120 transitions
Took 0.0030145645141601562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 202 Step: 11040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0032389163970947266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 203 Step: 11160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0033576488494873047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 204 Step: 11280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9927757259245067
Updated goal-option-1 on 120 transitions
Took 0.003507852554321289s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 205 Step: 11400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0028944015502929688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 206 Step: 11520
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6790670350469405
Updated goal-option-1 on 120 transitions
Took 0.003027200698852539s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 207 Step: 11640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029311180114746094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 208 Step: 11760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.592632366496694
Updated goal-option-1 on 120 transitions
Took 0.0037560462951660156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 209 Step: 11880
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4430185505649546
Updated goal-option-1 on 120 transitions
Took 0.003587961196899414s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=210 Seed=18] Took 0.06326580047607422s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 210 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -45.46892252238467
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 211 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.28774456772953
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 212 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.77270788571332
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 213 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.02674835367361
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 214 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.67630844004452
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 215 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.460192372091115
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 216 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.94036209688056
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 217 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.8495426196605
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 218 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.38274235196877
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 219 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.28667134261923
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 220 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.39330935571343
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 221 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.91465677879751
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 222 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.61374034918845
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 223 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.52374636428431
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 224 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.92609441280365
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 225 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.422878528013825
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 226 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.647817336022854
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 227 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.63070876524944
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 228 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.1560978917405
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 229 Step: 12000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.8843608146999
Took 5.463900089263916s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=230 Seed=18] Took 0.08080554008483887s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 230 Step: 12000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029137134552001953s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 231 Step: 12120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002999544143676758s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 232 Step: 12240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029735565185546875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 233 Step: 12360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9094885714617299
Updated goal-option-1 on 120 transitions
Took 0.002950429916381836s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 234 Step: 12480
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4900066518230568
Updated goal-option-1 on 120 transitions
Took 0.0031280517578125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 235 Step: 12600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0843760147938828
Updated goal-option-1 on 120 transitions
Took 0.0033478736877441406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 236 Step: 12720
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0024733543395996094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 237 Step: 12840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6272268060281145
Updated goal-option-1 on 120 transitions
Took 0.0029675960540771484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 238 Step: 12960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029935836791992188s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 239 Step: 13080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.970738756896336
Updated goal-option-1 on 120 transitions
Took 0.003821849822998047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 240 Step: 13200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002965688705444336s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 241 Step: 13320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.003175020217895508s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 242 Step: 13440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7354756604660109
Updated goal-option-1 on 120 transitions
Took 0.003114938735961914s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 243 Step: 13560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0029518604278564453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 244 Step: 13680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0031080245971679688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 245 Step: 13800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.935050195694567
Updated goal-option-1 on 120 transitions
Took 0.003262758255004883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 246 Step: 13920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7500178233055137
Updated goal-option-1 on 120 transitions
Took 0.003417491912841797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 247 Step: 14040
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.003313302993774414s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 248 Step: 14160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2225995569076047
Updated goal-option-1 on 120 transitions
Took 0.0031976699829101562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 249 Step: 14280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3062445525397623
Updated goal-option-1 on 120 transitions
Took 0.0030281543731689453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 250 Step: 14400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002963542938232422s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 251 Step: 14520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9718741650171445
Updated goal-option-1 on 120 transitions
Took 0.003047943115234375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 252 Step: 14640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7946638974185127
Updated goal-option-1 on 120 transitions
Took 0.003354310989379883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 253 Step: 14760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0173028206436805
Updated goal-option-1 on 120 transitions
Took 0.003286123275756836s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 254 Step: 14880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.002939939498901367s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 255 Step: 15000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9100511416755008
Updated goal-option-1 on 120 transitions
Took 0.002985239028930664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 256 Step: 15120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.247694940697672
Updated goal-option-1 on 120 transitions
Took 0.0031108856201171875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 257 Step: 15240
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.221968464548102
Updated goal-option-1 on 120 transitions
Took 0.0031480789184570312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 258 Step: 15360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.6215706775734784
Updated goal-option-1 on 120 transitions
Took 0.002962350845336914s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 259 Step: 15480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 120 transitions
Took 0.0022001266479492188s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 260 Step: 15600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3782284250469958
Updated goal-option-1 on 120 transitions
Took 0.0031447410583496094s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 261 Step: 15720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.38346481 0.61653519]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
goal-option-1 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6985787578629532
Updated goal-option-1 on 66 transitions
Took 0.0016696453094482422s to update distance table with 67 states and events {SE([10 16]), SE([ 4 18]), None}
DSG successfully reached SE([10 16])
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (10, 16) to [10 15]
Revised planner goal vertex to SE([10 16]) and dsc goal vertex to SE([10 15])
Planner goal: SE([10 16]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [10 16] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
goal-option-2 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.467754420890873
Updated goal-option-2 on 6 transitions
Took 0.00024700164794921875s to update distance table with 7 states and events {SE([10 16]), SE([10 15])}
DSG successfully reached SE([10 15])
[Random] Deep skill graphs target event: SE([ 4 18])
[Random] DSG selected event SE([ 4 18])
[DeepSkillGraphsAgent] Creating chain from SE([10 15]) -> SE([ 4 18])
Creating classifier of type cnn
Created model-free option goal-option-4 with option_idx=4
[Graph Consolidation] From (10, 15) to [ 4 18]
Revised planner goal vertex to SE([10 15]) and dsc goal vertex to SE([ 4 18])
Planner goal: SE([10 15]), DSC goal: SE([ 4 18]) and Goal: SE([ 4 18])
False
False
Rolling out DSC with goal vertex SE([ 4 18])
Rolling out goal-option-4, from [10 15] targeting {'player_x': 4, 'player_y': 18, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 48 transitions
Took 0.0013666152954101562s to update distance table with 49 states and events {None, SE([10 15])}
================================================================================
[Consolidation] Episode: 262 Step: 15840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.935311981359872
Updated goal-option-1 on 120 transitions
Took 0.003281831741333008s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 263 Step: 15960
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4584402264024714
Updated goal-option-1 on 120 transitions
Took 0.003306865692138672s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 264 Step: 16080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9649298011547043
Updated goal-option-1 on 120 transitions
Took 0.0031735897064208984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 265 Step: 16200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.905114275358972
Updated goal-option-2 on 120 transitions
Took 0.003181934356689453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 266 Step: 16320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5071657750639549
Updated goal-option-1 on 120 transitions
Took 0.0033409595489501953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 267 Step: 16440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4770349826637679
Updated goal-option-1 on 120 transitions
Took 0.0032656192779541016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 268 Step: 16560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5741758276541782
Updated goal-option-1 on 120 transitions
Took 0.0029990673065185547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 269 Step: 16680
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.197122094610957
Updated goal-option-1 on 120 transitions
Took 0.0029480457305908203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 270 Step: 16800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.059471350359108
Updated goal-option-1 on 120 transitions
Took 0.0031728744506835938s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 2.1219253540039062e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 271 Step: 16920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.502479407454141
Updated goal-option-1 on 120 transitions
Took 0.003103971481323242s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 272 Step: 17040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1828110164549661
Updated goal-option-1 on 120 transitions
Took 0.003132343292236328s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 273 Step: 17160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.858097725021209
Updated goal-option-2 on 120 transitions
Took 0.003116607666015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 274 Step: 17280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.593967929676708
Updated goal-option-1 on 120 transitions
Took 0.0031332969665527344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 275 Step: 17400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9564769390097223
Updated goal-option-2 on 120 transitions
Took 0.003045797348022461s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 276 Step: 17520
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6093111765220378
Updated goal-option-1 on 120 transitions
Took 0.0035202503204345703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 277 Step: 17640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.167035899510362
Updated goal-option-2 on 120 transitions
Took 0.0028641223907470703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 278 Step: 17760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3802878258796045
Updated goal-option-1 on 120 transitions
Took 0.003987312316894531s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 279 Step: 17880
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.18124107667245
Updated goal-option-2 on 120 transitions
Took 0.002902507781982422s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=280 Seed=18] Took 0.009044170379638672s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 280 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.80832965299487
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 281 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.97332521213684
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 282 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -46.307575807964895
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 283 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -43.665353829739615
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 284 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.9217215757817
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 285 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.673446564003825
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 286 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.68502392247319
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 287 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.0773592448968
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 288 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.765172329120105
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 289 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.26157179661095
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 290 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.18648604070768
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 291 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.40526322182268
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 292 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -41.38504090045171
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 293 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.67191086837556
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 294 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.791669661179185
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 295 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.823606772813946
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 296 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.30808843160048
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 297 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.91092336177826
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 298 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -44.23424600198632
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 299 Step: 18000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.82194123300724
Took 6.4585864543914795s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=300 Seed=18] Took 0.0676720142364502s to save gc logs
Enter Visualization
[]
[SE([10 15]), SE([10 16])]
PLOTS
[]
[]
PLOTS2
[10, 10]
[1, 1]
END UTILS
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 300 Step: 18000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3584826714553266
Updated goal-option-1 on 120 transitions
Took 0.0035715103149414062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.4373016357421875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 301 Step: 18120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6813825313012762
Updated goal-option-1 on 120 transitions
Took 0.0029859542846679688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 302 Step: 18240
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
goal-option-1 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.566402856383566
Updated goal-option-1 on 93 transitions
Took 0.0027565956115722656s to update distance table with 94 states and events {SE([10 16]), SE([ 4 18]), None}
DSG successfully reached SE([10 16])
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (10, 16) to [10 15]
Revised planner goal vertex to SE([10 16]) and dsc goal vertex to SE([10 15])
Planner goal: SE([10 16]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [10 16] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.641989168134472
Updated goal-option-2 on 27 transitions
Took 0.0007598400115966797s to update distance table with 28 states and events {SE([10 16]), None}
================================================================================
[Consolidation] Episode: 303 Step: 18360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.068149106128008
Updated goal-option-2 on 120 transitions
Took 0.002918720245361328s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 304 Step: 18480
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.360067655822751
Updated goal-option-1 on 120 transitions
Took 0.00426483154296875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 305 Step: 18600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9875545255574321
Updated goal-option-1 on 120 transitions
Took 0.003181934356689453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 306 Step: 18720
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
14.147049898074734
Updated goal-option-2 on 120 transitions
Took 0.002851247787475586s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 307 Step: 18840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6268751912358963
Updated goal-option-1 on 120 transitions
Took 0.0036144256591796875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 308 Step: 18960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4481508561022378
Updated goal-option-1 on 120 transitions
Took 0.0037004947662353516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 309 Step: 19080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2306403247390738
Updated goal-option-1 on 120 transitions
Took 0.0034415721893310547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 310 Step: 19200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.902503662742674
Updated goal-option-2 on 120 transitions
Took 0.0029969215393066406s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.67572021484375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 311 Step: 19320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3897716838523688
Updated goal-option-1 on 120 transitions
Took 0.003323793411254883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 312 Step: 19440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3611720380388348
Updated goal-option-1 on 120 transitions
Took 0.0034499168395996094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 313 Step: 19560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
14.757118907712753
Updated goal-option-2 on 120 transitions
Took 0.003040790557861328s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 314 Step: 19680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4421814180581531
Updated goal-option-1 on 120 transitions
Took 0.0034639835357666016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 315 Step: 19800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2290137014634548
Updated goal-option-1 on 120 transitions
Took 0.0032606124877929688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 316 Step: 19920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2310795541300479
Updated goal-option-1 on 120 transitions
Took 0.0033102035522460938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 317 Step: 20040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9817843782597414
Updated goal-option-1 on 120 transitions
Took 0.0033311843872070312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 318 Step: 20160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1605661677118353
Updated goal-option-1 on 120 transitions
Took 0.004465579986572266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 319 Step: 20280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.638244028668851
Updated goal-option-2 on 120 transitions
Took 0.0028579235076904297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 320 Step: 20400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2821614111895092
Updated goal-option-1 on 120 transitions
Took 0.003570556640625s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.9604644775390625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 321 Step: 20520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.86371338606945
Updated goal-option-2 on 120 transitions
Took 0.0028603076934814453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 322 Step: 20640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.201747813505962
Updated goal-option-2 on 120 transitions
Took 0.002989530563354492s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 323 Step: 20760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.257022333462721
Updated goal-option-1 on 120 transitions
Took 0.0033233165740966797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 324 Step: 20880
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2655488873061576
Updated goal-option-1 on 120 transitions
Took 0.0035452842712402344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 325 Step: 21000
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.869187815735737
Updated goal-option-2 on 120 transitions
Took 0.0029554367065429688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 326 Step: 21120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9502292112558197
Updated goal-option-2 on 120 transitions
Took 0.0029549598693847656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 327 Step: 21240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0875281679146716
Updated goal-option-1 on 120 transitions
Took 0.0035114288330078125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 328 Step: 21360
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.403811628797225
Updated goal-option-2 on 120 transitions
Took 0.0033321380615234375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 329 Step: 21480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.10478959521944
Updated goal-option-2 on 120 transitions
Took 0.0030317306518554688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 330 Step: 21600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.225189259349247
Updated goal-option-2 on 120 transitions
Took 0.0028769969940185547s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 331 Step: 21720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1219906816451186
Updated goal-option-1 on 120 transitions
Took 0.003172636032104492s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 332 Step: 21840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4672517885863614
Updated goal-option-1 on 120 transitions
Took 0.0032334327697753906s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 333 Step: 21960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.554336325142642
Updated goal-option-2 on 120 transitions
Took 0.0033752918243408203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 334 Step: 22080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
goal-option-1 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3428289115980732
Updated goal-option-1 on 108 transitions
Took 0.0031647682189941406s to update distance table with 109 states and events {SE([10 16]), SE([ 4 18]), None}
DSG successfully reached SE([10 16])
Unconnected Events: [SE([ 4 18]), SE([10 15])] | Probs: [[2.08598118e-21 1.00000000e+00]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (10, 16) to [10 15]
Revised planner goal vertex to SE([10 16]) and dsc goal vertex to SE([10 15])
Planner goal: SE([10 16]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [10 16] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.665559174049469
Updated goal-option-2 on 12 transitions
Took 0.0004944801330566406s to update distance table with 13 states and events {SE([10 16])}
================================================================================
[Consolidation] Episode: 335 Step: 22200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.757160314137026
Updated goal-option-2 on 120 transitions
Took 0.0032472610473632812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 336 Step: 22320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.395146970947583
Updated goal-option-2 on 120 transitions
Took 0.003245115280151367s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 337 Step: 22440
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.039091780080828
Updated goal-option-2 on 120 transitions
Took 0.002918720245361328s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 338 Step: 22560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.5607966869359924
Updated goal-option-2 on 120 transitions
Took 0.0031495094299316406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 339 Step: 22680
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0657663952125689
Updated goal-option-1 on 120 transitions
Took 0.0036001205444335938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 340 Step: 22800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.798723860998595
Updated goal-option-2 on 120 transitions
Took 0.0029306411743164062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 341 Step: 22920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.043027767452409
Updated goal-option-1 on 120 transitions
Took 0.003942251205444336s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 342 Step: 23040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.415462677190261
Updated goal-option-1 on 120 transitions
Took 0.003474712371826172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 343 Step: 23160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3370916844429308
Updated goal-option-1 on 120 transitions
Took 0.003582477569580078s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 344 Step: 23280
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.399882879551678
Updated goal-option-2 on 120 transitions
Took 0.0029871463775634766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 345 Step: 23400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.947049818389381
Updated goal-option-1 on 120 transitions
Took 0.0036106109619140625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 346 Step: 23520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.147095750782236
Updated goal-option-1 on 120 transitions
Took 0.003231048583984375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 347 Step: 23640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.269777607460994
Updated goal-option-2 on 120 transitions
Took 0.002895355224609375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 348 Step: 23760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0834142710566521
Updated goal-option-1 on 120 transitions
Took 0.0034034252166748047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 349 Step: 23880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7739237241579938
Updated goal-option-1 on 120 transitions
Took 0.0036661624908447266s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=350 Seed=18] Took 0.012984752655029297s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 350 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.42504625953734
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 351 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.14164797589183
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 352 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.84077308035921
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 353 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.735654019750655
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 354 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.84946107817814
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 355 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.843471786007285
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 356 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.71595651470125
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 357 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.880396477121394
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 358 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.48080015426967
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 359 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.69473802018911
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 360 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.92846561665647
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 361 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.82207146828296
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 362 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.636381399817765
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 363 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.41468862904003
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 364 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.19858372025192
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 365 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.56281438842416
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 366 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.212964047444984
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 367 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.27968816680368
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 368 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -39.823814495350234
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 369 Step: 24000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.93490062467754
Took 5.903761625289917s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=370 Seed=18] Took 0.11821794509887695s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 370 Step: 24000
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.14022722299255
Updated goal-option-2 on 120 transitions
Took 0.0033931732177734375s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 371 Step: 24120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.154401393252469
Updated goal-option-2 on 120 transitions
Took 0.003345489501953125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 372 Step: 24240
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.5556963993464406
Updated goal-option-2 on 120 transitions
Took 0.003231525421142578s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 373 Step: 24360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.040876353026458
Updated goal-option-1 on 120 transitions
Took 0.003064393997192383s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 374 Step: 24480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.324302913465848
Updated goal-option-2 on 120 transitions
Took 0.0033593177795410156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 375 Step: 24600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0855183542845925
Updated goal-option-1 on 120 transitions
Took 0.002896547317504883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 376 Step: 24720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.220467782867478
Updated goal-option-1 on 120 transitions
Took 0.003003835678100586s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 377 Step: 24840
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.607039305071036
Updated goal-option-2 on 120 transitions
Took 0.003164529800415039s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 378 Step: 24960
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4671524796500426
Updated goal-option-1 on 120 transitions
Took 0.0034482479095458984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 379 Step: 25080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9503232880724674
Updated goal-option-1 on 120 transitions
Took 0.0029637813568115234s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 380 Step: 25200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4967862244013281
Updated goal-option-1 on 120 transitions
Took 0.0033512115478515625s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.67572021484375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 381 Step: 25320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9007649804266403
Updated goal-option-1 on 120 transitions
Took 0.0035195350646972656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 382 Step: 25440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.057059606366871
Updated goal-option-1 on 120 transitions
Took 0.0035300254821777344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 383 Step: 25560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.834964541531008
Updated goal-option-2 on 120 transitions
Took 0.0029036998748779297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 384 Step: 25680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0424843293609705
Updated goal-option-1 on 120 transitions
Took 0.0034422874450683594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 385 Step: 25800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.724856904475018
Updated goal-option-2 on 120 transitions
Took 0.002839326858520508s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 386 Step: 25920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9163450221578809
Updated goal-option-1 on 120 transitions
Took 0.003473520278930664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 387 Step: 26040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.083133427458034
Updated goal-option-1 on 120 transitions
Took 0.0034868717193603516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 388 Step: 26160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.950548029194275
Updated goal-option-2 on 120 transitions
Took 0.0030024051666259766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 389 Step: 26280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.9563053175807
Updated goal-option-2 on 120 transitions
Took 0.002889394760131836s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 390 Step: 26400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7407240338726265
Updated goal-option-1 on 120 transitions
Took 0.0037093162536621094s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.9141387939453125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 391 Step: 26520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.681667801613609
Updated goal-option-2 on 120 transitions
Took 0.0030870437622070312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 392 Step: 26640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.761581857999166
Updated goal-option-2 on 120 transitions
Took 0.002943277359008789s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 393 Step: 26760
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.136091345133969
Updated goal-option-2 on 120 transitions
Took 0.00313568115234375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 394 Step: 26880
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3990934542780895
Updated goal-option-1 on 120 transitions
Took 0.003385782241821289s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 395 Step: 27000
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1530590194115924
Updated goal-option-1 on 120 transitions
Took 0.003226041793823242s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 396 Step: 27120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1028512767630752
Updated goal-option-1 on 120 transitions
Took 0.003312826156616211s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 397 Step: 27240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.956416896253359
Updated goal-option-2 on 120 transitions
Took 0.0029382705688476562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 398 Step: 27360
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.211999378477534
Updated goal-option-2 on 120 transitions
Took 0.002960205078125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 399 Step: 27480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.637429669427332
Updated goal-option-2 on 120 transitions
Took 0.002902507781982422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 400 Step: 27600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8757436287708131
Updated goal-option-1 on 120 transitions
Took 0.003458261489868164s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 2.3126602172851562e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 401 Step: 27720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.134379377575147
Updated goal-option-1 on 120 transitions
Took 0.0031757354736328125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 402 Step: 27840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.087795303072259
Updated goal-option-1 on 120 transitions
Took 0.0034482479095458984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 403 Step: 27960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9789354985990882
Updated goal-option-1 on 120 transitions
Took 0.0031592845916748047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 404 Step: 28080
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.047751062549651
Updated goal-option-2 on 120 transitions
Took 0.003050565719604492s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 405 Step: 28200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.951957924380189
Updated goal-option-2 on 120 transitions
Took 0.002938508987426758s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 406 Step: 28320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.855213121976703
Updated goal-option-2 on 120 transitions
Took 0.003029346466064453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 407 Step: 28440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7633705277342114
Updated goal-option-1 on 120 transitions
Took 0.0031642913818359375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 408 Step: 28560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.500697416696875
Updated goal-option-2 on 120 transitions
Took 0.003446817398071289s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 409 Step: 28680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.272228282565872
Updated goal-option-2 on 120 transitions
Took 0.0029702186584472656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 410 Step: 28800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.165023236024665
Updated goal-option-1 on 120 transitions
Took 0.0031900405883789062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.4836273193359375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 411 Step: 28920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9409525497428914
Updated goal-option-1 on 120 transitions
Took 0.003134489059448242s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 412 Step: 29040
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.018997228890102
Updated goal-option-2 on 120 transitions
Took 0.0029714107513427734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 413 Step: 29160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.048905203656648
Updated goal-option-2 on 120 transitions
Took 0.002989053726196289s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 414 Step: 29280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9560874173797562
Updated goal-option-1 on 120 transitions
Took 0.0034325122833251953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 415 Step: 29400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9691102243774234
Updated goal-option-1 on 120 transitions
Took 0.0033342838287353516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 416 Step: 29520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.62371434768041
Updated goal-option-2 on 120 transitions
Took 0.002938985824584961s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 417 Step: 29640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.8805461686376175
Updated goal-option-2 on 120 transitions
Took 0.002841949462890625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 418 Step: 29760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0868519171276707
Updated goal-option-1 on 120 transitions
Took 0.0034999847412109375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 419 Step: 29880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.467244842400154
Updated goal-option-2 on 120 transitions
Took 0.002961874008178711s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=420 Seed=18] Took 0.0796515941619873s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 420 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.527747803134844
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 421 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -49.15104091865942
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 422 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.436162640340626
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 423 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.430661580991
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 424 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -40.641771293572674
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 425 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.751134369987994
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 426 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.085105647624005
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 427 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.45973488385789
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 428 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.83802364394069
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 429 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -53.77487226840276
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 430 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.82383317872882
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 431 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.93085558153689
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 432 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.66086128388997
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 433 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.793783489149064
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 434 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.76731779798865
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 435 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.88360273126091
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 436 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.19956302456558
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 437 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.29757891409099
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 438 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.1721770549193
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 439 Step: 30000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.72111100656912
Took 7.668782949447632s to update distance table with 20040 states and events {SE([10 16]), SE([ 4 18]), None}
[Episode=440 Seed=18] Took 0.06757831573486328s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 440 Step: 30000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7922322419297189
Updated goal-option-1 on 120 transitions
Took 0.0032236576080322266s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 441 Step: 30120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.225194697268307
Updated goal-option-2 on 120 transitions
Took 0.0029392242431640625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 442 Step: 30240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2819680836316885
Updated goal-option-1 on 120 transitions
Took 0.0031790733337402344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 443 Step: 30360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.051664000709832
Updated goal-option-1 on 120 transitions
Took 0.003220796585083008s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 444 Step: 30480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
13.496786497954632
Updated goal-option-2 on 120 transitions
Took 0.0029587745666503906s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 445 Step: 30600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9427542595525957
Updated goal-option-1 on 120 transitions
Took 0.0033388137817382812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 446 Step: 30720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
13.93774106300303
Updated goal-option-2 on 120 transitions
Took 0.0029883384704589844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 447 Step: 30840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9876718313621446
Updated goal-option-1 on 120 transitions
Took 0.003779888153076172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 448 Step: 30960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.949460941050867
Updated goal-option-2 on 120 transitions
Took 0.0029296875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 449 Step: 31080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7503985343972852
Updated goal-option-1 on 120 transitions
Took 0.0031981468200683594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 450 Step: 31200
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.440098903010949
Updated goal-option-2 on 120 transitions
Took 0.003423452377319336s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 451 Step: 31320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9399380735271462
Updated goal-option-1 on 120 transitions
Took 0.0032765865325927734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 452 Step: 31440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9574968212760048
Updated goal-option-1 on 120 transitions
Took 0.003171205520629883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 453 Step: 31560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.128578517001999
Updated goal-option-1 on 120 transitions
Took 0.0032913684844970703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 454 Step: 31680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0662831717997159
Updated goal-option-1 on 120 transitions
Took 0.0031881332397460938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 455 Step: 31800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9258525108714993
Updated goal-option-1 on 120 transitions
Took 0.0032248497009277344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 456 Step: 31920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9636334734372142
Updated goal-option-1 on 120 transitions
Took 0.0033240318298339844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 457 Step: 32040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0099065721272082
Updated goal-option-1 on 120 transitions
Took 0.003462553024291992s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 458 Step: 32160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.132536043723425
Updated goal-option-2 on 120 transitions
Took 0.0029981136322021484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 459 Step: 32280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1396781870294785
Updated goal-option-1 on 120 transitions
Took 0.002973318099975586s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 460 Step: 32400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.295065032229537
Updated goal-option-2 on 120 transitions
Took 0.0030164718627929688s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 461 Step: 32520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.5356364224571735
Updated goal-option-2 on 120 transitions
Took 0.002911806106567383s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 462 Step: 32640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0773592219060468
Updated goal-option-1 on 120 transitions
Took 0.0032553672790527344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 463 Step: 32760
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.750526162213646
Updated goal-option-2 on 120 transitions
Took 0.0031173229217529297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 464 Step: 32880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9202983371722757
Updated goal-option-1 on 120 transitions
Took 0.003726482391357422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 465 Step: 33000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.079384684007186
Updated goal-option-1 on 120 transitions
Took 0.0032644271850585938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 466 Step: 33120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.572905209795054
Updated goal-option-2 on 120 transitions
Took 0.0035991668701171875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 467 Step: 33240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.852000586921349
Updated goal-option-2 on 120 transitions
Took 0.002933979034423828s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 468 Step: 33360
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
13.22028641651074
Updated goal-option-2 on 120 transitions
Took 0.0029404163360595703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 469 Step: 33480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9159431083162698
Updated goal-option-1 on 120 transitions
Took 0.003556966781616211s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 470 Step: 33600
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.415851929535468
Updated goal-option-2 on 120 transitions
Took 0.0029633045196533203s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 471 Step: 33720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8858005510135071
Updated goal-option-1 on 120 transitions
Took 0.003165721893310547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 472 Step: 33840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
16.556154378689826
Updated goal-option-2 on 120 transitions
Took 0.0029287338256835938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 473 Step: 33960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.304563589394093
Updated goal-option-2 on 120 transitions
Took 0.0028905868530273438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 474 Step: 34080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.932835128138958
Updated goal-option-1 on 120 transitions
Took 0.0036437511444091797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 475 Step: 34200
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.982460035049977
Updated goal-option-2 on 120 transitions
Took 0.0032808780670166016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 476 Step: 34320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1836974943373044
Updated goal-option-1 on 120 transitions
Took 0.00380706787109375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 477 Step: 34440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9070538588004594
Updated goal-option-1 on 120 transitions
Took 0.0037457942962646484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 478 Step: 34560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9370652932246256
Updated goal-option-1 on 120 transitions
Took 0.003211498260498047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 479 Step: 34680
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8270559554327321
Updated goal-option-1 on 120 transitions
Took 0.0031120777130126953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 480 Step: 34800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.070825596617546
Updated goal-option-1 on 120 transitions
Took 0.0030050277709960938s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 481 Step: 34920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0623179407238181
Updated goal-option-1 on 120 transitions
Took 0.0031266212463378906s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 482 Step: 35040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2115899766155285
Updated goal-option-1 on 120 transitions
Took 0.003316164016723633s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 483 Step: 35160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.896551454351062
Updated goal-option-2 on 120 transitions
Took 0.0033881664276123047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 484 Step: 35280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1641812813651176
Updated goal-option-1 on 120 transitions
Took 0.0032134056091308594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 485 Step: 35400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0258696867056296
Updated goal-option-1 on 120 transitions
Took 0.0031719207763671875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 486 Step: 35520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.566774669098474
Updated goal-option-2 on 120 transitions
Took 0.0034155845642089844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 487 Step: 35640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2041856813597929
Updated goal-option-1 on 120 transitions
Took 0.0028905868530273438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 488 Step: 35760
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.699567890027538
Updated goal-option-2 on 120 transitions
Took 0.003016948699951172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 489 Step: 35880
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0837111553282774
Updated goal-option-1 on 120 transitions
Took 0.003084421157836914s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=490 Seed=18] Took 0.008311748504638672s to save gc logs
Enter Visualization
[]
[SE([10 15]), SE([10 16])]
PLOTS
[]
[]
PLOTS2
[10, 10]
[1, 1]
END UTILS
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 490 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.29367381648626
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 491 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.450517115183175
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 492 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.04417831450701
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 493 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.2652984559536
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 494 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.189236868638545
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 495 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.746734108775854
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 496 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.04589512888924
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 497 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.97600834816694
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 498 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.92081523220986
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 499 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.150180604308844
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 500 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -48.89703121967614
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 501 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.52030155051034
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 502 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.63633312494494
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 503 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.302196899428964
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 504 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -50.50120439089369
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 505 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.66803403566155
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 506 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.02976671233773
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 507 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.71630287915468
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 508 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.36730559542775
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 509 Step: 36000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.7282814514474
Took 8.680856704711914s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=510 Seed=18] Took 0.07729840278625488s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 510 Step: 36000
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7790836227621597
Updated goal-option-1 on 120 transitions
Took 0.003179788589477539s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 511 Step: 36120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1055884807845067
Updated goal-option-1 on 120 transitions
Took 0.0030405521392822266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 512 Step: 36240
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.91608269753245
Updated goal-option-2 on 120 transitions
Took 0.002963542938232422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 513 Step: 36360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.263812728058112
Updated goal-option-1 on 120 transitions
Took 0.003239154815673828s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 514 Step: 36480
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.344471362803038
Updated goal-option-1 on 120 transitions
Took 0.003579854965209961s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 515 Step: 36600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1479273606211897
Updated goal-option-1 on 120 transitions
Took 0.0029659271240234375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 516 Step: 36720
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.716819737904839
Updated goal-option-2 on 120 transitions
Took 0.003101348876953125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 517 Step: 36840
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.91809931366394
Updated goal-option-2 on 120 transitions
Took 0.002839803695678711s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 518 Step: 36960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.555824847891927
Updated goal-option-2 on 120 transitions
Took 0.0032091140747070312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 519 Step: 37080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2012536084450207
Updated goal-option-1 on 120 transitions
Took 0.0031838417053222656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 520 Step: 37200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.163247619529144
Updated goal-option-1 on 120 transitions
Took 0.0032320022583007812s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 521 Step: 37320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9211022377436149
Updated goal-option-1 on 120 transitions
Took 0.0031664371490478516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 522 Step: 37440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1283117248889247
Updated goal-option-1 on 120 transitions
Took 0.0031719207763671875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 523 Step: 37560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.002665462571064
Updated goal-option-2 on 120 transitions
Took 0.002932310104370117s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 524 Step: 37680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0245451649966468
Updated goal-option-1 on 120 transitions
Took 0.0033164024353027344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 525 Step: 37800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8746137051726315
Updated goal-option-1 on 120 transitions
Took 0.0032012462615966797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 526 Step: 37920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0734438274627283
Updated goal-option-1 on 120 transitions
Took 0.0032417774200439453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 527 Step: 38040
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2020282528495674
Updated goal-option-1 on 120 transitions
Took 0.0035860538482666016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 528 Step: 38160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7909720495907503
Updated goal-option-1 on 120 transitions
Took 0.0032744407653808594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 529 Step: 38280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8413411878202034
Updated goal-option-1 on 120 transitions
Took 0.0031669139862060547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 530 Step: 38400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.229495144386549
Updated goal-option-1 on 120 transitions
Took 0.0035331249237060547s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 531 Step: 38520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.059642011673539
Updated goal-option-1 on 120 transitions
Took 0.0034172534942626953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 532 Step: 38640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.2296172438266995
Updated goal-option-2 on 120 transitions
Took 0.0028896331787109375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 533 Step: 38760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.4098364583527045
Updated goal-option-2 on 120 transitions
Took 0.003039836883544922s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 534 Step: 38880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0839253260701531
Updated goal-option-1 on 120 transitions
Took 0.0032596588134765625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 535 Step: 39000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2136946156235886
Updated goal-option-1 on 120 transitions
Took 0.0034399032592773438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 536 Step: 39120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8761768128412464
Updated goal-option-2 on 120 transitions
Took 0.002935647964477539s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 537 Step: 39240
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.119185714414816
Updated goal-option-1 on 120 transitions
Took 0.003543376922607422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 538 Step: 39360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9608487806270719
Updated goal-option-1 on 120 transitions
Took 0.0029726028442382812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 539 Step: 39480
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.085284217286097
Updated goal-option-1 on 120 transitions
Took 0.0030486583709716797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 540 Step: 39600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0813840829064656
Updated goal-option-1 on 120 transitions
Took 0.00408935546875s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 7.62939453125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 541 Step: 39720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.160489287966197
Updated goal-option-1 on 120 transitions
Took 0.003595113754272461s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 542 Step: 39840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.218720741531191
Updated goal-option-2 on 120 transitions
Took 0.0030345916748046875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 543 Step: 39960
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9716647483328367
Updated goal-option-1 on 120 transitions
Took 0.002991914749145508s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 544 Step: 40080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0331486035193242
Updated goal-option-1 on 120 transitions
Took 0.0032491683959960938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 545 Step: 40200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2425035201790942
Updated goal-option-1 on 120 transitions
Took 0.0037059783935546875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 546 Step: 40320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0748236202831376
Updated goal-option-1 on 120 transitions
Took 0.002864360809326172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 547 Step: 40440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.933842814944761
Updated goal-option-1 on 120 transitions
Took 0.0032324790954589844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 548 Step: 40560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8893254031223812
Updated goal-option-1 on 120 transitions
Took 0.0029604434967041016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 549 Step: 40680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8484321793862996
Updated goal-option-1 on 120 transitions
Took 0.0032155513763427734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 550 Step: 40800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9234458230278776
Updated goal-option-1 on 120 transitions
Took 0.0034644603729248047s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.9604644775390625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 551 Step: 40920
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.876209577634221
Updated goal-option-2 on 120 transitions
Took 0.0030455589294433594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 552 Step: 41040
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.533106335643727
Updated goal-option-2 on 120 transitions
Took 0.0029973983764648438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 553 Step: 41160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0917699545749904
Updated goal-option-1 on 120 transitions
Took 0.002869129180908203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 554 Step: 41280
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.884599142397444
Updated goal-option-2 on 120 transitions
Took 0.002987384796142578s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 555 Step: 41400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1099080905159904
Updated goal-option-1 on 120 transitions
Took 0.0029883384704589844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 556 Step: 41520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8181469575708018
Updated goal-option-1 on 120 transitions
Took 0.0031957626342773438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 557 Step: 41640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9177170082811191
Updated goal-option-1 on 120 transitions
Took 0.0032188892364501953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 558 Step: 41760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9474409431295238
Updated goal-option-1 on 120 transitions
Took 0.003229379653930664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 559 Step: 41880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9486413934648344
Updated goal-option-1 on 120 transitions
Took 0.0032012462615966797s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=560 Seed=18] Took 0.058380842208862305s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 560 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -52.134735006373376
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 561 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.33585074818984
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 562 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.81898767314851
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 563 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.48002249374986
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 564 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.28424031659961
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 565 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.57280335796531
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 566 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.99966349452734
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 567 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.07178644297528
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 568 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.923885544762015
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 569 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.77313151373528
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 570 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.29467442724854
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 571 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.793975102715194
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 572 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.39118685363792
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 573 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.95440708100796
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 574 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.917584917042404
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 575 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.295821758540114
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 576 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.42397215589881
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 577 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.2367995667737
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 578 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.7047333009541
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 579 Step: 42000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.82874446443748
Took 13.393520832061768s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=580 Seed=18] Took 0.0906534194946289s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 580 Step: 42000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0135602002839093
Updated goal-option-1 on 120 transitions
Took 0.0028181076049804688s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 581 Step: 42120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.389619259784618
Updated goal-option-2 on 120 transitions
Took 0.0029752254486083984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 582 Step: 42240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0957378333274035
Updated goal-option-1 on 120 transitions
Took 0.002904653549194336s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 583 Step: 42360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9372325317090837
Updated goal-option-1 on 120 transitions
Took 0.0031692981719970703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 584 Step: 42480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.990474634027729
Updated goal-option-2 on 120 transitions
Took 0.0029726028442382812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 585 Step: 42600
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.763744832816883
Updated goal-option-2 on 120 transitions
Took 0.0028960704803466797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 586 Step: 42720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9870494133660568
Updated goal-option-1 on 120 transitions
Took 0.0029175281524658203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 587 Step: 42840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2675020522901674
Updated goal-option-1 on 120 transitions
Took 0.00287628173828125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 588 Step: 42960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.28852383703703
Updated goal-option-2 on 120 transitions
Took 0.002930164337158203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 589 Step: 43080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.100810527892527
Updated goal-option-1 on 120 transitions
Took 0.003194093704223633s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 590 Step: 43200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3366494024368034
Updated goal-option-1 on 120 transitions
Took 0.003238201141357422s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 591 Step: 43320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.103228261694312
Updated goal-option-2 on 120 transitions
Took 0.0028541088104248047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 592 Step: 43440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.16908176553746
Updated goal-option-2 on 120 transitions
Took 0.0029408931732177734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 593 Step: 43560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.599525953943763
Updated goal-option-2 on 120 transitions
Took 0.0028905868530273438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 594 Step: 43680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8133173108372557
Updated goal-option-1 on 120 transitions
Took 0.0031175613403320312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 595 Step: 43800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.004774282949495
Updated goal-option-1 on 120 transitions
Took 0.002917051315307617s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 596 Step: 43920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0578265299618146
Updated goal-option-1 on 120 transitions
Took 0.003123760223388672s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 597 Step: 44040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.07062200953563
Updated goal-option-2 on 120 transitions
Took 0.0028634071350097656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 598 Step: 44160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0585834870945359
Updated goal-option-1 on 120 transitions
Took 0.002899646759033203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 599 Step: 44280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9682604550713648
Updated goal-option-1 on 120 transitions
Took 0.0032091140747070312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 600 Step: 44400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.26599977677688
Updated goal-option-2 on 120 transitions
Took 0.0029587745666503906s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 601 Step: 44520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8521501488527069
Updated goal-option-1 on 120 transitions
Took 0.002896547317504883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 602 Step: 44640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
12.27960777313759
Updated goal-option-2 on 120 transitions
Took 0.002983570098876953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 603 Step: 44760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8269215233310997
Updated goal-option-1 on 120 transitions
Took 0.0030553340911865234s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 604 Step: 44880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.927824651268089
Updated goal-option-2 on 120 transitions
Took 0.0029566287994384766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 605 Step: 45000
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.726516117108986
Updated goal-option-2 on 120 transitions
Took 0.003107309341430664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 606 Step: 45120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.138743521645665
Updated goal-option-2 on 120 transitions
Took 0.0029528141021728516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 607 Step: 45240
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.678816933717046
Updated goal-option-2 on 120 transitions
Took 0.0030298233032226562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 608 Step: 45360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.638112697478694
Updated goal-option-2 on 120 transitions
Took 0.0029990673065185547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 609 Step: 45480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.195326294060849
Updated goal-option-1 on 120 transitions
Took 0.0030639171600341797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 610 Step: 45600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8879981189551581
Updated goal-option-1 on 120 transitions
Took 0.0034203529357910156s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 2.0742416381835938e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 611 Step: 45720
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.465173562190362
Updated goal-option-2 on 120 transitions
Took 0.003281116485595703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 612 Step: 45840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0947680915860787
Updated goal-option-1 on 120 transitions
Took 0.003556966781616211s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 613 Step: 45960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9414690483486662
Updated goal-option-1 on 120 transitions
Took 0.0030524730682373047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 614 Step: 46080
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.992714845885833
Updated goal-option-2 on 120 transitions
Took 0.0032105445861816406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 615 Step: 46200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9268102249946345
Updated goal-option-1 on 120 transitions
Took 0.002843141555786133s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 616 Step: 46320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.093844066327918
Updated goal-option-1 on 120 transitions
Took 0.003412485122680664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 617 Step: 46440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9742995342852298
Updated goal-option-1 on 120 transitions
Took 0.0034475326538085938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 618 Step: 46560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.805380466394126
Updated goal-option-2 on 120 transitions
Took 0.0028967857360839844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 619 Step: 46680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.513112351442466
Updated goal-option-2 on 120 transitions
Took 0.003185749053955078s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 620 Step: 46800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.021775836292322
Updated goal-option-1 on 120 transitions
Took 0.0032613277435302734s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 621 Step: 46920
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.838498101259272
Updated goal-option-2 on 120 transitions
Took 0.0030603408813476562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 622 Step: 47040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.823659625835717
Updated goal-option-2 on 120 transitions
Took 0.0037720203399658203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 623 Step: 47160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8921172120497278
Updated goal-option-1 on 120 transitions
Took 0.0028505325317382812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 624 Step: 47280
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.50945633155338
Updated goal-option-2 on 120 transitions
Took 0.0028791427612304688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 625 Step: 47400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0864390757813756
Updated goal-option-1 on 120 transitions
Took 0.00412440299987793s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 626 Step: 47520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
12.116285633295774
Updated goal-option-2 on 120 transitions
Took 0.0029468536376953125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 627 Step: 47640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.245707585520687
Updated goal-option-2 on 120 transitions
Took 0.0029075145721435547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 628 Step: 47760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0202163767394572
Updated goal-option-1 on 120 transitions
Took 0.0033833980560302734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 629 Step: 47880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9961112602857375
Updated goal-option-1 on 120 transitions
Took 0.004186391830444336s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=630 Seed=18] Took 0.41969871520996094s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 630 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.401257154298946
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 631 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.054722188040614
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 632 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.08657554103411
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 633 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.2620426149806
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 634 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.35129556246102
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 635 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.05950719490647
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 636 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.979003425949486
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 637 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.14273441489786
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 638 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.56332201184705
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 639 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.11562645062804
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 640 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.655566302419174
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 641 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.85868012998253
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 642 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -58.64164765866008
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 643 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.823076363420114
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 644 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.52800317294896
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 645 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -47.62376881961245
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 646 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.53597875626292
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 647 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.05720612127334
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 648 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.83047073811758
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 649 Step: 48000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -56.60114522231743
Took 8.930126905441284s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=650 Seed=18] Took 0.012278318405151367s to save gc logs
Enter Visualization
[]
[SE([10 15]), SE([10 16])]
PLOTS
[]
[]
PLOTS2
[10, 10]
[1, 1]
END UTILS
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 650 Step: 48000
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.91471424823006
Updated goal-option-2 on 120 transitions
Took 0.0030791759490966797s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 651 Step: 48120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.169156597927213
Updated goal-option-2 on 120 transitions
Took 0.0031690597534179688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 652 Step: 48240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9154520237394298
Updated goal-option-1 on 120 transitions
Took 0.004939079284667969s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 653 Step: 48360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.961241519464207
Updated goal-option-1 on 120 transitions
Took 0.002950906753540039s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 654 Step: 48480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8571429441803722
Updated goal-option-1 on 120 transitions
Took 0.003365039825439453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 655 Step: 48600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0798547504721898
Updated goal-option-1 on 120 transitions
Took 0.003348112106323242s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 656 Step: 48720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.476722536220526
Updated goal-option-2 on 120 transitions
Took 0.0028154850006103516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 657 Step: 48840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8969657534510427
Updated goal-option-1 on 120 transitions
Took 0.0036840438842773438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 658 Step: 48960
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0537026074504683
Updated goal-option-1 on 120 transitions
Took 0.0032584667205810547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 659 Step: 49080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.028956016475617
Updated goal-option-1 on 120 transitions
Took 0.003116130828857422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 660 Step: 49200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1304238064874705
Updated goal-option-1 on 120 transitions
Took 0.0032548904418945312s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 1.5974044799804688e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 661 Step: 49320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8949395446648802
Updated goal-option-1 on 120 transitions
Took 0.0029287338256835938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 662 Step: 49440
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.89450167252549
Updated goal-option-2 on 120 transitions
Took 0.002994060516357422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 663 Step: 49560
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9364243321855096
Updated goal-option-1 on 120 transitions
Took 0.002996683120727539s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 664 Step: 49680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8853288803061115
Updated goal-option-2 on 120 transitions
Took 0.003009796142578125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 665 Step: 49800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9794090374900178
Updated goal-option-1 on 120 transitions
Took 0.003760099411010742s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 666 Step: 49920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0319299956011962
Updated goal-option-1 on 120 transitions
Took 0.0032372474670410156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 667 Step: 50040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
14.426433480122968
Updated goal-option-2 on 120 transitions
Took 0.0033180713653564453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 668 Step: 50160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9853641813194067
Updated goal-option-2 on 120 transitions
Took 0.003626108169555664s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 669 Step: 50280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9743613091350581
Updated goal-option-1 on 120 transitions
Took 0.003185272216796875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 670 Step: 50400
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0203757191093896
Updated goal-option-1 on 120 transitions
Took 0.0033998489379882812s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.9604644775390625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 671 Step: 50520
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0719518173045228
Updated goal-option-1 on 120 transitions
Took 0.0031960010528564453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 672 Step: 50640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9155083145849927
Updated goal-option-1 on 120 transitions
Took 0.0029442310333251953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 673 Step: 50760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.960035762463062
Updated goal-option-1 on 120 transitions
Took 0.0032122135162353516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 674 Step: 50880
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.962663604877889
Updated goal-option-2 on 120 transitions
Took 0.0033042430877685547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 675 Step: 51000
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9131149864776438
Updated goal-option-1 on 120 transitions
Took 0.002925872802734375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 676 Step: 51120
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8217102263470814
Updated goal-option-1 on 120 transitions
Took 0.0030395984649658203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 677 Step: 51240
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.813047145553819
Updated goal-option-1 on 120 transitions
Took 0.003021717071533203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 678 Step: 51360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.995347684055257
Updated goal-option-2 on 120 transitions
Took 0.0030274391174316406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 679 Step: 51480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.485648339633674
Updated goal-option-2 on 120 transitions
Took 0.002893209457397461s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 680 Step: 51600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9072379040892781
Updated goal-option-1 on 120 transitions
Took 0.0029668807983398438s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 681 Step: 51720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2183341863061
Updated goal-option-1 on 120 transitions
Took 0.0031626224517822266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 682 Step: 51840
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.874696538162728
Updated goal-option-2 on 120 transitions
Took 0.003115415573120117s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 683 Step: 51960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3756018897816427
Updated goal-option-1 on 120 transitions
Took 0.003270387649536133s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 684 Step: 52080
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.018969300552271
Updated goal-option-2 on 120 transitions
Took 0.002903461456298828s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 685 Step: 52200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0028482392310496
Updated goal-option-1 on 120 transitions
Took 0.002961397171020508s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 686 Step: 52320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2319811707377792
Updated goal-option-1 on 120 transitions
Took 0.0029692649841308594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 687 Step: 52440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9516721763259016
Updated goal-option-1 on 120 transitions
Took 0.003077983856201172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 688 Step: 52560
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9878669072463949
Updated goal-option-1 on 120 transitions
Took 0.0029304027557373047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 689 Step: 52680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
18.264944877652894
Updated goal-option-2 on 120 transitions
Took 0.003154754638671875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 690 Step: 52800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9611134292454947
Updated goal-option-1 on 120 transitions
Took 0.002921581268310547s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 691 Step: 52920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1320713953592805
Updated goal-option-1 on 120 transitions
Took 0.0030090808868408203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 692 Step: 53040
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.134963249239481
Updated goal-option-1 on 120 transitions
Took 0.0031371116638183594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 693 Step: 53160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.3478578697554657
Updated goal-option-2 on 120 transitions
Took 0.0031630992889404297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 694 Step: 53280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0595970398768024
Updated goal-option-1 on 120 transitions
Took 0.003604412078857422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 695 Step: 53400
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9829760959911568
Updated goal-option-1 on 120 transitions
Took 0.004361629486083984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 696 Step: 53520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.76754759571382
Updated goal-option-2 on 120 transitions
Took 0.002992868423461914s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 697 Step: 53640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7951572922210156
Updated goal-option-1 on 120 transitions
Took 0.002994060516357422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 698 Step: 53760
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.8077398383369045
Updated goal-option-2 on 120 transitions
Took 0.002961874008178711s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 699 Step: 53880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1578734113591465
Updated goal-option-1 on 120 transitions
Took 0.002982616424560547s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=700 Seed=18] Took 0.038727760314941406s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 700 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.38058801196166
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 701 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.89869219902903
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 702 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.69007370629697
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 703 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.11077465261042
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 704 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.751403126865625
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 705 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.26634703343734
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 706 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.91175953485072
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 707 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.764292429201305
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 708 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.6586022679694
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 709 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.08435314288363
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 710 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.44037189200753
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 711 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.20715069398284
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 712 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.51730318577029
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 713 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.84864406660199
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 714 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.65818007150665
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 715 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.385034444509074
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 716 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.45724881719798
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 717 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.65379915013909
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 718 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.240267005050555
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 719 Step: 54000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.594561838079244
Took 9.656383275985718s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=720 Seed=18] Took 0.0290834903717041s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 720 Step: 54000
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.708446559961885
Updated goal-option-2 on 120 transitions
Took 0.0029458999633789062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 721 Step: 54120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0752242592978634
Updated goal-option-1 on 120 transitions
Took 0.002949953079223633s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 722 Step: 54240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.068607716871156
Updated goal-option-2 on 120 transitions
Took 0.0028743743896484375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 723 Step: 54360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.921809344223965
Updated goal-option-1 on 120 transitions
Took 0.0029578208923339844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 724 Step: 54480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1596717779571775
Updated goal-option-1 on 120 transitions
Took 0.0029723644256591797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 725 Step: 54600
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.251083171615997
Updated goal-option-2 on 120 transitions
Took 0.0029754638671875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 726 Step: 54720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8703920698792752
Updated goal-option-1 on 120 transitions
Took 0.0028977394104003906s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 727 Step: 54840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.14745351204571
Updated goal-option-2 on 120 transitions
Took 0.0029489994049072266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 728 Step: 54960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.543606741538194
Updated goal-option-2 on 120 transitions
Took 0.0029582977294921875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 729 Step: 55080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9983050123401297
Updated goal-option-1 on 120 transitions
Took 0.003336191177368164s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 730 Step: 55200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.596530636378399
Updated goal-option-2 on 120 transitions
Took 0.0029468536376953125s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 731 Step: 55320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9577184686101413
Updated goal-option-1 on 120 transitions
Took 0.002890348434448242s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 732 Step: 55440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8974760382469813
Updated goal-option-1 on 120 transitions
Took 0.002898693084716797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 733 Step: 55560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9488694318394408
Updated goal-option-1 on 120 transitions
Took 0.0037126541137695312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 734 Step: 55680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.032598076412091
Updated goal-option-1 on 120 transitions
Took 0.0032503604888916016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 735 Step: 55800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8999751778026792
Updated goal-option-1 on 120 transitions
Took 0.003229856491088867s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 736 Step: 55920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0225236007964114
Updated goal-option-1 on 120 transitions
Took 0.0031633377075195312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 737 Step: 56040
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4324229881731774
Updated goal-option-2 on 120 transitions
Took 0.0029833316802978516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 738 Step: 56160
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1767056100399114
Updated goal-option-1 on 120 transitions
Took 0.003529071807861328s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 739 Step: 56280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9962827771721735
Updated goal-option-1 on 120 transitions
Took 0.003183603286743164s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 740 Step: 56400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.781140885465447
Updated goal-option-2 on 120 transitions
Took 0.002898693084716797s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 741 Step: 56520
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.124664316342815
Updated goal-option-1 on 120 transitions
Took 0.00335693359375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 742 Step: 56640
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9812822867353407
Updated goal-option-1 on 120 transitions
Took 0.0029573440551757812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 743 Step: 56760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3774406557089165
Updated goal-option-1 on 120 transitions
Took 0.0031576156616210938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 744 Step: 56880
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.277675218259295
Updated goal-option-2 on 120 transitions
Took 0.003100872039794922s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 745 Step: 57000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.087256557604935
Updated goal-option-1 on 120 transitions
Took 0.002936124801635742s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 746 Step: 57120
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8571557730789757
Updated goal-option-1 on 120 transitions
Took 0.002989053726196289s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 747 Step: 57240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7544810973627473
Updated goal-option-1 on 120 transitions
Took 0.0032455921173095703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 748 Step: 57360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.159390834141369
Updated goal-option-1 on 120 transitions
Took 0.0030145645141601562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 749 Step: 57480
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9008035143827527
Updated goal-option-1 on 120 transitions
Took 0.0029370784759521484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 750 Step: 57600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.966559700357418
Updated goal-option-2 on 120 transitions
Took 0.0030019283294677734s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 751 Step: 57720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9959343046119787
Updated goal-option-1 on 120 transitions
Took 0.0033576488494873047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 752 Step: 57840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.017085181350405
Updated goal-option-1 on 120 transitions
Took 0.003138303756713867s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 753 Step: 57960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8201450786871013
Updated goal-option-1 on 120 transitions
Took 0.0030117034912109375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 754 Step: 58080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9642283131240198
Updated goal-option-1 on 120 transitions
Took 0.0034530162811279297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 755 Step: 58200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0098117090088086
Updated goal-option-1 on 120 transitions
Took 0.003077983856201172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 756 Step: 58320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.354172026117643
Updated goal-option-2 on 120 transitions
Took 0.0029103755950927734s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 757 Step: 58440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8993360204688416
Updated goal-option-1 on 120 transitions
Took 0.0028350353240966797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 758 Step: 58560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0077668585806296
Updated goal-option-1 on 120 transitions
Took 0.0036258697509765625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 759 Step: 58680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0738099229964106
Updated goal-option-1 on 120 transitions
Took 0.0030906200408935547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 760 Step: 58800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.748817912458131
Updated goal-option-2 on 120 transitions
Took 0.003100156784057617s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 761 Step: 58920
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.044809402277073
Updated goal-option-2 on 120 transitions
Took 0.0029239654541015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 762 Step: 59040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.389549866169026
Updated goal-option-2 on 120 transitions
Took 0.0030426979064941406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 763 Step: 59160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.783491645939648
Updated goal-option-2 on 120 transitions
Took 0.0029642581939697266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 764 Step: 59280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.915367691401145
Updated goal-option-1 on 120 transitions
Took 0.0029494762420654297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 765 Step: 59400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.755142571968718
Updated goal-option-1 on 120 transitions
Took 0.003039836883544922s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 766 Step: 59520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.844545005503412
Updated goal-option-1 on 120 transitions
Took 0.0030143260955810547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 767 Step: 59640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
goal-option-1 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9824358688358931
Updated goal-option-1 on 89 transitions
Took 0.002223968505859375s to update distance table with 90 states and events {SE([10 16]), SE([ 4 18]), None}
DSG successfully reached SE([10 16])
[Random] Deep skill graphs target event: SE([ 4 18])
[Random] DSG selected event SE([ 4 18])
[Graph Consolidation] From (10, 16) to [ 4 18]
Revised planner goal vertex to SE([10 16]) and dsc goal vertex to SE([ 4 18])
Planner goal: SE([10 16]), DSC goal: SE([ 4 18]) and Goal: SE([ 4 18])
False
False
Rolling out DSC with goal vertex SE([ 4 18])
Rolling out goal-option-4, from [10 16] targeting {'player_x': 4, 'player_y': 18, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 31 transitions
Took 0.0006935596466064453s to update distance table with 32 states and events {SE([10 16]), None}
================================================================================
[Consolidation] Episode: 768 Step: 59760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9716181416370929
Updated goal-option-1 on 120 transitions
Took 0.0028390884399414062s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 769 Step: 59880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.653149283594555
Updated goal-option-2 on 120 transitions
Took 0.0029191970825195312s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=770 Seed=18] Took 0.013721227645874023s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 770 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.5947674268391
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 771 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.53564496617764
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 772 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.57504466781393
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 773 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.732278903597035
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 774 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.49887396390659
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 775 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.32956616545562
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 776 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.79167881136527
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 777 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.27342775068246
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 778 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.576662176055834
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 779 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.77351257484406
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 780 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.960991024039686
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 781 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.90839277789928
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 782 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.73633976187557
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 783 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.81424279790372
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 784 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.208880628459156
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 785 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.694936375366524
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 786 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.44591743592173
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 787 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.895467499038205
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 788 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.22512596496381
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 789 Step: 60000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.95731764892116
Took 11.988057136535645s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=790 Seed=18] Took 0.36850810050964355s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 790 Step: 60000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1579118530079533
Updated goal-option-1 on 120 transitions
Took 0.003176450729370117s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 791 Step: 60120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.624720491468906
Updated goal-option-2 on 120 transitions
Took 0.0031213760375976562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 792 Step: 60240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0886075439851537
Updated goal-option-1 on 120 transitions
Took 0.003116130828857422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 793 Step: 60360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8960339952415475
Updated goal-option-2 on 120 transitions
Took 0.002928018569946289s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 794 Step: 60480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
16.122298040737707
Updated goal-option-2 on 120 transitions
Took 0.0029108524322509766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 795 Step: 60600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.170550844743892
Updated goal-option-1 on 120 transitions
Took 0.0030510425567626953s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 796 Step: 60720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.016871659240375
Updated goal-option-2 on 120 transitions
Took 0.003283262252807617s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 797 Step: 60840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3669283476525653
Updated goal-option-1 on 120 transitions
Took 0.002859354019165039s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 798 Step: 60960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8928803384628378
Updated goal-option-1 on 120 transitions
Took 0.003815174102783203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 799 Step: 61080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9663722340336885
Updated goal-option-1 on 120 transitions
Took 0.0033054351806640625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 800 Step: 61200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8304444451148149
Updated goal-option-1 on 120 transitions
Took 0.003186464309692383s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 801 Step: 61320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8137604806611874
Updated goal-option-1 on 120 transitions
Took 0.0030066967010498047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 802 Step: 61440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8828700326702531
Updated goal-option-1 on 120 transitions
Took 0.003062725067138672s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 803 Step: 61560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.039500137060283
Updated goal-option-1 on 120 transitions
Took 0.0031833648681640625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 804 Step: 61680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.697863242744157
Updated goal-option-2 on 120 transitions
Took 0.0032215118408203125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 805 Step: 61800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2439252914492582
Updated goal-option-1 on 120 transitions
Took 0.0029401779174804688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 806 Step: 61920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.957664655831953
Updated goal-option-2 on 120 transitions
Took 0.00290679931640625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 807 Step: 62040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9061088828559242
Updated goal-option-1 on 120 transitions
Took 0.003273487091064453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 808 Step: 62160
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.061049323006835
Updated goal-option-1 on 120 transitions
Took 0.002930879592895508s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 809 Step: 62280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1707126356704067
Updated goal-option-1 on 120 transitions
Took 0.0028505325317382812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 810 Step: 62400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9172332522356993
Updated goal-option-1 on 120 transitions
Took 0.003061056137084961s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 811 Step: 62520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.012104382962078
Updated goal-option-1 on 120 transitions
Took 0.0037059783935546875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 812 Step: 62640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.285213036835389
Updated goal-option-1 on 120 transitions
Took 0.002898693084716797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 813 Step: 62760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.62641158948342
Updated goal-option-2 on 120 transitions
Took 0.0029053688049316406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 814 Step: 62880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9619983366667822
Updated goal-option-1 on 120 transitions
Took 0.003185749053955078s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 815 Step: 63000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.006873943909515
Updated goal-option-1 on 120 transitions
Took 0.0030570030212402344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 816 Step: 63120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0023696413473882
Updated goal-option-1 on 120 transitions
Took 0.002995014190673828s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 817 Step: 63240
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0572080907157826
Updated goal-option-1 on 120 transitions
Took 0.0028269290924072266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 818 Step: 63360
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.401366183223824
Updated goal-option-2 on 120 transitions
Took 0.0033490657806396484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 819 Step: 63480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.086085304773102
Updated goal-option-2 on 120 transitions
Took 0.00493931770324707s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 820 Step: 63600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0317548652776518
Updated goal-option-1 on 120 transitions
Took 0.0031633377075195312s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.198883056640625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 821 Step: 63720
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.737272594994422
Updated goal-option-2 on 120 transitions
Took 0.0031135082244873047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 822 Step: 63840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8904375129333039
Updated goal-option-1 on 120 transitions
Took 0.0029151439666748047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 823 Step: 63960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0453933293290376
Updated goal-option-1 on 120 transitions
Took 0.003276348114013672s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 824 Step: 64080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.536515642578403
Updated goal-option-2 on 120 transitions
Took 0.0030853748321533203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 825 Step: 64200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.629475574070101
Updated goal-option-2 on 120 transitions
Took 0.00428009033203125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 826 Step: 64320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
15.765647015107485
Updated goal-option-2 on 120 transitions
Took 0.0029015541076660156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 827 Step: 64440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8995018869093888
Updated goal-option-1 on 120 transitions
Took 0.003092527389526367s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 828 Step: 64560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.8234024712195
Updated goal-option-2 on 120 transitions
Took 0.0031561851501464844s to update distance table with 121 states and events {SE([10 16]), SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 829 Step: 64680
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0426713498257747
Updated goal-option-1 on 120 transitions
Took 0.0029418468475341797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 830 Step: 64800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9910652323946579
Updated goal-option-1 on 120 transitions
Took 0.002936840057373047s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 831 Step: 64920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0254052719681759
Updated goal-option-1 on 120 transitions
Took 0.0029358863830566406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 832 Step: 65040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8474163782479525
Updated goal-option-1 on 120 transitions
Took 0.0031366348266601562s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 833 Step: 65160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.885696455836296
Updated goal-option-2 on 120 transitions
Took 0.0029625892639160156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 834 Step: 65280
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.9695823762366285
Updated goal-option-2 on 120 transitions
Took 0.004725933074951172s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 835 Step: 65400
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2083183287980817
Updated goal-option-1 on 120 transitions
Took 0.0031752586364746094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 836 Step: 65520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.447574132122099
Updated goal-option-2 on 120 transitions
Took 0.0030269622802734375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 837 Step: 65640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3669436078294954
Updated goal-option-1 on 120 transitions
Took 0.002892732620239258s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 838 Step: 65760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8440966812634966
Updated goal-option-1 on 120 transitions
Took 0.002880096435546875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 839 Step: 65880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9778400068783153
Updated goal-option-1 on 120 transitions
Took 0.002948284149169922s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=840 Seed=18] Took 0.010193347930908203s to save gc logs
Enter Visualization
[]
[SE([10 15]), SE([10 16])]
PLOTS
[]
[]
PLOTS2
[10, 10]
[1, 1]
END UTILS
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 840 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.17263499668479
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 841 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.34819683019305
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 842 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.25279567949474
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 843 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.80960222915746
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 844 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.23409532569349
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 845 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.94271871994715
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 846 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -59.47122312267311
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 847 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.454963244497776
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 848 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.206739593995735
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 849 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.5769487972284
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 850 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.11960543785244
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 851 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.881902797698785
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 852 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.332744386047125
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 853 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.203639279468916
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 854 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.24678281584056
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 855 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.70274022873491
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 856 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.06224670400843
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 857 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.86083794222213
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 858 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.63454798411112
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 859 Step: 66000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.37427917448804
Took 7.013679265975952s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=860 Seed=18] Took 0.1426396369934082s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 860 Step: 66000
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.176695154933631
Updated goal-option-1 on 120 transitions
Took 0.002958059310913086s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 861 Step: 66120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8307295256384924
Updated goal-option-1 on 120 transitions
Took 0.0034151077270507812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 862 Step: 66240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8823128090714425
Updated goal-option-1 on 120 transitions
Took 0.002896547317504883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 863 Step: 66360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8734706555370488
Updated goal-option-1 on 120 transitions
Took 0.0031561851501464844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 864 Step: 66480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.566342861391604
Updated goal-option-2 on 120 transitions
Took 0.0029144287109375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 865 Step: 66600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0969114613964637
Updated goal-option-1 on 120 transitions
Took 0.003469705581665039s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 866 Step: 66720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2252270131941458
Updated goal-option-1 on 120 transitions
Took 0.0028967857360839844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 867 Step: 66840
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.064761860606571
Updated goal-option-2 on 120 transitions
Took 0.003553152084350586s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 868 Step: 66960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1232761637193278
Updated goal-option-1 on 120 transitions
Took 0.003208637237548828s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 869 Step: 67080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0233510848587823
Updated goal-option-1 on 120 transitions
Took 0.0032100677490234375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 870 Step: 67200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9775338739959271
Updated goal-option-1 on 120 transitions
Took 0.002955913543701172s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 871 Step: 67320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.35932466513744
Updated goal-option-2 on 120 transitions
Took 0.002947568893432617s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 872 Step: 67440
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.772331709663073
Updated goal-option-2 on 120 transitions
Took 0.0029397010803222656s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 873 Step: 67560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.017946506414935
Updated goal-option-1 on 120 transitions
Took 0.005437612533569336s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 874 Step: 67680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.020897222527613
Updated goal-option-2 on 120 transitions
Took 0.002885103225708008s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 875 Step: 67800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0522158140256956
Updated goal-option-1 on 120 transitions
Took 0.0030121803283691406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 876 Step: 67920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.351854164286385
Updated goal-option-2 on 120 transitions
Took 0.0029909610748291016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 877 Step: 68040
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0271988230110336
Updated goal-option-1 on 120 transitions
Took 0.0028612613677978516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 878 Step: 68160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.016547157118717
Updated goal-option-2 on 120 transitions
Took 0.0028972625732421875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 879 Step: 68280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.396504731227955
Updated goal-option-2 on 120 transitions
Took 0.0028967857360839844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 880 Step: 68400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.316202788768957
Updated goal-option-2 on 120 transitions
Took 0.0030591487884521484s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 881 Step: 68520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9357676790555569
Updated goal-option-1 on 120 transitions
Took 0.00359344482421875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 882 Step: 68640
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8906799998146319
Updated goal-option-1 on 120 transitions
Took 0.002924680709838867s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 883 Step: 68760
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0222856393614552
Updated goal-option-1 on 120 transitions
Took 0.00284576416015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 884 Step: 68880
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9036945867183244
Updated goal-option-1 on 120 transitions
Took 0.0028905868530273438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 885 Step: 69000
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.070775097294245
Updated goal-option-2 on 120 transitions
Took 0.0028960704803466797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 886 Step: 69120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9811268867890804
Updated goal-option-1 on 120 transitions
Took 0.0030035972595214844s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 887 Step: 69240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.626369907675931
Updated goal-option-2 on 120 transitions
Took 0.0029430389404296875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 888 Step: 69360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.401424837791031
Updated goal-option-2 on 120 transitions
Took 0.002964019775390625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 889 Step: 69480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0696071018873334
Updated goal-option-1 on 120 transitions
Took 0.0029354095458984375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 890 Step: 69600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.007222259028332
Updated goal-option-1 on 120 transitions
Took 0.003045320510864258s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 891 Step: 69720
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.197000216993426
Updated goal-option-2 on 120 transitions
Took 0.002913951873779297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 892 Step: 69840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9812675447326223
Updated goal-option-1 on 120 transitions
Took 0.0032389163970947266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 893 Step: 69960
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.090813557927808
Updated goal-option-2 on 120 transitions
Took 0.0029363632202148438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 894 Step: 70080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0110198790194689
Updated goal-option-1 on 120 transitions
Took 0.002946615219116211s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 895 Step: 70200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1246392886079657
Updated goal-option-1 on 120 transitions
Took 0.0029115676879882812s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 896 Step: 70320
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.912028146286806
Updated goal-option-2 on 120 transitions
Took 0.002950906753540039s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 897 Step: 70440
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
13.244933419579562
Updated goal-option-2 on 120 transitions
Took 0.0029191970825195312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 898 Step: 70560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.548493948454658
Updated goal-option-2 on 120 transitions
Took 0.0030579566955566406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 899 Step: 70680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.110498183051125
Updated goal-option-2 on 120 transitions
Took 0.003159761428833008s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 900 Step: 70800
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1193856473476436
Updated goal-option-1 on 120 transitions
Took 0.0028879642486572266s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 901 Step: 70920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9585140202204863
Updated goal-option-1 on 120 transitions
Took 0.0029001235961914062s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 902 Step: 71040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.012100723722434
Updated goal-option-1 on 120 transitions
Took 0.003147125244140625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 903 Step: 71160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8686090025186903
Updated goal-option-1 on 120 transitions
Took 0.002936124801635742s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 904 Step: 71280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.968583123426167
Updated goal-option-2 on 120 transitions
Took 0.0030057430267333984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 905 Step: 71400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.124199476093054
Updated goal-option-2 on 120 transitions
Took 0.0029439926147460938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 906 Step: 71520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.940151762566529
Updated goal-option-2 on 120 transitions
Took 0.0029811859130859375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 907 Step: 71640
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.01586859797438
Updated goal-option-2 on 120 transitions
Took 0.0028848648071289062s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 908 Step: 71760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.488378582522273
Updated goal-option-2 on 120 transitions
Took 0.003124237060546875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 909 Step: 71880
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.211585390071074
Updated goal-option-2 on 120 transitions
Took 0.0029120445251464844s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=910 Seed=18] Took 0.009625911712646484s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 910 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.921537801390514
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 911 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.975671809283085
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 912 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -57.11223191473982
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 913 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.73426276142709
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 914 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.18677134346217
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 915 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.20860126335174
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 916 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.71169369958807
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 917 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.77188654965721
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 918 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.84578830515966
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 919 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.91856904281303
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 920 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.89955773533438
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 921 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.47129388758913
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 922 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.07182572153397
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 923 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.1384941637516
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 924 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.08906206593383
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 925 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.115656964015216
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 926 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.25678231148049
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 927 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.11288779915776
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 928 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.288049039430916
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 929 Step: 72000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.683531200746074
Took 6.595569610595703s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=930 Seed=18] Took 0.011612892150878906s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 930 Step: 72000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.455560244619846
Updated goal-option-2 on 120 transitions
Took 0.0028390884399414062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 931 Step: 72120
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.179015496091563
Updated goal-option-2 on 120 transitions
Took 0.002875089645385742s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 932 Step: 72240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9111925528489278
Updated goal-option-1 on 120 transitions
Took 0.0030591487884521484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 933 Step: 72360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.257081321974208
Updated goal-option-2 on 120 transitions
Took 0.0028777122497558594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 934 Step: 72480
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8667896536140106
Updated goal-option-1 on 120 transitions
Took 0.002917766571044922s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 935 Step: 72600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9155080631441356
Updated goal-option-1 on 120 transitions
Took 0.002895355224609375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 936 Step: 72720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.465772511282315
Updated goal-option-2 on 120 transitions
Took 0.002888202667236328s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 937 Step: 72840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1099060792620683
Updated goal-option-1 on 120 transitions
Took 0.003245830535888672s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 938 Step: 72960
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.098788386831681
Updated goal-option-2 on 120 transitions
Took 0.0032491683959960938s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 939 Step: 73080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1681604545845807
Updated goal-option-1 on 120 transitions
Took 0.0029261112213134766s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 940 Step: 73200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8970988601164204
Updated goal-option-1 on 120 transitions
Took 0.0032303333282470703s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 2.4080276489257812e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 941 Step: 73320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8681077485817298
Updated goal-option-1 on 120 transitions
Took 0.00333404541015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 942 Step: 73440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9364024139920559
Updated goal-option-1 on 120 transitions
Took 0.0032088756561279297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 943 Step: 73560
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9583813889514903
Updated goal-option-1 on 120 transitions
Took 0.0028405189514160156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 944 Step: 73680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.796695825954279
Updated goal-option-2 on 120 transitions
Took 0.00289154052734375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 945 Step: 73800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.955381317241561
Updated goal-option-2 on 120 transitions
Took 0.0028612613677978516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 946 Step: 73920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0514903600941363
Updated goal-option-1 on 120 transitions
Took 0.0030469894409179688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 947 Step: 74040
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.615118589329843
Updated goal-option-2 on 120 transitions
Took 0.0031790733337402344s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 948 Step: 74160
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9405583114528989
Updated goal-option-1 on 120 transitions
Took 0.002953767776489258s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 949 Step: 74280
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.629829225654248
Updated goal-option-2 on 120 transitions
Took 0.002909421920776367s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 950 Step: 74400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.730521380173741
Updated goal-option-2 on 120 transitions
Took 0.0029227733612060547s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 951 Step: 74520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.835719337686896
Updated goal-option-2 on 120 transitions
Took 0.0028994083404541016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 952 Step: 74640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8836303768662409
Updated goal-option-1 on 120 transitions
Took 0.0032355785369873047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 953 Step: 74760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.590339560139303
Updated goal-option-2 on 120 transitions
Took 0.0029697418212890625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 954 Step: 74880
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8918345282775447
Updated goal-option-1 on 120 transitions
Took 0.003462076187133789s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 955 Step: 75000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0627180092300117
Updated goal-option-1 on 120 transitions
Took 0.0029571056365966797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 956 Step: 75120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.232114552665131
Updated goal-option-1 on 120 transitions
Took 0.003201723098754883s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 957 Step: 75240
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.787237155161439
Updated goal-option-1 on 120 transitions
Took 0.0028972625732421875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 958 Step: 75360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.22634236895967
Updated goal-option-2 on 120 transitions
Took 0.0028998851776123047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 959 Step: 75480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.709045248106122
Updated goal-option-2 on 120 transitions
Took 0.0029065608978271484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 960 Step: 75600
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8761310526200302
Updated goal-option-1 on 120 transitions
Took 0.002926349639892578s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 961 Step: 75720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8365652184422044
Updated goal-option-1 on 120 transitions
Took 0.002924680709838867s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 962 Step: 75840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9214067167427574
Updated goal-option-1 on 120 transitions
Took 0.002909421920776367s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 963 Step: 75960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2665463848081726
Updated goal-option-1 on 120 transitions
Took 0.0030236244201660156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 964 Step: 76080
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8936880201530591
Updated goal-option-1 on 120 transitions
Took 0.0028700828552246094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 965 Step: 76200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8888091207688437
Updated goal-option-1 on 120 transitions
Took 0.0031583309173583984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 966 Step: 76320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9482421880972544
Updated goal-option-1 on 120 transitions
Took 0.0029680728912353516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 967 Step: 76440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0295944010853038
Updated goal-option-1 on 120 transitions
Took 0.0029582977294921875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 968 Step: 76560
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.988706684360902
Updated goal-option-2 on 120 transitions
Took 0.0029370784759521484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 969 Step: 76680
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8036466322582633
Updated goal-option-1 on 120 transitions
Took 0.0037517547607421875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 970 Step: 76800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.7494149611198475
Updated goal-option-2 on 120 transitions
Took 0.0029354095458984375s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 7.152557373046875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 971 Step: 76920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9858101324132232
Updated goal-option-1 on 120 transitions
Took 0.0064585208892822266s to update distance table with 121 states and events {SE([ 4 18])}
================================================================================
[Consolidation] Episode: 972 Step: 77040
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8413777996789529
Updated goal-option-1 on 120 transitions
Took 0.003033161163330078s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 973 Step: 77160
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8951455452067777
Updated goal-option-1 on 120 transitions
Took 0.0028998851776123047s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 974 Step: 77280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8929482509857815
Updated goal-option-1 on 120 transitions
Took 0.00318145751953125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 975 Step: 77400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.0201687434954305
Updated goal-option-2 on 120 transitions
Took 0.002902507781982422s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 976 Step: 77520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0632072246337274
Updated goal-option-1 on 120 transitions
Took 0.0031032562255859375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 977 Step: 77640
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9548631446688977
Updated goal-option-1 on 120 transitions
Took 0.003250598907470703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 978 Step: 77760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.861892569413225
Updated goal-option-1 on 120 transitions
Took 0.0033111572265625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 979 Step: 77880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.140178528924784
Updated goal-option-2 on 120 transitions
Took 0.0028543472290039062s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=980 Seed=18] Took 0.010069608688354492s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 980 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.01875360915437
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 981 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.996958730276674
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 982 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.397376420907676
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 983 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.83410678379005
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 984 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.68912669405108
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 985 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.07777445530519
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 986 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.39006914527272
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 987 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.78169992216863
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 988 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.64773472840898
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 989 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.92980807321146
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 990 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.70752115093637
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 991 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.28746325906832
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 992 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.62656357861124
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 993 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.519146000558976
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 994 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.13271382963285
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 995 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.90042803576216
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 996 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.38045811327174
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 997 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.50196221657097
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 998 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.71877690893598
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 999 Step: 78000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.90071831282694
Took 14.975131273269653s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=1000 Seed=18] Took 0.06698441505432129s to save gc logs
Enter Visualization
[]
[SE([10 15]), SE([10 16])]
PLOTS
[]
[]
PLOTS2
[10, 10]
[1, 1]
END UTILS
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 1000 Step: 78000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.946302614024766
Updated goal-option-1 on 120 transitions
Took 0.0035250186920166016s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.4836273193359375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1001 Step: 78120
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8142874291540397
Updated goal-option-1 on 120 transitions
Took 0.004366636276245117s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1002 Step: 78240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.96910830278215
Updated goal-option-1 on 120 transitions
Took 0.003252267837524414s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1003 Step: 78360
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0146799861122047
Updated goal-option-1 on 120 transitions
Took 0.003161907196044922s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1004 Step: 78480
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.25735626564849
Updated goal-option-2 on 120 transitions
Took 0.0032575130462646484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1005 Step: 78600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.121775920001909
Updated goal-option-1 on 120 transitions
Took 0.0031294822692871094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1006 Step: 78720
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.930090442541266
Updated goal-option-1 on 120 transitions
Took 0.0029249191284179688s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1007 Step: 78840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.990086776592459
Updated goal-option-2 on 120 transitions
Took 0.0031125545501708984s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1008 Step: 78960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9625864531354175
Updated goal-option-1 on 120 transitions
Took 0.0030579566955566406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1009 Step: 79080
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.755100234101216
Updated goal-option-2 on 120 transitions
Took 0.0030863285064697266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1010 Step: 79200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9715252062874743
Updated goal-option-1 on 120 transitions
Took 0.003142833709716797s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1011 Step: 79320
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0043710496555753
Updated goal-option-1 on 120 transitions
Took 0.0030226707458496094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1012 Step: 79440
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8449757344124365
Updated goal-option-1 on 120 transitions
Took 0.0030460357666015625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1013 Step: 79560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9306951106248089
Updated goal-option-1 on 120 transitions
Took 0.0030517578125s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1014 Step: 79680
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.3045056999350586
Updated goal-option-2 on 120 transitions
Took 0.0029735565185546875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1015 Step: 79800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8492659481091275
Updated goal-option-1 on 120 transitions
Took 0.0033779144287109375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1016 Step: 79920
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0449264559810636
Updated goal-option-1 on 120 transitions
Took 0.0029404163360595703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1017 Step: 80040
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9526037712402265
Updated goal-option-1 on 120 transitions
Took 0.003041982650756836s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1018 Step: 80160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
5.6432434157080325
Updated goal-option-2 on 120 transitions
Took 0.002930879592895508s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1019 Step: 80280
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.021669046018881
Updated goal-option-1 on 120 transitions
Took 0.003074169158935547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1020 Step: 80400
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0216338752839393
Updated goal-option-1 on 120 transitions
Took 0.0030214786529541016s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 8.821487426757812e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1021 Step: 80520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
6.5540777993211075
Updated goal-option-2 on 120 transitions
Took 0.003165721893310547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1022 Step: 80640
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.042906837205616
Updated goal-option-2 on 120 transitions
Took 0.003006458282470703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1023 Step: 80760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
16.802824791520834
Updated goal-option-2 on 120 transitions
Took 0.0034029483795166016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1024 Step: 80880
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8821183949992375
Updated goal-option-1 on 120 transitions
Took 0.003130197525024414s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1025 Step: 81000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9797571177242648
Updated goal-option-1 on 120 transitions
Took 0.0031931400299072266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1026 Step: 81120
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8264361061124182
Updated goal-option-1 on 120 transitions
Took 0.0030028820037841797s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1027 Step: 81240
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.041409568832994
Updated goal-option-1 on 120 transitions
Took 0.0030307769775390625s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1028 Step: 81360
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.526014895488818
Updated goal-option-2 on 120 transitions
Took 0.0030906200408935547s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1029 Step: 81480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
4.657969019686182
Updated goal-option-2 on 120 transitions
Took 0.0031812191009521484s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1030 Step: 81600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8806536355281516
Updated goal-option-1 on 120 transitions
Took 0.0031223297119140625s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 6.4373016357421875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1031 Step: 81720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.300088558168637
Updated goal-option-2 on 120 transitions
Took 0.003285646438598633s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1032 Step: 81840
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.048212740910901
Updated goal-option-1 on 120 transitions
Took 0.0031642913818359375s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1033 Step: 81960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0564349670653241
Updated goal-option-1 on 120 transitions
Took 0.002973794937133789s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1034 Step: 82080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
12.98101372915941
Updated goal-option-2 on 120 transitions
Took 0.0034058094024658203s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1035 Step: 82200
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0356792798017886
Updated goal-option-1 on 120 transitions
Took 0.002943277359008789s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1036 Step: 82320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.044110818453124
Updated goal-option-1 on 120 transitions
Took 0.0029604434967041016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1037 Step: 82440
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
8.988975966349244
Updated goal-option-2 on 120 transitions
Took 0.002955198287963867s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1038 Step: 82560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8580461573374231
Updated goal-option-1 on 120 transitions
Took 0.0035033226013183594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1039 Step: 82680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8527395530996295
Updated goal-option-1 on 120 transitions
Took 0.002955198287963867s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1040 Step: 82800
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9301888856943688
Updated goal-option-1 on 120 transitions
Took 0.0030641555786132812s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 2.288818359375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1041 Step: 82920
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9913307271622297
Updated goal-option-1 on 120 transitions
Took 0.0035049915313720703s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1042 Step: 83040
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
9.209950369317085
Updated goal-option-2 on 120 transitions
Took 0.0030944347381591797s to update distance table with 121 states and events {SE([10 16]), SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1043 Step: 83160
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.814431247417815
Updated goal-option-2 on 120 transitions
Took 0.0029616355895996094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1044 Step: 83280
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.612095766377024
Updated goal-option-2 on 120 transitions
Took 0.0029528141021728516s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1045 Step: 83400
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
3.9987005140040615
Updated goal-option-2 on 120 transitions
Took 0.002870798110961914s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1046 Step: 83520
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0753848430876554
Updated goal-option-1 on 120 transitions
Took 0.003005504608154297s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1047 Step: 83640
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 851, 'bonus': 0.03427955850955305, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59729, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8742334661218288
Updated goal-option-1 on 120 transitions
Took 0.003003358840942383s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1048 Step: 83760
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0293617217810984
Updated goal-option-1 on 120 transitions
Took 0.0030913352966308594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1049 Step: 83880
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.535303878287475
Updated goal-option-2 on 120 transitions
Took 0.002974987030029297s to update distance table with 121 states and events {SE([ 4 18]), None}
[Episode=1050 Seed=18] Took 0.009926795959472656s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1050 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.66136370971799
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1051 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.98360907007009
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1052 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.84331779554486
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1053 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.25209089630516
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1054 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.778037732001394
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1055 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.772339324466884
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1056 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -64.05414098902838
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1057 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.91192001407035
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1058 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -64.04270526219625
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1059 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.782397801522166
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1060 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -64.08898044121452
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1061 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.795495852595195
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1062 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.57317744860484
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1063 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.74665301607456
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1064 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -62.16885534378525
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1065 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -64.26730472478084
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1066 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -64.47201851382852
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1067 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.261740058485884
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1068 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.925482746213675
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x147404723b80>
================================================================================
[Expansion] Episode: 1069 Step: 84000
================================================================================
Attempting to expand SE([ 4 18])
[RND Rollout] Reward: 0.0	IntrinsicReward: -64.17808601428624
Took 35.225707054138184s to update distance table with 20040 states and events {SE([ 4 18]), None}
[Episode=1070 Seed=18] Took 0.1800687313079834s to save gc logs
[SE([ 4 18]), SE([10 15]), SE([10 16])]
================================================================================
[Consolidation] Episode: 1070 Step: 84000
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.09814143021192
Updated goal-option-2 on 120 transitions
Took 0.0029611587524414062s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1071 Step: 84120
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8167493144599561
Updated goal-option-1 on 120 transitions
Took 0.0029778480529785156s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1072 Step: 84240
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.896591498206059
Updated goal-option-2 on 120 transitions
Took 0.002980947494506836s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1073 Step: 84360
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.46438428790619
Updated goal-option-2 on 120 transitions
Took 0.0029277801513671875s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1074 Step: 84480
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7960684686020073
Updated goal-option-1 on 120 transitions
Took 0.0030121803283691406s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1075 Step: 84600
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0048669384945201
Updated goal-option-1 on 120 transitions
Took 0.003026723861694336s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1076 Step: 84720
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1707270586155836
Updated goal-option-1 on 120 transitions
Took 0.003507375717163086s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1077 Step: 84840
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9834893667248252
Updated goal-option-2 on 120 transitions
Took 0.0029768943786621094s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1078 Step: 84960
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.969682149134489
Updated goal-option-1 on 120 transitions
Took 0.002927541732788086s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1079 Step: 85080
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1653723327187542
Updated goal-option-1 on 120 transitions
Took 0.0030260086059570312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1080 Step: 85200
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8987975538688189
Updated goal-option-1 on 120 transitions
Took 0.002910137176513672s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.9604644775390625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1081 Step: 85320
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 790, 'bonus': 0.035578403348241, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18333, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.824948087193954
Updated goal-option-1 on 120 transitions
Took 0.0032854080200195312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1082 Step: 85440
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 784, 'bonus': 0.03571428571428571, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15786, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9049421812910806
Updated goal-option-1 on 120 transitions
Took 0.002977132797241211s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1083 Step: 85560
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 781, 'bonus': 0.03578281334822566, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7528, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.106631952278307
Updated goal-option-1 on 120 transitions
Took 0.0029082298278808594s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1084 Step: 85680
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8675098665275648
Updated goal-option-1 on 120 transitions
Took 0.0029191970825195312s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1085 Step: 85800
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.565547888943304
Updated goal-option-2 on 120 transitions
Took 0.0029518604278564453s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1086 Step: 85920
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
11.108335927904895
Updated goal-option-2 on 120 transitions
Took 0.0032389163970947266s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1087 Step: 86040
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1460321936727114
Updated goal-option-1 on 120 transitions
Took 0.003209352493286133s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1088 Step: 86160
================================================================================
[Random] Deep skill graphs target event: SE([10 16])
[Random] DSG selected event SE([10 16])
[Graph Consolidation] From (4, 18) to [10 16]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 16])
Planner goal: SE([ 4 18]), DSC goal: SE([10 16]) and Goal: SE([10 16])
False
False
Rolling out DSC with goal vertex SE([10 16])
Rolling out goal-option-1, from [ 4 18] targeting {'count': 798, 'bonus': 0.03539961627023943, 'player_pos': (10, 16), 'player_x': 10, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22188, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7653815169850283
Updated goal-option-1 on 120 transitions
Took 0.0029058456420898438s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1089 Step: 86280
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
7.349783989290397
Updated goal-option-2 on 120 transitions
Took 0.0028688907623291016s to update distance table with 121 states and events {SE([ 4 18]), None}
================================================================================
[Consolidation] Episode: 1090 Step: 86400
================================================================================
Unconnected Events: [SE([10 15]), SE([10 16])] | Probs: [[0.32471638 0.67528362]]
[BoltzmannClosest] DSG selected event: SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
[-trajReplay] Replaying negative trajectory with positive relabel
10.223765272879973
Updated goal-option-2 on 120 transitions
Took 0.003324747085571289s to update distance table with 121 states and events {SE([ 4 18]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 1091 Step: 86520
================================================================================
[Random] Deep skill graphs target event: SE([10 15])
[Random] DSG selected event SE([10 15])
[Graph Consolidation] From (4, 18) to [10 15]
Revised planner goal vertex to SE([ 4 18]) and dsc goal vertex to SE([10 15])
Planner goal: SE([ 4 18]), DSC goal: SE([10 15]) and Goal: SE([10 15])
False
False
Rolling out DSC with goal vertex SE([10 15])
Rolling out goal-option-2, from [ 4 18] targeting {'count': 172, 'bonus': 0.07624928516630233, 'player_pos': (10, 15), 'player_x': 10, 'player_y': 15, 'room_number': 1, 'jumping': 0, 'dead': False, 'falling': False, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15792, 'has_key': False, 'door_open': True, 'left_door_open': True, 'right_door_open': True}
