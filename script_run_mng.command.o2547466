Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MinigridFourRooms 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MinigridFourRooms/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridFourRooms 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridFourRooms/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridFourRooms/18/initiation_set_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridFourRooms/18/value_function_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridFourRooms/18/accepted_events 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridFourRooms/18/rejected_events 
Creating classifier of type cnn
Creating rainbow with sigma=0.5
Created model-free option global-option with option_idx=0
[DSGTrainer] Adding new SalientEvent  SE([ 8 16])
[Seed=18] Device count: 1 Device Name: NVIDIA GeForce GTX 1080 Ti
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 0 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -13.423153355906834
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 1 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.26699216137058
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 2 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -82.3792712329523
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 3 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -105.11178221873706
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 4 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -84.16328648912895
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 5 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -122.89825440035202
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 6 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -129.61352978955256
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 7 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -111.89461135136662
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 8 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -122.51146097911987
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 9 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -167.17184090986848
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 10 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -153.2723227746901
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 11 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -145.1597758801654
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 12 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -201.8309713145718
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 13 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -187.41638221871108
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 14 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -164.24042227020254
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 15 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -200.78031616968292
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 16 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -192.6234234989388
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 17 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -199.27842560980935
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 18 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -214.71457956370432
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 19 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -249.5628473199904
Accepted New Salient Event:  SE([15  7])
[DSGTrainer] Adding new SalientEvent  SE([15  7])
Took 2.742856025695801s to update distance table with 20040 states and events {SE([15  7]), SE([ 8 16]), None}
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 20 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -210.36407210945617
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 21 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -227.79097197204828
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 22 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -224.46076475875452
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 23 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -217.4520450186683
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 24 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -225.73461980605498
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 25 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -224.9153549913899
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 26 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -232.161371823051
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 27 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -243.15716927638277
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 28 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -112.29979799494322
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 29 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -116.5580611396581
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 30 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -186.5098197710322
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 31 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -233.5660952696344
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 32 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -130.3389753420197
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 33 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -276.57953898236156
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 34 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -272.90547938644886
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 35 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -199.83483249886194
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 36 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -281.9858958190307
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 37 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -241.69607720919885
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 38 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -260.25292467162944
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 39 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -127.75960879118065
Accepted New Salient Event:  SE([9 1])
[DSGTrainer] Adding new SalientEvent  SE([9 1])
Took 1.9988362789154053s to update distance table with 20040 states and events {SE([ 8 16]), SE([9 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -220.62825456319842
Took 0.025152206420898438s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -304.12315890192986
Took 0.020437955856323242s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -272.50389728322625
Took 0.02095651626586914s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -293.82262992998585
Took 0.02487945556640625s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -298.99086848576553
Took 0.025963306427001953s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -292.4107104167342
Took 0.024623632431030273s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -301.565719287144
Took 0.02530050277709961s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -299.53480167189264
Took 0.026752710342407227s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -223.48858098991332
Took 0.025056838989257812s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -283.3702769803349
Took 0.01916360855102539s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -278.70477451354964
Took 0.024903535842895508s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -155.67151086532976
Took 0.019286155700683594s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -110.50926131464075
Took 0.03658127784729004s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -318.1163503676653
Took 0.018768787384033203s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -227.8224103521352
Took 0.02463841438293457s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -310.7166649531573
Took 0.024791479110717773s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -149.43174326844746
Took 0.02484130859375s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -200.68723982496886
Took 0.024526596069335938s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -350.9363585487008
Took 0.02482318878173828s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -334.3695677667856
Took 0.027286529541015625s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -323.12585574761033
Took 0.031081199645996094s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -326.87938670488074
Took 0.02507925033569336s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -270.5345513236607
Took 0.022559165954589844s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -317.6673679254018
Took 0.025194406509399414s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -333.9801859250292
Took 0.021106243133544922s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -326.7429412584752
Took 0.021923542022705078s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -338.6612038332969
Took 0.028019189834594727s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -342.5717741176486
Took 0.025417089462280273s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -267.9416988368612
Took 0.019776582717895508s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.19089424951744
Took 0.02722644805908203s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -343.8802199680358
Took 0.024837017059326172s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -362.9476970732212
Took 0.025527477264404297s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -346.3219704590738
Took 0.054106950759887695s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -299.0683336025104
Took 0.025488853454589844s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -367.9813449457288
Took 0.02464604377746582s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -185.34494565099158
Took 0.025876998901367188s to update distance table with 1001 states and events {SE([ 8 16]), SE([9 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -123.94332768919412
Took 0.024950265884399414s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -363.12410542648286
Took 0.024510860443115234s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -335.0603612246923
Took 0.02714991569519043s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -377.98891669511795
Took 0.026459455490112305s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -355.38169175539224
Took 0.03292584419250488s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -63.78665301477304
Took 0.020287513732910156s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -323.98238928220235
Took 0.02072763442993164s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -355.35632023285143
Took 0.025257349014282227s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -375.8653630428016
Took 0.035077571868896484s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -314.44099378725514
Took 0.025162458419799805s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -103.59428106229461
Took 0.019251585006713867s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -335.262142587002
Took 0.01883411407470703s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -370.14288095757365
Took 0.02221083641052246s to update distance table with 1001 states and events {SE([ 8 16]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -115.66186157608172
Took 0.025232315063476562s to update distance table with 1001 states and events {SE([ 8 16]), None}
[SE([ 8 16]), SE([15  7]), SE([9 1])]
================================================================================
[Consolidation] Episode: 90 Step: 0
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([9 1])
Creating classifier of type cnn
Created model-free option goal-option-1 with option_idx=1
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002355337142944336s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 91 Step: 100
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([15  7])
Creating classifier of type cnn
Created model-free option goal-option-2 with option_idx=2
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002371072769165039s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 92 Step: 200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023806095123291016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 93 Step: 300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024254322052001953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 94 Step: 400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023720264434814453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 95 Step: 500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0018117427825927734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 96 Step: 600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002682924270629883s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 97 Step: 700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002366781234741211s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 98 Step: 800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002371072769165039s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 99 Step: 900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002485036849975586s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 100 Step: 1000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002374410629272461s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 101 Step: 1100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023336410522460938s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 102 Step: 1200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.001986980438232422s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 103 Step: 1300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002354860305786133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 104 Step: 1400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026404857635498047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 105 Step: 1500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024237632751464844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 106 Step: 1600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024225711822509766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 107 Step: 1700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0023467540740966797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 108 Step: 1800
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002362966537475586s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 109 Step: 1900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002408742904663086s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 110 Step: 2000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0024001598358154297s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 111 Step: 2100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023391246795654297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 112 Step: 2200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002482175827026367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 113 Step: 2300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027463436126708984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 114 Step: 2400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0023365020751953125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 115 Step: 2500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002357006072998047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 116 Step: 2600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023851394653320312s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 117 Step: 2700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0027146339416503906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 118 Step: 2800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002460956573486328s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 119 Step: 2900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0019299983978271484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 120 Step: 3000
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024504661560058594s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 121 Step: 3100
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0028243064880371094s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 122 Step: 3200
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002341032028198242s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 123 Step: 3300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026159286499023438s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 124 Step: 3400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0024118423461914062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 125 Step: 3500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002414226531982422s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 126 Step: 3600
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024242401123046875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 127 Step: 3700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0024673938751220703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 128 Step: 3800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027294158935546875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 129 Step: 3900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002435445785522461s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 130 Step: 4000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023794174194335938s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 131 Step: 4100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002447843551635742s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 132 Step: 4200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023851394653320312s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 133 Step: 4300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002367258071899414s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 134 Step: 4400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023946762084960938s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 135 Step: 4500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0025148391723632812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 136 Step: 4600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002382040023803711s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 137 Step: 4700
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024483203887939453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 138 Step: 4800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1])] | Probs: [[0.47386408 0.52613592]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002785205841064453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 139 Step: 4900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.001798868179321289s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=140 Seed=18] Took 0.08240318298339844s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 140 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -366.3657592735253
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 141 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -174.68028052365116
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 142 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -325.3684441706282
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 143 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -376.2511702924967
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 144 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -254.10916302533587
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 145 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -353.0548716012854
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 146 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -405.33359728753567
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 147 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -404.39121297281235
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 148 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -350.8432654081844
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 149 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -416.7940952447243
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 150 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -269.48278859688435
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 151 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -386.2919945642352
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 152 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -416.61116662458517
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 153 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -404.3773404848762
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 154 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -410.6450274195522
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 155 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -424.06424739956856
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 156 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -250.7939761262387
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 157 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -197.37055874773068
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 158 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -399.442583207041
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 159 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -304.56047922946163
Accepted New Salient Event:  SE([5 2])
[DSGTrainer] Adding new SalientEvent  SE([5 2])
Took 2.8036367893218994s to update distance table with 20040 states and events {SE([ 8 16]), None, SE([5 2])}
[Episode=160 Seed=18] Took 0.08163881301879883s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2])]
================================================================================
[Consolidation] Episode: 160 Step: 5000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031723976135253906s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 161 Step: 5100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([5 2])
Creating classifier of type cnn
Created model-free option goal-option-3 with option_idx=3
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0029997825622558594s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 162 Step: 5200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030295848846435547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 163 Step: 5300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031685829162597656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 164 Step: 5400
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0029768943786621094s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 165 Step: 5500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003221273422241211s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 166 Step: 5600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002387523651123047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 167 Step: 5700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0030181407928466797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 168 Step: 5800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032498836517333984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 169 Step: 5900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031023025512695312s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 170 Step: 6000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003003358840942383s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 171 Step: 6100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031003952026367188s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 172 Step: 6200
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030672550201416016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 173 Step: 6300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.002429485321044922s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 174 Step: 6400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031027793884277344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 175 Step: 6500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031957626342773438s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 176 Step: 6600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003053903579711914s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 177 Step: 6700
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030841827392578125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 178 Step: 6800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0029718875885009766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 179 Step: 6900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031218528747558594s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 180 Step: 7000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003002166748046875s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 181 Step: 7100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003072500228881836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 182 Step: 7200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032601356506347656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 183 Step: 7300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002325296401977539s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 184 Step: 7400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003337860107421875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 185 Step: 7500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003286123275756836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 186 Step: 7600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0029916763305664062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 187 Step: 7700
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031380653381347656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 188 Step: 7800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003386259078979492s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 189 Step: 7900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0030460357666015625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 190 Step: 8000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.002816915512084961s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 191 Step: 8100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030372142791748047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 192 Step: 8200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003040790557861328s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 193 Step: 8300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030248165130615234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 194 Step: 8400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032150745391845703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 195 Step: 8500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003062009811401367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 196 Step: 8600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030243396759033203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 197 Step: 8700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031659603118896484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 198 Step: 8800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032072067260742188s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 199 Step: 8900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030553340911865234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 200 Step: 9000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003167390823364258s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 201 Step: 9100
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003077268600463867s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 202 Step: 9200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031766891479492188s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 203 Step: 9300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031147003173828125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 204 Step: 9400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032105445861816406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 205 Step: 9500
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002970457077026367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 206 Step: 9600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003145456314086914s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 207 Step: 9700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0022792816162109375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 208 Step: 9800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003069162368774414s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 209 Step: 9900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2])] | Probs: [[0.32188206 0.3573888  0.32072915]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003126382827758789s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=210 Seed=18] Took 0.04864335060119629s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 210 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -416.2665641094791
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 211 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -414.8363519310951
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 212 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -422.72225167416036
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 213 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.8289959002286
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 214 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -306.7096445799107
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 215 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -312.7824350168812
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 216 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -449.7697203159332
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 217 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -422.726302228868
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 218 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -410.601630163379
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 219 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -438.6435050815344
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 220 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -424.87384461949114
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 221 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -432.5012201219797
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 222 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -440.6097280681133
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 223 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -225.18402215380047
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 224 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -437.8137154355645
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 225 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -449.9511367343366
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 226 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -435.5844016682822
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 227 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -453.15960900485516
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 228 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -453.3153180629015
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 229 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -458.6093158312142
Accepted New Salient Event:  SE([14 10])
[DSGTrainer] Adding new SalientEvent  SE([14 10])
Took 6.838242769241333s to update distance table with 20040 states and events {SE([ 8 16]), SE([14 10]), None}
[Episode=230 Seed=18] Took 0.336745023727417s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])]
================================================================================
[Consolidation] Episode: 230 Step: 10000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([14 10])
Creating classifier of type cnn
Created model-free option goal-option-4 with option_idx=4
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003911256790161133s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 231 Step: 10100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004065752029418945s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 232 Step: 10200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038709640502929688s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 233 Step: 10300
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004019498825073242s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 234 Step: 10400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003952980041503906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 235 Step: 10500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003690958023071289s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 236 Step: 10600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004290580749511719s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 237 Step: 10700
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003794431686401367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 238 Step: 10800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003711700439453125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 239 Step: 10900
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.002875804901123047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 240 Step: 11000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003569364547729492s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 241 Step: 11100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003522157669067383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 242 Step: 11200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038471221923828125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 243 Step: 11300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035812854766845703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 244 Step: 11400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0029883384704589844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 245 Step: 11500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0040357112884521484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 246 Step: 11600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034825801849365234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 247 Step: 11700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037088394165039062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 248 Step: 11800
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037834644317626953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 249 Step: 11900
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037114620208740234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 250 Step: 12000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004567861557006836s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 251 Step: 12100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037109851837158203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 252 Step: 12200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003528594970703125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 253 Step: 12300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038285255432128906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 254 Step: 12400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036840438842773438s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 255 Step: 12500
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037813186645507812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 256 Step: 12600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003016948699951172s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 257 Step: 12700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035593509674072266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 258 Step: 12800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004269838333129883s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 259 Step: 12900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037207603454589844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 260 Step: 13000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036287307739257812s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 261 Step: 13100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003654003143310547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 262 Step: 13200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039141178131103516s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 263 Step: 13300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002850770950317383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 264 Step: 13400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003793001174926758s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 265 Step: 13500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00371551513671875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 266 Step: 13600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003584146499633789s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 267 Step: 13700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037598609924316406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 268 Step: 13800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003856658935546875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 269 Step: 13900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003927469253540039s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 270 Step: 14000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039365291595458984s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 271 Step: 14100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039479732513427734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 272 Step: 14200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038995742797851562s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 273 Step: 14300
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035698413848876953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 274 Step: 14400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037965774536132812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 275 Step: 14500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003638744354248047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 276 Step: 14600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10])] | Probs: [[0.24279212 0.26957446 0.24192249 0.24571094]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003529071807861328s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 277 Step: 14700
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038912296295166016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 278 Step: 14800
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003942251205444336s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 279 Step: 14900
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004026174545288086s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=280 Seed=18] Took 0.055599212646484375s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 280 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -331.8710482020688
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 281 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -246.13042625703383
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 282 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -459.0477272346616
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 283 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -387.496070267749
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 284 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -468.18904938548803
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 285 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -490.6112293154001
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 286 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -454.10484063252807
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 287 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -459.3600100465119
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 288 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -416.18005906930193
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 289 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -413.77117765136063
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 290 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -181.47103147255257
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 291 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -470.5722349733114
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 292 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -462.3725772500038
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 293 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -289.03730349382386
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 294 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -441.0277595545631
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 295 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -271.7231157408969
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 296 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -419.0727179662208
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 297 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.70221441448666
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 298 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -474.2151014767587
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x14584475a100>
================================================================================
[Expansion] Episode: 299 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -427.1287144799717
Accepted New Salient Event:  SE([14 11])
[DSGTrainer] Adding new SalientEvent  SE([14 11])
Took 6.552701711654663s to update distance table with 20040 states and events {SE([14 11]), SE([ 8 16]), SE([14 10]), None}
[Episode=300 Seed=18] Took 0.07634615898132324s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 300 Step: 15000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004485607147216797s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 301 Step: 15100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004285097122192383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 302 Step: 15200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004214763641357422s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 303 Step: 15300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([14 11])
Creating classifier of type cnn
Created model-free option goal-option-5 with option_idx=5
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004618167877197266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 304 Step: 15400
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003910541534423828s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 305 Step: 15500
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004796504974365234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 306 Step: 15600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004025459289550781s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 307 Step: 15700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004531383514404297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 308 Step: 15800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004386425018310547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 309 Step: 15900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004689216613769531s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 310 Step: 16000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004202365875244141s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 311 Step: 16100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004618167877197266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 312 Step: 16200
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004265546798706055s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 313 Step: 16300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003503084182739258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 314 Step: 16400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004041194915771484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 315 Step: 16500
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004454374313354492s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 316 Step: 16600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004366397857666016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 317 Step: 16700
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004547834396362305s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 318 Step: 16800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00392913818359375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 319 Step: 16900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0047953128814697266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 320 Step: 17000
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004497528076171875s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 321 Step: 17100
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004038333892822266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 322 Step: 17200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005171537399291992s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 323 Step: 17300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.013937950134277344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 324 Step: 17400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004626274108886719s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 325 Step: 17500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00470423698425293s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 326 Step: 17600
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0046596527099609375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 327 Step: 17700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0042552947998046875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 328 Step: 17800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0044133663177490234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 329 Step: 17900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004763126373291016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 330 Step: 18000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004160642623901367s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 331 Step: 18100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004263877868652344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 332 Step: 18200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004521369934082031s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 333 Step: 18300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003324270248413086s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 334 Step: 18400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0042209625244140625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 335 Step: 18500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004266023635864258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 336 Step: 18600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004795074462890625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 337 Step: 18700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004084110260009766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 338 Step: 18800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0046842098236083984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 339 Step: 18900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003908872604370117s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 340 Step: 19000
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004295825958251953s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 341 Step: 19100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00428318977355957s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 342 Step: 19200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0048024654388427734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 343 Step: 19300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00356292724609375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 344 Step: 19400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004587888717651367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 345 Step: 19500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00417327880859375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 346 Step: 19600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004604816436767578s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 347 Step: 19700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004748106002807617s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 348 Step: 19800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004225015640258789s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 349 Step: 19900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004361629486083984s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=350 Seed=18] Took 0.05420565605163574s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 350 Step: 20000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035381317138671875s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 351 Step: 20100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0045740604400634766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 352 Step: 20200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004290342330932617s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 353 Step: 20300
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005226850509643555s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 354 Step: 20400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003972053527832031s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 355 Step: 20500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0044672489166259766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 356 Step: 20600
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.005437135696411133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 357 Step: 20700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004767417907714844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 358 Step: 20800
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004607200622558594s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 359 Step: 20900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004212856292724609s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 360 Step: 21000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0046215057373046875s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 361 Step: 21100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0043752193450927734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 362 Step: 21200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004809379577636719s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 363 Step: 21300
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004538536071777344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 364 Step: 21400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004252433776855469s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 365 Step: 21500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0052869319915771484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 366 Step: 21600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00400090217590332s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 367 Step: 21700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004018306732177734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 368 Step: 21800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0040204524993896484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 369 Step: 21900
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004608631134033203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 370 Step: 22000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004761457443237305s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.4836273193359375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 371 Step: 22100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004326820373535156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 372 Step: 22200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0043184757232666016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 373 Step: 22300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0049877166748046875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 374 Step: 22400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004790067672729492s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 375 Step: 22500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004958629608154297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 376 Step: 22600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0033006668090820312s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 377 Step: 22700
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0046041011810302734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 378 Step: 22800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0047528743743896484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 379 Step: 22900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004678487777709961s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 380 Step: 23000
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004585981369018555s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 381 Step: 23100
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0052945613861083984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 382 Step: 23200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004515171051025391s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 383 Step: 23300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004479408264160156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 384 Step: 23400
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00481724739074707s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 385 Step: 23500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00397801399230957s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 386 Step: 23600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00450897216796875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 387 Step: 23700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00400853157043457s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 388 Step: 23800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0047643184661865234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 389 Step: 23900
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004227399826049805s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 390 Step: 24000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00453495979309082s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 1.5974044799804688e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 391 Step: 24100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00464630126953125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 392 Step: 24200
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0043714046478271484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 393 Step: 24300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004850864410400391s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 394 Step: 24400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004392385482788086s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 395 Step: 24500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004651546478271484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 396 Step: 24600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004266262054443359s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 397 Step: 24700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.19249915 0.21373368 0.19180965 0.20115504 0.20080248]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004636049270629883s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 398 Step: 24800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004799365997314453s to update distance table with 101 states and events {SE([14 11]), SE([ 8 16]), SE([14 10]), None}
================================================================================
[Consolidation] Episode: 399 Step: 24900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004462242126464844s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=400 Seed=18] Took 0.04778742790222168s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 400 Step: 25000
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034418106079101562s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 401 Step: 25100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004380464553833008s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 402 Step: 25200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004166603088378906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 403 Step: 25300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003369569778442383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 404 Step: 25400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0045948028564453125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 405 Step: 25500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00437474250793457s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 406 Step: 25600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004572391510009766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 407 Step: 25700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00431060791015625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 408 Step: 25800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004898786544799805s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 409 Step: 25900
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0046520233154296875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 410 Step: 26000
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003210783004760742s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 411 Step: 26100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004422903060913086s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 412 Step: 26200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004160642623901367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 413 Step: 26300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004485607147216797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 414 Step: 26400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005338907241821289s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 415 Step: 26500
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0044612884521484375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 416 Step: 26600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004266023635864258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 417 Step: 26700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004115104675292969s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 418 Step: 26800
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00458073616027832s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 419 Step: 26900
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004585981369018555s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 420 Step: 27000
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032432079315185547s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 421 Step: 27100
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004066944122314453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 422 Step: 27200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004743099212646484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 423 Step: 27300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032930374145507812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 424 Step: 27400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004577159881591797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 425 Step: 27500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004498481750488281s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 426 Step: 27600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004731416702270508s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 427 Step: 27700
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004064083099365234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 428 Step: 27800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004389286041259766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 429 Step: 27900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004659891128540039s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 430 Step: 28000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032088756561279297s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 431 Step: 28100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004391908645629883s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 432 Step: 28200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004101991653442383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 433 Step: 28300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0041463375091552734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 434 Step: 28400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004157543182373047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 435 Step: 28500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005234241485595703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 436 Step: 28600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004622936248779297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 437 Step: 28700
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003433704376220703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 438 Step: 28800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004522085189819336s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 439 Step: 28900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005842447280883789s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 440 Step: 29000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031251907348632812s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 441 Step: 29100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004537105560302734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 442 Step: 29200
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004010200500488281s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 443 Step: 29300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004014015197753906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 444 Step: 29400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004602193832397461s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 445 Step: 29500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004177570343017578s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 446 Step: 29600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004376411437988281s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 447 Step: 29700
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035696029663085938s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 448 Step: 29800
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004837512969970703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 449 Step: 29900
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0044019222259521484s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=450 Seed=18] Took 0.3157386779785156s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 450 Step: 30000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003160238265991211s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 451 Step: 30100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005071878433227539s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 452 Step: 30200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005708932876586914s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 453 Step: 30300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004585981369018555s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 454 Step: 30400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0043315887451171875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 455 Step: 30500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0043332576751708984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 456 Step: 30600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004006385803222656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 457 Step: 30700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034842491149902344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 458 Step: 30800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005781650543212891s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 459 Step: 30900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.005095243453979492s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 460 Step: 31000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003295421600341797s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 461 Step: 31100
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004380941390991211s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 462 Step: 31200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004785299301147461s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 463 Step: 31300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004448890686035156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 464 Step: 31400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004579067230224609s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 465 Step: 31500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004415988922119141s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 466 Step: 31600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0046308040618896484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 467 Step: 31700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004760026931762695s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 468 Step: 31800
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.005379676818847656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 469 Step: 31900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.005056142807006836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 470 Step: 32000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036039352416992188s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 471 Step: 32100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00590825080871582s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 472 Step: 32200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0048296451568603516s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 473 Step: 32300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0043637752532958984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 474 Step: 32400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004855632781982422s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 475 Step: 32500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004944801330566406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 476 Step: 32600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0041561126708984375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 477 Step: 32700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034418106079101562s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 478 Step: 32800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0041697025299072266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 479 Step: 32900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0050814151763916016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 480 Step: 33000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0053217411041259766s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 481 Step: 33100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004621267318725586s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 482 Step: 33200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004377841949462891s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 483 Step: 33300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0040934085845947266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 484 Step: 33400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004539012908935547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 485 Step: 33500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004685878753662109s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 486 Step: 33600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004700422286987305s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 487 Step: 33700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00419926643371582s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 488 Step: 33800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004104137420654297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 489 Step: 33900
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004187822341918945s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 490 Step: 34000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003506183624267578s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 491 Step: 34100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004527091979980469s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 492 Step: 34200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004116058349609375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 493 Step: 34300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004694938659667969s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 494 Step: 34400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004540681838989258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 495 Step: 34500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004090547561645508s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 496 Step: 34600
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005168914794921875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 497 Step: 34700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036346912384033203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 498 Step: 34800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004617452621459961s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 499 Step: 34900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003919363021850586s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=500 Seed=18] Took 0.04629874229431152s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 500 Step: 35000
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004712104797363281s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 501 Step: 35100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004262447357177734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 502 Step: 35200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004307746887207031s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 503 Step: 35300
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004626750946044922s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 504 Step: 35400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004242897033691406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 505 Step: 35500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0045850276947021484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 506 Step: 35600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039637088775634766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 507 Step: 35700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003462553024291992s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 508 Step: 35800
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004843950271606445s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 509 Step: 35900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004468202590942383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 510 Step: 36000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004718303680419922s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 511 Step: 36100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004128932952880859s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 512 Step: 36200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004406929016113281s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 513 Step: 36300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004559755325317383s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 514 Step: 36400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003728151321411133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 515 Step: 36500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004144191741943359s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 516 Step: 36600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039594173431396484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 517 Step: 36700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00393986701965332s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 518 Step: 36800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004818916320800781s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 519 Step: 36900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004174232482910156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 520 Step: 37000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0044116973876953125s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 521 Step: 37100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004282712936401367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 522 Step: 37200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004567384719848633s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 523 Step: 37300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004491090774536133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 524 Step: 37400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00325775146484375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 525 Step: 37500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004570484161376953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 526 Step: 37600
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004015207290649414s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 527 Step: 37700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004478931427001953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 528 Step: 37800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00403141975402832s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 529 Step: 37900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004315853118896484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 530 Step: 38000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004271507263183594s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 1.5735626220703125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 531 Step: 38100
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031790733337402344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 532 Step: 38200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0043489933013916016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 533 Step: 38300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004704713821411133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 534 Step: 38400
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004572391510009766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 535 Step: 38500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004239559173583984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 536 Step: 38600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0042877197265625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 537 Step: 38700
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004050493240356445s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 538 Step: 38800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005301713943481445s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 539 Step: 38900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0065195560455322266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 540 Step: 39000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038573741912841797s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 541 Step: 39100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003979682922363281s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 542 Step: 39200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004316091537475586s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 543 Step: 39300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005249738693237305s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 544 Step: 39400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004317522048950195s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 545 Step: 39500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004396915435791016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 546 Step: 39600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004374027252197266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 547 Step: 39700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005331516265869141s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 548 Step: 39800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003342151641845703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 549 Step: 39900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004561901092529297s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=550 Seed=18] Took 0.05547332763671875s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 550 Step: 40000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004286289215087891s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 551 Step: 40100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004201650619506836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 552 Step: 40200
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004412412643432617s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 553 Step: 40300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004164457321166992s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 554 Step: 40400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004621744155883789s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 555 Step: 40500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00448918342590332s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 556 Step: 40600
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004750967025756836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 557 Step: 40700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0046520233154296875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 558 Step: 40800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0045318603515625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 559 Step: 40900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00413966178894043s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 560 Step: 41000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.15539441 0.17253594 0.15483782 0.25779041 0.25944142]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004599094390869141s to update distance table with 101 states and events {SE([ 8 16]), SE([14 10]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 561 Step: 41100
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00445246696472168s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 562 Step: 41200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004711627960205078s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 563 Step: 41300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004431486129760742s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 564 Step: 41400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004395723342895508s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 565 Step: 41500
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004662513732910156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 566 Step: 41600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0042858123779296875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 567 Step: 41700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00400543212890625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 568 Step: 41800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004220008850097656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 569 Step: 41900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0033278465270996094s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 570 Step: 42000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004299640655517578s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 1.5497207641601562e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 571 Step: 42100
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004239797592163086s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 572 Step: 42200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003999471664428711s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 573 Step: 42300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0041124820709228516s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 574 Step: 42400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004655361175537109s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 575 Step: 42500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0046749114990234375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 576 Step: 42600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003472566604614258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 577 Step: 42700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.005147457122802734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 578 Step: 42800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004112720489501953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 579 Step: 42900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.005410671234130859s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 580 Step: 43000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004499912261962891s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 581 Step: 43100
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005217552185058594s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 582 Step: 43200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0047070980072021484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 583 Step: 43300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004221439361572266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 584 Step: 43400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004679441452026367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 585 Step: 43500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004221439361572266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 586 Step: 43600
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004773855209350586s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 587 Step: 43700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004648685455322266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 588 Step: 43800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0042858123779296875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 589 Step: 43900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004336833953857422s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 590 Step: 44000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004594087600708008s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 591 Step: 44100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004236936569213867s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 592 Step: 44200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004494428634643555s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 593 Step: 44300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0033211708068847656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 594 Step: 44400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004311323165893555s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 595 Step: 44500
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004466533660888672s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 596 Step: 44600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004461765289306641s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 597 Step: 44700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004589557647705078s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 598 Step: 44800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004756927490234375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 599 Step: 44900
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004469394683837891s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=600 Seed=18] Took 0.05185103416442871s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 600 Step: 45000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0031938552856445312s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 601 Step: 45100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0046367645263671875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 602 Step: 45200
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0041675567626953125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 603 Step: 45300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004718303680419922s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 604 Step: 45400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0052700042724609375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 605 Step: 45500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003427267074584961s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 606 Step: 45600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00347900390625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 607 Step: 45700
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0036225318908691406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 608 Step: 45800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003689289093017578s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 609 Step: 45900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036017894744873047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 610 Step: 46000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003660440444946289s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 1.2159347534179688e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 611 Step: 46100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034720897674560547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 612 Step: 46200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038661956787109375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 613 Step: 46300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003394603729248047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 614 Step: 46400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003514528274536133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 615 Step: 46500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037689208984375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 616 Step: 46600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033941268920898438s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 617 Step: 46700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003431081771850586s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 618 Step: 46800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034520626068115234s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 619 Step: 46900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0036780834197998047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 620 Step: 47000
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004665851593017578s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 5.245208740234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 621 Step: 47100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033636093139648438s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 622 Step: 47200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035555362701416016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 623 Step: 47300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00359344482421875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 624 Step: 47400
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0032892227172851562s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 625 Step: 47500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033791065216064453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 626 Step: 47600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0032503604888916016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 627 Step: 47700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035932064056396484s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 628 Step: 47800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003641843795776367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 629 Step: 47900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036139488220214844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 630 Step: 48000
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003351926803588867s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 631 Step: 48100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003133535385131836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 632 Step: 48200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003506898880004883s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 633 Step: 48300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0035953521728515625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 634 Step: 48400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004038810729980469s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 635 Step: 48500
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0031325817108154297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 636 Step: 48600
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00347900390625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 637 Step: 48700
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003198862075805664s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 638 Step: 48800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.12533406 0.13915963 0.12488514 0.40136752 0.20925365]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004360675811767578s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 639 Step: 48900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003448963165283203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 640 Step: 49000
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003262042999267578s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 641 Step: 49100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003446817398071289s to update distance table with 101 states and events {SE([14 11]), SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 642 Step: 49200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.007819414138793945s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 643 Step: 49300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0030760765075683594s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 644 Step: 49400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003468751907348633s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 645 Step: 49500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0034089088439941406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 646 Step: 49600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0035772323608398438s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 647 Step: 49700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036928653717041016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 648 Step: 49800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0031709671020507812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 649 Step: 49900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003794431686401367s to update distance table with 101 states and events {SE([14 11]), SE([ 8 16]), SE([14 10]), None}
[Episode=650 Seed=18] Took 0.0386204719543457s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 650 Step: 50000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0037920475006103516s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 651 Step: 50100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033855438232421875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 652 Step: 50200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036001205444335938s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 653 Step: 50300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003988027572631836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 654 Step: 50400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0034189224243164062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 655 Step: 50500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033698081970214844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 656 Step: 50600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004671573638916016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 657 Step: 50700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037801265716552734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 658 Step: 50800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0034134387969970703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 659 Step: 50900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0036444664001464844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 660 Step: 51000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034928321838378906s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 661 Step: 51100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0035724639892578125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 662 Step: 51200
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003747701644897461s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 663 Step: 51300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00333404541015625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 664 Step: 51400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036585330963134766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 665 Step: 51500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003702402114868164s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 666 Step: 51600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037322044372558594s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 667 Step: 51700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003093242645263672s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 668 Step: 51800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003289461135864258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 669 Step: 51900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003654003143310547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 670 Step: 52000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032291412353515625s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 671 Step: 52100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003357410430908203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 672 Step: 52200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003746509552001953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 673 Step: 52300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003720521926879883s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 674 Step: 52400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036039352416992188s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 675 Step: 52500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037174224853515625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 676 Step: 52600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035665035247802734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 677 Step: 52700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037648677825927734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 678 Step: 52800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035674571990966797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 679 Step: 52900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004888772964477539s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 680 Step: 53000
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004080057144165039s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 681 Step: 53100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036144256591796875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 682 Step: 53200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003502368927001953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 683 Step: 53300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003645181655883789s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 684 Step: 53400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003087282180786133s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 685 Step: 53500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003592967987060547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 686 Step: 53600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033512115478515625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 687 Step: 53700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037076473236083984s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 688 Step: 53800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0035855770111083984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 689 Step: 53900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039234161376953125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 690 Step: 54000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003583669662475586s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 691 Step: 54100
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003406524658203125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 692 Step: 54200
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003912687301635742s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 693 Step: 54300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003226757049560547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 694 Step: 54400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032608509063720703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 695 Step: 54500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038232803344726562s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 696 Step: 54600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003542184829711914s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 697 Step: 54700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003144502639770508s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 698 Step: 54800
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003502368927001953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 699 Step: 54900
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003467559814453125s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=700 Seed=18] Took 0.05516624450683594s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 700 Step: 55000
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032825469970703125s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 701 Step: 55100
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004481077194213867s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 702 Step: 55200
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003488302230834961s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 703 Step: 55300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0030748844146728516s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 704 Step: 55400
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003397226333618164s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 705 Step: 55500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.005417346954345703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 706 Step: 55600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032715797424316406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 707 Step: 55700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003402233123779297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 708 Step: 55800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003587961196899414s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 709 Step: 55900
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033576488494873047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 710 Step: 56000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004903316497802734s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 711 Step: 56100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0035729408264160156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 712 Step: 56200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00311279296875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 713 Step: 56300
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032837390899658203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 714 Step: 56400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032808780670166016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 715 Step: 56500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003579378128051758s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 716 Step: 56600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003549814224243164s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 717 Step: 56700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003615856170654297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 718 Step: 56800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035240650177001953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 719 Step: 56900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038909912109375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 720 Step: 57000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004845857620239258s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 721 Step: 57100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003756999969482422s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 722 Step: 57200
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036733150482177734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 723 Step: 57300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033364295959472656s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 724 Step: 57400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037190914154052734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 725 Step: 57500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004271984100341797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 726 Step: 57600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003418445587158203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 727 Step: 57700
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.005438327789306641s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 728 Step: 57800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031385421752929688s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 729 Step: 57900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038933753967285156s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 730 Step: 58000
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003175497055053711s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 731 Step: 58100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003571033477783203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 732 Step: 58200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003077983856201172s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 733 Step: 58300
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003459453582763672s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 734 Step: 58400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033283233642578125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 735 Step: 58500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003217935562133789s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 736 Step: 58600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003260374069213867s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 737 Step: 58700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004145145416259766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 738 Step: 58800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003072977066040039s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 739 Step: 58900
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038971900939941406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 740 Step: 59000
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003389596939086914s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 741 Step: 59100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034656524658203125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 742 Step: 59200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034444332122802734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 743 Step: 59300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0037970542907714844s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 744 Step: 59400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0034134387969970703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 745 Step: 59500
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003134012222290039s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 746 Step: 59600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033249855041503906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 747 Step: 59700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033435821533203125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 748 Step: 59800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036313533782958984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 749 Step: 59900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003593921661376953s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=750 Seed=18] Took 0.04597020149230957s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 750 Step: 60000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035762786865234375s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 1.3113021850585938e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 751 Step: 60100
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003223896026611328s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 752 Step: 60200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036935806274414062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 753 Step: 60300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003349781036376953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 754 Step: 60400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033235549926757812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 755 Step: 60500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003786802291870117s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 756 Step: 60600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003356456756591797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 757 Step: 60700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003284454345703125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 758 Step: 60800
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003475666046142578s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 759 Step: 60900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003668546676635742s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 760 Step: 61000
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038802623748779297s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 761 Step: 61100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035982131958007812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 762 Step: 61200
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003444671630859375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 763 Step: 61300
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0036132335662841797s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 764 Step: 61400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003361225128173828s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 765 Step: 61500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003908634185791016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 766 Step: 61600
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036602020263671875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 767 Step: 61700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003388643264770508s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 768 Step: 61800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003662109375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 769 Step: 61900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034189224243164062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 770 Step: 62000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040357112884521484s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 771 Step: 62100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037107467651367188s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 772 Step: 62200
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036966800689697266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 773 Step: 62300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003002643585205078s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 774 Step: 62400
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037431716918945312s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 775 Step: 62500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003625154495239258s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 776 Step: 62600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003484964370727539s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 777 Step: 62700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003972768783569336s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 778 Step: 62800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004090547561645508s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 779 Step: 62900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035762786865234375s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 780 Step: 63000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003314971923828125s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 781 Step: 63100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037729740142822266s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 782 Step: 63200
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0037992000579833984s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 783 Step: 63300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003692626953125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 784 Step: 63400
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003410816192626953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 785 Step: 63500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0031273365020751953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 786 Step: 63600
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003908634185791016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 787 Step: 63700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036427974700927734s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 788 Step: 63800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003530263900756836s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 789 Step: 63900
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003788471221923828s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 790 Step: 64000
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.004191875457763672s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 791 Step: 64100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036287307739257812s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 792 Step: 64200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003709554672241211s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 793 Step: 64300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035483837127685547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 794 Step: 64400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003571033477783203s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 795 Step: 64500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003828763961791992s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 796 Step: 64600
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0036537647247314453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 797 Step: 64700
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003470897674560547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 798 Step: 64800
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037071704864501953s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 799 Step: 64900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033576488494873047s to update distance table with 101 states and events {SE([ 8 16]), None}
[Episode=800 Seed=18] Took 0.06979918479919434s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])]
================================================================================
[Consolidation] Episode: 800 Step: 65000
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033228397369384766s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 801 Step: 65100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035877227783203125s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 802 Step: 65200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034475326538085938s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 803 Step: 65300
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036623477935791016s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 804 Step: 65400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037543773651123047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 805 Step: 65500
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038192272186279297s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 806 Step: 65600
================================================================================
[Random] Deep skill graphs target event: SE([14 10])
[Random] DSG selected event SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038309097290039062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 807 Step: 65700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004077434539794922s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 808 Step: 65800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038352012634277344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 809 Step: 65900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004183769226074219s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 810 Step: 66000
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.00316619873046875s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 811 Step: 66100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035507678985595703s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 812 Step: 66200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0033774375915527344s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 813 Step: 66300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033860206604003906s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 814 Step: 66400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0036935806274414062s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 815 Step: 66500
================================================================================
[Random] Deep skill graphs target event: SE([14 11])
[Random] DSG selected event SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0032973289489746094s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 816 Step: 66600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (8, 16) to [5 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([5 2])
Planner goal: SE([ 8 16]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003917694091796875s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 817 Step: 66700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003760814666748047s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 818 Step: 66800
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038111209869384766s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 819 Step: 66900
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003779172897338867s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 820 Step: 67000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038444995880126953s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 821 Step: 67100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003916501998901367s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 822 Step: 67200
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003684520721435547s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 823 Step: 67300
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003603696823120117s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 824 Step: 67400
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 10])
[Graph Consolidation] From (8, 16) to [14 10]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 10])
Planner goal: SE([ 8 16]), DSC goal: SE([14 10]) and Goal: SE([14 10])
False
False
Rolling out DSC with goal vertex SE([14 10])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 10), 'player_x': 14, 'player_y': 10, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003975391387939453s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 825 Step: 67500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003580331802368164s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 826 Step: 67600
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003968238830566406s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 827 Step: 67700
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037784576416015625s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 828 Step: 67800
================================================================================
[Random] Deep skill graphs target event: SE([9 1])
[Random] DSG selected event SE([9 1])
[Graph Consolidation] From (8, 16) to [9 1]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([9 1])
Planner goal: SE([ 8 16]), DSC goal: SE([9 1]) and Goal: SE([9 1])
False
False
Rolling out DSC with goal vertex SE([9 1])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (9, 1), 'player_x': 9, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032339096069335938s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 829 Step: 67900
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.003832101821899414s to update distance table with 101 states and events {SE([ 8 16]), None}
================================================================================
[Consolidation] Episode: 830 Step: 68000
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0038344860076904297s to update distance table with 101 states and events {SE([ 8 16]), None}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 831 Step: 68100
================================================================================
Unconnected Events: [SE([15  7]), SE([9 1]), SE([5 2]), SE([14 10]), SE([14 11])] | Probs: [[0.10405147 0.11552936 0.10367878 0.33321252 0.34352788]]
[BoltzmannClosest] DSG selected event: SE([14 11])
[Graph Consolidation] From (8, 16) to [14 11]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 11])
Planner goal: SE([ 8 16]), DSC goal: SE([14 11]) and Goal: SE([14 11])
False
False
Rolling out DSC with goal vertex SE([14 11])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (14, 11), 'player_x': 14, 'player_y': 11, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
