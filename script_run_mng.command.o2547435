Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MinigridEmpty8x8_distance11 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MinigridEmpty8x8_distance11/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8_distance11 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8_distance11/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8_distance11/18/initiation_set_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8_distance11/18/value_function_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8_distance11/18/accepted_events 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8_distance11/18/rejected_events 
Creating classifier of type cnn
Creating rainbow with sigma=0.5
Created model-free option global-option with option_idx=0
[DSGTrainer] Adding new SalientEvent  SE([1 1])
[Seed=18] Device count: 1 Device Name: NVIDIA GeForce GTX 1080 Ti
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 0 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -4.8108893684111536
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 1 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -106.93801615666598
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 2 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -123.23640893772244
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 3 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -133.06570029718569
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 4 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -160.0335423387587
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 5 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -166.96940742246807
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 6 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -159.78590295789763
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 7 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -194.5926284827292
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 8 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -193.43117959797382
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 9 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -189.70558400615118
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 10 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -188.40895372489467
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 11 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -214.67425579577684
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 12 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -206.61548218410462
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 13 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -223.10521144978702
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 14 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -209.11979171214625
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 15 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -210.5413743229583
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 16 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -229.63307450711727
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 17 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -217.46119605889544
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 18 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -205.8562762683723
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 19 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -244.0985223799944
Accepted New Salient Event:  SE([6 6])
[DSGTrainer] Adding new SalientEvent  SE([6 6])
Accepted New Salient Event:  SE([5 2])
[DSGTrainer] Adding new SalientEvent  SE([5 2])
Took 8.653532981872559s to update distance table with 20040 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 20 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -245.05628093332052
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 21 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -189.1941759530455
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 22 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -255.37254856526852
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 23 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -253.70968797430396
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 24 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -246.73061104118824
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 25 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -212.62098622089252
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 26 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -250.52616789750755
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 27 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -250.4578506128164
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 28 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -253.76832196314353
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 29 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -245.477128271712
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 30 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -270.8245579376817
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 31 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -237.92716918248334
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 32 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -233.34327741223387
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 33 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -277.69959032535553
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 34 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -252.72204781509936
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 35 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -241.49574212206062
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 36 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -269.7742525944486
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 37 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -275.5770279094577
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 38 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -268.2257986149634
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 39 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -278.7873528015334
Accepted New Salient Event:  SE([2 5])
[DSGTrainer] Adding new SalientEvent  SE([2 5])
Took 13.267531633377075s to update distance table with 20040 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -236.1833003796637
Took 0.047913312911987305s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -288.58593356702477
Took 0.054810285568237305s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -268.2182427130174
Took 0.04850625991821289s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -275.5526057481766
Took 0.06528329849243164s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -285.2750754763838
Took 0.06350302696228027s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -242.01201377203688
Took 0.05085444450378418s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -238.87930549691373
Took 0.05292654037475586s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -265.7358913118951
Took 0.05910825729370117s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 2.0	IntrinsicReward: -245.0616569030608
Took 0.05651736259460449s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -291.6351917758584
Took 0.05344128608703613s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -239.1914000827819
Took 0.07097387313842773s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -283.71729429252446
Took 0.057036638259887695s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -280.0702535044402
Took 0.07399868965148926s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -231.97677276679315
Took 0.06540369987487793s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -265.91472459817305
Took 0.06081271171569824s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -301.2450915744994
Took 0.04995322227478027s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -288.6278209704906
Took 0.054532527923583984s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -280.08252635458484
Took 0.05276036262512207s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -290.19174486852717
Took 0.06433248519897461s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -284.4911182979122
Took 0.06878185272216797s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -256.77653560062754
Took 0.05001378059387207s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -277.59622882975964
Took 0.05670499801635742s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -285.39713829325046
Took 0.04082894325256348s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -297.73598219512496
Took 0.0686182975769043s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -283.647591305853
Took 0.05956006050109863s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -304.8455757200718
Took 0.04429817199707031s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -292.782965246588
Took 0.040250539779663086s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -295.26997300889343
Took 0.05058908462524414s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -288.16573897679336
Took 0.055411577224731445s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -234.67013070584653
Took 0.04267120361328125s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -320.57512878999114
Took 0.03072524070739746s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -304.4375366641907
Took 0.04934549331665039s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -303.68609185004607
Took 0.058152198791503906s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -297.2658834680915
Took 0.04300642013549805s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -273.96850077988347
Took 0.0916140079498291s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -297.9414364330005
Took 0.059411048889160156s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -308.27172447554767
Took 0.05780458450317383s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -251.92055809637532
Took 0.06416726112365723s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -317.85805972106755
Took 0.05976557731628418s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
[RND Rollout] Reward: 2.0	IntrinsicReward: -293.26922835886944
Took 0.05942058563232422s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -301.7632448395598
Took 0.06596732139587402s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -323.7118591243634
Took 0.06369900703430176s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -306.16556333284825
Took 0.049199819564819336s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -300.77591043151915
Took 0.05236172676086426s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -286.3080453691073
Took 0.05348825454711914s to update distance table with 1001 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -313.56167372572236
Took 0.07058262825012207s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -340.4168211799115
Took 0.07519769668579102s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -296.8659569094307
Took 0.05711483955383301s to update distance table with 1001 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -312.04962727916427
Took 0.09841489791870117s to update distance table with 1001 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -328.8685627072118
Took 0.05567622184753418s to update distance table with 1001 states and events {SE([2 5]), None, SE([1 1])}
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 90 Step: 0
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[DeepSkillGraphsAgent] Creating chain from SE([1 1]) -> SE([2 5])
Creating classifier of type cnn
Created model-free option goal-option-1 with option_idx=1
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-1 on 91 transitions
Took 0.0029861927032470703s to update distance table with 92 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99878594e-01 1.04451461e-04 1.69546250e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[DeepSkillGraphsAgent] Creating chain from SE([2 5]) -> SE([1 1])
Creating classifier of type cnn
Created model-free option goal-option-2 with option_idx=2
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 72 transitions
Took 0.002468109130859375s to update distance table with 73 states and events {SE([2 5]), None, SE([6 6])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 91 Step: 163
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-1 on 73 transitions
Took 0.002427816390991211s to update distance table with 74 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99878594e-01 1.04451461e-04 1.69546250e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 14 transitions
Took 0.00051116943359375s to update distance table with 15 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 92 Step: 250
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1515, 'bonus': 0.025691749776935398, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-1 on 168 transitions
Took 0.006066799163818359s to update distance table with 169 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[Random] Deep skill graphs target event: SE([6 6])
[Random] DSG selected event SE([6 6])
[DeepSkillGraphsAgent] Creating chain from SE([2 5]) -> SE([6 6])
Creating classifier of type cnn
Created model-free option goal-option-3 with option_idx=3
[Graph Consolidation] From (2, 5) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [2 5] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 88 transitions
Took 0.003020763397216797s to update distance table with 89 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 93 Step: 506
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.024220540409996
Updated goal-option-1 on 166 transitions
Took 0.005601167678833008s to update distance table with 167 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 94 Step: 672
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1524, 'bonus': 0.025615775978927998, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
9.767642383774122
Updated goal-option-1 on 134 transitions
Took 0.004465579986572266s to update distance table with 135 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 95 Step: 806
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1515, 'bonus': 0.025691749776935398, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.9577201197544736
Updated goal-option-1 on 236 transitions
Took 0.009209871292114258s to update distance table with 237 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[DeepSkillGraphsAgent] Creating chain from SE([2 5]) -> SE([5 2])
Creating classifier of type cnn
Created model-free option goal-option-4 with option_idx=4
[Graph Consolidation] From (2, 5) to [5 2]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([5 2])
Planner goal: SE([2 5]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [2 5] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 20 transitions
Took 0.0007216930389404297s to update distance table with 21 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 96 Step: 1062
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
15.459087805615532
Updated goal-option-4 on 215 transitions
Took 0.007165431976318359s to update distance table with 216 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[DeepSkillGraphsAgent] Creating chain from SE([5 2]) -> SE([1 1])
Creating classifier of type cnn
Created model-free option goal-option-5 with option_idx=5
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 19 transitions
Took 0.0006608963012695312s to update distance table with 20 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 97 Step: 1296
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
12.300511196255684
Updated goal-option-4 on 256 transitions
Took 0.009450197219848633s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 98 Step: 1552
================================================================================
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1522, 'bonus': 0.0256326007925508, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8982029995231917
Updated goal-option-1 on 238 transitions
Took 0.009316205978393555s to update distance table with 239 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 15 transitions
Took 0.0005412101745605469s to update distance table with 16 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 99 Step: 1805
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1531, 'bonus': 0.02555714898303573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.2964802697682996
Updated goal-option-1 on 146 transitions
Took 0.0053501129150390625s to update distance table with 147 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
24.6670911749204
Updated goal-option-2 on 27 transitions
Took 0.0009565353393554688s to update distance table with 28 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1524, 'bonus': 0.025615775978927998, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.037919998831219
Updated goal-option-1 on 43 transitions
Took 0.0013804435729980469s to update distance table with 44 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 100 Step: 2021
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([6 6])
Planner goal: SE([1 1]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [1 1] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
15.041258702675501
Updated goal-option-3 on 84 transitions
Took 0.0027222633361816406s to update distance table with 85 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 101 Step: 2105
================================================================================
[Random] Deep skill graphs target event: SE([5 2])
[Random] DSG selected event SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
10.754851581321823
Updated goal-option-4 on 56 transitions
Took 0.0017740726470947266s to update distance table with 57 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.38853761 0.22292478 0.38853761]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
18.590640767415362
Updated goal-option-2 on 20 transitions
Took 0.0007150173187255859s to update distance table with 21 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 102 Step: 2181
================================================================================
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1515, 'bonus': 0.025691749776935398, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.7765215169638395
Updated goal-option-1 on 256 transitions
Took 0.011141777038574219s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 103 Step: 2437
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
10.77595209791547
Updated goal-option-4 on 138 transitions
Took 0.006474971771240234s to update distance table with 139 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 104 Step: 2575
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1524, 'bonus': 0.025615775978927998, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.6607640244894557
Updated goal-option-1 on 256 transitions
Took 0.01097559928894043s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 105 Step: 2831
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.748291782119818
Updated goal-option-1 on 103 transitions
Took 0.0034384727478027344s to update distance table with 104 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
11.23861911892891
Updated goal-option-2 on 31 transitions
Took 0.001081705093383789s to update distance table with 32 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 106 Step: 2965
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
11.232138988044527
Updated goal-option-4 on 228 transitions
Took 0.010003805160522461s to update distance table with 229 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([2 5])
Planner goal: SE([5 2]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [5 2] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.169969745973746
Updated goal-option-1 on 28 transitions
Took 0.0010066032409667969s to update distance table with 29 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 107 Step: 3221
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1545, 'bonus': 0.025441092565739218, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.992746376404257
Updated goal-option-1 on 123 transitions
Took 0.005172014236450195s to update distance table with 124 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
30.77721881121397
Updated goal-option-2 on 102 transitions
Took 0.0034210681915283203s to update distance table with 103 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 108 Step: 3446
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1642, 'bonus': 0.0246781968201642, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3193, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.952879432837168
Updated goal-option-4 on 30 transitions
Took 0.0008740425109863281s to update distance table with 31 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([2 5])
Planner goal: SE([5 2]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [5 2] targeting {'count': 1522, 'bonus': 0.0256326007925508, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9690556575854616
Updated goal-option-1 on 10 transitions
Took 0.00038170814514160156s to update distance table with 11 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 109 Step: 3486
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1515, 'bonus': 0.025691749776935398, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8109675178097355
Updated goal-option-1 on 256 transitions
Took 0.010549545288085938s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 110 Step: 3742
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.02114239 0.62198918 0.35686842]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9839674760070112
Updated goal-option-1 on 14 transitions
Took 0.0004076957702636719s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
7.120263963054728
Updated goal-option-2 on 52 transitions
Took 0.0018227100372314453s to update distance table with 53 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1, from [1 1] targeting {'count': 1545, 'bonus': 0.025441092565739218, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.4670042332548365
Updated goal-option-1 on 179 transitions
Creating goal-option-1-0 with parent goal-option-1
Creating classifier of type cnn
Created model-free option goal-option-1-0 with option_idx=6
Case 3: Adding edge from goal-option-1 to SE([2 5])
Took 0.005940675735473633s to update distance table with 180 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
14.836979625622432
Updated goal-option-2 on 11 transitions
Took 0.0005738735198974609s to update distance table with 12 states and events {SE([2 5]), None}
Adding edge from SE([2 5]) to goal-option-1
Took 0.11141443252563477s to add potential edges.
================================================================================
[Consolidation] Episode: 111 Step: 3998
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1-0, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-1-0 on 10 transitions
Rolling out goal-option-1, from [1 1] targeting {'count': 1545, 'bonus': 0.025441092565739218, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.400103873085408
Updated goal-option-1 on 104 transitions
Took 0.004540681838989258s to update distance table with 115 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.162844537484525
Updated goal-option-2 on 142 transitions
Took 0.005032062530517578s to update distance table with 143 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 112 Step: 4254
================================================================================
[Random] Deep skill graphs target event: SE([6 6])
[Random] DSG selected event SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([6 6])
Planner goal: SE([1 1]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [1 1] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.33137332201004
Updated goal-option-3 on 96 transitions
Took 0.003286123275756836s to update distance table with 97 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 113 Step: 4350
================================================================================
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1-0, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-1-0 on 102 transitions
True
False
[Planner] Rolling out from {'count': 1517, 'bonus': 0.025674808298154838, 'player_pos': (4, 3), 'player_x': 4, 'player_y': 3, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [4 3] targeting {'count': 1562, 'bonus': 0.025302269968462875, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3591804648267811
Updated goal-option-1 on 154 transitions
Took 0.008632898330688477s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 114 Step: 4606
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4606, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1531, 'bonus': 0.02555714898303573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.495825855802464
Updated goal-option-1 on 88 transitions
Took 0.0028526782989501953s to update distance table with 89 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 115 Step: 4694
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1-0, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1-0 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-1-0 on 95 transitions
Rolling out goal-option-1, from [1 2] targeting {'count': 1515, 'bonus': 0.025691749776935398, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.761146830084423
Updated goal-option-1 on 148 transitions
Took 0.011930227279663086s to update distance table with 244 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 116 Step: 4937
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.27481369011932
Updated goal-option-4 on 256 transitions
Took 0.011059999465942383s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 117 Step: 5193
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1639, 'bonus': 0.024700771787671945, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2161, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.114109862309236
Updated goal-option-4 on 62 transitions
Took 0.0021457672119140625s to update distance table with 63 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.38853761 0.22292478 0.38853761]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
9.179143266800121
Updated goal-option-2 on 53 transitions
Took 0.001804351806640625s to update distance table with 54 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8463, 'bonus': 0.010870207379990003, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6661815346748219
Updated goal-option-1 on 79 transitions
Took 0.002838611602783203s to update distance table with 80 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99789419e-01 1.74417840e-04 3.61626648e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
8.187544438574049
Updated goal-option-2 on 62 transitions
Took 0.0030829906463623047s to update distance table with 63 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 118 Step: 5449
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1-0, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.296170488331053
Updated goal-option-1-0 on 83 transitions
Took 0.0028297901153564453s to update distance table with 84 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 119 Step: 5532
================================================================================
[Random] Deep skill graphs target event: SE([6 6])
[Random] DSG selected event SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([6 6])
Planner goal: SE([1 1]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [1 1] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.6952123272986634
Updated goal-option-3 on 256 transitions
Took 0.008475542068481445s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 120 Step: 5788
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probs: [[0.01671176 0.49164412 0.49164412]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1639, 'bonus': 0.024700771787671945, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2161, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.626680682765113
Updated goal-option-4 on 133 transitions
Took 0.0054988861083984375s to update distance table with 134 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.38853761 0.22292478 0.38853761]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([2 5])
Planner goal: SE([5 2]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1-0, from [5 2] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1-0 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.232935407923328
Updated goal-option-1-0 on 13 transitions
True
False
[Planner] Rolling out from {'count': 1595, 'bonus': 0.02503915429180672, 'player_pos': (4, 4), 'player_x': 4, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [4 4] targeting {'count': 1522, 'bonus': 0.0256326007925508, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.368197548996519
Updated goal-option-1 on 110 transitions
Took 0.004134178161621094s to update distance table with 124 states and events {SE([5 2]), None}
Took 4.076957702636719e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 121 Step: 6044
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1639, 'bonus': 0.024700771787671945, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2161, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.7834962091098228
Updated goal-option-4 on 256 transitions
Took 0.009280681610107422s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 122 Step: 6300
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1642, 'bonus': 0.0246781968201642, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3193, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.645008483418712
Updated goal-option-4 on 63 transitions
Took 0.0016562938690185547s to update distance table with 64 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 123 Step: 6363
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.984490488966306
Updated goal-option-4 on 256 transitions
Took 0.009525060653686523s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 124 Step: 6619
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6619, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.018367906411489
Updated goal-option-1 on 256 transitions
Took 0.00958871841430664s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 125 Step: 6875
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1545, 'bonus': 0.025441092565739218, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.2565160890420275
Updated goal-option-1 on 99 transitions
Took 0.0032885074615478516s to update distance table with 100 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99785287e-01 1.74417119e-04 4.02958386e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
6.889250862598419
Updated goal-option-2 on 14 transitions
Took 0.0005459785461425781s to update distance table with 15 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8762, 'bonus': 0.010683126613865841, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1554, 'bonus': 0.02536731447159205, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8778833242754143
Updated goal-option-1 on 143 transitions
Took 0.004503726959228516s to update distance table with 144 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 126 Step: 7131
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1557, 'bonus': 0.025342864042323516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.1568714850951753
Updated goal-option-1 on 138 transitions
Took 0.005220890045166016s to update distance table with 139 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 127 Step: 7269
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.3096387741111575
Updated goal-option-4 on 48 transitions
Took 0.001837015151977539s to update distance table with 49 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.38853761 0.22292478 0.38853761]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3657, 'bonus': 0.016536268671305282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
7.2150408004721
Updated goal-option-3 on 102 transitions
Took 0.0034003257751464844s to update distance table with 103 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 128 Step: 7419
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.225061969701634
Updated goal-option-1 on 33 transitions
Took 0.0012013912200927734s to update distance table with 34 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 129 Step: 7452
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.842313238244126
Updated goal-option-4 on 256 transitions
Took 0.010801553726196289s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 130 Step: 7708
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1557, 'bonus': 0.025342864042323516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.7451817297273213
Updated goal-option-1 on 58 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [2 5] targeting {'count': 3663, 'bonus': 0.016522719903220323, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4350, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8906530280907947
Updated goal-option-3 on 57 transitions
Took 0.003957271575927734s to update distance table with 116 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Took 5.1975250244140625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 131 Step: 7823
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.372076686057779
Updated goal-option-4 on 256 transitions
Took 0.009209871292114258s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 132 Step: 8079
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1522, 'bonus': 0.0256326007925508, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7387685665377866
Updated goal-option-1 on 12 transitions
Took 0.0004532337188720703s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[9.99785287e-01 1.74417119e-04 4.02958386e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.7330220277402915
Updated goal-option-2 on 240 transitions
Took 0.009308338165283203s to update distance table with 241 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4951937821176315
Updated goal-option-1 on 4 transitions
Took 9.965896606445312e-05s to update distance table with 5 states and events {SE([1 1])}
================================================================================
[Consolidation] Episode: 133 Step: 8335
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1347758182397125
Updated goal-option-1 on 64 transitions
Took 0.0020651817321777344s to update distance table with 65 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[Random] Deep skill graphs target event: SE([6 6])
[Random] DSG selected event SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [2 5] targeting {'count': 3657, 'bonus': 0.016536268671305282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.036568438013396
Updated goal-option-3 on 192 transitions
Took 0.007529258728027344s to update distance table with 193 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 134 Step: 8591
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([5 2])
Planner goal: SE([2 5]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8591, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.491340841063195
Updated goal-option-1 on 83 transitions
Took 0.003076314926147461s to update distance table with 84 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 135 Step: 8674
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
Expanding goal-option-1's pessimistic classifier to include SE([1 1])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([5 2])
Planner goal: SE([2 5]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8674, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1562, 'bonus': 0.025302269968462875, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5996659655372303
Updated goal-option-1 on 158 transitions
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [2 5] targeting {'count': 1646, 'bonus': 0.024648192922358196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.669626236726076
Updated goal-option-4 on 46 transitions
Took 0.01009058952331543s to update distance table with 205 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.38853761 0.22292478 0.38853761]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8440243701140084
Updated goal-option-2 on 52 transitions
Took 0.0021631717681884766s to update distance table with 53 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 136 Step: 8930
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([5 2])
Planner goal: SE([2 5]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8930, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1531, 'bonus': 0.02555714898303573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1857664092228963
Updated goal-option-1 on 54 transitions
Took 0.0015876293182373047s to update distance table with 55 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 137 Step: 8984
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([5 2])
Planner goal: SE([2 5]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8984, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1569, 'bonus': 0.02524576458934144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9528021994251874
Updated goal-option-1 on 256 transitions
Took 0.00976419448852539s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 138 Step: 9240
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.03287413 0.96712587]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([5 2])
Planner goal: SE([2 5]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9240, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1531, 'bonus': 0.02555714898303573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7639988935354984
Updated goal-option-1 on 256 transitions
Took 0.008535385131835938s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 139 Step: 9496
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1562, 'bonus': 0.025302269968462875, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.613143944491943
Updated goal-option-1 on 256 transitions
Took 0.009542703628540039s to update distance table with 257 states and events {None, SE([1 1])}
[Episode=140 Seed=18] Took 0.05692481994628906s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 140 Step: 9752
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9752, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1654, 'bonus': 0.02458851198024517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.181294654121344
Updated goal-option-1 on 58 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 141 Step: 9810
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9810, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1562, 'bonus': 0.025302269968462875, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5695117675595813
Updated goal-option-1 on 110 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -338.5580406151712
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 142 Step: 9920
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9920, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1545, 'bonus': 0.025441092565739218, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7651531256613184
Updated goal-option-1 on 233 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 143 Step: 10153
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1554, 'bonus': 0.02536731447159205, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.924865414856603
Updated goal-option-1 on 142 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 144 Step: 10295
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10295, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1669, 'bonus': 0.024477768982403232, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9920, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4060793189176668
Updated goal-option-1 on 114 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -336.54565442353487
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 145 Step: 10409
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1562, 'bonus': 0.025302269968462875, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2037925542605044
Updated goal-option-1 on 85 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 146 Step: 10494
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10494, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.0635852552765046
Updated goal-option-1 on 211 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 147 Step: 10705
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10705, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1641, 'bonus': 0.024685714930565622, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.015051300254997
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 148 Step: 10961
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10961, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1569, 'bonus': 0.02524576458934144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.737364045471093
Updated goal-option-1 on 88 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -327.45373128261417
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 149 Step: 11049
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1557, 'bonus': 0.025342864042323516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5413766703395932
Updated goal-option-1 on 247 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -311.9604084359016
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 150 Step: 11296
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1590, 'bonus': 0.02507849312877596, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.571658444431451
Updated goal-option-1 on 40 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -329.3254985753447
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 151 Step: 11336
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11336, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9671378066804672
Updated goal-option-1 on 127 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -314.48198132170364
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 152 Step: 11463
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1653, 'bonus': 0.02459594839716409, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3726602696963663
Updated goal-option-1 on 39 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -298.5844912994653
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 153 Step: 11502
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11502, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1554, 'bonus': 0.02536731447159205, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8461870475966704
Updated goal-option-1 on 109 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -284.75290908291936
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 154 Step: 11611
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11611, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1546, 'bonus': 0.02543286319707309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9485529743134976
Updated goal-option-1 on 83 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 155 Step: 11694
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1687, 'bonus': 0.02434683198329917, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6464991613670632
Updated goal-option-1 on 82 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 156 Step: 11776
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11776, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1606, 'bonus': 0.02495325642529748, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6974, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.907835788635844
Updated goal-option-1 on 124 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -335.78243025392294
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 157 Step: 11900
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1569, 'bonus': 0.02524576458934144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.913661490120585
Updated goal-option-1 on 47 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 158 Step: 11947
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11947, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1569, 'bonus': 0.02524576458934144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9271110073309535
Updated goal-option-1 on 68 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -309.6824494418688
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 159 Step: 12015
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1697, 'bonus': 0.02427499107135649, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2823064880389154
Updated goal-option-1 on 84 transitions
Took 6.7835564613342285s to update distance table with 12377 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=160 Seed=18] Took 0.09725785255432129s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 160 Step: 12099
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12099, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9480166397291176
Updated goal-option-1 on 57 transitions
Took 0.0017192363739013672s to update distance table with 58 states and events {None, SE([1 1]), SE([6 6])}
Took 2.7894973754882812e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 161 Step: 12156
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[DeepSkillGraphsAgent] Creating chain from SE([1 1]) -> SE([5 2])
Creating classifier of type cnn
Created model-free option goal-option-6 with option_idx=7
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.025780458535467
Updated goal-option-4 on 191 transitions
Took 0.00809168815612793s to update distance table with 192 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 162 Step: 12347
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1646, 'bonus': 0.024648192922358196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.240671829930667
Updated goal-option-4 on 54 transitions
Took 0.001865386962890625s to update distance table with 55 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.24983784 0.50032432 0.24983784]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.5101584325234096
Updated goal-option-2 on 199 transitions
Took 0.008630752563476562s to update distance table with 200 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 163 Step: 12600
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4, from [1 1] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.4636469906376255
Updated goal-option-4 on 177 transitions
Creating goal-option-4-0 with parent goal-option-4
Creating classifier of type cnn
Created model-free option goal-option-4-0 with option_idx=8
Case 3: Adding edge from goal-option-4 to SE([5 2])
Took 0.006249904632568359s to update distance table with 178 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[Random] Deep skill graphs target event: SE([2 5])
[Random] DSG selected event SE([2 5])
[DeepSkillGraphsAgent] Creating chain from SE([5 2]) -> SE([2 5])
Creating classifier of type cnn
Created model-free option goal-option-7 with option_idx=9
[Graph Consolidation] From (5, 2) to [2 5]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([2 5])
Planner goal: SE([5 2]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-1-0, from [5 2] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1-0 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.6472408957779408
Updated goal-option-1-0 on 54 transitions
True
False
[Planner] Rolling out from {'count': 1560, 'bonus': 0.025318484177091666, 'player_pos': (3, 4), 'player_x': 3, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12831, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [3 4] targeting {'count': 1590, 'bonus': 0.02507849312877596, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.147438540061315
Updated goal-option-1 on 25 transitions
Took 0.002683401107788086s to update distance table with 80 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 164 Step: 12856
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1646, 'bonus': 0.024648192922358196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.3199791548152766
Updated goal-option-4 on 137 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3671, 'bonus': 0.01650470657553921, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.2669153354870963
Updated goal-option-3 on 43 transitions
Took 0.006294727325439453s to update distance table with 181 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 165 Step: 13036
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1956, 'bonus': 0.022610781582306727, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12993, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9496755731456419
Updated goal-option-4 on 130 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3669, 'bonus': 0.016509204383655284, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
6.675138805617416
Updated goal-option-3 on 78 transitions
Took 0.007173299789428711s to update distance table with 209 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 166 Step: 13244
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 11 transitions
Rolling out goal-option-4, from [1 2] targeting {'count': 1639, 'bonus': 0.024700771787671945, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2161, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.587545309464137
Updated goal-option-4 on 229 transitions
Took 0.009662151336669922s to update distance table with 241 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[0.33304511 0.66695489]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3657, 'bonus': 0.016536268671305282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.256852057907316
Updated goal-option-3 on 16 transitions
Took 0.0006017684936523438s to update distance table with 17 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 167 Step: 13500
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1968, 'bonus': 0.022541740866685808, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13484, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8420179223155115
Updated goal-option-4 on 136 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3669, 'bonus': 0.016509204383655284, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.382550071304043
Updated goal-option-3 on 16 transitions
Took 0.005337238311767578s to update distance table with 153 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 168 Step: 13652
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 22 transitions
True
False
[Planner] Rolling out from {'count': 2405, 'bonus': 0.02039118475715464, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13674, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 1701, 'bonus': 0.024246432248443597, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5921, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.1485227488719665
Updated goal-option-4 on 10 transitions
Took 0.0010907649993896484s to update distance table with 33 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.24983784 0.50032432 0.24983784]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3669, 'bonus': 0.016509204383655284, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.841164351094003
Updated goal-option-3 on 224 transitions
Took 0.007621049880981445s to update distance table with 225 states and events {SE([1 1]), SE([5 2]), None}
================================================================================
[Consolidation] Episode: 169 Step: 13908
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1641, 'bonus': 0.024685714930565622, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0699304993385854
Updated goal-option-1 on 64 transitions
Took 0.0019237995147705078s to update distance table with 65 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 1766, 'bonus': 0.023796037813647444, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 1637, 'bonus': 0.024715856229864275, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7295882863956589
Updated goal-option-4 on 12 transitions
Took 0.0005314350128173828s to update distance table with 13 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 170 Step: 13984
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13984, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1642, 'bonus': 0.0246781968201642, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3193, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7571614955225563
Updated goal-option-4 on 166 transitions
Took 0.00650787353515625s to update distance table with 167 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from SE([5 2]) to goal-option-4
Took 0.14100360870361328s to add potential edges.
================================================================================
[Consolidation] Episode: 171 Step: 14150
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 146 transitions
True
False
[Planner] Rolling out from {'count': 1925, 'bonus': 0.02279211529192759, 'player_pos': (4, 2), 'player_x': 4, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [4 2] targeting {'count': 1739, 'bonus': 0.023980056885558414, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.381415846198797
Updated goal-option-4 on 10 transitions
Took 0.004914045333862305s to update distance table with 157 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.24983784 0.50032432 0.24983784]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 4399, 'bonus': 0.015077280653594389, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13652, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.761663042139589
Updated goal-option-3 on 100 transitions
Took 0.0035576820373535156s to update distance table with 101 states and events {SE([1 1]), SE([5 2]), None}
================================================================================
[Consolidation] Episode: 172 Step: 14406
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1678, 'bonus': 0.0244120371254637, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1091434699232863
Updated goal-option-1 on 45 transitions
Took 0.0015292167663574219s to update distance table with 46 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 1767, 'bonus': 0.023789303403490326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 1960, 'bonus': 0.022587697572631283, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13166, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6472264411972792
Updated goal-option-4 on 49 transitions
Took 0.0017194747924804688s to update distance table with 50 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 173 Step: 14500
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1949, 'bonus': 0.022651349466027825, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12777, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.4057302604625037
Updated goal-option-4 on 39 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3657, 'bonus': 0.016536268671305282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.6673771594961484
Updated goal-option-3 on 39 transitions
Took 0.002907276153564453s to update distance table with 79 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 174 Step: 14578
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1669, 'bonus': 0.024477768982403232, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9920, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2992800140211767
Updated goal-option-1 on 42 transitions
Took 0.0014438629150390625s to update distance table with 43 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 175 Step: 14620
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14620, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1995, 'bonus': 0.022388683141982252, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.222930387565584
Updated goal-option-4 on 159 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 3663, 'bonus': 0.016522719903220323, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4350, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.8715655550812227
Updated goal-option-3 on 97 transitions
Took 0.008536338806152344s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 176 Step: 14876
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14876, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1995, 'bonus': 0.022388683141982252, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5330125607442167
Updated goal-option-4 on 55 transitions
Took 0.0018265247344970703s to update distance table with 56 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 177 Step: 14931
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14931, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6428745782029803
Updated goal-option-4 on 13 transitions
Took 0.0005233287811279297s to update distance table with 14 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.40010374 0.40010374 0.19979252]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.53436755227006
Updated goal-option-3 on 243 transitions
Took 0.008864641189575195s to update distance table with 244 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 178 Step: 15187
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1654, 'bonus': 0.02458851198024517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1943130361744099
Updated goal-option-1 on 256 transitions
Took 0.008585214614868164s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 179 Step: 15443
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 70 transitions
True
False
[Planner] Rolling out from {'count': 2416, 'bonus': 0.020344711469278985, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 1701, 'bonus': 0.024246432248443597, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5921, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8900843225419521
Updated goal-option-4 on 48 transitions
Deleting edge from SE([5 2]) to goal-option-4
Took 0.004212379455566406s to update distance table with 119 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.40010374 0.40010374 0.19979252]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.6624341148232653
Updated goal-option-2 on 24 transitions
Took 0.0008673667907714844s to update distance table with 25 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 180 Step: 15585
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15585, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1713, 'bonus': 0.024161356785259637, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6383068207980822
Updated goal-option-4 on 255 transitions
Took 0.00970458984375s to update distance table with 256 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from SE([5 2]) to goal-option-4
Took 0.16427826881408691s to add potential edges.
================================================================================
[Consolidation] Episode: 181 Step: 15840
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 99 transitions
True
False
[Planner] Rolling out from {'count': 2419, 'bonus': 0.020332091984056118, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15939, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 1949, 'bonus': 0.022651349466027825, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12777, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5063632080952327
Updated goal-option-4 on 6 transitions
Took 0.0033991336822509766s to update distance table with 106 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.40010374 0.40010374 0.19979252]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.4504748515288037
Updated goal-option-3 on 81 transitions
Took 0.0032329559326171875s to update distance table with 82 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 182 Step: 16026
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1968, 'bonus': 0.022541740866685808, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13484, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7689071243105372
Updated goal-option-4 on 239 transitions
Took 0.007850170135498047s to update distance table with 240 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 183 Step: 16265
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1646, 'bonus': 0.024648192922358196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9490669965744019
Updated goal-option-4 on 162 transitions
Took 0.005417823791503906s to update distance table with 163 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 184 Step: 16427
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16427, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1678, 'bonus': 0.0244120371254637, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5255, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4154872077884095
Updated goal-option-4 on 86 transitions
Deleting edge from SE([5 2]) to goal-option-4
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3, from [5 2] targeting {'count': 4403, 'bonus': 0.015070430457578103, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.640239548224669
Updated goal-option-3 on 26 transitions
Creating goal-option-3-0 with parent goal-option-3
Creating classifier of type cnn
Created model-free option goal-option-3-0 with option_idx=10
Case 3: Adding edge from goal-option-3 to SE([6 6])
Adding edge from SE([5 2]) to goal-option-3
Adding edge from goal-option-4 to goal-option-3
Took 0.0036339759826660156s to update distance table with 113 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 185 Step: 16539
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1995, 'bonus': 0.022388683141982252, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.015034832060337
Updated goal-option-4 on 123 transitions
Took 0.004141330718994141s to update distance table with 124 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[0.66695489 0.33304511]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2022, 'bonus': 0.022238701440076274, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4408, 'bonus': 0.01506188082821945, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.7838721889772535
Updated goal-option-3 on 128 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.004350423812866211s to update distance table with 129 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 186 Step: 16790
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1567, 'bonus': 0.02526187034191383, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3251007288491645
Updated goal-option-1 on 61 transitions
Took 0.0018188953399658203s to update distance table with 62 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 1790, 'bonus': 0.02363597296235327, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4398, 'bonus': 0.015078994662655072, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9871545076027685
Updated goal-option-3 on 186 transitions
Took 0.007535219192504883s to update distance table with 187 states and events {SE([6 6]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 187 Step: 17037
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1969, 'bonus': 0.022536015980024166, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13636, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8261420278028508
Updated goal-option-4 on 88 transitions
Took 0.003381013870239258s to update distance table with 89 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 188 Step: 17125
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17125, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1945, 'bonus': 0.02267462937912591, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4227977782319494
Updated goal-option-4 on 80 transitions
Took 0.0032682418823242188s to update distance table with 81 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 189 Step: 17205
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1641, 'bonus': 0.024685714930565622, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4184056754264767
Updated goal-option-1 on 88 transitions
Took 0.002470731735229492s to update distance table with 89 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probs: [[0.99339905 0.00468324 0.00191771]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.613228014021209
Updated goal-option-2 on 84 transitions
Took 0.0031130313873291016s to update distance table with 85 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 190 Step: 17377
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 17 transitions
Rolling out goal-option-4, from [2 2] targeting {'count': 2020, 'bonus': 0.02224970797449924, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9988587637090943
Updated goal-option-4 on 49 transitions
Took 0.0024306774139404297s to update distance table with 67 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2026, 'bonus': 0.022216737285146886, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17443, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9781370470921198
Updated goal-option-3 on 27 transitions
Took 0.001039266586303711s to update distance table with 28 states and events {SE([5 2]), None, SE([6 6])}
Adding edge from SE([5 2]) to goal-option-4
Adding edge from SE([6 6]) to goal-option-3
Took 0.417278528213501s to add potential edges.
================================================================================
[Consolidation] Episode: 191 Step: 17470
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1790, 'bonus': 0.02363597296235327, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8796395697806142
Updated goal-option-1 on 90 transitions
True
False
[Planner] Rolling out from {'count': 1797, 'bonus': 0.023589892481053584, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4413, 'bonus': 0.015053345733281098, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.417033430809776
Updated goal-option-3 on 115 transitions
Took 0.0069959163665771484s to update distance table with 206 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 192 Step: 17675
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1697, 'bonus': 0.02427499107135649, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1115523326922865
Updated goal-option-1 on 85 transitions
Took 0.002910614013671875s to update distance table with 86 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 193 Step: 17760
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17760, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1697, 'bonus': 0.02427499107135649, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3332543979661586
Updated goal-option-1 on 256 transitions
Took 0.009863853454589844s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 194 Step: 18016
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1606, 'bonus': 0.02495325642529748, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6974, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1586897080799319
Updated goal-option-1 on 45 transitions
Took 0.001527547836303711s to update distance table with 46 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 195 Step: 18061
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1669, 'bonus': 0.024477768982403232, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9920, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9174904125130436
Updated goal-option-1 on 76 transitions
Took 0.0025970935821533203s to update distance table with 77 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 196 Step: 18137
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5393507799143513
Updated goal-option-4 on 95 transitions
Took 0.0030515193939208984s to update distance table with 96 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[0.5 0.5]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2035, 'bonus': 0.022167554926073633, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 1707, 'bonus': 0.024203782378574807, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11336, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.103192573202495
Updated goal-option-1 on 161 transitions
Took 0.005437374114990234s to update distance table with 162 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 197 Step: 18393
================================================================================
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18393, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1654, 'bonus': 0.02458851198024517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3484173884897521
Updated goal-option-1 on 104 transitions
Took 0.0034165382385253906s to update distance table with 105 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 198 Step: 18497
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.161533092459043
Updated goal-option-4-0 on 127 transitions
Took 0.004439592361450195s to update distance table with 128 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 199 Step: 18624
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.3241648898632437
Updated goal-option-4-0 on 250 transitions
Took 0.008592367172241211s to update distance table with 251 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.40010374 0.40010374 0.19979252]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3-0 on 6 transitions
Took 0.00024771690368652344s to update distance table with 7 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 200 Step: 18880
================================================================================
Unconnected Events: [SE([6 6]), SE([5 2])] | Probs: [[0.00690251 0.99309749]]
[BoltzmannClosest] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1308238110646154
Updated goal-option-4-0 on 45 transitions
True
False
[Planner] Rolling out from {'count': 3611, 'bonus': 0.016641261908140255, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18925, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 1995, 'bonus': 0.022388683141982252, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7959080459550023
Updated goal-option-4 on 53 transitions
Took 0.003287792205810547s to update distance table with 99 states and events {None, SE([1 1]), SE([6 6])}
Took 0.3323371410369873s to add potential edges.
================================================================================
[Consolidation] Episode: 201 Step: 18978
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1796, 'bonus': 0.023596458909150436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2875245815755882
Updated goal-option-1 on 42 transitions
Took 0.00112152099609375s to update distance table with 43 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 202 Step: 19020
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1716, 'bonus': 0.02414022747926338, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11502, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3392459075886942
Updated goal-option-1 on 103 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [2 5] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.6741528113683066
Updated goal-option-3-0 on 138 transitions
True
False
[Planner] Rolling out from {'count': 2121, 'bonus': 0.021713491635397368, 'player_pos': (5, 4), 'player_x': 5, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19261, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 4] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5742990995446842
Updated goal-option-3 on 15 transitions
Took 0.009495019912719727s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
================================================================================
[Consolidation] Episode: 203 Step: 19276
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19276, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1627, 'bonus': 0.024791695181436636, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7766, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.014344973279082
Updated goal-option-1 on 81 transitions
Took 0.0027065277099609375s to update distance table with 82 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 204 Step: 19357
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19357, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1654, 'bonus': 0.02458851198024517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.009783057988375
Updated goal-option-1 on 98 transitions
Took 0.0032346248626708984s to update distance table with 99 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 205 Step: 19455
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19455, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1790, 'bonus': 0.02363597296235327, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3001046780980914
Updated goal-option-1 on 199 transitions
Took 0.00711512565612793s to update distance table with 200 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 206 Step: 19654
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19654, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1709, 'bonus': 0.024189615691742994, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.215027477675014
Updated goal-option-1 on 256 transitions
Took 0.011876821517944336s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 207 Step: 19910
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19910, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1790, 'bonus': 0.02363597296235327, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5310463905334473
Updated goal-option-1 on 174 transitions
Took 0.005978584289550781s to update distance table with 175 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 208 Step: 20084
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20084, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1718, 'bonus': 0.02412617203266904, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11611, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1299247162613442
Updated goal-option-1 on 256 transitions
Took 0.009121894836425781s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 209 Step: 20340
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20340, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1767, 'bonus': 0.023789303403490326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0627672498424847
Updated goal-option-1 on 104 transitions
Took 0.0033583641052246094s to update distance table with 105 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
[Episode=210 Seed=18] Took 0.05912518501281738s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 210 Step: 20444
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1956, 'bonus': 0.022610781582306727, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12993, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.1809100114335913
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 211 Step: 20700
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1956, 'bonus': 0.022610781582306727, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12993, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8410104852707232
Updated goal-option-4 on 104 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 212 Step: 20804
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20804, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2022, 'bonus': 0.022238701440076274, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0026777676050214
Updated goal-option-4 on 141 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -280.11149269668385
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 213 Step: 20945
================================================================================
Attempting to expand SE([6 6])
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20945, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1653, 'bonus': 0.02459594839716409, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4183207286728754
Updated goal-option-1 on 105 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [2 5] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.2047910971774
Updated goal-option-3-0 on 46 transitions
Rolling out goal-option-3, from [3 4] targeting {'count': 3669, 'bonus': 0.016509204383655284, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2991575312380697
Updated goal-option-3 on 105 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 214 Step: 21201
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21201, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2035, 'bonus': 0.022167554926073633, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9658720948866435
Updated goal-option-4 on 21 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -313.4456299014855
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 215 Step: 21222
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21222, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2026, 'bonus': 0.022216737285146886, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17443, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7175785749451091
Updated goal-option-4 on 100 transitions
Deleting edge from SE([5 2]) to goal-option-4
[RND Rollout] Reward: 0.0	IntrinsicReward: -317.64415371231735
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 216 Step: 21322
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0405131038193287
Updated goal-option-4 on 203 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -325.7313376776874
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 217 Step: 21525
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21525, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2131, 'bonus': 0.02166248500719623, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.455537754136163
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 218 Step: 21781
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1654, 'bonus': 0.02458851198024517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5138856911410887
Updated goal-option-1 on 155 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 219 Step: 21936
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1767, 'bonus': 0.023789303403490326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5923274349642662
Updated goal-option-1 on 101 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 220 Step: 22037
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1796, 'bonus': 0.023596458909150436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.519709528175019
Updated goal-option-1 on 66 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 221 Step: 22103
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22103, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1949, 'bonus': 0.022651349466027825, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12777, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1798274625550236
Updated goal-option-4 on 156 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -294.8628746061586
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 222 Step: 22259
================================================================================
Attempting to expand SE([5 2])
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([5 2])
Planner goal: SE([1 1]), DSC goal: SE([5 2]) and Goal: SE([5 2])
False
False
Rolling out DSC with goal vertex SE([5 2])
Rolling out goal-option-4-0, from [1 1] targeting {'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.99035134125883
Updated goal-option-4-0 on 78 transitions
Rolling out goal-option-4, from [2 2] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.183975760131009
Updated goal-option-4 on 118 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -308.43434627959505
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 223 Step: 22455
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22455, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2020, 'bonus': 0.02224970797449924, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8066155192469746
Updated goal-option-4 on 98 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 224 Step: 22553
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22553, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1796, 'bonus': 0.023596458909150436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1889674602584406
Updated goal-option-1 on 193 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 225 Step: 22746
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22746, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1687, 'bonus': 0.02434683198329917, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2468071422025337
Updated goal-option-1 on 218 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -323.6484528593719
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 226 Step: 22964
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22964, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1796, 'bonus': 0.023596458909150436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.0510368359677584
Updated goal-option-1 on 37 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -305.70218768622726
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 227 Step: 23001
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23001, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1718, 'bonus': 0.02412617203266904, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11611, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1587395801451374
Updated goal-option-1 on 224 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -273.01653592661023
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 228 Step: 23225
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1969, 'bonus': 0.022536015980024166, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13636, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1823366121254832
Updated goal-option-4 on 59 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 229 Step: 23284
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23284, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1892, 'bonus': 0.022990024493585143, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23001, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3739772827009074
Updated goal-option-1 on 140 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -291.19681043410674
Took 13.805768489837646s to update distance table with 13010 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=230 Seed=18] Took 0.06495141983032227s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 230 Step: 23424
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2026, 'bonus': 0.022216737285146886, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17443, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.323320309563381
Updated goal-option-4 on 89 transitions
Took 0.003180980682373047s to update distance table with 90 states and events {None, SE([1 1]), SE([6 6])}
Adding edge from SE([5 2]) to goal-option-4
Took 0.4729762077331543s to add potential edges.
================================================================================
[Consolidation] Episode: 231 Step: 23513
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.124717337389787
Updated goal-option-1 on 121 transitions
Took 0.0038068294525146484s to update distance table with 122 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 232 Step: 23634
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1892, 'bonus': 0.022990024493585143, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23001, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1329812648999276
Updated goal-option-1 on 237 transitions
Took 0.008759021759033203s to update distance table with 238 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 233 Step: 23871
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23871, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1725, 'bonus': 0.02407717061715384, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9904424849645795
Updated goal-option-1 on 40 transitions
Took 0.001363515853881836s to update distance table with 41 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 234 Step: 23911
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2228, 'bonus': 0.021185679930351788, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22455, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2027235780916516
Updated goal-option-4 on 256 transitions
Took 0.008846044540405273s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 235 Step: 24167
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
Expanding goal-option-4's pessimistic classifier to include SE([2 5])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24167, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1709, 'bonus': 0.024189615691742994, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0753097505895075
Updated goal-option-1 on 247 transitions
Took 0.008096456527709961s to update distance table with 248 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 236 Step: 24414
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.62245933 0.37754067]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24414, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2020, 'bonus': 0.02224970797449924, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1349207661628071
Updated goal-option-4 on 118 transitions
Took 0.004093170166015625s to update distance table with 119 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 237 Step: 24532
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0527621989380822
Updated goal-option-1 on 108 transitions
Took 0.0033996105194091797s to update distance table with 109 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 238 Step: 24640
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24640, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1678, 'bonus': 0.0244120371254637, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9931859999626607
Updated goal-option-1 on 103 transitions
Deleting edge from SE([2 5]) to goal-option-1
True
False
[Planner] Rolling out from {'count': 1950, 'bonus': 0.022645540682891915, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4418, 'bonus': 0.015044825131628671, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2219519270317896
Updated goal-option-3 on 49 transitions
Took 0.0051727294921875s to update distance table with 153 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 239 Step: 24792
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1926, 'bonus': 0.022786197567488776, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1626480605111558
Updated goal-option-1 on 64 transitions
Took 0.002812623977661133s to update distance table with 65 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 240 Step: 24856
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1766, 'bonus': 0.023796037813647444, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2801779405960183
Updated goal-option-1 on 58 transitions
True
False
[Planner] Rolling out from {'count': 1959, 'bonus': 0.02259346194622841, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 6460, 'bonus': 0.012441815044835988, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.0169407223259004
Updated goal-option-3 on 198 transitions
Took 0.008569478988647461s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
Adding edge from SE([2 5]) to goal-option-1
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([2 5]) to goal-option-4
Took 0.46266651153564453s to add potential edges.
================================================================================
[Consolidation] Episode: 241 Step: 25112
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.62010643 0.37989357]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2014, 'bonus': 0.02228282589107932, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15561, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.053625803226712
Updated goal-option-4 on 72 transitions
Took 0.0022230148315429688s to update distance table with 73 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.40010374 0.40010374 0.19979252]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.34835930996471
Updated goal-option-2 on 39 transitions
Took 0.0014727115631103516s to update distance table with 40 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.62010643 0.37989357]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 13350, 'bonus': 0.00865484644815831, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25223, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2022, 'bonus': 0.022238701440076274, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.119932193211402
Updated goal-option-4 on 50 transitions
Took 0.0014710426330566406s to update distance table with 51 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.40010374 0.40010374 0.19979252]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.4001913785934446
Updated goal-option-2 on 95 transitions
Took 0.00354766845703125s to update distance table with 96 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 242 Step: 25368
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25368, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8787791196322233
Updated goal-option-1 on 81 transitions
True
False
[Planner] Rolling out from {'count': 1984, 'bonus': 0.022450662753346864, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25449, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.342063769698143
Updated goal-option-3 on 175 transitions
Took 0.009358882904052734s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 243 Step: 25624
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1766, 'bonus': 0.023796037813647444, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8007565500674312
Updated goal-option-1 on 120 transitions
Took 0.00407099723815918s to update distance table with 121 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 244 Step: 25744
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1892, 'bonus': 0.022990024493585143, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23001, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4245267603387182
Updated goal-option-1 on 256 transitions
Took 0.00869441032409668s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 245 Step: 26000
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61774787 0.38225213]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1995, 'bonus': 0.022388683141982252, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4159382665598834
Updated goal-option-4 on 215 transitions
Took 0.0076177120208740234s to update distance table with 216 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 246 Step: 26215
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26215, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1796, 'bonus': 0.023596458909150436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2053728511125925
Updated goal-option-1 on 41 transitions
Took 0.0013954639434814453s to update distance table with 42 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 247 Step: 26256
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1766, 'bonus': 0.023796037813647444, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.049193817891709
Updated goal-option-1 on 74 transitions
Took 0.0030159950256347656s to update distance table with 75 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 248 Step: 26330
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61774787 0.38225213]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21222, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4449311177367747
Updated goal-option-4 on 111 transitions
Took 0.0035943984985351562s to update distance table with 112 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 249 Step: 26441
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26441, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1729, 'bonus': 0.024049303512194094, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0400205825765927
Updated goal-option-1 on 140 transitions
Took 0.004361629486083984s to update distance table with 141 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 250 Step: 26581
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1767, 'bonus': 0.023789303403490326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.021493533633864
Updated goal-option-1 on 175 transitions
Took 0.0059070587158203125s to update distance table with 176 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 0.3007071018218994s to add potential edges.
================================================================================
[Consolidation] Episode: 251 Step: 26756
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3827566 0.3827566 0.2344868]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1995, 'bonus': 0.022388683141982252, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.02700880974188
Updated goal-option-4 on 180 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 3671, 'bonus': 0.01650470657553921, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6329188821216423
Updated goal-option-3 on 76 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.008083343505859375s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
================================================================================
[Consolidation] Episode: 252 Step: 27012
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1851, 'bonus': 0.02324324663889676, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.213152764033686
Updated goal-option-1 on 191 transitions
True
False
[Planner] Rolling out from {'count': 2011, 'bonus': 0.02229944040256456, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27203, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4417, 'bonus': 0.015046528094465257, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.724522450613597
Updated goal-option-3 on 65 transitions
Took 0.009438753128051758s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 253 Step: 27268
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61538376 0.38461624]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2003, 'bonus': 0.02234392810843759, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14944, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8062264741512768
Updated goal-option-4 on 164 transitions
Took 0.005182027816772461s to update distance table with 165 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 13350, 'bonus': 0.00865484644815831, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25223, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.205271326833301
Updated goal-option-2 on 56 transitions
Took 0.002279996871948242s to update distance table with 57 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1984, 'bonus': 0.022450662753346864, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25449, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5024393298398186
Updated goal-option-1 on 12 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [2 5] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.808024104436239
Updated goal-option-3-0 on 24 transitions
Took 0.0012586116790771484s to update distance table with 37 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 254 Step: 27524
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61301418 0.38698582]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1892, 'bonus': 0.022990024493585143, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23001, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0637975497679277
Updated goal-option-1 on 256 transitions
Took 0.008816003799438477s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 255 Step: 27780
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27780, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0108542025922063
Updated goal-option-1 on 256 transitions
Took 0.008597373962402344s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 256 Step: 28036
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61063923 0.38936077]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0106335414133214
Updated goal-option-1 on 256 transitions
Took 0.008816719055175781s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 257 Step: 28292
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61301418 0.38698582]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28292, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1926, 'bonus': 0.022786197567488776, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3062713505590662
Updated goal-option-1 on 256 transitions
Took 0.008453130722045898s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 258 Step: 28548
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28548, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1926, 'bonus': 0.022786197567488776, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1596448050597494
Updated goal-option-1 on 44 transitions
Took 0.0014996528625488281s to update distance table with 45 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 259 Step: 28592
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1999, 'bonus': 0.02236627204212922, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5116764405328367
Updated goal-option-4 on 39 transitions
Deleting edge from SE([5 2]) to goal-option-4
Took 0.001422882080078125s to update distance table with 40 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 260 Step: 28631
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28631, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2022, 'bonus': 0.022238701440076274, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4517588813085947
Updated goal-option-4 on 136 transitions
Took 0.004288434982299805s to update distance table with 137 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from SE([5 2]) to goal-option-4
Took 0.4027283191680908s to add potential edges.
================================================================================
[Consolidation] Episode: 261 Step: 28767
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1790, 'bonus': 0.02363597296235327, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1488001788167825
Updated goal-option-1 on 123 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [2 5] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
7.183528674973382
Updated goal-option-3-0 on 133 transitions
Took 0.01484370231628418s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 262 Step: 29023
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.60587367 0.39412633]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29023, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2019, 'bonus': 0.02225521737361166, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28890, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9059775510856083
Updated goal-option-1 on 122 transitions
Took 0.0038955211639404297s to update distance table with 123 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 263 Step: 29145
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2035, 'bonus': 0.022167554926073633, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.129446911662817
Updated goal-option-4 on 242 transitions
True
False
[Planner] Rolling out from {'count': 2514, 'bonus': 0.01994423410775127, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4418, 'bonus': 0.015044825131628671, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4854968703455396
Updated goal-option-3 on 14 transitions
Took 0.008662700653076172s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
================================================================================
[Consolidation] Episode: 264 Step: 29401
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.60825903 0.39174097]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2035, 'bonus': 0.022167554926073633, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2023059052012541
Updated goal-option-4 on 75 transitions
Took 0.002034902572631836s to update distance table with 76 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 265 Step: 29476
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.60825903 0.39174097]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1729, 'bonus': 0.024049303512194094, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1429580378374367
Updated goal-option-1 on 94 transitions
Took 0.0027539730072021484s to update distance table with 95 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 266 Step: 29570
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29570, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2466, 'bonus': 0.0201374031110059, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25273, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.409217206453814
Updated goal-option-4 on 156 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.7528428584337234
Updated goal-option-3-0 on 100 transitions
Took 0.010524749755859375s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
================================================================================
[Consolidation] Episode: 267 Step: 29826
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29826, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2003, 'bonus': 0.02234392810843759, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14944, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4380560641487439
Updated goal-option-4 on 201 transitions
Took 0.008553504943847656s to update distance table with 202 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 268 Step: 30027
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61063923 0.38936077]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30027, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 1999, 'bonus': 0.02236627204212922, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3403111700973813
Updated goal-option-4 on 22 transitions
Took 0.0007579326629638672s to update distance table with 23 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[0.66695489 0.33304511]]
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 2516, 'bonus': 0.0199363055707225, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 3671, 'bonus': 0.01650470657553921, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5460457214803405
Updated goal-option-3 on 83 transitions
Took 0.0028471946716308594s to update distance table with 84 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 269 Step: 30132
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2131, 'bonus': 0.02166248500719623, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.127706162673908
Updated goal-option-4 on 13 transitions
True
False
[Planner] Rolling out from {'count': 2522, 'bonus': 0.019912576573338177, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4398, 'bonus': 0.015078994662655072, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9424947060920574
Updated goal-option-3 on 243 transitions
Took 0.008833885192871094s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 270 Step: 30388
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2020, 'bonus': 0.02224970797449924, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0097252605395897
Updated goal-option-4 on 116 transitions
True
False
[Planner] Rolling out from {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 3671, 'bonus': 0.01650470657553921, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4780677218809195
Updated goal-option-3 on 140 transitions
Took 0.008546590805053711s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 0.3784153461456299s to add potential edges.
================================================================================
[Consolidation] Episode: 271 Step: 30644
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3791285 0.3791285 0.241743 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30644, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1797, 'bonus': 0.023589892481053584, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.310428522108646
Updated goal-option-1 on 102 transitions
Took 0.003215312957763672s to update distance table with 103 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 272 Step: 30746
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38004265 0.38004265 0.23991471]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30746, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2084, 'bonus': 0.021905397716916176, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20945, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7395231998568281
Updated goal-option-4 on 53 transitions
Reverting to the DSC policy over options targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.106351632762838
Updated goal-option-3-0 on 36 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4044083238509641
Updated goal-option-3 on 167 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.009593009948730469s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 273 Step: 31002
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31002, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1797, 'bonus': 0.023589892481053584, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2949994671123999
Updated goal-option-1 on 120 transitions
True
False
[Planner] Rolling out from {'count': 2049, 'bonus': 0.022091694090300196, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 6476, 'bonus': 0.012426435786739165, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4963989295562108
Updated goal-option-3 on 136 transitions
Took 0.009369134902954102s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 274 Step: 31258
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.61063923 0.38936077]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1950, 'bonus': 0.022645540682891915, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.199162460932196
Updated goal-option-1 on 165 transitions
Took 0.005525827407836914s to update distance table with 166 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 275 Step: 31423
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.60825903 0.39174097]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31423, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2035, 'bonus': 0.022167554926073633, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.011907258629799
Updated goal-option-4 on 212 transitions
Took 0.007370471954345703s to update distance table with 213 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[0.25371381 0.61959375 0.12669244]]
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
7.287937566637993
Updated goal-option-3-0 on 44 transitions
Took 0.0016143321990966797s to update distance table with 45 states and events {SE([1 1]), SE([5 2]), None}
================================================================================
[Consolidation] Episode: 276 Step: 31679
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31679, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2552, 'bonus': 0.019795189561622396, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31635, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1578493203435627
Updated goal-option-4 on 184 transitions
Took 0.0061070919036865234s to update distance table with 185 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 277 Step: 31863
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1959, 'bonus': 0.02259346194622841, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3391203269063883
Updated goal-option-1 on 121 transitions
True
False
[Planner] Rolling out from {'count': 2056, 'bonus': 0.022054054569561544, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31984, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4408, 'bonus': 0.01506188082821945, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8286658729880283
Updated goal-option-3 on 135 transitions
Took 0.008645296096801758s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
================================================================================
[Consolidation] Episode: 278 Step: 32119
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2483, 'bonus': 0.02006834877696495, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2404907182879263
Updated goal-option-4 on 256 transitions
Took 0.010377168655395508s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 279 Step: 32375
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1814, 'bonus': 0.023479095302146476, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19123, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2666236674008162
Updated goal-option-1 on 111 transitions
True
False
[Planner] Rolling out from {'count': 2083, 'bonus': 0.02191065522274417, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32486, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3593665097119674
Updated goal-option-3 on 145 transitions
Took 0.010212898254394531s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
[Episode=280 Seed=18] Took 0.05707192420959473s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 280 Step: 32631
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32631, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2465, 'bonus': 0.02014148736276902, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25184, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1196614224841628
Updated goal-option-4 on 50 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -325.9434441998601
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 281 Step: 32681
================================================================================
Attempting to expand SE([6 6])
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32681, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2056, 'bonus': 0.022054054569561544, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31984, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9691852412877545
Updated goal-option-1 on 100 transitions
True
False
[Planner] Rolling out from {'count': 2087, 'bonus': 0.021889647878295008, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4411, 'bonus': 0.01505675802976226, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6992916111592893
Updated goal-option-3 on 24 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 282 Step: 32805
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32805, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-1, goal-option-4] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2049, 'bonus': 0.022091694090300196, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0470075093952345
Updated goal-option-1 on 245 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2544, 'bonus': 0.019826289642953604, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1973844318725597
Updated goal-option-4 on 11 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 283 Step: 33061
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2049, 'bonus': 0.022091694090300196, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8126128309618229
Updated goal-option-1 on 78 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -309.77773615159094
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 284 Step: 33139
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33139, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2154, 'bonus': 0.021546520679428582, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21525, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.274735983450528
Updated goal-option-4 on 185 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -245.04769059095997
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 285 Step: 33324
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1886, 'bonus': 0.0230265649529252, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22964, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1465940493407674
Updated goal-option-1 on 116 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 286 Step: 33440
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33440, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1984, 'bonus': 0.022450662753346864, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25449, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0876368964090943
Updated goal-option-1 on 36 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -248.43297463891213
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 287 Step: 33476
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21222, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7904490129369982
Updated goal-option-4 on 239 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 288 Step: 33715
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4075784004308423
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 289 Step: 33971
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33971, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1851, 'bonus': 0.02324324663889676, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8313077655612914
Updated goal-option-1 on 91 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 290 Step: 34062
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2084, 'bonus': 0.021905397716916176, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20945, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0378608076108826
Updated goal-option-4 on 43 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 291 Step: 34105
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2014, 'bonus': 0.02228282589107932, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1308789305174614
Updated goal-option-1 on 122 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 292 Step: 34227
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2087, 'bonus': 0.021889647878295008, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0181931295880566
Updated goal-option-1 on 206 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -279.054730524309
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 293 Step: 34433
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1927, 'bonus': 0.02278028445007573, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0471255836884181
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 294 Step: 34689
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8663799862881175
Updated goal-option-4 on 141 transitions
Deleting edge from SE([5 2]) to goal-option-4
[RND Rollout] Reward: 3.0	IntrinsicReward: -302.1908248793334
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 295 Step: 34830
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2093, 'bonus': 0.02185824984939871, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0781046996266885
Updated goal-option-1 on 128 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -335.3742240779102
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 296 Step: 34958
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33139, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9856603134343973
Updated goal-option-1 on 117 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 297 Step: 35075
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35075, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21222, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.202419940614442
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 298 Step: 35331
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21222, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9278378092050552
Updated goal-option-4 on 70 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -312.2573396960215
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 299 Step: 35401
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33139, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9562546045799566
Updated goal-option-1 on 151 transitions
Took 9.13042426109314s to update distance table with 10949 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=300 Seed=18] Took 0.0723564624786377s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 300 Step: 35552
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1886, 'bonus': 0.0230265649529252, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22964, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1605757014120666
Updated goal-option-1 on 112 transitions
Took 0.0037946701049804688s to update distance table with 113 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from SE([5 2]) to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 0.47838592529296875s to add potential edges.
================================================================================
[Consolidation] Episode: 301 Step: 35664
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.36876279 0.36876279 0.26247441]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35664, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1926, 'bonus': 0.022786197567488776, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.173663692149947
Updated goal-option-1 on 28 transitions
Took 0.000850677490234375s to update distance table with 29 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2173, 'bonus': 0.021452116007007204, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2516, 'bonus': 0.0199363055707225, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6746563514862111
Updated goal-option-4 on 41 transitions
Took 0.0014448165893554688s to update distance table with 42 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 302 Step: 35733
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.36779259 0.36779259 0.26441482]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35733, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2589, 'bonus': 0.019653231723767556, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1754212153609842
Updated goal-option-4 on 64 transitions
Took 0.0021843910217285156s to update distance table with 65 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 303 Step: 35797
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.36779259 0.36779259 0.26441482]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35797, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4171512823862333
Updated goal-option-4 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4403, 'bonus': 0.015070430457578103, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0098656588012265
Updated goal-option-3 on 69 transitions
Deleting edge from SE([5 2]) to goal-option-3
Took 0.002782583236694336s to update distance table with 82 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 304 Step: 35878
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2514, 'bonus': 0.01994423410775127, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8646960356678718
Updated goal-option-4 on 125 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.9653291033976004
Updated goal-option-3-0 on 6 transitions
Rolling out goal-option-3, from [5 2] targeting {'count': 4418, 'bonus': 0.015044825131628671, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3433595922376427
Updated goal-option-3 on 17 transitions
Took 0.006237506866455078s to update distance table with 149 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 305 Step: 36026
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2083, 'bonus': 0.02191065522274417, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32486, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4270964308123457
Updated goal-option-1 on 126 transitions
Took 0.0040400028228759766s to update distance table with 127 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 306 Step: 36152
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36152, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2014, 'bonus': 0.02228282589107932, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9804880390422005
Updated goal-option-1 on 16 transitions
True
False
[Planner] Rolling out from {'count': 2176, 'bonus': 0.021437323142813602, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4408, 'bonus': 0.01506188082821945, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.900143041692931
Updated goal-option-3 on 43 transitions
Took 0.002009153366088867s to update distance table with 60 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 307 Step: 36211
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36211, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2228, 'bonus': 0.021185679930351788, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22455, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8658725494088438
Updated goal-option-4 on 196 transitions
Took 0.006817817687988281s to update distance table with 197 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 308 Step: 36407
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36407, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1959, 'bonus': 0.02259346194622841, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.955065575303248
Updated goal-option-1 on 256 transitions
Took 0.009239912033081055s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 309 Step: 36663
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.58175938 0.41824062]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36663, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0326474619408448
Updated goal-option-4 on 26 transitions
Took 0.0009319782257080078s to update distance table with 27 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 4.98910939e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.5762063825414288
Updated goal-option-2 on 96 transitions
Took 0.003573894500732422s to update distance table with 97 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 310 Step: 36785
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.58175938 0.41824062]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36785, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2484, 'bonus': 0.020064308847628203, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9561105996963398
Updated goal-option-4 on 78 transitions
Took 0.002311229705810547s to update distance table with 79 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 4.98910939e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2702, 'bonus': 0.019237885149322023, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4417, 'bonus': 0.015046528094465257, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4467365410031572
Updated goal-option-3 on 178 transitions
Took 0.005959987640380859s to update distance table with 179 states and events {SE([5 2]), None}
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 0.4432847499847412s to add potential edges.
================================================================================
[Consolidation] Episode: 311 Step: 37041
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.36779259 0.36779259 0.26441482]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37041, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8839652167231429
Updated goal-option-4 on 139 transitions
Took 0.0047452449798583984s to update distance table with 140 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 312 Step: 37180
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.36779259 0.36779259 0.26441482]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37180, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2173, 'bonus': 0.021452116007007204, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.173717419025283
Updated goal-option-1 on 38 transitions
Took 0.0010657310485839844s to update distance table with 39 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2191, 'bonus': 0.021363815131845643, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37218, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2514, 'bonus': 0.01994423410775127, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1761416363600108
Updated goal-option-4 on 34 transitions
Took 0.0012001991271972656s to update distance table with 35 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 313 Step: 37252
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3668178  0.3668178  0.26636439]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8275985444225551
Updated goal-option-4 on 172 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7753957153343765
Updated goal-option-3 on 84 transitions
Deleting edge from SE([5 2]) to goal-option-3
Took 0.008669376373291016s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 314 Step: 37508
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3668178  0.3668178  0.26636439]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2483, 'bonus': 0.02006834877696495, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7272237754411263
Updated goal-option-4 on 16 transitions
Took 0.0005636215209960938s to update distance table with 17 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2716, 'bonus': 0.019188238911333408, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 3663, 'bonus': 0.016522719903220323, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4350, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4482404163447757
Updated goal-option-3 on 240 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([6 6]) to goal-option-3
Took 0.010387182235717773s to update distance table with 241 states and events {SE([1 1]), SE([5 2]), None}
================================================================================
[Consolidation] Episode: 315 Step: 37764
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2087, 'bonus': 0.021889647878295008, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.881951786600912
Updated goal-option-1 on 73 transitions
Took 0.0022826194763183594s to update distance table with 74 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 316 Step: 37837
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.58175938 0.41824062]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2571, 'bonus': 0.019721909504608663, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9761297487077258
Updated goal-option-4 on 163 transitions
Took 0.005365133285522461s to update distance table with 164 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 317 Step: 38000
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2696, 'bonus': 0.019259280394283634, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0071175418829135
Updated goal-option-4 on 256 transitions
Took 0.008781671524047852s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 318 Step: 38256
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46505705 0.53494295]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2601, 'bonus': 0.0196078431372549, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0355561021551378
Updated goal-option-4 on 256 transitions
Took 0.008205890655517578s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 319 Step: 38512
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38512, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2522, 'bonus': 0.019912576573338177, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1041785416246832
Updated goal-option-4 on 256 transitions
Took 0.00841379165649414s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 320 Step: 38768
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38768, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2601, 'bonus': 0.0196078431372549, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0699068145011288
Updated goal-option-4 on 183 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.310077703661389
Updated goal-option-3-0 on 62 transitions
Rolling out goal-option-3, from [5 3] targeting {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4714503040704778
Updated goal-option-3 on 11 transitions
Took 0.011818885803222656s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
Took 0.5126762390136719s to add potential edges.
================================================================================
[Consolidation] Episode: 321 Step: 39024
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46008512 0.53991488]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2686, 'bonus': 0.019295098316976827, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36003, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7853672034568615
Updated goal-option-4 on 135 transitions
Took 0.00439000129699707s to update distance table with 136 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2736, 'bonus': 0.019117977822546813, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39159, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.8303886166928955
Updated goal-option-3 on 30 transitions
Took 0.001046895980834961s to update distance table with 31 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 322 Step: 39189
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46008512 0.53991488]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2708, 'bonus': 0.019216561050602196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9732534040345087
Updated goal-option-4 on 186 transitions
Took 0.006204128265380859s to update distance table with 187 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 4.98910939e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.707881136073006
Updated goal-option-2 on 70 transitions
Took 0.0027997493743896484s to update distance table with 71 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 323 Step: 39445
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2556, 'bonus': 0.01977969430323089, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32681, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9178189641812392
Updated goal-option-4 on 50 transitions
True
False
[Planner] Rolling out from {'count': 2742, 'bonus': 0.01909704954279511, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4413, 'bonus': 0.015053345733281098, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.046189278517014
Updated goal-option-3 on 206 transitions
Took 0.010633468627929688s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
================================================================================
[Consolidation] Episode: 324 Step: 39701
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39701, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2093, 'bonus': 0.02185824984939871, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0453014488368073
Updated goal-option-1 on 256 transitions
Took 0.009434223175048828s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 325 Step: 39957
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46505705 0.53494295]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39957, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33139, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0902288771719426
Updated goal-option-1 on 41 transitions
Took 0.0012364387512207031s to update distance table with 42 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.886276338559886
Updated goal-option-2 on 63 transitions
Took 0.002538442611694336s to update distance table with 64 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46008512 0.53991488]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 16124, 'bonus': 0.007875236506747693, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 1950, 'bonus': 0.022645540682891915, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9539379130493845
Updated goal-option-1 on 21 transitions
Took 0.0006380081176757812s to update distance table with 22 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.61774787 0.38225213]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2227, 'bonus': 0.021190435947906452, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2696, 'bonus': 0.019259280394283634, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0215779872317063
Updated goal-option-4 on 9 transitions
Took 0.0003688335418701172s to update distance table with 10 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 326 Step: 40091
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45760206 0.54239794]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2173, 'bonus': 0.021452116007007204, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1833989724085938
Updated goal-option-1 on 118 transitions
Took 0.0037844181060791016s to update distance table with 119 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 327 Step: 40209
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40209, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1129702533936607
Updated goal-option-1 on 146 transitions
True
False
[Planner] Rolling out from {'count': 2230, 'bonus': 0.021176177494381335, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40355, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8341, 'bonus': 0.010949415576853557, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.409772616565524
Updated goal-option-3 on 110 transitions
Took 0.009673595428466797s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 328 Step: 40465
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45512111 0.54487889]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40465, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2225, 'bonus': 0.0211999576001272, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0272499364059609
Updated goal-option-1 on 67 transitions
Took 0.001909494400024414s to update distance table with 68 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2248, 'bonus': 0.02109122703047989, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8341, 'bonus': 0.010949415576853557, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.0163409796313965
Updated goal-option-3 on 114 transitions
Took 0.004673957824707031s to update distance table with 115 states and events {SE([6 6]), SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 329 Step: 40646
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40646, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2056, 'bonus': 0.022054054569561544, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31984, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9483181496727324
Updated goal-option-1 on 256 transitions
Took 0.008764982223510742s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 330 Step: 40902
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40902, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2544, 'bonus': 0.019826289642953604, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8116168348175107
Updated goal-option-4 on 113 transitions
Took 0.0033676624298095703s to update distance table with 114 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Took 0.5169405937194824s to add potential edges.
================================================================================
[Consolidation] Episode: 331 Step: 41015
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45264238 0.54735762]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2230, 'bonus': 0.021176177494381335, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40355, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0485334894612983
Updated goal-option-1 on 24 transitions
Took 0.0006124973297119141s to update distance table with 25 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2256, 'bonus': 0.021053798026662976, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2696, 'bonus': 0.019259280394283634, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9826970576465904
Updated goal-option-4 on 14 transitions
Took 0.0005140304565429688s to update distance table with 15 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 332 Step: 41053
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45264238 0.54735762]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41053, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0506778762931317
Updated goal-option-1 on 151 transitions
Took 0.005120515823364258s to update distance table with 152 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 333 Step: 41204
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45512111 0.54487889]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41204, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33139, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3419271782040596
Updated goal-option-1 on 184 transitions
Took 0.00669407844543457s to update distance table with 185 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 334 Step: 41388
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2708, 'bonus': 0.019216561050602196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2370990805455253
Updated goal-option-4 on 159 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.79054215266591
Updated goal-option-3-0 on 97 transitions
Took 0.009220123291015625s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 335 Step: 41644
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41644, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8672397243837776
Updated goal-option-1 on 60 transitions
True
False
[Planner] Rolling out from {'count': 2257, 'bonus': 0.02104913339870572, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41704, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4922670354445777
Updated goal-option-3 on 196 transitions
Took 0.010042905807495117s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 336 Step: 41900
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9379807808723166
Updated goal-option-4 on 118 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-3-0, from [5 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.46723183327251
Updated goal-option-3-0 on 100 transitions
Rolling out goal-option-3, from [3 6] targeting {'count': 4403, 'bonus': 0.015070430457578103, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4172530292796168
Updated goal-option-3 on 38 transitions
Took 0.008653640747070312s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
================================================================================
[Consolidation] Episode: 337 Step: 42156
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45760206 0.54239794]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2702, 'bonus': 0.019237885149322023, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8453369764162059
Updated goal-option-4 on 241 transitions
Took 0.008311986923217773s to update distance table with 242 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 4.98910939e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.867133251080911
Updated goal-option-2 on 15 transitions
Took 0.0006585121154785156s to update distance table with 16 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 338 Step: 42412
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42412, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2556, 'bonus': 0.01977969430323089, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32681, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0879284697895248
Updated goal-option-4 on 98 transitions
Took 0.0030336380004882812s to update distance table with 99 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 339 Step: 42510
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46008512 0.53991488]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42510, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2589, 'bonus': 0.019653231723767556, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1396855765900002
Updated goal-option-4 on 256 transitions
Took 0.008559942245483398s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 340 Step: 42766
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46257015 0.53742985]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42766, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2556, 'bonus': 0.01977969430323089, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32681, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.748242421484575
Updated goal-option-4 on 59 transitions
Took 0.0017976760864257812s to update distance table with 60 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 4.98910939e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 16124, 'bonus': 0.007875236506747693, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.8034314232714035
Updated goal-option-2 on 197 transitions
Took 0.008273124694824219s to update distance table with 198 states and events {SE([5 2]), SE([2 5]), None}
Took 0.5147416591644287s to add potential edges.
================================================================================
[Consolidation] Episode: 341 Step: 43022
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43022, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0567541105234606
Updated goal-option-1 on 69 transitions
True
False
[Planner] Rolling out from {'count': 2295, 'bonus': 0.020874143036171647, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4417, 'bonus': 0.015046528094465257, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2371003758417416
Updated goal-option-3 on 187 transitions
Took 0.012237310409545898s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 342 Step: 43278
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
Expanding goal-option-3's pessimistic classifier to include SE([2 5])
[DeepSkillGraphsAgent] Creating chain from SE([5 2]) -> SE([6 6])
Creating classifier of type cnn
Created model-free option goal-option-8 with option_idx=11
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43278, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2227, 'bonus': 0.021190435947906452, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8567868586261896
Updated goal-option-1 on 146 transitions
True
False
[Planner] Rolling out from {'count': 2319, 'bonus': 0.020765845843612775, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8341, 'bonus': 0.010949415576853557, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5274477501710255
Updated goal-option-3 on 110 transitions
Took 0.009688615798950195s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 343 Step: 43534
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43534, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2544, 'bonus': 0.019826289642953604, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7051245174925738
Updated goal-option-4 on 144 transitions
True
False
[Planner] Rolling out from {'count': 2767, 'bonus': 0.019010582334423435, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4411, 'bonus': 0.01505675802976226, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6193560245528555
Updated goal-option-3 on 112 transitions
Took 0.00960540771484375s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 344 Step: 43790
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.46257015 0.53742985]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2696, 'bonus': 0.019259280394283634, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.972315817417023
Updated goal-option-4 on 256 transitions
Took 0.008342981338500977s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 345 Step: 44046
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2093, 'bonus': 0.02185824984939871, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.009417107302239
Updated goal-option-1 on 94 transitions
Took 0.0030722618103027344s to update distance table with 95 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 346 Step: 44140
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44140, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2696, 'bonus': 0.019259280394283634, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8541754220449734
Updated goal-option-4 on 106 transitions
Took 0.0037462711334228516s to update distance table with 107 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 347 Step: 44246
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2087, 'bonus': 0.021889647878295008, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8902469935726985
Updated goal-option-1 on 81 transitions
True
False
[Planner] Rolling out from {'count': 2337, 'bonus': 0.020685720094603028, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 3671, 'bonus': 0.01650470657553921, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5420303964971476
Updated goal-option-3 on 175 transitions
Took 0.01158452033996582s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 348 Step: 44502
================================================================================
Candidate events: [SE([5 2]), SE([2 5])] | Probabilities: [0.45760206 0.54239794]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44502, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2225, 'bonus': 0.0211999576001272, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9402598590287478
Updated goal-option-1 on 256 transitions
Took 0.009499549865722656s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 349 Step: 44758
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44758, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2256, 'bonus': 0.021053798026662976, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8406987223914477
Updated goal-option-1 on 256 transitions
Took 0.008731842041015625s to update distance table with 257 states and events {None, SE([1 1])}
[Episode=350 Seed=18] Took 0.059600114822387695s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 350 Step: 45014
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45014, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2736, 'bonus': 0.019117977822546813, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39159, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0493365387706195
Updated goal-option-4 on 69 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -292.5900394192722
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 351 Step: 45083
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45083, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2337, 'bonus': 0.020685720094603028, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0014666180344924
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 352 Step: 45339
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45339, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2737, 'bonus': 0.019114484997483857, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8512071444294066
Updated goal-option-4 on 58 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -320.4731290177442
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 353 Step: 45397
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2225, 'bonus': 0.0211999576001272, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.954709713493497
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 354 Step: 45653
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45653, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2767, 'bonus': 0.019010582334423435, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9424362684490593
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 355 Step: 45909
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45909, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2191, 'bonus': 0.021363815131845643, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37218, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0419754318770815
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 356 Step: 46165
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46165, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2083, 'bonus': 0.02191065522274417, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32486, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9077981730302174
Updated goal-option-1 on 82 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -318.67067892383784
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 357 Step: 46247
================================================================================
Attempting to expand SE([6 6])
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46247, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2176, 'bonus': 0.021437323142813602, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2541110035177827
Updated goal-option-1 on 36 transitions
True
False
[Planner] Rolling out from {'count': 2445, 'bonus': 0.02022369785697524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46283, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 6460, 'bonus': 0.012441815044835988, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4320182682089664
Updated goal-option-3 on 131 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 358 Step: 46414
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46414, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2819, 'bonus': 0.018834429162764506, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7759356053102584
Updated goal-option-4 on 139 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 359 Step: 46553
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46553, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2819, 'bonus': 0.018834429162764506, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1506412091918967
Updated goal-option-4 on 40 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 360 Step: 46593
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46593, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2718, 'bonus': 0.019181177921614535, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8677803879038671
Updated goal-option-4 on 195 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -301.4030083416146
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 361 Step: 46788
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2191, 'bonus': 0.021363815131845643, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37218, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9039050352669532
Updated goal-option-1 on 149 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -302.91663904325105
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 362 Step: 46937
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46937, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2248, 'bonus': 0.02109122703047989, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1452533797025681
Updated goal-option-1 on 79 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 363 Step: 47016
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2176, 'bonus': 0.021437323142813602, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9704921789378284
Updated goal-option-1 on 131 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -313.36684143543243
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 364 Step: 47147
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47147, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2936, 'bonus': 0.018455336763139055, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7269925687122166
Updated goal-option-4 on 39 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -329.5101386718452
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 365 Step: 47186
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47186, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2458, 'bonus': 0.02017014687752732, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46937, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0977671884579463
Updated goal-option-1 on 81 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 366 Step: 47267
================================================================================
Attempting to expand SE([6 6])
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([5 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47267, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2716, 'bonus': 0.019188238911333408, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7863651536897523
Updated goal-option-4 on 134 transitions
True
False
[Planner] Rolling out from {'count': 3140, 'bonus': 0.017845765256206243, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2378409313566892
Updated goal-option-3 on 73 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 367 Step: 47474
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47474, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2807, 'bonus': 0.018874645071534885, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45083, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7761984368984081
Updated goal-option-4 on 71 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 368 Step: 47545
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47545, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47147, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1010271168227215
Updated goal-option-1 on 77 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 369 Step: 47622
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47622, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2191, 'bonus': 0.021363815131845643, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37218, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8487778319589173
Updated goal-option-1 on 215 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -310.87272684881464
Took 4.958930253982544s to update distance table with 10851 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=370 Seed=18] Took 0.05118608474731445s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 370 Step: 47837
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([6 6])
Planner goal: SE([2 5]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2103, 'bonus': 0.02180621871193172, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.967065922558385
Updated goal-option-1 on 20 transitions
True
False
[Planner] Rolling out from {'count': 2480, 'bonus': 0.02008048322256247, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47857, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8341, 'bonus': 0.010949415576853557, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7846714810627262
Updated goal-option-3 on 19 transitions
Took 0.00147247314453125s to update distance table with 40 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([2 5]) to goal-option-3
Adding edge from SE([6 6]) to goal-option-3
Took 0.49190592765808105s to add potential edges.
================================================================================
[Consolidation] Episode: 371 Step: 47876
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40265934 0.28374924 0.31359141]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47876, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2936, 'bonus': 0.018455336763139055, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8175218892486199
Updated goal-option-4 on 107 transitions
Took 0.0034799575805664062s to update distance table with 108 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8463, 'bonus': 0.010870207379990003, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.432674117315383
Updated goal-option-2 on 75 transitions
Took 0.0025267601013183594s to update distance table with 76 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 372 Step: 48058
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40265934 0.28374924 0.31359141]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2248, 'bonus': 0.02109122703047989, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9375430835309878
Updated goal-option-1 on 36 transitions
Took 0.0010366439819335938s to update distance table with 37 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 373 Step: 48094
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40391969 0.28463739 0.31144292]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2696, 'bonus': 0.019259280394283634, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.91991488332147
Updated goal-option-4 on 256 transitions
Took 0.008700847625732422s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 374 Step: 48350
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40506692 0.2826056  0.31232749]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48350, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2176, 'bonus': 0.021437323142813602, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0078740457847157
Updated goal-option-1 on 19 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8344, 'bonus': 0.010947447024610965, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40646, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3825288137278882
Updated goal-option-3 on 42 transitions
Took 0.0018541812896728516s to update distance table with 62 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 375 Step: 48411
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40506692 0.2826056  0.31232749]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48411, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2702, 'bonus': 0.019237885149322023, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9572027130932307
Updated goal-option-4 on 146 transitions
Took 0.0048656463623046875s to update distance table with 147 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2768015737334886
Updated goal-option-2 on 21 transitions
Took 0.0007770061492919922s to update distance table with 22 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 376 Step: 48578
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40391969 0.28463739 0.31144292]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2445, 'bonus': 0.02022369785697524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46283, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8575644659690367
Updated goal-option-1 on 54 transitions
Took 0.001584768295288086s to update distance table with 55 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 377 Step: 48632
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40391969 0.28463739 0.31144292]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48632, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2475, 'bonus': 0.02010075630518424, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9687586350230878
Updated goal-option-1 on 34 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8331, 'bonus': 0.010955985095400366, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4957175788926145
Updated goal-option-3 on 123 transitions
Took 0.005495309829711914s to update distance table with 158 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 378 Step: 48789
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40391969 0.28463739 0.31144292]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2248, 'bonus': 0.02109122703047989, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0383878310596988
Updated goal-option-1 on 62 transitions
Took 0.0019197463989257812s to update distance table with 63 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 379 Step: 48851
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2497, 'bonus': 0.020012010810811352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48369, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0509617093461332
Updated goal-option-1 on 23 transitions
Took 0.0006244182586669922s to update distance table with 24 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 8762, 'bonus': 0.010683126613865841, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.6096580694387623
Updated goal-option-2 on 22 transitions
Took 0.0009226799011230469s to update distance table with 23 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 17603, 'bonus': 0.007537141271820723, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48896, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2755, 'bonus': 0.019051939705278707, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41547, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7534194429345588
Updated goal-option-4 on 45 transitions
Took 0.0013611316680908203s to update distance table with 46 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 380 Step: 48941
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40632967 0.28348659 0.31018374]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2475, 'bonus': 0.02010075630518424, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9188993251923495
Updated goal-option-1 on 26 transitions
Took 0.0008950233459472656s to update distance table with 27 states and events {None, SE([1 1]), SE([6 6])}
Took 0.4111149311065674s to add potential edges.
================================================================================
[Consolidation] Episode: 381 Step: 48967
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40758764 0.28436425 0.30804811]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48967, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3056, 'bonus': 0.01808936513231054, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47186, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8855555370188596
Updated goal-option-4 on 256 transitions
Took 0.008602142333984375s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 382 Step: 49223
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40642611 0.28640364 0.30717025]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49223, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2256, 'bonus': 0.021053798026662976, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0113545398667174
Updated goal-option-1 on 22 transitions
Took 0.0007793903350830078s to update distance table with 23 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.58661758 0.41338242]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9025, 'bonus': 0.010526315789473684, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47876, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5957616010132956
Updated goal-option-3 on 9 transitions
Took 0.00036716461181640625s to update distance table with 10 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 383 Step: 49254
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49254, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2295, 'bonus': 0.020874143036171647, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0105593221677573
Updated goal-option-1 on 34 transitions
Took 0.0011601448059082031s to update distance table with 35 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 384 Step: 49288
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2295, 'bonus': 0.020874143036171647, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0008308493824145
Updated goal-option-1 on 84 transitions
Took 0.00238037109375s to update distance table with 85 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 385 Step: 49372
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49372, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2718, 'bonus': 0.019181177921614535, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9736184416042989
Updated goal-option-4 on 94 transitions
Took 0.0031859874725341797s to update distance table with 95 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 386 Step: 49466
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40401595 0.28756656 0.30841749]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49466, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2503, 'bonus': 0.019988010789211325, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9413298755700206
Updated goal-option-1 on 230 transitions
Took 0.0071239471435546875s to update distance table with 231 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 387 Step: 49696
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40401595 0.28756656 0.30841749]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49696, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3140, 'bonus': 0.017845765256206243, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8235974797982214
Updated goal-option-4 on 215 transitions
Took 0.0071446895599365234s to update distance table with 216 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 388 Step: 49911
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2337, 'bonus': 0.020685720094603028, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.973185326707026
Updated goal-option-1 on 81 transitions
Took 0.002572298049926758s to update distance table with 82 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 389 Step: 49992
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2497, 'bonus': 0.020012010810811352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48369, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0051147239112155
Updated goal-option-1 on 247 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 6460, 'bonus': 0.012441815044835988, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0066645223720403
Updated goal-option-3 on 9 transitions
Took 0.009181499481201172s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
================================================================================
[Consolidation] Episode: 390 Step: 50248
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40517529 0.2855222  0.30930251]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50248, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2445, 'bonus': 0.02022369785697524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46283, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0547400076676459
Updated goal-option-1 on 74 transitions
Took 0.0025048255920410156s to update distance table with 75 states and events {None, SE([1 1]), SE([6 6])}
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 0.36150312423706055s to add potential edges.
================================================================================
[Consolidation] Episode: 391 Step: 50322
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40642611 0.28640364 0.30717025]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2936, 'bonus': 0.018455336763139055, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9390550617807101
Updated goal-option-4 on 22 transitions
Took 0.0005362033843994141s to update distance table with 23 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3310, 'bonus': 0.017381449986274954, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4126505325006884
Updated goal-option-3 on 20 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0007107257843017578s to update distance table with 21 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 392 Step: 50364
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40408816 0.29050857 0.30540326]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2256, 'bonus': 0.021053798026662976, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1135797853343152
Updated goal-option-1 on 115 transitions
Took 0.00383758544921875s to update distance table with 116 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.58175938 0.41824062]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2536, 'bonus': 0.01985753676973844, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50479, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2718, 'bonus': 0.019181177921614535, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8615739222654363
Updated goal-option-4 on 9 transitions
Took 0.00035262107849121094s to update distance table with 10 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 393 Step: 50488
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40401595 0.28756656 0.30841749]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2295, 'bonus': 0.020874143036171647, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8813744660749333
Updated goal-option-1 on 32 transitions
Took 0.0010752677917480469s to update distance table with 33 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 394 Step: 50520
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40401595 0.28756656 0.30841749]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50520, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0333467934200231
Updated goal-option-1 on 36 transitions
Took 0.0012505054473876953s to update distance table with 37 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 395 Step: 50556
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40401595 0.28756656 0.30841749]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50556, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2227, 'bonus': 0.021190435947906452, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0914494126785899
Updated goal-option-1 on 17 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 4412, 'bonus': 0.015055051591491946, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.4624500123336333
Updated goal-option-3 on 8 transitions
Took 0.0008246898651123047s to update distance table with 26 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 396 Step: 50581
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40401595 0.28756656 0.30841749]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2507, 'bonus': 0.019972058663135294, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48874, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8387467506740774
Updated goal-option-1 on 256 transitions
Took 0.008867025375366211s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 397 Step: 50837
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40525961 0.28845176 0.30628863]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2497, 'bonus': 0.020012010810811352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48369, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.240799072046652
Updated goal-option-1 on 256 transitions
Took 0.008208513259887695s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 398 Step: 51093
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40525961 0.28845176 0.30628863]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51093, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2337, 'bonus': 0.020685720094603028, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9508464023330961
Updated goal-option-1 on 61 transitions
Took 0.002086162567138672s to update distance table with 62 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 399 Step: 51154
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40525961 0.28845176 0.30628863]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2475, 'bonus': 0.02010075630518424, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9005722481530037
Updated goal-option-1 on 14 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8332, 'bonus': 0.010955327611372086, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4898683659055016
Updated goal-option-3 on 79 transitions
Took 0.003189563751220703s to update distance table with 94 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 400 Step: 51247
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40525961 0.28845176 0.30628863]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51247, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2535, 'bonus': 0.019861453057473933, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50239, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0172117716736264
Updated goal-option-1 on 21 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8332, 'bonus': 0.010955327611372086, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.620188954840885
Updated goal-option-3 on 32 transitions
Took 0.0017828941345214844s to update distance table with 54 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-4 to goal-option-1
Adding edge from SE([5 2]) to goal-option-1
Took 0.38196635246276855s to add potential edges.
================================================================================
[Consolidation] Episode: 401 Step: 51300
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40525961 0.28845176 0.30628863]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2337, 'bonus': 0.020685720094603028, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9313476608766543
Updated goal-option-1 on 54 transitions
Deleting edge from goal-option-4 to goal-option-1
Deleting edge from SE([5 2]) to goal-option-1
Took 0.0018439292907714844s to update distance table with 55 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 402 Step: 51354
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40649846 0.28933354 0.30416799]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2716, 'bonus': 0.019188238911333408, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0805924232698911
Updated goal-option-4 on 37 transitions
Took 0.0010890960693359375s to update distance table with 38 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.467371935907163
Updated goal-option-2 on 152 transitions
Took 0.005076169967651367s to update distance table with 153 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 403 Step: 51543
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40413632 0.2934632  0.30240048]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2319, 'bonus': 0.020765845843612775, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0276466199300354
Updated goal-option-1 on 256 transitions
Took 0.009208202362060547s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 404 Step: 51799
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40413632 0.2934632  0.30240048]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2737, 'bonus': 0.019114484997483857, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8725355019678874
Updated goal-option-4 on 26 transitions
Took 0.0009508132934570312s to update distance table with 27 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8305907593323636
Updated goal-option-2 on 9 transitions
Took 0.0003516674041748047s to update distance table with 10 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 405 Step: 51834
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40294788 0.2955409  0.30151122]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47147, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8727620939413706
Updated goal-option-1 on 83 transitions
Took 0.0027379989624023438s to update distance table with 84 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 406 Step: 51917
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40294788 0.2955409  0.30151122]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2458, 'bonus': 0.02017014687752732, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46937, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9508630388244595
Updated goal-option-1 on 46 transitions
Took 0.0015671253204345703s to update distance table with 47 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 407 Step: 51963
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40294788 0.2955409  0.30151122]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51963, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2337, 'bonus': 0.020685720094603028, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8925436501769716
Updated goal-option-1 on 23 transitions
Took 0.0006041526794433594s to update distance table with 24 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 408 Step: 51986
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40294788 0.2955409  0.30151122]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51986, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2757, 'bonus': 0.019045028063583717, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42018, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8420045847944939
Updated goal-option-4 on 87 transitions
Took 0.002925872802734375s to update distance table with 88 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.972970844058493
Updated goal-option-1 on 122 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 8762, 'bonus': 0.010683126613865841, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.818920885905241
Updated goal-option-2 on 12 transitions
Took 0.004549741744995117s to update distance table with 135 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 409 Step: 52207
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40173054 0.29464804 0.30362141]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52207, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2257, 'bonus': 0.02104913339870572, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41704, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8818985115336834
Updated goal-option-1 on 256 transitions
Took 0.007981300354003906s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 410 Step: 52463
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.40173054 0.29464804 0.30362141]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2755, 'bonus': 0.019051939705278707, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41547, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.790073422445392
Updated goal-option-4 on 14 transitions
Took 0.00045561790466308594s to update distance table with 15 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3384, 'bonus': 0.017190354104313223, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52477, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 8334, 'bonus': 0.010954012998346249, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36211, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.011368908484777
Updated goal-option-3 on 42 transitions
Took 0.0014655590057373047s to update distance table with 43 states and events {SE([5 2]), None, SE([6 6])}
Took 0.4298229217529297s to add potential edges.
================================================================================
[Consolidation] Episode: 411 Step: 52519
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.39935348 0.29882166 0.30182487]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2537, 'bonus': 0.019853622797734376, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50573, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9134696168797855
Updated goal-option-1 on 58 transitions
Took 0.0015201568603515625s to update distance table with 59 states and events {None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 412 Step: 52577
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.39935348 0.29882166 0.30182487]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52577, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3384, 'bonus': 0.017190354104313223, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52477, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.672327873930335
Updated goal-option-4 on 78 transitions
Took 0.0025565624237060547s to update distance table with 79 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.166683518074877
Updated goal-option-2 on 40 transitions
Took 0.001399993896484375s to update distance table with 41 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 413 Step: 52695
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.39935348 0.29882166 0.30182487]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52695, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2257, 'bonus': 0.02104913339870572, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41704, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0666246556862355
Updated goal-option-1 on 29 transitions
Took 0.0010862350463867188s to update distance table with 30 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.57199613 0.42800387]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2545, 'bonus': 0.019822394114938212, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2737, 'bonus': 0.019114484997483857, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8437822734933983
Updated goal-option-4 on 35 transitions
Deleting edge from SE([5 2]) to goal-option-4
Took 0.0012531280517578125s to update distance table with 36 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3388, 'bonus': 0.017180203318601237, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 2497, 'bonus': 0.020012010810811352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48369, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0265384396847541
Updated goal-option-1 on 175 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [2 5] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.631168950137084
Updated goal-option-2 on 17 transitions
Took 0.0065877437591552734s to update distance table with 193 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 414 Step: 52951
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.39695721 0.3000138  0.30302899]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3310, 'bonus': 0.017381449986274954, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7955103090444807
Updated goal-option-4 on 11 transitions
Took 0.0002765655517578125s to update distance table with 12 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3389, 'bonus': 0.0171776684306024, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 6476, 'bonus': 0.012426435786739165, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0726848335369774
Updated goal-option-3 on 42 transitions
Took 0.0014498233795166016s to update distance table with 43 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 415 Step: 53004
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3957639  0.30211805 0.30211805]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53004, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47147, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8991735693150097
Updated goal-option-1 on 10 transitions
Took 0.00040793418884277344s to update distance table with 11 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2549, 'bonus': 0.019806834933486603, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53014, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9058, 'bonus': 0.010507123617866617, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1049724424230878
Updated goal-option-3 on 18 transitions
Took 0.0006954669952392578s to update distance table with 19 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 416 Step: 53032
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3957639  0.30211805 0.30211805]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2541, 'bonus': 0.019837990021453852, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52195, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.042091623544693
Updated goal-option-1 on 11 transitions
Took 0.0003371238708496094s to update distance table with 12 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2551, 'bonus': 0.019799069069658004, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9031, 'bonus': 0.010522818480847511, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0814327293185777
Updated goal-option-3 on 13 transitions
Took 0.0004878044128417969s to update distance table with 14 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 417 Step: 53056
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.39456587 0.30120349 0.30423064]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47147, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2283162964100869
Updated goal-option-1 on 50 transitions
Took 0.001489877700805664s to update distance table with 51 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 418 Step: 53106
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3957639  0.30211805 0.30211805]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2507, 'bonus': 0.019972058663135294, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48874, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9752336432962658
Updated goal-option-1 on 256 transitions
Took 0.008785724639892578s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 419 Step: 53362
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3957639  0.30211805 0.30211805]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53362, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2431, 'bonus': 0.020281847857870915, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46247, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2156504414518152
Updated goal-option-1 on 26 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8331, 'bonus': 0.010955985095400366, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.095493288343525
Updated goal-option-3 on 7 transitions
Took 0.000885009765625s to update distance table with 34 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
[Episode=420 Seed=18] Took 0.06080985069274902s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 420 Step: 53395
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53395, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2503, 'bonus': 0.019988010789211325, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0485153030725864
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 421 Step: 53651
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53651, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2538, 'bonus': 0.019849711139180454, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.084494103567349
Updated goal-option-1 on 93 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -287.06267910139286
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 422 Step: 53744
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 2.0	IntrinsicReward: -306.6476112008095
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 423 Step: 53744
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2497, 'bonus': 0.020012010810811352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48369, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9302695632109493
Updated goal-option-1 on 75 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -242.8859163376037
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 424 Step: 53819
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53819, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2503, 'bonus': 0.019988010789211325, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.975595133054641
Updated goal-option-1 on 29 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -260.9365616419818
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 425 Step: 53848
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53848, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2541, 'bonus': 0.019837990021453852, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52195, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9471579149988303
Updated goal-option-1 on 66 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 426 Step: 53914
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2551, 'bonus': 0.019799069069658004, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.12694641486065
Updated goal-option-1 on 20 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 427 Step: 53934
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2538, 'bonus': 0.019849711139180454, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9609365970753253
Updated goal-option-1 on 24 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8344, 'bonus': 0.010947447024610965, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40646, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4143034365093499
Updated goal-option-3 on 41 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 428 Step: 53999
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53999, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7442618540942375
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 429 Step: 54255
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54255, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2553, 'bonus': 0.01979131233319198, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9951412309599889
Updated goal-option-1 on 11 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -301.38935004081577
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 430 Step: 54266
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -314.53359320713207
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 431 Step: 54266
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54266, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2537, 'bonus': 0.019853622797734376, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50573, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0547123945885655
Updated goal-option-1 on 32 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 432 Step: 54298
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -325.3409394919872
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 433 Step: 54298
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54298, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3266, 'bonus': 0.017498140921285422, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48557, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9347136734704661
Updated goal-option-4 on 48 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -264.6509163894225
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 434 Step: 54346
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54346, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3385, 'bonus': 0.017187814721168516, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52655, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.963906467009131
Updated goal-option-4 on 53 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -313.83893281640485
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 435 Step: 54399
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2552, 'bonus': 0.019795189561622396, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8922493801230477
Updated goal-option-1 on 8 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -310.97834218339995
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 436 Step: 54407
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54407, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2560, 'bonus': 0.01976423537605237, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53819, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9871276550089257
Updated goal-option-1 on 35 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 437 Step: 54442
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54442, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2547, 'bonus': 0.019814609942592133, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.021157099262326
Updated goal-option-1 on 77 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -298.7861885803286
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 438 Step: 54519
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2936, 'bonus': 0.018455336763139055, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9400175856187558
Updated goal-option-4 on 43 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -269.0950849605724
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 439 Step: 54562
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -307.8801464885473
Took 21.106117486953735s to update distance table with 14200 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=440 Seed=18] Took 0.09132099151611328s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 440 Step: 54562
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.39097941 0.3075553  0.30146529]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54562, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 2936, 'bonus': 0.018455336763139055, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6703468321894223
Updated goal-option-4 on 16 transitions
Took 0.0005443096160888672s to update distance table with 17 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3491, 'bonus': 0.01692485963531647, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 9062, 'bonus': 0.010504804420483137, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.713987427815381
Updated goal-option-3 on 33 transitions
Took 0.0011551380157470703s to update distance table with 34 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-4 to goal-option-1
Adding edge from SE([5 2]) to goal-option-1
Adding edge from SE([5 2]) to goal-option-4
Took 0.43569350242614746s to add potential edges.
================================================================================
[Consolidation] Episode: 441 Step: 54611
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54611, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9096000877128958
Updated goal-option-1 on 19 transitions
Deleting edge from goal-option-4 to goal-option-1
Deleting edge from SE([5 2]) to goal-option-1
Took 0.0005631446838378906s to update distance table with 20 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.55724785 0.44275215]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2728, 'bonus': 0.01914598952668709, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54630, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 8976, 'bonus': 0.010555008273018727, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47474, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8533082461029394
Updated goal-option-3 on 44 transitions
Took 0.001577138900756836s to update distance table with 45 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 442 Step: 54674
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54674, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2560, 'bonus': 0.01976423537605237, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53819, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9267431414996584
Updated goal-option-1 on 56 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9031, 'bonus': 0.010522818480847511, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9273026822391985
Updated goal-option-3 on 116 transitions
Took 0.005788564682006836s to update distance table with 173 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 443 Step: 54846
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54846, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2581, 'bonus': 0.019683666479473904, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53848, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0515334228612676
Updated goal-option-1 on 256 transitions
Took 0.00832223892211914s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 444 Step: 55102
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2553, 'bonus': 0.01979131233319198, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0111555101400083
Updated goal-option-1 on 7 transitions
Took 0.00026869773864746094s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.55724785 0.44275215]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2736, 'bonus': 0.019117977822546813, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9843, 'bonus': 0.010079436599430669, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53999, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9939117230971655
Updated goal-option-3 on 42 transitions
Took 0.0014820098876953125s to update distance table with 43 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 445 Step: 55151
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55151, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2539, 'bonus': 0.01984580179179854, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0973558221685136
Updated goal-option-1 on 256 transitions
Took 0.00885009765625s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 446 Step: 55407
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55407, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2545, 'bonus': 0.019822394114938212, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9498645436064698
Updated goal-option-1 on 24 transitions
Took 0.0008857250213623047s to update distance table with 25 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2738, 'bonus': 0.019110994086122903, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55431, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9049, 'bonus': 0.010512347433273488, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51247, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1744611529509228
Updated goal-option-3 on 11 transitions
Took 0.0004513263702392578s to update distance table with 12 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 447 Step: 55442
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.38977462 0.30968904 0.30053634]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55442, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2553, 'bonus': 0.01979131233319198, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0282513838726075
Updated goal-option-1 on 87 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9025, 'bonus': 0.010526315789473684, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47876, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0007406466829232
Updated goal-option-3 on 61 transitions
Took 0.005080461502075195s to update distance table with 149 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 448 Step: 55590
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.29979806 0.35535209 0.34484985]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2728, 'bonus': 0.01914598952668709, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54630, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9735954225611833
Updated goal-option-1 on 17 transitions
Took 0.0005474090576171875s to update distance table with 18 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2741, 'bonus': 0.019100532816794493, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55607, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12619, 'bonus': 0.00890199876762518, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55151, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.781919522096424
Updated goal-option-3 on 23 transitions
Took 0.0008289813995361328s to update distance table with 24 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 449 Step: 55630
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30086185 0.35306465 0.3460735 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55630, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2626, 'bonus': 0.019514284806274117, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54266, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0421973322404594
Updated goal-option-1 on 110 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9035, 'bonus': 0.010520488877435999, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49254, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9812323525070381
Updated goal-option-3 on 28 transitions
Took 0.00453639030456543s to update distance table with 139 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 450 Step: 55768
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30508541 0.35093175 0.34398284]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55768, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8900291267841581
Updated goal-option-4 on 256 transitions
Took 0.009511947631835938s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
Took 0.5904035568237305s to add potential edges.
================================================================================
[Consolidation] Episode: 451 Step: 56024
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30508541 0.35093175 0.34398284]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2552, 'bonus': 0.019795189561622396, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9230528815961777
Updated goal-option-1 on 181 transitions
Took 0.006138324737548828s to update distance table with 182 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.46505705 0.53494295]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2748, 'bonus': 0.019076189842912893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9043, 'bonus': 0.010515834308520003, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8367263008677771
Updated goal-option-3 on 37 transitions
Took 0.0012993812561035156s to update distance table with 38 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 452 Step: 56242
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30934203 0.34878216 0.34187581]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2738, 'bonus': 0.019110994086122903, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55431, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8977189214565534
Updated goal-option-1 on 8 transitions
Took 0.00036525726318359375s to update distance table with 9 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.47003595 0.52996405]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2751, 'bonus': 0.019065785593519964, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56250, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3337, 'bonus': 0.017310989648230364, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7580894475962733
Updated goal-option-4 on 248 transitions
Took 0.00842738151550293s to update distance table with 249 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 453 Step: 56498
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30720961 0.34985903 0.34293136]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3388, 'bonus': 0.017180203318601237, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8644274719677435
Updated goal-option-4 on 256 transitions
Took 0.009420394897460938s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 454 Step: 56754
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30720961 0.34985903 0.34293136]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56754, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2552, 'bonus': 0.019795189561622396, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.333230659124827
Updated goal-option-1 on 21 transitions
Took 0.0007178783416748047s to update distance table with 22 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 455 Step: 56775
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30720961 0.34985903 0.34293136]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56775, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2609, 'bonus': 0.01957775820486337, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.19207856851402
Updated goal-option-1 on 27 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12621, 'bonus': 0.008901293407395268, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.817500157299496
Updated goal-option-3 on 14 transitions
Took 0.0015149116516113281s to update distance table with 42 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 456 Step: 56816
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30720961 0.34985903 0.34293136]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2642, 'bonus': 0.019455105641024067, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7867001073068405
Updated goal-option-1 on 23 transitions
Took 0.0005769729614257812s to update distance table with 24 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.46754569 0.53245431]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2801, 'bonus': 0.018894849871330582, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56839, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3310, 'bonus': 0.017381449986274954, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6951363186737831
Updated goal-option-4 on 29 transitions
Took 0.0010302066802978516s to update distance table with 30 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probs: [[1.00000000e+00 2.43994112e-19 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2, from [5 2] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8573361711446628
Updated goal-option-2 on 148 transitions
Creating goal-option-2-0 with parent goal-option-2
Creating classifier of type cnn
Created model-free option goal-option-2-0 with option_idx=12
Case 3: Adding edge from goal-option-2 to SE([1 1])
Adding edge from goal-option-2 to goal-option-1
Took 0.005507230758666992s to update distance table with 149 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30508541 0.35093175 0.34398284]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 18856, 'bonus': 0.007282411495024129, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2642, 'bonus': 0.019455105641024067, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7943968295515654
Updated goal-option-1 on 56 transitions
Took 0.0018651485443115234s to update distance table with 57 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 457 Step: 57072
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.30720961 0.34985903 0.34293136]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57072, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2552, 'bonus': 0.019795189561622396, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8261847715769242
Updated goal-option-1 on 159 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12622, 'bonus': 0.008900940790150795, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55630, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.143259958135632
Updated goal-option-3 on 20 transitions
Took 0.0060765743255615234s to update distance table with 180 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 458 Step: 57251
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31148259 0.34770118 0.34081623]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57251, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3377, 'bonus': 0.017208161357142596, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.761836087078224
Updated goal-option-4 on 256 transitions
Took 0.00809788703918457s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 459 Step: 57507
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31256396 0.3454366  0.34199945]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57507, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2733, 'bonus': 0.019128467797450026, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8850247547871627
Updated goal-option-1 on 36 transitions
Took 0.00089263916015625s to update distance table with 37 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2824, 'bonus': 0.018817748237374535, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 2936, 'bonus': 0.018455336763139055, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.211358654105352
Updated goal-option-4 on 168 transitions
True
False
[Planner] Rolling out from {'count': 3504, 'bonus': 0.016893434459987148, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57711, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7000353546305136
Updated goal-option-2 on 52 transitions
Took 0.00834798812866211s to update distance table with 221 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 460 Step: 57763
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31149331 0.34425335 0.34425335]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57763, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2751, 'bonus': 0.019065785593519964, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56250, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9478065874390819
Updated goal-option-1 on 31 transitions
Took 0.0007200241088867188s to update distance table with 32 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2856, 'bonus': 0.018712029714127994, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3411, 'bonus': 0.017122183231250473, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54346, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9076680056127057
Updated goal-option-4 on 225 transitions
Took 0.0075836181640625s to update distance table with 226 states and events {SE([2 5]), None}
Adding edge from SE([1 1]) to goal-option-1
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from SE([1 1]) to goal-option-2
Took 0.9330742359161377s to add potential edges.
================================================================================
[Consolidation] Episode: 461 Step: 58019
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31148259 0.34081623 0.34770118]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2748, 'bonus': 0.019076189842912893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8565246666500553
Updated goal-option-1 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9058, 'bonus': 0.010507123617866617, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9142128826580315
Updated goal-option-3 on 17 transitions
Took 0.0010228157043457031s to update distance table with 30 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 462 Step: 58048
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31148259 0.34081623 0.34770118]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58048, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2741, 'bonus': 0.019100532816794493, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55607, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7769379691166036
Updated goal-option-1 on 112 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12624, 'bonus': 0.008900235681361305, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9141517885857158
Updated goal-option-3 on 144 transitions
Took 0.008763313293457031s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
================================================================================
[Consolidation] Episode: 463 Step: 58304
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31363123 0.33975266 0.34661611]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2856, 'bonus': 0.018712029714127994, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8607089839373167
Updated goal-option-1 on 110 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12627, 'bonus': 0.00889917833230128, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57251, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0084118401967785
Updated goal-option-3 on 18 transitions
Took 0.004027366638183594s to update distance table with 129 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 464 Step: 58432
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31795253 0.33761361 0.34443386]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2642, 'bonus': 0.019455105641024067, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9223889638225006
Updated goal-option-1 on 20 transitions
Took 0.0006310939788818359s to update distance table with 21 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2871, 'bonus': 0.018663083698528475, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3385, 'bonus': 0.017187814721168516, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52655, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7815340449186889
Updated goal-option-4 on 43 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 19 transitions
True
False
[Planner] Rolling out from {'count': 3640, 'bonus': 0.016574838603294898, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.5222851901142684
Updated goal-option-2 on 28 transitions
Took 0.0032393932342529297s to update distance table with 91 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31795253 0.33761361 0.34443386]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 18966, 'bonus': 0.007261262329146037, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3389, 'bonus': 0.0171776684306024, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0232626704706087
Updated goal-option-4 on 61 transitions
Took 0.0019378662109375s to update distance table with 62 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.39080089 0.29242207 0.31677704]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3531, 'bonus': 0.01682872219399103, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58603, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.533729206162987
Updated goal-option-2 on 85 transitions
Took 0.002911090850830078s to update distance table with 86 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 465 Step: 58688
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.31687734 0.33985354 0.34326912]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58688, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3265, 'bonus': 0.01750082037018273, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47983, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0976643615105761
Updated goal-option-4 on 25 transitions
Took 0.0008804798126220703s to update distance table with 26 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3542, 'bonus': 0.01680257031774874, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58713, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 9062, 'bonus': 0.010504804420483137, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9994426547843017
Updated goal-option-3 on 12 transitions
Took 0.00044727325439453125s to update distance table with 13 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 466 Step: 58725
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32013593 0.33993203 0.33993203]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3389, 'bonus': 0.0171776684306024, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7512209774216725
Updated goal-option-4 on 62 transitions
Took 0.002093076705932617s to update distance table with 63 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 467 Step: 58787
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32013593 0.33993203 0.33993203]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58787, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3384, 'bonus': 0.017190354104313223, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52477, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8830600472326475
Updated goal-option-4 on 256 transitions
Took 0.008955955505371094s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 468 Step: 59043
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32122243 0.33769186 0.34108572]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2642, 'bonus': 0.019455105641024067, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9414270426097668
Updated goal-option-1 on 15 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 9065, 'bonus': 0.010503066029911539, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53395, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2559064323748197
Updated goal-option-3 on 37 transitions
Took 0.0015952587127685547s to update distance table with 53 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 469 Step: 59095
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3234067  0.33660518 0.33998812]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59095, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3389, 'bonus': 0.0171776684306024, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7305857091048041
Updated goal-option-4 on 49 transitions
Took 0.001653909683227539s to update distance table with 50 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3873513  0.29866784 0.31398086]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3544, 'bonus': 0.016797828517084896, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59144, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 2856, 'bonus': 0.018712029714127994, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7728696664751963
Updated goal-option-1 on 42 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12616, 'bonus': 0.008903057122447032, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54611, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9587513720309054
Updated goal-option-3 on 21 transitions
Took 0.002136707305908203s to update distance table with 64 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 470 Step: 59207
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3255987  0.33551466 0.33888664]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59207, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2733, 'bonus': 0.019128467797450026, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8492771695808385
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12620, 'bonus': 0.00890164606655063, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55442, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7403864687786693
Updated goal-option-3 on 53 transitions
Took 0.002160787582397461s to update distance table with 63 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Took 0.9388625621795654s to add potential edges.
================================================================================
[Consolidation] Episode: 471 Step: 59269
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33000561 0.33332222 0.33667217]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59269, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2796, 'bonus': 0.018911736861805844, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56802, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8543969848593651
Updated goal-option-1 on 34 transitions
Took 0.0011734962463378906s to update distance table with 35 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38505191 0.30593669 0.3090114 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2903, 'bonus': 0.01855993633210361, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59303, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.764004993562897
Updated goal-option-2 on 82 transitions
Took 0.0028243064880371094s to update distance table with 83 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 472 Step: 59385
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33000561 0.33332222 0.33667217]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59385, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2903, 'bonus': 0.01855993633210361, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59303, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8746381080162089
Updated goal-option-1 on 25 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12629, 'bonus': 0.008898473642247334, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.944682062369341
Updated goal-option-3 on 231 transitions
Took 0.008689403533935547s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
================================================================================
[Consolidation] Episode: 473 Step: 59641
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32779836 0.33442033 0.33778131]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59641, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2738, 'bonus': 0.019110994086122903, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55431, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9806864432904913
Updated goal-option-1 on 58 transitions
Took 0.0018384456634521484s to update distance table with 59 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38622764 0.30381742 0.30995494]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2907, 'bonus': 0.018547162802488575, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59699, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12632, 'bonus': 0.008897416920979808, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59095, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6800366487192071
Updated goal-option-3 on 29 transitions
Took 0.001051187515258789s to update distance table with 30 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 474 Step: 59728
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32779836 0.33442033 0.33778131]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59728, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2867, 'bonus': 0.018676098402828818, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58414, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7717972079571247
Updated goal-option-1 on 86 transitions
Took 0.0026521682739257812s to update distance table with 87 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38622764 0.30381742 0.30995494]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2908, 'bonus': 0.0185439735388071, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.6100207181771595
Updated goal-option-2 on 52 transitions
Took 0.0019245147705078125s to update distance table with 53 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 475 Step: 59866
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32668933 0.33328889 0.34002178]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2818, 'bonus': 0.01883777067421859, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57231, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8369458728744871
Updated goal-option-1 on 34 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12621, 'bonus': 0.008901293407395268, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0140065588163176
Updated goal-option-3 on 50 transitions
Took 0.0028221607208251953s to update distance table with 85 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 476 Step: 59950
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32889277 0.33219819 0.33890904]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59950, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9949940835848299
Updated goal-option-4 on 203 transitions
Took 0.006927490234375s to update distance table with 204 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3551, 'bonus': 0.01678126377408007, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 12624, 'bonus': 0.008900235681361305, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1992594886059855
Updated goal-option-3 on 53 transitions
Took 0.0018477439880371094s to update distance table with 54 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 477 Step: 60206
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32889277 0.33219819 0.33890904]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2896, 'bonus': 0.01858235365617916, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8993938609688823
Updated goal-option-1 on 15 transitions
Took 0.0005624294281005859s to update distance table with 16 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38505191 0.30593669 0.3090114 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2935, 'bonus': 0.0184584805050515, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60221, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3542, 'bonus': 0.01680257031774874, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58713, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7706102968810441
Updated goal-option-4 on 241 transitions
Took 0.009241819381713867s to update distance table with 242 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 478 Step: 60462
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32889277 0.33219819 0.33890904]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60462, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2893, 'bonus': 0.01859198597837567, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8303122657429912
Updated goal-option-1 on 18 transitions
Took 0.00046515464782714844s to update distance table with 19 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38505191 0.30593669 0.3090114 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 2971, 'bonus': 0.01834630774138222, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3491, 'bonus': 0.01692485963531647, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8072741231185266
Updated goal-option-4 on 59 transitions
Took 0.0020551681518554688s to update distance table with 60 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 479 Step: 60539
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32777633 0.33107054 0.34115313]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60539, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2923, 'bonus': 0.018496331154174848, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8370811174708335
Updated goal-option-1 on 20 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12638, 'bonus': 0.00889530460735348, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59950, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0042553057221053
Updated goal-option-3 on 30 transitions
Took 0.0016016960144042969s to update distance table with 51 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 480 Step: 60589
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3299835 0.3299835 0.340033 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2818, 'bonus': 0.01883777067421859, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57231, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8906817632086216
Updated goal-option-1 on 12 transitions
Took 0.00034332275390625s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38387162 0.30806419 0.30806419]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2976, 'bonus': 0.018330889377669163, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60601, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12623, 'bonus': 0.008900588214808906, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55768, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8252558564974201
Updated goal-option-3 on 14 transitions
Took 0.0004096031188964844s to update distance table with 15 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 0.8394613265991211s to add potential edges.
================================================================================
[Consolidation] Episode: 481 Step: 60615
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33107054 0.32777633 0.34115313]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60615, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7340640842044285
Updated goal-option-4 on 256 transitions
Took 0.012823104858398438s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 482 Step: 60871
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33215383 0.32557675 0.34226942]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60871, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3422, 'bonus': 0.017094641498783945, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8555583162933377
Updated goal-option-4 on 256 transitions
Took 0.009128570556640625s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 483 Step: 61127
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33323336 0.32338482 0.34338182]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61127, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3501, 'bonus': 0.01690067088544646, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56868, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7465921678958898
Updated goal-option-4 on 256 transitions
Took 0.010124921798706055s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 484 Step: 61383
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33323336 0.32338482 0.34338182]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2906, 'bonus': 0.018550353712241646, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8211912481823095
Updated goal-option-1 on 14 transitions
Took 0.0003895759582519531s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38502824 0.31209782 0.30287394]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3114, 'bonus': 0.01792011101901568, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12632, 'bonus': 0.008897416920979808, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59095, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8624569751397528
Updated goal-option-3 on 12 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0004799365997314453s to update distance table with 13 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 485 Step: 61409
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33545894 0.3223054  0.34223566]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2824, 'bonus': 0.018817748237374535, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9613000265596309
Updated goal-option-1 on 11 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12629, 'bonus': 0.008898473642247334, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.643731746668658
Updated goal-option-3 on 10 transitions
Took 0.0006296634674072266s to update distance table with 22 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 486 Step: 61430
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33769186 0.32122243 0.34108572]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2856, 'bonus': 0.018712029714127994, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8310271178053018
Updated goal-option-1 on 69 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12634, 'bonus': 0.008896712649247119, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59269, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7545354903236894
Updated goal-option-3 on 11 transitions
Took 0.0027370452880859375s to update distance table with 81 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 487 Step: 61510
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33769186 0.32122243 0.34108572]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61510, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2906, 'bonus': 0.018550353712241646, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8364505593143744
Updated goal-option-1 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12643, 'bonus': 0.00889354549475152, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0546539572034748
Updated goal-option-3 on 47 transitions
Took 0.0019311904907226562s to update distance table with 60 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 488 Step: 61569
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33769186 0.32122243 0.34108572]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61569, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3384, 'bonus': 0.017190354104313223, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52477, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9185020005852608
Updated goal-option-4 on 256 transitions
Took 0.010212898254394531s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 489 Step: 61825
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33769186 0.32122243 0.34108572]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3385, 'bonus': 0.017187814721168516, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52655, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6972305227897158
Updated goal-option-4 on 25 transitions
Took 0.0004985332489013672s to update distance table with 26 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 10 transitions
True
False
[Planner] Rolling out from {'count': 3683, 'bonus': 0.016477796709963355, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61860, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 18966, 'bonus': 0.007261262329146037, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4278617373261695
Updated goal-option-2 on 94 transitions
Took 0.0035903453826904297s to update distance table with 105 states and events {SE([5 2]), None, SE([6 6])}
[Episode=490 Seed=18] Took 0.05252861976623535s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 490 Step: 61954
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61954, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2893, 'bonus': 0.01859198597837567, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0377770488739906
Updated goal-option-1 on 19 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -266.54975226381794
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 491 Step: 61973
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61973, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2893, 'bonus': 0.01859198597837567, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.834022462256705
Updated goal-option-1 on 26 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -319.1944324821234
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 492 Step: 61999
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61999, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2907, 'bonus': 0.018547162802488575, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59699, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9396724518894928
Updated goal-option-1 on 13 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -331.4953723549843
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 493 Step: 62012
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2976, 'bonus': 0.018330889377669163, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60601, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7458612630542651
Updated goal-option-1 on 16 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -316.08345788158476
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 494 Step: 62028
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62028, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3411, 'bonus': 0.017122183231250473, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54346, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7497953838085237
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 495 Step: 62284
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62284, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2893, 'bonus': 0.01859198597837567, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0518111494147566
Updated goal-option-1 on 26 transitions
[RND Rollout] Reward: 12.0	IntrinsicReward: -285.44258815213107
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 496 Step: 62310
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62310, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2975, 'bonus': 0.018333969940564226, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7703669401596516
Updated goal-option-1 on 9 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -251.43980399076827
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 497 Step: 62319
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62319, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3384, 'bonus': 0.017190354104313223, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52477, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6923870924241914
Updated goal-option-4 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 498 Step: 62575
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 9.0	IntrinsicReward: -277.3731560735032
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 499 Step: 62575
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3337, 'bonus': 0.017310989648230364, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7075976046269813
Updated goal-option-4 on 18 transitions
[RND Rollout] Reward: 11.0	IntrinsicReward: -299.31684753857553
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 500 Step: 62593
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62593, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2906, 'bonus': 0.018550353712241646, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.936983677296317
Updated goal-option-1 on 80 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -319.9717544168234
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 501 Step: 62673
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3594, 'bonus': 0.01668057294081454, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62593, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9157743292346678
Updated goal-option-4 on 24 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -301.7374317040667
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 502 Step: 62697
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62697, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3388, 'bonus': 0.017180203318601237, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9390104534471927
Updated goal-option-4 on 18 transitions
[RND Rollout] Reward: 12.0	IntrinsicReward: -324.8493731538765
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 503 Step: 62715
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3300, 'bonus': 0.017407765595569783, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7573414615691529
Updated goal-option-1 on 94 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -262.6200913370121
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 504 Step: 62809
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 2.0	IntrinsicReward: -309.52556531276787
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 505 Step: 62809
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3122, 'bonus': 0.017897136508262645, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61522, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7824988268834331
Updated goal-option-1 on 46 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -320.1185110285878
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 506 Step: 62855
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62855, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2907, 'bonus': 0.018547162802488575, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59699, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7541965877084427
Updated goal-option-1 on 17 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -287.93332297657616
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 507 Step: 62872
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 3.0	IntrinsicReward: -260.22697142488323
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 508 Step: 62872
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62872, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2935, 'bonus': 0.0184584805050515, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60221, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7634996500568696
Updated goal-option-1 on 26 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -265.44123774860054
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 509 Step: 62898
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2971, 'bonus': 0.01834630774138222, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7482360394351814
Updated goal-option-1 on 69 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -306.28081388864666
Took 122.44853067398071s to update distance table with 19051 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=510 Seed=18] Took 0.05207681655883789s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 510 Step: 62967
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32733613 0.3145011  0.35816277]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62967, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3352, 'bonus': 0.01727221339633667, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62872, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7107447588249394
Updated goal-option-1 on 15 transitions
Took 0.0003669261932373047s to update distance table with 16 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.38146205 0.31545353 0.30308442]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3398, 'bonus': 0.017154904816703558, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12638, 'bonus': 0.00889530460735348, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59950, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1607671270687734
Updated goal-option-3 on 37 transitions
Took 0.0013234615325927734s to update distance table with 38 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 0.9186022281646729s to add potential edges.
================================================================================
[Consolidation] Episode: 511 Step: 63019
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32616208 0.31337308 0.36046484]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2971, 'bonus': 0.01834630774138222, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.860829904810458
Updated goal-option-1 on 16 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12638, 'bonus': 0.00889530460735348, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59950, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3730199104150136
Updated goal-option-3 on 12 transitions
Took 0.0010733604431152344s to update distance table with 29 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 512 Step: 63047
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32836369 0.3123492  0.35928711]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63047, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3398, 'bonus': 0.017154904816703558, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.038312430532129
Updated goal-option-1 on 89 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12626, 'bonus': 0.008899530740115786, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0781595379511515
Updated goal-option-3 on 21 transitions
Took 0.003755331039428711s to update distance table with 111 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 513 Step: 63157
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33057287 0.31132181 0.35810532]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63157, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3217, 'bonus': 0.017630899487083906, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62319, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.972534749010931
Updated goal-option-1 on 188 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12633, 'bonus': 0.008897064764207749, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59207, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7925193394262959
Updated goal-option-3 on 51 transitions
Took 0.00926518440246582s to update distance table with 240 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 514 Step: 63396
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33057287 0.31132181 0.35810532]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63396, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3385, 'bonus': 0.017187814721168516, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52655, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9380846089246321
Updated goal-option-4 on 12 transitions
Took 0.0004489421844482422s to update distance table with 13 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3626347  0.30594214 0.33142316]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3777, 'bonus': 0.016271459425797673, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 17603, 'bonus': 0.007537141271820723, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48896, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3473590205675399
Updated goal-option-2 on 184 transitions
Took 0.006196022033691406s to update distance table with 185 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33057287 0.31132181 0.35810532]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 19751, 'bonus': 0.007115500532674395, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3642, 'bonus': 0.01657028695180078, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62697, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7180468381501148
Updated goal-option-4 on 17 transitions
Took 0.0005114078521728516s to update distance table with 18 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
True
False
[Planner] Rolling out from {'count': 3787, 'bonus': 0.016249961914196396, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63614, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9170065899322062
Updated goal-option-2 on 38 transitions
Took 0.0015308856964111328s to update distance table with 44 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 515 Step: 63652
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33057287 0.31132181 0.35810532]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63652, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3398, 'bonus': 0.017154904816703558, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8770898609048453
Updated goal-option-1 on 57 transitions
Took 0.0020072460174560547s to update distance table with 58 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.37904655 0.31978824 0.30116522]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3413, 'bonus': 0.017117165741551164, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63709, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22279, 'bonus': 0.006699650588835071, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6896806514123455
Updated goal-option-3 on 46 transitions
Took 0.0016367435455322266s to update distance table with 47 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 516 Step: 63755
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33160007 0.30918186 0.35921807]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3303, 'bonus': 0.017399858365729354, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7777118728803245
Updated goal-option-1 on 9 transitions
Took 0.0003063678741455078s to update distance table with 10 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.37783222 0.32196738 0.3002004 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3418, 'bonus': 0.017104641289927988, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 7733, 'bonus': 0.011371715736405084, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1978, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.1535500011273796
Updated goal-option-2 on 144 transitions
Took 0.0051572322845458984s to update distance table with 145 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 19761, 'bonus': 0.0071136999150549895, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3786, 'bonus': 0.016252107831923043, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63609, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7300243125914241
Updated goal-option-4 on 103 transitions
Took 0.003545999526977539s to update distance table with 104 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 517 Step: 64011
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3300, 'bonus': 0.017407765595569783, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8831451421843634
Updated goal-option-1 on 256 transitions
Took 0.008584022521972656s to update distance table with 257 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 518 Step: 64267
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32819862 0.30908582 0.36271557]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64267, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3196, 'bonus': 0.017688728441930625, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62028, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8237527032904591
Updated goal-option-1 on 37 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12643, 'bonus': 0.00889354549475152, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8975606895694437
Updated goal-option-3 on 33 transitions
Took 0.0024576187133789062s to update distance table with 71 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 519 Step: 64337
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32819862 0.30908582 0.36271557]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64337, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3192, 'bonus': 0.017699808135119715, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8019299167068757
Updated goal-option-1 on 165 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22283, 'bonus': 0.006699049237914837, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7637658916986906
Updated goal-option-3 on 21 transitions
Took 0.0063323974609375s to update distance table with 187 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 520 Step: 64523
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32819862 0.30908582 0.36271557]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64523, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3300, 'bonus': 0.017407765595569783, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7769081959256815
Updated goal-option-1 on 256 transitions
Took 0.008422136306762695s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 0.8592970371246338s to add potential edges.
================================================================================
[Consolidation] Episode: 521 Step: 64779
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32599757 0.31009848 0.36390394]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3377, 'bonus': 0.017208161357142596, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62967, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.84366082875875
Updated goal-option-1 on 13 transitions
Took 0.00034689903259277344s to update distance table with 14 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.5124974 0.4875026]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3454, 'bonus': 0.017015269548251433, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12630, 'bonus': 0.008898121359991322, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6966863946832773
Updated goal-option-3 on 14 transitions
Took 0.0005295276641845703s to update distance table with 15 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 522 Step: 64806
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32819862 0.30908582 0.36271557]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64806, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3405, 'bonus': 0.017137262215442182, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7746670760083617
Updated goal-option-1 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22279, 'bonus': 0.006699650588835071, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7216836315302448
Updated goal-option-3 on 18 transitions
Took 0.001031637191772461s to update distance table with 31 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 523 Step: 64836
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32819862 0.30908582 0.36271557]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3217, 'bonus': 0.017630899487083906, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62319, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.037662645233031
Updated goal-option-1 on 82 transitions
Took 0.0027027130126953125s to update distance table with 83 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3458, 'bonus': 0.017005425596285893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64918, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12640, 'bonus': 0.00889460083706025, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6356912812493498
Updated goal-option-3 on 56 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0019321441650390625s to update distance table with 57 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 524 Step: 64974
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64974, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3777, 'bonus': 0.016271459425797673, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7085118603754236
Updated goal-option-4 on 50 transitions
Took 0.0015063285827636719s to update distance table with 51 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3795, 'bonus': 0.016232825118589134, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 12636, 'bonus': 0.008896008544727062, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59728, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5575017781918915
Updated goal-option-3 on 25 transitions
Took 0.0008893013000488281s to update distance table with 26 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 525 Step: 65049
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3491, 'bonus': 0.01692485963531647, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7483006948006263
Updated goal-option-4 on 100 transitions
Took 0.0035028457641601562s to update distance table with 101 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 526 Step: 65149
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65149, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3413, 'bonus': 0.017117165741551164, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63709, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9717471612028913
Updated goal-option-1 on 46 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22279, 'bonus': 0.006699650588835071, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7553709633924344
Updated goal-option-3 on 32 transitions
Took 0.002351999282836914s to update distance table with 79 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 527 Step: 65227
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3795, 'bonus': 0.016232825118589134, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9935022814288027
Updated goal-option-4 on 39 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.0009968280792236328s to update distance table with 40 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3799, 'bonus': 0.01622427702683335, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65266, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3400, 'bonus': 0.017149858514250885, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7773685990574046
Updated goal-option-1 on 29 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
True
False
[Planner] Rolling out from {'count': 3126, 'bonus': 0.017885682339724072, 'player_pos': (2, 3), 'player_x': 2, 'player_y': 3, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65298, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9845967070124615
Updated goal-option-2 on 138 transitions
Took 0.00652766227722168s to update distance table with 171 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33040724 0.30806966 0.3615231 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 19973, 'bonus': 0.007075845620714534, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65436, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3405, 'bonus': 0.017137262215442182, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9324120714550928
Updated goal-option-1 on 13 transitions
Took 0.0003528594970703125s to update distance table with 14 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.51749286 0.48250714]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 3470, 'bonus': 0.0169759959366261, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65449, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3504, 'bonus': 0.016893434459987148, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57711, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7024375817211217
Updated goal-option-4 on 11 transitions
Took 0.000446319580078125s to update distance table with 12 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3845, 'bonus': 0.016126934718260072, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 12640, 'bonus': 0.00889460083706025, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7533531875440888
Updated goal-option-3 on 21 transitions
Took 0.00075531005859375s to update distance table with 22 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 528 Step: 65481
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3293874  0.31020537 0.36040722]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65481, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3544, 'bonus': 0.016797828517084896, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59144, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9417543352588895
Updated goal-option-4 on 245 transitions
Took 0.01058053970336914s to update distance table with 246 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3848, 'bonus': 0.016120647005479025, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 22287, 'bonus': 0.006698448048894698, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9969847793234331
Updated goal-option-3 on 11 transitions
Took 0.0004150867462158203s to update distance table with 12 states and events {SE([5 2])}
================================================================================
[Consolidation] Episode: 529 Step: 65737
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32616208 0.31337308 0.36046484]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3458, 'bonus': 0.017005425596285893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64918, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7487443176215588
Updated goal-option-1 on 148 transitions
Took 0.004940509796142578s to update distance table with 149 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3493, 'bonus': 0.016920013576624343, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12645, 'bonus': 0.008892842141870137, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61569, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7013540709866027
Updated goal-option-3 on 9 transitions
Took 0.0003733634948730469s to update distance table with 10 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 530 Step: 65894
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32836369 0.3123492  0.35928711]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65894, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3303, 'bonus': 0.017399858365729354, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6960697004065891
Updated goal-option-1 on 48 transitions
Took 0.0011758804321289062s to update distance table with 49 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.5124974 0.4875026]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3497, 'bonus': 0.016910333934197906, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65942, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 12640, 'bonus': 0.00889460083706025, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7348809911361064
Updated goal-option-3 on 45 transitions
Took 0.00156402587890625s to update distance table with 46 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 0.9407126903533936s to add potential edges.
================================================================================
[Consolidation] Episode: 531 Step: 65987
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32718227 0.3112254  0.36159233]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3422, 'bonus': 0.017094641498783945, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7708894232009339
Updated goal-option-4 on 6 transitions
Took 0.00025177001953125s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3860, 'bonus': 0.01609556949949126, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65993, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3413, 'bonus': 0.017117165741551164, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63709, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8587923669723128
Updated goal-option-1 on 17 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 8 transitions
True
False
[Planner] Rolling out from {'count': 3137, 'bonus': 0.017854296416882943, 'player_pos': (2, 3), 'player_x': 2, 'player_y': 3, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66018, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 19761, 'bonus': 0.0071136999150549895, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8549425239953614
Updated goal-option-2 on 214 transitions
Took 0.00632786750793457s to update distance table with 240 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32498475 0.31224191 0.36277334]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 20146, 'bonus': 0.007045398866644257, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3400, 'bonus': 0.017149858514250885, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7765334699791318
Updated goal-option-1 on 11 transitions
Took 0.0003085136413574219s to update distance table with 12 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 532 Step: 66243
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3227949  0.31325487 0.36395023]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66243, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3642, 'bonus': 0.01657028695180078, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62697, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.861634663107738
Updated goal-option-4 on 15 transitions
Took 0.00038933753967285156s to update distance table with 16 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Unconnected Events: [SE([1 1]), SE([2 5])] | Probs: [[1.00000000e+00 9.99117157e-20]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 10 transitions
Rolling out goal-option-2, from [4 2] targeting {'count': 18966, 'bonus': 0.007261262329146037, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6496734034493974
Updated goal-option-2 on 231 transitions
Took 0.00919651985168457s to update distance table with 242 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 533 Step: 66499
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32178185 0.31541014 0.36280802]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3377, 'bonus': 0.017208161357142596, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62967, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7860789136847779
Updated goal-option-1 on 13 transitions
Took 0.0003457069396972656s to update distance table with 14 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.37444433 0.31590551 0.30965016]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3507, 'bonus': 0.01688620732191951, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66512, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 20146, 'bonus': 0.007045398866644257, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2050884763399758
Updated goal-option-2 on 141 transitions
Took 0.004999399185180664s to update distance table with 142 states and events {SE([6 6]), SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 534 Step: 66653
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32178185 0.31541014 0.36280802]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66653, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3786, 'bonus': 0.016252107831923043, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63609, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6553685685388403
Updated goal-option-4 on 9 transitions
Took 0.0003604888916015625s to update distance table with 10 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3922, 'bonus': 0.015967841215554487, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3469, 'bonus': 0.016978442574375578, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65295, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8854306296405631
Updated goal-option-1 on 11 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
True
False
[Planner] Rolling out from {'count': 3146, 'bonus': 0.01782873955801673, 'player_pos': (2, 3), 'player_x': 2, 'player_y': 3, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 8463, 'bonus': 0.010870207379990003, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4150559138999412
Updated goal-option-2 on 7 transitions
Took 0.0008544921875s to update distance table with 24 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32178185 0.31541014 0.36280802]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 20166, 'bonus': 0.007041904298269631, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66685, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3531, 'bonus': 0.01682872219399103, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58603, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7251641161657686
Updated goal-option-4 on 78 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.002645254135131836s to update distance table with 79 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3923, 'bonus': 0.015965805928921335, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66763, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 12641, 'bonus': 0.008894249014548116, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60615, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6610199518555361
Updated goal-option-3 on 28 transitions
Took 0.0009915828704833984s to update distance table with 29 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 535 Step: 66791
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32294769 0.31655289 0.36049942]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66791, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3507, 'bonus': 0.01688620732191951, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66512, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.735496870697002
Updated goal-option-1 on 76 transitions
Took 0.002674579620361328s to update distance table with 77 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.50499983 0.49500017]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3518, 'bonus': 0.016859786954334186, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22282, 'bonus': 0.006699199560463924, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63396, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8021963275165008
Updated goal-option-3 on 8 transitions
Took 0.0003235340118408203s to update distance table with 9 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 536 Step: 66875
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32513807 0.31552879 0.35933314]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3542, 'bonus': 0.01680257031774874, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58713, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8131494658784965
Updated goal-option-4 on 256 transitions
Took 0.009336471557617188s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 537 Step: 67131
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.32616208 0.31337308 0.36046484]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3509, 'bonus': 0.016881394379731986, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7877466166241883
Updated goal-option-1 on 56 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22285, 'bonus': 0.006698748623171796, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64523, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6007368932379052
Updated goal-option-3 on 71 transitions
Took 0.0048999786376953125s to update distance table with 128 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 538 Step: 67258
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33057287 0.31132181 0.35810532]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3922, 'bonus': 0.015967841215554487, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7289866854938915
Updated goal-option-4 on 10 transitions
Took 0.00040411949157714844s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([6 6]), SE([2 5])] | Probabilities: [0.48001066 0.51998934]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3931, 'bonus': 0.015949551604596525, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 22291, 'bonus': 0.006697847021702022, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0919520809826717
Updated goal-option-3 on 56 transitions
Took 0.002184629440307617s to update distance table with 57 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 539 Step: 67324
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33278956 0.31029092 0.35691952]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3413, 'bonus': 0.017117165741551164, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63709, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7982357664005405
Updated goal-option-1 on 27 transitions
Took 0.0009264945983886719s to update distance table with 28 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([5 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([5 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3574, 'bonus': 0.016727179829474116, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67351, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3542, 'bonus': 0.01680257031774874, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58713, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7652056642258778
Updated goal-option-4 on 73 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 24 transitions
True
False
[Planner] Rolling out from {'count': 3945, 'bonus': 0.01592122559943443, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 18966, 'bonus': 0.007261262329146037, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7030641254968941
Updated goal-option-2 on 42 transitions
Took 0.005261659622192383s to update distance table with 140 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33160007 0.30918186 0.35921807]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 20229, 'bonus': 0.0070309303024908, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3531, 'bonus': 0.01682872219399103, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58603, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7684160389821341
Updated goal-option-4 on 90 transitions
Took 0.002788066864013672s to update distance table with 91 states and events {None, SE([1 1])}
================================================================================
[Consolidation] Episode: 540 Step: 67580
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33262336 0.30705006 0.36032658]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67580, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3445, 'bonus': 0.017037481092399637, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64502, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7462743115541395
Updated goal-option-1 on 232 transitions
Took 0.01361846923828125s to update distance table with 233 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([6 6]), SE([5 2])] | Probabilities: [0.51998934 0.48001066]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3588, 'bonus': 0.016694514082354447, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67812, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22279, 'bonus': 0.006699650588835071, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7322882489585654
Updated goal-option-3 on 24 transitions
Took 0.0009295940399169922s to update distance table with 25 states and events {SE([2 5]), None}
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 0.969897985458374s to add potential edges.
================================================================================
[Consolidation] Episode: 541 Step: 67836
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3336427  0.30492647 0.36143083]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3848, 'bonus': 0.016120647005479025, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.756198909119508
Updated goal-option-4 on 60 transitions
Took 0.0020372867584228516s to update distance table with 61 states and events {None, SE([1 1]), SE([6 6])}
================================================================================
[Consolidation] Episode: 542 Step: 67896
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67896, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3795, 'bonus': 0.016232825118589134, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6861278170497163
Updated goal-option-4 on 74 transitions
Took 0.0021982192993164062s to update distance table with 75 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3979, 'bonus': 0.015853057338939592, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67970, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 22285, 'bonus': 0.006698748623171796, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64523, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7796814141933014
Updated goal-option-3 on 18 transitions
Took 0.0006434917449951172s to update distance table with 19 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 543 Step: 67988
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3931, 'bonus': 0.015949551604596525, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7747114114183232
Updated goal-option-4 on 25 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.000911712646484375s to update distance table with 26 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3989, 'bonus': 0.015833173902871023, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6815835235000759
Updated goal-option-1 on 64 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 11 transitions
True
False
[Planner] Rolling out from {'count': 3156, 'bonus': 0.01780047136272261, 'player_pos': (2, 3), 'player_x': 2, 'player_y': 3, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68088, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6147272475440093
Updated goal-option-2 on 95 transitions
Took 0.006711244583129883s to update distance table with 171 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 544 Step: 68183
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68183, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3509, 'bonus': 0.016881394379731986, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7294839589390123
Updated goal-option-1 on 31 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22284, 'bonus': 0.006698898925484507, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64337, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8103986870566452
Updated goal-option-3 on 19 transitions
Took 0.0017235279083251953s to update distance table with 51 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 545 Step: 68233
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33688837 0.3017961  0.36131553]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68233, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3497, 'bonus': 0.016910333934197906, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65942, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7143132728048704
Updated goal-option-1 on 9 transitions
Took 0.00027751922607421875s to update distance table with 10 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3603, 'bonus': 0.016659726559488115, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22281, 'bonus': 0.0066993498931329, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63157, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6458936532338461
Updated goal-option-3 on 20 transitions
Took 0.0007855892181396484s to update distance table with 21 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 546 Step: 68262
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33566946 0.30070416 0.36362638]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68262, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3497, 'bonus': 0.016910333934197906, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65942, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7966735195368528
Updated goal-option-1 on 37 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22298, 'bonus': 0.006696795613293865, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6504825558428351
Updated goal-option-3 on 21 transitions
Took 0.001920938491821289s to update distance table with 59 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 547 Step: 68320
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33566946 0.30070416 0.36362638]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3845, 'bonus': 0.016126934718260072, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.728019228405821
Updated goal-option-4 on 10 transitions
Took 0.0003705024719238281s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34661611 0.31363123 0.33975266]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 4020, 'bonus': 0.015772007446912796, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8378188096154062
Updated goal-option-1 on 49 transitions
Took 0.0017392635345458984s to update distance table with 50 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Revised planner goal vertex to SE([2 5]) and dsc goal vertex to SE([1 1])
Planner goal: SE([2 5]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 11 transitions
Creating goal-option-2-0-0 with parent goal-option-2-0
Creating classifier of type cnn
Created model-free option goal-option-2-0-0 with option_idx=13
Case 1: Adding edge from goal-option-2-0 to goal-option-2
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-2-0 to goal-option-2
True
False
[Planner] Rolling out from {'count': 3161, 'bonus': 0.017786387594901105, 'player_pos': (2, 3), 'player_x': 2, 'player_y': 3, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 19751, 'bonus': 0.007115500532674395, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5339332728540127
Updated goal-option-2 on 55 transitions
Took 0.002480030059814453s to update distance table with 67 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 20493, 'bonus': 0.0069854957051325725, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3612, 'bonus': 0.016638958140993042, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68299, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8259949969841095
Updated goal-option-1 on 72 transitions
Took 0.0021626949310302734s to update distance table with 73 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.3671654  0.33222499 0.30060961]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3619, 'bonus': 0.016622858516380252, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68517, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.366826527551109
Updated goal-option-2 on 26 transitions
Took 0.0009243488311767578s to update distance table with 27 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33344318 0.30171187 0.36484495]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 20518, 'bonus': 0.006981238696129261, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3862, 'bonus': 0.01609140128253687, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7602577961227867
Updated goal-option-4 on 16 transitions
Took 0.0004534721374511719s to update distance table with 17 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3454366  0.31256396 0.34199945]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4048, 'bonus': 0.015717365336548286, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3518, 'bonus': 0.016859786954334186, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7865408016838645
Updated goal-option-1 on 17 transitions
Took 0.0006399154663085938s to update distance table with 18 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 548 Step: 68576
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33122431 0.30271622 0.36605947]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3922, 'bonus': 0.015967841215554487, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1381674518299458
Updated goal-option-4 on 9 transitions
Took 0.0003952980041503906s to update distance table with 10 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34651428 0.31041932 0.3430664 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4063, 'bonus': 0.01568832540534904, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68585, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 19973, 'bonus': 0.007075845620714534, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65436, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2369468247483237
Updated goal-option-2 on 44 transitions
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3464, 'bonus': 0.01699069165076462, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65195, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.814713212203468
Updated goal-option-1 on 11 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22291, 'bonus': 0.006697847021702022, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7936258805311726
Updated goal-option-3 on 42 transitions
Took 0.0033347606658935547s to update distance table with 98 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 549 Step: 68682
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33122431 0.30271622 0.36605947]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3862, 'bonus': 0.01609140128253687, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1600162985895055
Updated goal-option-4 on 250 transitions
Took 0.012269735336303711s to update distance table with 251 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34651428 0.31041932 0.3430664 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4065, 'bonus': 0.015684465563881998, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68932, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 19751, 'bonus': 0.007115500532674395, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1835583036072588
Updated goal-option-2 on 2 transitions
Took 0.0002624988555908203s to update distance table with 7 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 550 Step: 68938
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33122431 0.30271622 0.36605947]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68938, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3619, 'bonus': 0.016622858516380252, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68517, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7516765340134177
Updated goal-option-1 on 19 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22287, 'bonus': 0.006698448048894698, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6705999455062601
Updated goal-option-3 on 78 transitions
Took 0.003372669219970703s to update distance table with 98 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-1 to goal-option-2
Adding edge from goal-option-4 to goal-option-2
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from SE([2 5]) to goal-option-2
Took 1.066317081451416s to add potential edges.
================================================================================
[Consolidation] Episode: 551 Step: 69035
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33344318 0.30171187 0.36484495]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3687, 'bonus': 0.016468855962311107, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68957, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7294922132305647
Updated goal-option-1 on 8 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22292, 'bonus': 0.006697696790180887, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65481, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7321486784352196
Updated goal-option-3 on 54 transitions
Took 0.0017426013946533203s to update distance table with 63 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 552 Step: 69097
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33344318 0.30171187 0.36484495]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69097, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3509, 'bonus': 0.016881394379731986, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9386076266382947
Updated goal-option-1 on 11 transitions
Took 0.00039458274841308594s to update distance table with 12 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.3671654  0.33222499 0.30060961]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3708, 'bonus': 0.01642215463607155, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 12 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 8924, 'bonus': 0.010585715534396724, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0556360329260848
Updated goal-option-2 on 81 transitions
Deleting edge from goal-option-1 to goal-option-2
Deleting edge from SE([2 5]) to goal-option-2
Deleting edge from goal-option-4 to goal-option-2
Took 0.0035707950592041016s to update distance table with 94 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33344318 0.30171187 0.36484495]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 20541, 'bonus': 0.006977329113762267, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69201, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3786, 'bonus': 0.016252107831923043, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63609, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8089219925387345
Updated goal-option-4 on 8 transitions
Took 0.00031757354736328125s to update distance table with 9 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3454366  0.31256396 0.34199945]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4070, 'bonus': 0.01567482841055192, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69209, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 8 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 18856, 'bonus': 0.007282411495024129, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5776853922023075
Updated goal-option-2 on 136 transitions
Took 0.00532984733581543s to update distance table with 145 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 553 Step: 69353
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33344318 0.30171187 0.36484495]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3509, 'bonus': 0.016881394379731986, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7463081568162232
Updated goal-option-1 on 47 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22304, 'bonus': 0.006695894800069752, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68262, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5592231626147466
Updated goal-option-3 on 21 transitions
Took 0.0018875598907470703s to update distance table with 69 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 554 Step: 69421
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33344318 0.30171187 0.36484495]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69421, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8588474239496624
Updated goal-option-1 on 43 transitions
Took 0.001617431640625s to update distance table with 44 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.3671654  0.33222499 0.30060961]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 3740, 'bonus': 0.016351748504193214, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69464, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3989, 'bonus': 0.015833173902871023, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6216856455990005
Updated goal-option-4 on 76 transitions
Took 0.0034685134887695312s to update distance table with 77 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3454366  0.31256396 0.34199945]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4094, 'bonus': 0.015628816094818164, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69540, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [4 2] targeting {'count': 16124, 'bonus': 0.007875236506747693, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9614449127079687
Updated goal-option-2 on 9 transitions
Took 0.00046181678771972656s to update distance table with 13 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33243515 0.30382285 0.36374199]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 20570, 'bonus': 0.00697240898952155, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3739, 'bonus': 0.01635393500530671, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7944651778480729
Updated goal-option-1 on 15 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22298, 'bonus': 0.006696795613293865, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7837834595877341
Updated goal-option-3 on 13 transitions
Took 0.0008347034454345703s to update distance table with 29 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 555 Step: 69580
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69580, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4065, 'bonus': 0.015684465563881998, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68932, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8080517649284001
Updated goal-option-4 on 7 transitions
Took 0.0002493858337402344s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34435487 0.31471665 0.34092848]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 4097, 'bonus': 0.015623093000542114, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 9 transitions
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 20146, 'bonus': 0.007045398866644257, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4103288274627548
Updated goal-option-2 on 14 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7748658248079501
Updated goal-option-1 on 68 transitions
Took 0.0033311843872070312s to update distance table with 92 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.36374199 0.33243515 0.30382285]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 3784, 'bonus': 0.01625640221905888, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 3799, 'bonus': 0.01622427702683335, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65266, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7672850069973398
Updated goal-option-4 on 158 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.011970996856689453s to update distance table with 159 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 556 Step: 69836
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3336427  0.30492647 0.36143083]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3507, 'bonus': 0.01688620732191951, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66512, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6844797124513531
Updated goal-option-1 on 37 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22287, 'bonus': 0.006698448048894698, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5927826341633734
Updated goal-option-3 on 9 transitions
Took 0.0016388893127441406s to update distance table with 47 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 557 Step: 69882
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3336427  0.30492647 0.36143083]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69882, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3574, 'bonus': 0.016727179829474116, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67351, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7665552533855907
Updated goal-option-1 on 30 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22289, 'bonus': 0.006698147515074466, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.699453992196937
Updated goal-option-3 on 48 transitions
Took 0.0030968189239501953s to update distance table with 79 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 558 Step: 69960
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33586964 0.30390742 0.36022294]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3603, 'bonus': 0.016659726559488115, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8753000968064484
Updated goal-option-1 on 16 transitions
Took 0.0003993511199951172s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.36253077 0.33465808 0.30281115]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 3958, 'bonus': 0.015895057564452583, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69976, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 4065, 'bonus': 0.015684465563881998, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68932, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7472339706300529
Updated goal-option-4 on 45 transitions
Took 0.001760244369506836s to update distance table with 46 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34326912 0.31687734 0.33985354]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 4112, 'bonus': 0.015594571538795133, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70021, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [3 2] targeting {'count': 3698, 'bonus': 0.01644434374852436, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7339304616173586
Updated goal-option-1 on 103 transitions
Took 0.0037415027618408203s to update distance table with 108 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.36253077 0.33465808 0.30281115]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3975, 'bonus': 0.015861031714362882, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 7 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 13712, 'bonus': 0.008539837321064439, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8928835006554925
Updated goal-option-2 on 81 transitions
Took 0.003559112548828125s to update distance table with 89 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 559 Step: 70216
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33586964 0.30390742 0.36022294]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3783, 'bonus': 0.016258550689592154, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8210074511858133
Updated goal-option-1 on 75 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22307, 'bonus': 0.006695444529754865, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6000618958821544
Updated goal-option-3 on 13 transitions
Took 0.004286050796508789s to update distance table with 89 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
[Episode=560 Seed=18] Took 0.052652597427368164s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 560 Step: 70304
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3990, 'bonus': 0.01583118967153259, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70291, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6803503482461833
Updated goal-option-1 on 12 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -299.07605172274634
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 561 Step: 70316
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3619, 'bonus': 0.016622858516380252, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68517, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8760510732968457
Updated goal-option-1 on 10 transitions
[RND Rollout] Reward: 9.0	IntrinsicReward: -290.1602784449351
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 562 Step: 70326
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -310.9168783959467
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 563 Step: 70326
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 8.0	IntrinsicReward: -307.45566615404096
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 564 Step: 70326
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70326, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3848, 'bonus': 0.016120647005479025, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7471433227877257
Updated goal-option-4 on 11 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -267.06792301358655
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 565 Step: 70337
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -305.0488413826097
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 566 Step: 70337
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70337, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3784, 'bonus': 0.01625640221905888, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7085705917013699
Updated goal-option-1 on 16 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -327.5313141196966
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 567 Step: 70353
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3975, 'bonus': 0.015861031714362882, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7187566640512034
Updated goal-option-1 on 12 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -265.05109388334677
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 568 Step: 70365
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70365, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3621, 'bonus': 0.016618267200585898, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68640, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7421713385348673
Updated goal-option-1 on 14 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -260.5129199446528
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 569 Step: 70379
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70379, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3958, 'bonus': 0.015895057564452583, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69976, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7587890035947732
Updated goal-option-1 on 11 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -321.7792309820652
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 570 Step: 70390
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3862, 'bonus': 0.01609140128253687, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66258, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7136649026971057
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -272.89259889908135
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 571 Step: 70397
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4207, 'bonus': 0.015417492434686497, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.724285919237252
Updated goal-option-4 on 216 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 572 Step: 70613
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 5.0	IntrinsicReward: -318.82698119804263
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 573 Step: 70613
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70613, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-1, goal-option-4] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3990, 'bonus': 0.01583118967153259, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70291, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7111867286856213
Updated goal-option-1 on 18 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 4112, 'bonus': 0.015594571538795133, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70021, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6020739210498319
Updated goal-option-4 on 35 transitions
[RND Rollout] Reward: 13.0	IntrinsicReward: -306.94923274964094
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 574 Step: 70666
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3922, 'bonus': 0.015967841215554487, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6999027354897356
Updated goal-option-4 on 12 transitions
[RND Rollout] Reward: 9.0	IntrinsicReward: -264.32098598685116
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 575 Step: 70678
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -324.77934472518973
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 576 Step: 70678
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3993, 'bonus': 0.015825241450517984, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6873740200498984
Updated goal-option-1 on 127 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -295.36578230187297
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 577 Step: 70805
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70805, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3783, 'bonus': 0.016258550689592154, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6779883781387825
Updated goal-option-1 on 45 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22291, 'bonus': 0.006697847021702022, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4875400191197148
Updated goal-option-3 on 10 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 578 Step: 70860
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70860, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3958, 'bonus': 0.015895057564452583, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69976, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7104906497183462
Updated goal-option-1 on 57 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22311, 'bonus': 0.006694844310611592, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69882, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5933108704384937
Updated goal-option-3 on 10 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 579 Step: 70927
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4238, 'bonus': 0.015361001225823307, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70631, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6984929152446635
Updated goal-option-1 on 36 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22304, 'bonus': 0.006695894800069752, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68262, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5694901237564701
Updated goal-option-3 on 10 transitions
Took 115.21471691131592s to update distance table with 16705 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=580 Seed=18] Took 0.06994223594665527s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 580 Step: 70973
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3336427  0.30492647 0.36143083]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70973, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4063, 'bonus': 0.01568832540534904, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68585, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8487381414736186
Updated goal-option-4 on 256 transitions
Took 0.02647113800048828s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
Adding edge from goal-option-4 to goal-option-1
Adding edge from SE([5 2]) to goal-option-1
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 1.1419486999511719s to add potential edges.
================================================================================
[Consolidation] Episode: 581 Step: 71229
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71229, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3975, 'bonus': 0.015861031714362882, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7007764400404198
Updated goal-option-1 on 16 transitions
Deleting edge from goal-option-4 to goal-option-1
Deleting edge from SE([5 2]) to goal-option-1
Took 0.0005290508270263672s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.36253077 0.33465808 0.30281115]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4464, 'bonus': 0.01496710850223124, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 21 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 13350, 'bonus': 0.00865484644815831, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25223, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.691642854689506
Updated goal-option-2 on 5 transitions
Took 0.0009329319000244141s to update distance table with 27 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33465808 0.30281115 0.36253077]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 20721, 'bonus': 0.006946957542794883, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3932, 'bonus': 0.01594752330273742, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69873, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7294796017053713
Updated goal-option-1 on 47 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22301, 'bonus': 0.006696345161239233, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4467962772775722
Updated goal-option-3 on 9 transitions
Took 0.0018219947814941406s to update distance table with 57 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 582 Step: 71327
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33688837 0.3017961  0.36131553]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3922, 'bonus': 0.015967841215554487, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66662, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9258595812681306
Updated goal-option-4 on 256 transitions
Took 0.015465021133422852s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 583 Step: 71583
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33688837 0.3017961  0.36131553]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71583, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3784, 'bonus': 0.01625640221905888, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 195 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6618102658091355
Updated goal-option-1 on 31 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22299, 'bonus': 0.00669664545250875, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7390054646905112
Updated goal-option-3 on 6 transitions
Took 0.0010635852813720703s to update distance table with 38 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 584 Step: 71620
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33688837 0.3017961  0.36131553]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71620, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3958, 'bonus': 0.015895057564452583, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69976, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8046942170045174
Updated goal-option-1 on 256 transitions
Took 0.022977828979492188s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 585 Step: 71876
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3381039  0.30288502 0.35901108]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71876, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4602, 'bonus': 0.014740991400388204, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71614, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 196 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8173787138797199
Updated goal-option-1 on 16 transitions
Took 0.0003604888916015625s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.36131553 0.33688837 0.3017961 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 4603, 'bonus': 0.014739390076023, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 4224, 'bonus': 0.01538643637241659, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6997675355303654
Updated goal-option-4 on 32 transitions
Took 0.0012404918670654297s to update distance table with 33 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34217939 0.31904595 0.33877465]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4563, 'bonus': 0.01480385305614425, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71924, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 16124, 'bonus': 0.007875236506747693, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5455478544617112
Updated goal-option-2 on 203 transitions
Took 0.0072557926177978516s to update distance table with 209 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 586 Step: 72132
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33707782 0.30500063 0.35792155]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4093, 'bonus': 0.01563072519103182, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 197 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7334846473210371
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22297, 'bonus': 0.006696945784180726, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9872130241531591
Updated goal-option-3 on 10 transitions
Took 0.0005843639373779297s to update distance table with 18 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 587 Step: 72149
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33707782 0.30500063 0.35792155]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72149, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4224, 'bonus': 0.01538643637241659, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7897641074009257
Updated goal-option-4 on 14 transitions
Took 0.0005135536193847656s to update distance table with 15 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34217939 0.31904595 0.33877465]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4581, 'bonus': 0.014774740239264542, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72163, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 22306, 'bonus': 0.006695594609766758, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7467488301028111
Updated goal-option-3 on 214 transitions
Took 0.018101930618286133s to update distance table with 215 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 588 Step: 72377
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33931601 0.30397087 0.35671312]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72377, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4190, 'bonus': 0.015448737310436523, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70337, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.699096067620555
Updated goal-option-4 on 256 transitions
Took 0.01884770393371582s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 589 Step: 72633
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34034541 0.3018593  0.35779529]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72633, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4097, 'bonus': 0.015623093000542114, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9080892890379145
Updated goal-option-4 on 256 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.020064830780029297s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 590 Step: 72889
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34034541 0.3018593  0.35779529]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72889, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4581, 'bonus': 0.014774740239264542, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72163, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9121622813470435
Updated goal-option-4 on 10 transitions
Took 0.0003733634948730469s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.32122243 0.33769186]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4789, 'bonus': 0.014450323889576911, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72899, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 20581, 'bonus': 0.006970545456416095, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.520466414272276
Updated goal-option-2 on 40 transitions
Took 0.0014357566833496094s to update distance table with 41 states and events {SE([5 2]), None, SE([6 6])}
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 1.2903215885162354s to add potential edges.
================================================================================
[Consolidation] Episode: 591 Step: 72939
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33931601 0.30397087 0.35671312]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72939, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4241, 'bonus': 0.015355567229582588, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70850, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 198 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8308891464091047
Updated goal-option-1 on 11 transitions
Took 0.0003383159637451172s to update distance table with 12 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35901108 0.3381039  0.30288502]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 4991, 'bonus': 0.014154880754301795, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72950, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 4112, 'bonus': 0.015594571538795133, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70021, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6231807261291477
Updated goal-option-4 on 88 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.0030868053436279297s to update distance table with 89 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.32122243 0.33769186]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4807, 'bonus': 0.014423243612783817, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 40 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 19973, 'bonus': 0.007075845620714534, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65436, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1670530659457048
Updated goal-option-2 on 117 transitions
Took 0.005728721618652344s to update distance table with 158 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 592 Step: 73195
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33828257 0.30609073 0.35562669]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73195, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4246, 'bonus': 0.01534652337036732, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70963, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 199 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8124975508975761
Updated goal-option-1 on 10 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22307, 'bonus': 0.006695444529754865, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6139925674792212
Updated goal-option-3 on 8 transitions
Took 0.000858306884765625s to update distance table with 19 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 593 Step: 73213
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33828257 0.30609073 0.35562669]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73213, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3963, 'bonus': 0.015885027237483865, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7013204633775686
Updated goal-option-4 on 12 transitions
Took 0.0003447532653808594s to update distance table with 13 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.32122243 0.33769186]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 4835, 'bonus': 0.014381419703158196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 4070, 'bonus': 0.01567482841055192, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70326, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6403017012636143
Updated goal-option-1 on 244 transitions
Took 0.022581815719604492s to update distance table with 245 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 594 Step: 73469
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33843903 0.30930998 0.35225099]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73469, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4464, 'bonus': 0.01496710850223124, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7225041348358681
Updated goal-option-1 on 256 transitions
Took 0.01698613166809082s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 595 Step: 73725
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33620368 0.31035511 0.35344121]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 3963, 'bonus': 0.015885027237483865, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6127603379002777
Updated goal-option-4 on 12 transitions
Took 0.00044536590576171875s to update distance table with 13 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34333674 0.32012505 0.33653821]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5268, 'bonus': 0.013777712461369822, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 28 transitions
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [4 2] targeting {'count': 20526, 'bonus': 0.006979878096097605, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6075302819168664
Updated goal-option-2 on 112 transitions
Took 0.006201744079589844s to update distance table with 141 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 596 Step: 73877
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33633743 0.31359894 0.35006362]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5001, 'bonus': 0.014140721622265264, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 200 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6989829874959196
Updated goal-option-1 on 21 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22313, 'bonus': 0.006694544261566708, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6772370281381698
Updated goal-option-3 on 9 transitions
Took 0.000949859619140625s to update distance table with 31 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 597 Step: 73907
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33633743 0.31359894 0.35006362]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73907, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4246, 'bonus': 0.01534652337036732, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70963, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 201 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7334622745519371
Updated goal-option-1 on 128 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31877, 'bonus': 0.005600944622958541, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72149, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.70843652792998
Updated goal-option-3 on 8 transitions
Took 0.005657672882080078s to update distance table with 137 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 598 Step: 74043
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33633743 0.31359894 0.35006362]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4070, 'bonus': 0.01567482841055192, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69209, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8201494885150948
Updated goal-option-4 on 9 transitions
Took 0.0003192424774169922s to update distance table with 10 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3444903  0.32120063 0.33430907]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5338, 'bonus': 0.013687077150699013, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74052, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 18856, 'bonus': 0.007282411495024129, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4649209192239614
Updated goal-option-2 on 114 transitions
Took 0.004594326019287109s to update distance table with 115 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 599 Step: 74166
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33528072 0.31575549 0.34896379]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74166, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4244, 'bonus': 0.01535013899613792, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 202 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6998350307198303
Updated goal-option-1 on 75 transitions
Took 0.0024900436401367188s to update distance table with 76 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35580994 0.33175499 0.31243508]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5033, 'bonus': 0.01409569632468742, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74241, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 20570, 'bonus': 0.00697240898952155, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.658515177667141
Updated goal-option-2 on 23 transitions
Took 0.0008776187896728516s to update distance table with 24 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 600 Step: 74264
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33528072 0.31575549 0.34896379]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74264, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5002, 'bonus': 0.014139308044851598, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 203 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7085109120439922
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22308, 'bonus': 0.0066952944598345325, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69097, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5251404871262094
Updated goal-option-3 on 7 transitions
Took 0.0004904270172119141s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-4 to goal-option-3
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 1.4502007961273193s to add potential edges.
================================================================================
[Consolidation] Episode: 601 Step: 74278
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33528072 0.31575549 0.34896379]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74278, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5005, 'bonus': 0.01413506985480439, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 204 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7550582000007254
Updated goal-option-1 on 78 transitions
Took 0.002964496612548828s to update distance table with 79 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35580994 0.33175499 0.31243508]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 5040, 'bonus': 0.014085904245475275, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 4230, 'bonus': 0.015375520133814751, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8532950540554934
Updated goal-option-4 on 57 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.002306699752807617s to update distance table with 58 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3444903  0.32120063 0.33430907]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5362, 'bonus': 0.01365641151736129, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 22313, 'bonus': 0.006694544261566708, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6230554624735934
Updated goal-option-3 on 8 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0002460479736328125s to update distance table with 9 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 602 Step: 74421
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33528072 0.31575549 0.34896379]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74421, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4112, 'bonus': 0.015594571538795133, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70021, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7452438577992536
Updated goal-option-4 on 9 transitions
Took 0.0002982616424560547s to update distance table with 10 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.3444903  0.32120063 0.33430907]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5365, 'bonus': 0.013652592788242301, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 24 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 2] targeting {'count': 20581, 'bonus': 0.006970545456416095, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.2076155199181464
Updated goal-option-2 on 10 transitions
Took 0.0011873245239257812s to update distance table with 35 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33422011 0.31792    0.34785989]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 21022, 'bonus': 0.006897043801891763, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74464, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4464, 'bonus': 0.01496710850223124, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 205 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7024160393290391
Updated goal-option-1 on 125 transitions
Took 0.00637364387512207s to update distance table with 126 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35469618 0.33071653 0.31458729]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5065, 'bonus': 0.01405109839972998, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 22306, 'bonus': 0.006695594609766758, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8729644433538618
Updated goal-option-3 on 8 transitions
Took 0.0003294944763183594s to update distance table with 9 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 603 Step: 74597
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33422011 0.31792    0.34785989]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74597, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5002, 'bonus': 0.014139308044851598, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 206 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6541084089391941
Updated goal-option-1 on 80 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31877, 'bonus': 0.005600944622958541, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72149, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6745428436358148
Updated goal-option-3 on 10 transitions
Took 0.0027213096618652344s to update distance table with 91 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 604 Step: 74687
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33422011 0.31792    0.34785989]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74687, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5067, 'bonus': 0.014048325065369655, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74677, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 207 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6899018832468414
Updated goal-option-1 on 14 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31876, 'bonus': 0.005601032477468141, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71620, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6321397045472016
Updated goal-option-3 on 6 transitions
Took 0.0008497238159179688s to update distance table with 21 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 605 Step: 74707
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33422011 0.31792    0.34785989]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4603, 'bonus': 0.014739390076023, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 208 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6285168709268284
Updated goal-option-1 on 23 transitions
Took 0.0008435249328613281s to update distance table with 24 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35469618 0.33071653 0.31458729]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5070, 'bonus': 0.014044168141158105, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31880, 'bonus': 0.005600681084232282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73213, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5018282692258557
Updated goal-option-3 on 8 transitions
Took 0.00033593177795410156s to update distance table with 9 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 606 Step: 74738
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33422011 0.31792    0.34785989]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74738, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5040, 'bonus': 0.014085904245475275, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 209 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6456221116306708
Updated goal-option-1 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31873, 'bonus': 0.005601296065804024, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6324816779937309
Updated goal-option-3 on 7 transitions
Took 0.0005650520324707031s to update distance table with 20 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 607 Step: 74757
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33422011 0.31792    0.34785989]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74757, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4246, 'bonus': 0.01534652337036732, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70963, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 210 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6557469513103377
Updated goal-option-1 on 29 transitions
Took 0.0006382465362548828s to update distance table with 30 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35469618 0.33071653 0.31458729]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5073, 'bonus': 0.014040014904887734, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74786, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31873, 'bonus': 0.005601296065804024, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6242096211497072
Updated goal-option-3 on 7 transitions
Took 0.00029778480529785156s to update distance table with 8 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 608 Step: 74793
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33644896 0.31685569 0.34669535]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4464, 'bonus': 0.01496710850223124, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 211 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6647815544025174
Updated goal-option-1 on 143 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31886, 'bonus': 0.005600154118362036, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74278, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.558858230987691
Updated goal-option-3 on 8 transitions
Took 0.0053558349609375s to update distance table with 152 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 609 Step: 74944
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33644896 0.31685569 0.34669535]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74944, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5065, 'bonus': 0.01405109839972998, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 212 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6956203986338182
Updated goal-option-1 on 9 transitions
Took 0.0003299713134765625s to update distance table with 10 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35352116 0.33293369 0.31354514]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5076, 'bonus': 0.014035865351108649, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74953, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 20721, 'bonus': 0.006946957542794883, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4759152167758278
Updated goal-option-2 on 244 transitions
Took 0.012556076049804688s to update distance table with 248 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 610 Step: 75200
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33644896 0.31685569 0.34669535]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5074, 'bonus': 0.014038631311397813, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 213 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7761178690746978
Updated goal-option-1 on 56 transitions
Took 0.0014464855194091797s to update distance table with 57 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35352116 0.33293369 0.31354514]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5078, 'bonus': 0.014033101025064882, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 20229, 'bonus': 0.0070309303024908, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.435062991476607
Updated goal-option-2 on 33 transitions
Took 0.0013110637664794922s to update distance table with 34 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33644896 0.31685569 0.34669535]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 21182, 'bonus': 0.006870945727775229, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5072, 'bonus': 0.01404139890754326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74750, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 214 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7265817163167178
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31880, 'bonus': 0.005600681084232282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73213, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7038592379463552
Updated goal-option-3 on 13 transitions
Took 0.0007505416870117188s to update distance table with 21 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from goal-option-2-0 to goal-option-4
Took 1.2491509914398193s to add potential edges.
================================================================================
[Consolidation] Episode: 611 Step: 75309
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33644896 0.31685569 0.34669535]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5001, 'bonus': 0.014140721622265264, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 215 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6078988833896882
Updated goal-option-1 on 87 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31880, 'bonus': 0.005600681084232282, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73213, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5949668212498658
Updated goal-option-3 on 6 transitions
Took 0.004334926605224609s to update distance table with 94 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 612 Step: 75402
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.3386851 0.3157879 0.345527 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75402, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4563, 'bonus': 0.01480385305614425, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71924, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5999562056545266
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2-0 to goal-option-4
Took 0.0003159046173095703s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34226942 0.32557675 0.33215383]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5633, 'bonus': 0.01332386195346053, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 20166, 'bonus': 0.007041904298269631, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66685, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.1048171583856092
Updated goal-option-2 on 43 transitions
Took 0.0015969276428222656s to update distance table with 44 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 21184, 'bonus': 0.006870621374116408, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4624, 'bonus': 0.014705882352941176, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72139, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 216 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6533015231687059
Updated goal-option-1 on 8 transitions
Took 0.0003185272216796875s to update distance table with 9 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35123909 0.33410895 0.31465196]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5096, 'bonus': 0.014008295367013144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 20518, 'bonus': 0.006981238696129261, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3024371708984728
Updated goal-option-2 on 193 transitions
Took 0.007928133010864258s to update distance table with 199 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 613 Step: 75658
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75658, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5072, 'bonus': 0.01404139890754326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74750, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7372015378439304
Updated goal-option-1 on 117 transitions
Took 0.004050016403198242s to update distance table with 118 states and events {SE([5 2]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 614 Step: 75775
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75775, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5069, 'bonus': 0.01404555337252126, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74701, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 217 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6830578633363902
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31894, 'bonus': 0.0055994517285288, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74944, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4631342268529743
Updated goal-option-3 on 12 transitions
Took 0.0007123947143554688s to update distance table with 22 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 615 Step: 75796
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5076, 'bonus': 0.014035865351108649, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74953, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 218 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6182017868373827
Updated goal-option-1 on 60 transitions
Took 0.002179861068725586s to update distance table with 61 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35123909 0.33410895 0.31465196]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5099, 'bonus': 0.014004173865810708, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 20581, 'bonus': 0.006970545456416095, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3551155127576628
Updated goal-option-2 on 45 transitions
Took 0.001994609832763672s to update distance table with 46 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 616 Step: 75901
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75901, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4063, 'bonus': 0.01568832540534904, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68585, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8071869819298096
Updated goal-option-4 on 11 transitions
Took 0.0004525184631347656s to update distance table with 12 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34226942 0.32557675 0.33215383]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5744, 'bonus': 0.013194495349231488, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75912, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 41 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 2] targeting {'count': 5040, 'bonus': 0.014085904245475275, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 219 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6957133746330152
Updated goal-option-1 on 15 transitions
Took 0.0020020008087158203s to update distance table with 57 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35123909 0.33410895 0.31465196]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5129, 'bonus': 0.013963157940958374, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75968, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31878, 'bonus': 0.005600856772582914, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72377, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4597320412871449
Updated goal-option-3 on 7 transitions
Took 0.00029540061950683594s to update distance table with 8 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 617 Step: 75975
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75975, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5039, 'bonus': 0.014087301864593216, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 220 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6415210714051534
Updated goal-option-1 on 32 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31878, 'bonus': 0.005600856772582914, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72377, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6463517331516327
Updated goal-option-3 on 9 transitions
Took 0.0014443397521972656s to update distance table with 42 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 618 Step: 76016
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5076, 'bonus': 0.014035865351108649, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74953, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 221 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6639174594173786
Updated goal-option-1 on 27 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31876, 'bonus': 0.005601032477468141, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71620, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48775194661505133
Updated goal-option-3 on 9 transitions
Took 0.0014920234680175781s to update distance table with 37 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 619 Step: 76052
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76052, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5033, 'bonus': 0.01409569632468742, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74241, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 222 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6399516714337777
Updated goal-option-1 on 20 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31895, 'bonus': 0.005599363948381144, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6379496208657095
Updated goal-option-3 on 19 transitions
Took 0.0014691352844238281s to update distance table with 40 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 620 Step: 76091
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5072, 'bonus': 0.01404139890754326, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74750, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 223 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6594131934248891
Updated goal-option-1 on 8 transitions
Took 0.0003323554992675781s to update distance table with 9 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35123909 0.33410895 0.31465196]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5147, 'bonus': 0.013938720698803529, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76099, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 4] targeting {'count': 20581, 'bonus': 0.006970545456416095, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2726684280514289
Updated goal-option-2 on 215 transitions
Took 0.011806964874267578s to update distance table with 219 states and events {SE([6 6]), SE([2 5]), None, SE([5 2])}
Adding edge from goal-option-2-0 to goal-option-4
Took 1.160754680633545s to add potential edges.
================================================================================
[Consolidation] Episode: 621 Step: 76317
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33761361 0.31795253 0.34443386]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5133, 'bonus': 0.013957716335942309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 224 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6146231998028099
Updated goal-option-1 on 13 transitions
Took 0.0003294944763183594s to update distance table with 14 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35123909 0.33410895 0.31465196]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5150, 'bonus': 0.013934660285832352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31903, 'bonus': 0.005598661855785878, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6666039384073681
Updated goal-option-3 on 24 transitions
Took 0.0011446475982666016s to update distance table with 25 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 622 Step: 76354
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33985354 0.31687734 0.34326912]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5095, 'bonus': 0.014009670009611718, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75396, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 225 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5842739987308564
Updated goal-option-1 on 9 transitions
Took 0.0003325939178466797s to update distance table with 10 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35006362 0.33633743 0.31359894]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76363, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 6 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 18966, 'bonus': 0.007261262329146037, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.914422822730583
Updated goal-option-2 on 145 transitions
Took 0.0071430206298828125s to update distance table with 152 states and events {SE([6 6]), SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 623 Step: 76514
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33985354 0.31687734 0.34326912]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4789, 'bonus': 0.014450323889576911, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72899, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8452998145938464
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2-0 to goal-option-4
Took 0.0002758502960205078s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34115313 0.32777633 0.33107054]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5992, 'bonus': 0.012918559733220045, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76521, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5099, 'bonus': 0.014004173865810708, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6464240298341707
Updated goal-option-1 on 249 transitions
Took 0.00856637954711914s to update distance table with 250 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 624 Step: 76770
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34101832 0.31796337 0.34101832]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76770, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5133, 'bonus': 0.013957716335942309, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76043, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 226 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7245657882434121
Updated goal-option-1 on 10 transitions
Took 0.0003108978271484375s to update distance table with 11 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35006362 0.33633743 0.31359894]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5173, 'bonus': 0.013903647892017406, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76780, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31894, 'bonus': 0.0055994517285288, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74944, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6375229063961241
Updated goal-option-3 on 8 transitions
Took 0.0003266334533691406s to update distance table with 9 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 625 Step: 76788
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34101832 0.31796337 0.34101832]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5074, 'bonus': 0.014038631311397813, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 227 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7900097156331212
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31891, 'bonus': 0.005599715093743861, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74738, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.656603210441994
Updated goal-option-3 on 7 transitions
Took 0.0005202293395996094s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 626 Step: 76804
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34101832 0.31796337 0.34101832]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76804, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4835, 'bonus': 0.014381419703158196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6982025642237163
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.0003001689910888672s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34228068 0.32885966 0.32885966]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5994, 'bonus': 0.012916404304868808, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5094, 'bonus': 0.014011045056973283, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 228 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6319242830056397
Updated goal-option-1 on 125 transitions
Took 0.005448341369628906s to update distance table with 126 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35006362 0.33633743 0.31359894]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5175, 'bonus': 0.013900960937138317, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 21022, 'bonus': 0.006897043801891763, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74464, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.993307759364446
Updated goal-option-2 on 124 transitions
Took 0.004990577697753906s to update distance table with 125 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 627 Step: 77060
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34101832 0.31796337 0.34101832]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5744, 'bonus': 0.013194495349231488, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75912, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7158462089490673
Updated goal-option-4 on 6 transitions
Took 0.00023484230041503906s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34228068 0.32885966 0.32885966]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 6132, 'bonus': 0.012770236105969923, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77066, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 12 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 5099, 'bonus': 0.014004173865810708, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 229 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6647835476538059
Updated goal-option-1 on 4 transitions
Took 0.0006990432739257812s to update distance table with 17 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.35006362 0.33633743 0.31359894]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 5177, 'bonus': 0.013898275539462893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 4224, 'bonus': 0.01538643637241659, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.797536536932534
Updated goal-option-4 on 20 transitions
Took 0.0009067058563232422s to update distance table with 21 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34228068 0.32885966 0.32885966]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6140, 'bonus': 0.012761914022253898, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 20166, 'bonus': 0.007041904298269631, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66685, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.548856466197643
Updated goal-option-2 on 214 transitions
Took 0.007371425628662109s to update distance table with 215 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 628 Step: 77316
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34101832 0.31796337 0.34101832]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5175, 'bonus': 0.013900960937138317, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 230 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.69227926471541
Updated goal-option-1 on 11 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31893, 'bonus': 0.0055995395128049215, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6883542014652466
Updated goal-option-3 on 15 transitions
Took 0.0008938312530517578s to update distance table with 27 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 629 Step: 77342
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34326912 0.31687734 0.33985354]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77342, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5177, 'bonus': 0.013898275539462893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 231 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6762599958924946
Updated goal-option-1 on 114 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31903, 'bonus': 0.005598661855785878, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.617018825527894
Updated goal-option-3 on 8 transitions
Took 0.004145383834838867s to update distance table with 123 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
[Episode=630 Seed=18] Took 0.04897117614746094s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 630 Step: 77464
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 15.0	IntrinsicReward: -307.21019164158497
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 631 Step: 77464
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 13.0	IntrinsicReward: -312.74695855844766
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 632 Step: 77464
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 8.0	IntrinsicReward: -306.0144346654415
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 633 Step: 77464
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77464, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5268, 'bonus': 0.013777712461369822, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0302868667689065
Updated goal-option-4 on 6 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -297.6854434006964
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 634 Step: 77470
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 19.0	IntrinsicReward: -316.8896314576268
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 635 Step: 77470
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 20.0	IntrinsicReward: -280.06652443134226
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 636 Step: 77470
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5633, 'bonus': 0.01332386195346053, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7335789363674472
Updated goal-option-4 on 6 transitions
[RND Rollout] Reward: 15.0	IntrinsicReward: -288.70769397116965
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 637 Step: 77476
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 20.0	IntrinsicReward: -275.84489092516014
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 638 Step: 77476
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77476, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6145, 'bonus': 0.01275672097462393, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8409899158948133
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 22.0	IntrinsicReward: -314.8268742484506
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 639 Step: 77483
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 18.0	IntrinsicReward: -286.7807150706649
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 640 Step: 77483
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5096, 'bonus': 0.014008295367013144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7028443440582678
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 641 Step: 77739
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 17.0	IntrinsicReward: -307.62627833965234
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 642 Step: 77739
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 26.0	IntrinsicReward: -308.4302061905619
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 643 Step: 77739
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5173, 'bonus': 0.013903647892017406, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76780, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 232 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.601607802444509
Updated goal-option-1 on 130 transitions
[RND Rollout] Reward: 17.0	IntrinsicReward: -302.7642667371547
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 644 Step: 77869
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77869, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5338, 'bonus': 0.013687077150699013, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74052, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9229228254787777
Updated goal-option-4 on 6 transitions
[RND Rollout] Reward: 19.0	IntrinsicReward: -261.35566720270435
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 645 Step: 77875
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5096, 'bonus': 0.014008295367013144, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 233 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6542526351819203
Updated goal-option-1 on 139 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31909, 'bonus': 0.005598135459621827, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77342, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5613672231099086
Updated goal-option-3 on 11 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 646 Step: 78025
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78025, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5268, 'bonus': 0.013777712461369822, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6588475650129945
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 23.0	IntrinsicReward: -312.3986714044586
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 647 Step: 78032
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4835, 'bonus': 0.014381419703158196, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9637839912874556
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 22.0	IntrinsicReward: -271.71893806860317
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 648 Step: 78039
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5362, 'bonus': 0.01365641151736129, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7769615600169715
Updated goal-option-4 on 6 transitions
[RND Rollout] Reward: 21.0	IntrinsicReward: -302.0034270333126
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 649 Step: 78045
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78045, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5135, 'bonus': 0.013954997918088904, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76072, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 234 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.704231576871467
Updated goal-option-1 on 9 transitions
[RND Rollout] Reward: 27.0	IntrinsicReward: -318.8091653957963
Took 88.64714527130127s to update distance table with 18628 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=650 Seed=18] Took 0.06527590751647949s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 650 Step: 78054
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34223566 0.3223054  0.33545894]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78054, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5174, 'bonus': 0.013902304219833355, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76797, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 235 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6266346377142723
Updated goal-option-1 on 57 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31901, 'bonus': 0.005598837354174894, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42681861488880984
Updated goal-option-3 on 14 transitions
Took 0.0027875900268554688s to update distance table with 72 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 1.3762767314910889s to add potential edges.
================================================================================
[Consolidation] Episode: 651 Step: 78125
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34223566 0.3223054  0.33545894]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78125, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5174, 'bonus': 0.013902304219833355, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76797, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 236 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6926046060247266
Updated goal-option-1 on 12 transitions
Took 0.000316619873046875s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34669535 0.33644896 0.31685569]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5228, 'bonus': 0.013830319420447757, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 18856, 'bonus': 0.007282411495024129, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8657954036186037
Updated goal-option-2 on 46 transitions
Took 0.001744985580444336s to update distance table with 50 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34223566 0.3223054  0.33545894]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21283, 'bonus': 0.00685462305724871, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78186, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4807, 'bonus': 0.014423243612783817, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7236335831173396
Updated goal-option-4 on 13 transitions
Took 0.00040411949157714844s to update distance table with 14 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34226942 0.33215383 0.32557675]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6643, 'bonus': 0.012269245987824175, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78199, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 19 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 20493, 'bonus': 0.0069854957051325725, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.056150651772817
Updated goal-option-2 on 9 transitions
Took 0.001142740249633789s to update distance table with 29 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34223566 0.3223054  0.33545894]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 21289, 'bonus': 0.006853657050471312, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5098, 'bonus': 0.014005547295310977, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 237 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.73313482893754
Updated goal-option-1 on 10 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31903, 'bonus': 0.005598661855785878, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6340278296056622
Updated goal-option-3 on 8 transitions
Took 0.0005774497985839844s to update distance table with 19 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 652 Step: 78245
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34223566 0.3223054  0.33545894]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5365, 'bonus': 0.013652592788242301, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.740176114536964
Updated goal-option-4 on 130 transitions
Took 0.004521608352661133s to update distance table with 131 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34226942 0.33215383 0.32557675]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 6653, 'bonus': 0.012260021683093524, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5130, 'bonus': 0.013961796943056517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76007, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7053209952722516
Updated goal-option-1 on 126 transitions
Took 0.0042951107025146484s to update distance table with 127 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 653 Step: 78501
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34338182 0.32338482 0.33323336]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78501, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5099, 'bonus': 0.014004173865810708, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 238 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5856798906453183
Updated goal-option-1 on 23 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31898, 'bonus': 0.005599100632705742, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3841411458210103
Updated goal-option-3 on 10 transitions
Took 0.0011603832244873047s to update distance table with 34 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 654 Step: 78534
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34564005 0.32227264 0.33208731]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78534, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5135, 'bonus': 0.013954997918088904, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76072, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 239 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6507211316514899
Updated goal-option-1 on 14 transitions
Took 0.0003421306610107422s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5233, 'bonus': 0.01382371058009312, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78548, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 18856, 'bonus': 0.007282411495024129, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8173321067500032
Updated goal-option-2 on 23 transitions
Took 0.000978231430053711s to update distance table with 28 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34564005 0.32227264 0.33208731]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21302, 'bonus': 0.006851565436087111, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5744, 'bonus': 0.013194495349231488, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75912, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6060958100812014
Updated goal-option-4 on 215 transitions
Took 0.0150146484375s to update distance table with 216 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 655 Step: 78790
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34675197 0.32009241 0.33315563]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5204, 'bonus': 0.013862174325035692, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77869, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 240 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6270311085870431
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31903, 'bonus': 0.005598661855785878, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7677263860398579
Updated goal-option-3 on 7 transitions
Took 0.000518798828125s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 656 Step: 78806
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34675197 0.32009241 0.33315563]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78806, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5228, 'bonus': 0.013830319420447757, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 241 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6075904443132661
Updated goal-option-1 on 41 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31907, 'bonus': 0.005598310908511931, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47964829578995705
Updated goal-option-3 on 7 transitions
Took 0.001856088638305664s to update distance table with 49 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 657 Step: 78854
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34675197 0.32009241 0.33315563]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5175, 'bonus': 0.013900960937138317, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 242 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6424286848111708
Updated goal-option-1 on 30 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39895, 'bonus': 0.005006575448249273, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5325476439188453
Updated goal-option-3 on 8 transitions
Took 0.0009124279022216797s to update distance table with 39 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 658 Step: 78892
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34675197 0.32009241 0.33315563]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5367, 'bonus': 0.013650048747823636, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 243 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6266081422049966
Updated goal-option-1 on 17 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39892, 'bonus': 0.005006763699577523, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5089473640748265
Updated goal-option-3 on 8 transitions
Took 0.0008947849273681641s to update distance table with 26 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 659 Step: 78917
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34675197 0.32009241 0.33315563]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5150, 'bonus': 0.013934660285832352, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 244 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6313715120777488
Updated goal-option-1 on 11 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 38375, 'bonus': 0.005104765608901558, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78025, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5293752796642961
Updated goal-option-3 on 52 transitions
Took 0.0032525062561035156s to update distance table with 64 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 660 Step: 78980
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6181, 'bonus': 0.012719517237340857, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6939657017871023
Updated goal-option-4 on 6 transitions
Took 0.00024318695068359375s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 6680, 'bonus': 0.012235219605809911, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78986, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 7 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [3 2] targeting {'count': 5177, 'bonus': 0.013898275539462893, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 245 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.579617358873226
Updated goal-option-1 on 5 transitions
Took 0.0004711151123046875s to update distance table with 13 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34435487 0.34092848 0.31471665]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5420, 'bonus': 0.01358314562310403, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 21302, 'bonus': 0.006851565436087111, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1775421812351234
Updated goal-option-2 on 32 transitions
Took 0.0011425018310546875s to update distance table with 33 states and events {SE([2 5]), None, SE([6 6])}
Took 1.374929428100586s to add potential edges.
================================================================================
[Consolidation] Episode: 661 Step: 79030
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79030, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5633, 'bonus': 0.01332386195346053, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8690825044115384
Updated goal-option-4 on 256 transitions
Took 0.011905670166015625s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 662 Step: 79286
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5175, 'bonus': 0.013900960937138317, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 246 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6587552436403491
Updated goal-option-1 on 18 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39897, 'bonus': 0.005006449959160028, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.691150821963249
Updated goal-option-3 on 7 transitions
Took 0.0006239414215087891s to update distance table with 26 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 663 Step: 79311
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5370, 'bonus': 0.013646235352373378, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78884, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 247 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5658090146678822
Updated goal-option-1 on 56 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31898, 'bonus': 0.005599100632705742, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46676989483554454
Updated goal-option-3 on 6 transitions
Took 0.0025568008422851562s to update distance table with 63 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 664 Step: 79373
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5218, 'bonus': 0.013843565587089459, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78054, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 248 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5749836118363315
Updated goal-option-1 on 75 transitions
Took 0.0033309459686279297s to update distance table with 76 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5510, 'bonus': 0.013471755760359808, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 20721, 'bonus': 0.006946957542794883, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.193064134097794
Updated goal-option-2 on 177 transitions
Took 0.006626129150390625s to update distance table with 182 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 665 Step: 79629
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5367, 'bonus': 0.013650048747823636, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 249 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6777161146081033
Updated goal-option-1 on 40 transitions
Took 0.0015153884887695312s to update distance table with 41 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5513, 'bonus': 0.01346808981015532, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79669, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39891, 'bonus': 0.005006826454739366, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78125, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4943255650689262
Updated goal-option-3 on 6 transitions
Took 0.0002665519714355469s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 666 Step: 79675
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5420, 'bonus': 0.01358314562310403, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 250 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.570901211530011
Updated goal-option-1 on 9 transitions
Took 0.00028634071350097656s to update distance table with 10 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5514, 'bonus': 0.013466868491648147, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39900, 'bonus': 0.005006261743217589, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6248365929659727
Updated goal-option-3 on 7 transitions
Took 0.00034499168395996094s to update distance table with 8 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 667 Step: 79691
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79691, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6145, 'bonus': 0.01275672097462393, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77470, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6057602793704367
Updated goal-option-4 on 10 transitions
Took 0.000347137451171875s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6836, 'bonus': 0.012094807845871497, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79701, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 40 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 2] targeting {'count': 19761, 'bonus': 0.0071136999150549895, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2575776650792077
Updated goal-option-2 on 206 transitions
Took 0.008349418640136719s to update distance table with 247 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 668 Step: 79947
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79947, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5233, 'bonus': 0.01382371058009312, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78548, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 251 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7052944711730129
Updated goal-option-1 on 75 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 31910, 'bonus': 0.005598047741362361, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77464, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.566481404771754
Updated goal-option-3 on 6 transitions
Took 0.0031113624572753906s to update distance table with 82 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 669 Step: 80028
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34902057 0.31898079 0.33199864]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80028, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6132, 'bonus': 0.012770236105969923, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77066, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8611651154715622
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.0002694129943847656s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 6878, 'bonus': 0.012057823272239218, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5515, 'bonus': 0.013465647505336954, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80022, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 252 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6948604378849268
Updated goal-option-1 on 11 transitions
Took 0.0004780292510986328s to update distance table with 12 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34435487 0.34092848 0.31471665]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5516, 'bonus': 0.013464426851071168, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39898, 'bonus': 0.00500638721815384, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6151808537903798
Updated goal-option-3 on 6 transitions
Took 0.0002627372741699219s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 670 Step: 80052
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80052, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5992, 'bonus': 0.012918559733220045, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76521, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7049958105400155
Updated goal-option-4 on 6 transitions
Took 0.00023674964904785156s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 6883, 'bonus': 0.012053442909805919, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5510, 'bonus': 0.013471755760359808, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 253 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6079665102374415
Updated goal-option-1 on 16 transitions
Took 0.0006070137023925781s to update distance table with 17 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 5517, 'bonus': 0.013463206528700325, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80074, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 6883, 'bonus': 0.012053442909805919, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6586338918824138
Updated goal-option-4 on 68 transitions
Took 0.0027196407318115234s to update distance table with 69 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6893, 'bonus': 0.01204469648756003, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5373, 'bonus': 0.013642425151167634, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6525137815345712
Updated goal-option-1 on 166 transitions
Took 0.0071828365325927734s to update distance table with 167 states and events {SE([5 2]), None}
Adding edge from goal-option-4 to goal-option-1
Adding edge from SE([5 2]) to goal-option-1
Adding edge from goal-option-4 to goal-option-3
Adding edge from SE([5 2]) to goal-option-3
Took 1.3909850120544434s to add potential edges.
================================================================================
[Consolidation] Episode: 671 Step: 80308
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6140, 'bonus': 0.012761914022253898, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8206847341212765
Updated goal-option-4 on 6 transitions
Took 0.0003032684326171875s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34223566 0.33545894 0.3223054 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6963, 'bonus': 0.011984000056756225, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 18966, 'bonus': 0.007261262329146037, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.252690780837581
Updated goal-option-2 on 250 transitions
Took 0.024187088012695312s to update distance table with 251 states and events {SE([5 2])}
================================================================================
[Consolidation] Episode: 672 Step: 80564
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80564, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5373, 'bonus': 0.013642425151167634, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 254 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6596350248116503
Updated goal-option-1 on 22 transitions
Deleting edge from goal-option-4 to goal-option-1
Deleting edge from SE([5 2]) to goal-option-1
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39904, 'bonus': 0.005006010821645458, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80028, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49969854304032735
Updated goal-option-3 on 6 transitions
Took 0.0009837150573730469s to update distance table with 29 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 673 Step: 80592
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 5744, 'bonus': 0.013194495349231488, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75912, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.594671081395039
Updated goal-option-4 on 6 transitions
Took 0.0002665519714355469s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34223566 0.33545894 0.3223054 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7222, 'bonus': 0.01176714914274736, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80598, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 1 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 20526, 'bonus': 0.006979878096097605, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.237894972441373
Updated goal-option-2 on 159 transitions
Took 0.006364345550537109s to update distance table with 161 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 674 Step: 80758
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80758, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6878, 'bonus': 0.012057823272239218, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6897239854230257
Updated goal-option-4 on 6 transitions
Took 0.0001952648162841797s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34223566 0.33545894 0.3223054 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7280, 'bonus': 0.011720180773462385, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 12 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 20721, 'bonus': 0.006946957542794883, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8985900302728018
Updated goal-option-2 on 238 transitions
Took 0.010356664657592773s to update distance table with 251 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 675 Step: 81014
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81014, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6140, 'bonus': 0.012761914022253898, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7371519861187329
Updated goal-option-4 on 6 transitions
Took 0.0002446174621582031s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34223566 0.33545894 0.3223054 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7343, 'bonus': 0.011669795239484684, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 19973, 'bonus': 0.007075845620714534, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65436, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.267419350960038
Updated goal-option-2 on 22 transitions
Took 0.0010514259338378906s to update distance table with 28 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 21355, 'bonus': 0.006843057860368849, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81047, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5516, 'bonus': 0.013464426851071168, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 255 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6136854849174083
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39893, 'bonus': 0.005006700946775324, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78534, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7836530294865084
Updated goal-option-3 on 25 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0013611316680908203s to update distance table with 33 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 676 Step: 81079
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5367, 'bonus': 0.013650048747823636, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 256 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5928054523979837
Updated goal-option-1 on 141 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39892, 'bonus': 0.005006763699577523, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48034815588037477
Updated goal-option-3 on 11 transitions
Took 0.010766983032226562s to update distance table with 153 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 677 Step: 81231
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34452417 0.32446064 0.33101518]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81231, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5373, 'bonus': 0.013642425151167634, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6837557236061969
Updated goal-option-1 on 256 transitions
Took 0.022176504135131836s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 678 Step: 81487
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81487, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5515, 'bonus': 0.013465647505336954, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80022, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 257 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6984140059161267
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39909, 'bonus': 0.005005697222731302, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81231, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4774364110267939
Updated goal-option-3 on 8 transitions
Took 0.0005571842193603516s to update distance table with 18 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 679 Step: 81504
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5231, 'bonus': 0.0138263529791577, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 258 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6794301304652635
Updated goal-option-1 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39894, 'bonus': 0.005006638196332624, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78806, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4466191549244381
Updated goal-option-3 on 46 transitions
Took 0.002821207046508789s to update distance table with 59 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 680 Step: 81562
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81562, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5371, 'bonus': 0.013644964930609014, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78909, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 259 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6405100325042362
Updated goal-option-1 on 13 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39898, 'bonus': 0.00500638721815384, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4553228006698191
Updated goal-option-3 on 7 transitions
Took 0.0006012916564941406s to update distance table with 21 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-4 to goal-option-3
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 1.369798183441162s to add potential edges.
================================================================================
[Consolidation] Episode: 681 Step: 81582
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6140, 'bonus': 0.012761914022253898, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7354371656189885
Updated goal-option-4 on 8 transitions
Took 0.000308990478515625s to update distance table with 9 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 7698, 'bonus': 0.01139753794182585, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5420, 'bonus': 0.01358314562310403, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7422939478191731
Updated goal-option-1 on 248 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Took 0.00830221176147461s to update distance table with 249 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 682 Step: 81838
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81838, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5571, 'bonus': 0.013397797850969013, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 260 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6594362025788089
Updated goal-option-1 on 51 transitions
Took 0.0018317699432373047s to update distance table with 52 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34443386 0.33761361 0.31795253]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 5614, 'bonus': 0.013346389522571566, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81889, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 6608, 'bonus': 0.012301695782628073, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6398839153560418
Updated goal-option-4 on 205 transitions
Took 0.012949943542480469s to update distance table with 206 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 683 Step: 82094
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34792794 0.32440586 0.3276662 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5509, 'bonus': 0.013472978409158474, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 261 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6751559113134284
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39896, 'bonus': 0.005006512702525123, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.56113082431539
Updated goal-option-3 on 9 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0005586147308349609s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 684 Step: 82110
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34792794 0.32440586 0.3276662 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82110, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6680, 'bonus': 0.012235219605809911, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78986, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8199320605406933
Updated goal-option-4 on 256 transitions
Took 0.008984804153442383s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 685 Step: 82366
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5571, 'bonus': 0.013397797850969013, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 262 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6838545436064402
Updated goal-option-1 on 30 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39904, 'bonus': 0.005006010821645458, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80028, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4860385244034908
Updated goal-option-3 on 6 transitions
Took 0.0013737678527832031s to update distance table with 37 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 686 Step: 82402
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82402, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6963, 'bonus': 0.011984000056756225, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7331923108015742
Updated goal-option-4 on 6 transitions
Took 0.0002377033233642578s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34443386 0.33761361 0.31795253]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7729, 'bonus': 0.011374657965622858, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 8 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 2] targeting {'count': 21283, 'bonus': 0.00685462305724871, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78186, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5521170482491005
Updated goal-option-2 on 2 transitions
Took 0.0004038810729980469s to update distance table with 11 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21375, 'bonus': 0.006839855680567695, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7222, 'bonus': 0.01176714914274736, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80598, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6533854309280585
Updated goal-option-4 on 240 transitions
Took 0.008324146270751953s to update distance table with 241 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 687 Step: 82658
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82658, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5514, 'bonus': 0.013466868491648147, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 263 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6366780672474687
Updated goal-option-1 on 49 transitions
Took 0.0019309520721435547s to update distance table with 50 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 5789, 'bonus': 0.013143112497237697, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 6653, 'bonus': 0.012260021683093524, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7616739000761751
Updated goal-option-4 on 207 transitions
Took 0.0074536800384521484s to update distance table with 208 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 688 Step: 82914
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35017736 0.32003801 0.32978462]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5515, 'bonus': 0.013465647505336954, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80022, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 264 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5716296725400575
Updated goal-option-1 on 9 transitions
Took 0.00036215782165527344s to update distance table with 10 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34770118 0.34081623 0.31148259]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 5807, 'bonus': 0.0131227267869966, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 7343, 'bonus': 0.011669795239484684, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.736723019558395
Updated goal-option-4 on 37 transitions
Took 0.0014376640319824219s to update distance table with 38 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34443386 0.33761361 0.31795253]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7766, 'bonus': 0.011347529145953276, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2-0, goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 5420, 'bonus': 0.01358314562310403, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 265 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6388730726948139
Updated goal-option-1 on 4 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39896, 'bonus': 0.005006512702525123, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4937360458438101
Updated goal-option-3 on 6 transitions
Took 0.0005431175231933594s to update distance table with 15 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 689 Step: 82974
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35017736 0.32003801 0.32978462]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82974, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5807, 'bonus': 0.0131227267869966, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 266 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.728945169980515
Updated goal-option-1 on 10 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39897, 'bonus': 0.005006449959160028, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.534160308076837
Updated goal-option-3 on 8 transitions
Took 0.0005474090576171875s to update distance table with 19 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 690 Step: 82992
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6598, 'bonus': 0.012311014544499706, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7140739302540946
Updated goal-option-4 on 6 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.00023818016052246094s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 7768, 'bonus': 0.011346068247441145, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5516, 'bonus': 0.013464426851071168, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 267 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6290248083487656
Updated goal-option-1 on 17 transitions
Took 0.0006468296051025391s to update distance table with 18 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5820, 'bonus': 0.013108062627326908, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 20721, 'bonus': 0.006946957542794883, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0145258447598844
Updated goal-option-2 on 115 transitions
Took 0.004578828811645508s to update distance table with 120 states and events {SE([1 1]), SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 21384, 'bonus': 0.006838416165518485, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83134, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5789, 'bonus': 0.013143112497237697, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 268 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5630266481034812
Updated goal-option-1 on 10 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39910, 'bonus': 0.005005634510020462, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5177257089277557
Updated goal-option-3 on 7 transitions
Took 0.0005934238433837891s to update distance table with 18 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2-0 to goal-option-1
Took 1.5942811965942383s to add potential edges.
================================================================================
[Consolidation] Episode: 691 Step: 83151
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83151, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5823, 'bonus': 0.01310468556617919, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83144, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 269 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5975311114154632
Updated goal-option-1 on 135 transitions
Took 0.008083343505859375s to update distance table with 136 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5824, 'bonus': 0.013103560459023979, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 12 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 4] targeting {'count': 20146, 'bonus': 0.007045398866644257, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.0580508474792754
Updated goal-option-2 on 4 transitions
Took 0.0006072521209716797s to update distance table with 17 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 21388, 'bonus': 0.006837776672725623, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83302, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5820, 'bonus': 0.013108062627326908, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 270 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6093748557787482
Updated goal-option-1 on 9 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39909, 'bonus': 0.005005697222731302, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81231, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5215237104379282
Updated goal-option-3 on 11 transitions
Took 0.0007262229919433594s to update distance table with 21 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 692 Step: 83322
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6893, 'bonus': 0.01204469648756003, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6467725129776235
Updated goal-option-4 on 16 transitions
Took 0.0005478858947753906s to update distance table with 17 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7924, 'bonus': 0.011233827907252846, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 9 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 2] targeting {'count': 20541, 'bonus': 0.006977329113762267, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69201, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.036326044428665
Updated goal-option-2 on 11 transitions
Took 0.000720977783203125s to update distance table with 21 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21393, 'bonus': 0.006836977558967273, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83358, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6598, 'bonus': 0.012311014544499706, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8292461507765857
Updated goal-option-4 on 220 transitions
Took 0.009350776672363281s to update distance table with 221 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 693 Step: 83578
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83578, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6643, 'bonus': 0.012269245987824175, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78199, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7290250254394133
Updated goal-option-4 on 256 transitions
Took 0.01323390007019043s to update distance table with 257 states and events {SE([2 5]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 694 Step: 83834
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35357829 0.3167475  0.32967421]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5515, 'bonus': 0.013465647505336954, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80022, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 271 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7164520427231261
Updated goal-option-1 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39906, 'bonus': 0.005005885375007214, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3966526545388868
Updated goal-option-3 on 6 transitions
Took 0.0004553794860839844s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 695 Step: 83846
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35357829 0.3167475  0.32967421]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83846, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6616, 'bonus': 0.012294255990122585, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78045, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7312953396688533
Updated goal-option-4 on 6 transitions
Took 0.0002799034118652344s to update distance table with 7 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7928, 'bonus': 0.01123099358705957, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 7 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 20229, 'bonus': 0.0070309303024908, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1539752806006631
Updated goal-option-2 on 8 transitions
Took 0.0006299018859863281s to update distance table with 16 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21397, 'bonus': 0.006836338469644604, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6883, 'bonus': 0.012053442909805919, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80058, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7450620671363247
Updated goal-option-4 on 56 transitions
Took 0.0022521018981933594s to update distance table with 57 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7933, 'bonus': 0.011227453701830573, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21182, 'bonus': 0.006870945727775229, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4444873433182206
Updated goal-option-2 on 50 transitions
Took 0.0017368793487548828s to update distance table with 51 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21402, 'bonus': 0.0068355398599588505, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83973, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6836, 'bonus': 0.012094807845871497, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79701, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7791331294822493
Updated goal-option-4 on 15 transitions
Took 0.00040221214294433594s to update distance table with 16 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7938, 'bonus': 0.011223917161691232, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 8 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 2] targeting {'count': 21384, 'bonus': 0.006838416165518485, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83134, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.564938940604528
Updated goal-option-2 on 4 transitions
Took 0.00046443939208984375s to update distance table with 13 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 21411, 'bonus': 0.0068341030675394135, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5823, 'bonus': 0.01310468556617919, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83144, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 272 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5744791722344786
Updated goal-option-1 on 10 transitions
Took 0.0003268718719482422s to update distance table with 11 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25747014 0.38796058 0.35456928]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6029, 'bonus': 0.01287885809773041, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84010, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 6680, 'bonus': 0.012235219605809911, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78986, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7639217557851227
Updated goal-option-4 on 92 transitions
Took 0.004378795623779297s to update distance table with 93 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 696 Step: 84102
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6029, 'bonus': 0.01287885809773041, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84010, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 273 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6086886325689751
Updated goal-option-1 on 169 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39912, 'bonus': 0.005005509091669591, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40828459676396983
Updated goal-option-3 on 6 transitions
Took 0.010265111923217773s to update distance table with 176 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 697 Step: 84277
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35245629 0.31891564 0.32862807]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7729, 'bonus': 0.011374657965622858, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6948526221948366
Updated goal-option-4 on 7 transitions
Took 0.00026917457580566406s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25563905 0.38520147 0.35915947]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8066, 'bonus': 0.011134504398372281, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84284, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5614, 'bonus': 0.013346389522571566, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81889, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 274 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5958204942894733
Updated goal-option-1 on 19 transitions
Took 0.0007295608520507812s to update distance table with 20 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25747014 0.38796058 0.35456928]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6080, 'bonus': 0.012824729401064426, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84303, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39914, 'bonus': 0.005005383682745481, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82402, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5427345643412977
Updated goal-option-3 on 6 transitions
Took 0.00027060508728027344s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 698 Step: 84309
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7729, 'bonus': 0.011374657965622858, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8252335747980503
Updated goal-option-4 on 29 transitions
Took 0.0010590553283691406s to update distance table with 30 states and events {SE([2 5]), None, SE([1 1]), SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25563905 0.38520147 0.35915947]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8079, 'bonus': 0.011125542470338886, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21182, 'bonus': 0.006870945727775229, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2641167112882585
Updated goal-option-2 on 20 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5819, 'bonus': 0.013109188894685375, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82984, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 275 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5665239731353642
Updated goal-option-1 on 9 transitions
Took 0.0010249614715576172s to update distance table with 30 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25655591 0.386583   0.35686109]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6089, 'bonus': 0.01281524793884014, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 2 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 4] targeting {'count': 20541, 'bonus': 0.006977329113762267, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69201, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9857890391961123
Updated goal-option-2 on 128 transitions
Took 0.004700899124145508s to update distance table with 131 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 699 Step: 84497
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84497, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5825, 'bonus': 0.013102435641608368, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 276 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6250539231728883
Updated goal-option-1 on 22 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39918, 'bonus': 0.005005132893172824, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4899299973049643
Updated goal-option-3 on 7 transitions
Took 0.0010221004486083984s to update distance table with 30 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
[Episode=700 Seed=18] Took 0.07070660591125488s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 700 Step: 84526
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84526, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5571, 'bonus': 0.013397797850969013, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 277 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.567854467368717
Updated goal-option-1 on 174 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -316.08208934171125
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 701 Step: 84700
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 23.0	IntrinsicReward: -195.80876741977409
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 702 Step: 84700
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6104, 'bonus': 0.012799492126228447, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 278 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6306189989444256
Updated goal-option-1 on 43 transitions
[RND Rollout] Reward: 20.0	IntrinsicReward: -330.95400219783187
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 703 Step: 84743
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 23.0	IntrinsicReward: -300.5427207078319
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 704 Step: 84743
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 29.0	IntrinsicReward: -321.31319221435115
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 705 Step: 84743
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7766, 'bonus': 0.011347529145953276, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7263808582896911
Updated goal-option-4 on 85 transitions
[RND Rollout] Reward: 20.0	IntrinsicReward: -261.39136678841896
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 706 Step: 84828
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 23.0	IntrinsicReward: -286.40645297872834
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 707 Step: 84828
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 27.0	IntrinsicReward: -325.76171413622797
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 708 Step: 84828
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 24.0	IntrinsicReward: -306.84070683375467
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 709 Step: 84828
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8079, 'bonus': 0.011125542470338886, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7565882641653464
Updated goal-option-4 on 26 transitions
[RND Rollout] Reward: 34.0	IntrinsicReward: -287.53689336297975
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 710 Step: 84854
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 12.0	IntrinsicReward: -307.16847436130047
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 711 Step: 84854
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7933, 'bonus': 0.011227453701830573, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8365524604211373
Updated goal-option-4 on 10 transitions
[RND Rollout] Reward: 32.0	IntrinsicReward: -294.53221142920665
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 712 Step: 84864
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6105, 'bonus': 0.012798443803844426, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 279 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5867079170475229
Updated goal-option-1 on 25 transitions
[RND Rollout] Reward: 29.0	IntrinsicReward: -328.3831326626241
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 713 Step: 84889
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 29.0	IntrinsicReward: -298.19610882224515
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 714 Step: 84889
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -336.20586421340704
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 715 Step: 84889
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 32.0	IntrinsicReward: -183.07212746836012
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 716 Step: 84889
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 27.0	IntrinsicReward: -321.94280496705323
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 717 Step: 84889
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84889, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7280, 'bonus': 0.011720180773462385, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8868743166664746
Updated goal-option-4 on 6 transitions
[RND Rollout] Reward: 28.0	IntrinsicReward: -333.0877596363425
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 718 Step: 84895
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 35.0	IntrinsicReward: -280.7966612208402
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 719 Step: 84895
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 27.0	IntrinsicReward: -277.5534747255733
Took 94.80202269554138s to update distance table with 20409 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=720 Seed=18] Took 0.06688547134399414s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 720 Step: 84895
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84895, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5807, 'bonus': 0.0131227267869966, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 280 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5982109293747505
Updated goal-option-1 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39923, 'bonus': 0.005004819459211506, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84526, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5776551220820685
Updated goal-option-3 on 6 transitions
Took 0.0004563331604003906s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Took 1.6340656280517578s to add potential edges.
================================================================================
[Consolidation] Episode: 721 Step: 84907
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84907, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7924, 'bonus': 0.011233827907252846, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7223171316125455
Updated goal-option-4 on 11 transitions
Took 0.0003066062927246094s to update distance table with 12 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25374083 0.38618379 0.36007538]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8160, 'bonus': 0.01107018606925119, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84918, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5818, 'bonus': 0.013110315452406242, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82968, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 281 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5850731405380016
Updated goal-option-1 on 18 transitions
Took 0.0006744861602783203s to update distance table with 19 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25465321 0.38757239 0.35777441]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6338, 'bonus': 0.012560990367620792, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 7343, 'bonus': 0.011669795239484684, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7028929846887227
Updated goal-option-4 on 24 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.0009443759918212891s to update distance table with 25 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25374083 0.38618379 0.36007538]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8168, 'bonus': 0.011064763494314402, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5789, 'bonus': 0.013143112497237697, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 282 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6514811136637085
Updated goal-option-1 on 91 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39911, 'bonus': 0.0050055717996666076, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81562, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7189051927218224
Updated goal-option-3 on 8 transitions
Took 0.003632068634033203s to update distance table with 100 states and events {SE([5 2]), SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 722 Step: 85059
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85059, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5789, 'bonus': 0.013143112497237697, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 283 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6554670198808499
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39913, 'bonus': 0.005005446386029264, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82110, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4992088601843352
Updated goal-option-3 on 9 transitions
Took 0.0006291866302490234s to update distance table with 19 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 723 Step: 85077
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85077, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7924, 'bonus': 0.011233827907252846, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6616504904195087
Updated goal-option-4 on 11 transitions
Took 0.00040435791015625s to update distance table with 12 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25374083 0.38618379 0.36007538]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8176, 'bonus': 0.01105934888009522, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85088, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 6003, 'bonus': 0.012906718211039439, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 284 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5829544624422996
Updated goal-option-1 on 13 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Took 0.0005121231079101562s to update distance table with 14 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25465321 0.38757239 0.35777441]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6353, 'bonus': 0.012546152794578422, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 20541, 'bonus': 0.006977329113762267, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69201, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1947300537627619
Updated goal-option-2 on 91 transitions
Took 0.0033261775970458984s to update distance table with 96 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 724 Step: 85196
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85196, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5823, 'bonus': 0.01310468556617919, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83144, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 285 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6020306423402354
Updated goal-option-1 on 28 transitions
Took 0.0009472370147705078s to update distance table with 29 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25465321 0.38757239 0.35777441]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6357, 'bonus': 0.01254220498051134, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85224, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 15 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 4] targeting {'count': 20581, 'bonus': 0.006970545456416095, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1499843649169643
Updated goal-option-2 on 3 transitions
Took 0.0006687641143798828s to update distance table with 19 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21559, 'bonus': 0.00681060501325673, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8160, 'bonus': 0.01107018606925119, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84918, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8799691875988964
Updated goal-option-4 on 12 transitions
Took 0.00035381317138671875s to update distance table with 13 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25563905 0.38520147 0.35915947]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8192, 'bonus': 0.011048543456039804, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85254, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 1] targeting {'count': 21411, 'bonus': 0.0068341030675394135, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.690792298700963
Updated goal-option-2 on 4 transitions
Took 0.0003402233123779297s to update distance table with 10 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21565, 'bonus': 0.0068096574947584055, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85263, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7766, 'bonus': 0.011347529145953276, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6472317964051234
Updated goal-option-4 on 12 transitions
Took 0.0003681182861328125s to update distance table with 13 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25754658 0.38421434 0.35823908]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8194, 'bonus': 0.011047195003791416, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 5825, 'bonus': 0.013102435641608368, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 286 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5559468245663545
Updated goal-option-1 on 14 transitions
Took 0.00052642822265625s to update distance table with 15 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.2584679  0.38558879 0.35594331]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6360, 'bonus': 0.01253924656438798, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 7729, 'bonus': 0.011374657965622858, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7629607729613781
Updated goal-option-4 on 163 transitions
Took 0.007870674133300781s to update distance table with 164 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 725 Step: 85452
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35017736 0.32003801 0.32978462]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7343, 'bonus': 0.011669795239484684, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6863427439208211
Updated goal-option-4 on 8 transitions
Took 0.0003159046173095703s to update distance table with 9 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25662264 0.382836   0.36054136]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8200, 'bonus': 0.011043152607484653, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 6104, 'bonus': 0.012799492126228447, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6232226793964705
Updated goal-option-1 on 248 transitions
Took 0.022377490997314453s to update distance table with 249 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 726 Step: 85708
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6353, 'bonus': 0.012546152794578422, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 287 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6478989033251333
Updated goal-option-1 on 31 transitions
Took 0.0006625652313232422s to update distance table with 32 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25938656 0.38695928 0.35365415]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6427, 'bonus': 0.012473715947708236, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39906, 'bonus': 0.005005885375007214, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80592, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4763770640724235
Updated goal-option-3 on 8 transitions
Took 0.00033354759216308594s to update distance table with 9 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 727 Step: 85747
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85747, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8192, 'bonus': 0.011048543456039804, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85254, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8196156456266372
Updated goal-option-4 on 14 transitions
Took 0.00031685829162597656s to update distance table with 15 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25754658 0.38421434 0.35823908]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8434, 'bonus': 0.010888879747610963, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 1] targeting {'count': 21417, 'bonus': 0.006833145709116626, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84358, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9095875987480333
Updated goal-option-2 on 238 transitions
Took 0.008948087692260742s to update distance table with 243 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 728 Step: 86003
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35133022 0.32109165 0.32757813]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86003, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6080, 'bonus': 0.012824729401064426, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84303, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 288 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.557260100430048
Updated goal-option-1 on 6 transitions
Took 0.00025200843811035156s to update distance table with 7 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25938656 0.38695928 0.35365415]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6429, 'bonus': 0.01247177557032266, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86009, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39914, 'bonus': 0.005005383682745481, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82402, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47412188559494634
Updated goal-option-3 on 6 transitions
Took 0.0002655982971191406s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 729 Step: 86015
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35017736 0.32003801 0.32978462]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6104, 'bonus': 0.012799492126228447, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84519, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6366551478741805
Updated goal-option-1 on 256 transitions
Took 0.021171092987060547s to update distance table with 257 states and events {SE([5 2]), None, SE([1 1])}
================================================================================
[Consolidation] Episode: 730 Step: 86271
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8114, 'bonus': 0.011101521345712146, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5940988023804072
Updated goal-option-4 on 7 transitions
Took 0.00029468536376953125s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25760393 0.38047605 0.36192002]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8695, 'bonus': 0.010724207460084102, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86278, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21302, 'bonus': 0.006851565436087111, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.602414152838967
Updated goal-option-2 on 18 transitions
Took 0.0006630420684814453s to update distance table with 19 states and events {SE([5 2]), None, SE([6 6])}
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-4 to goal-option-3
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from goal-option-2-0 to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 1.473069429397583s to add potential edges.
================================================================================
[Consolidation] Episode: 731 Step: 86296
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6131, 'bonus': 0.012771277511566434, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 289 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6345385083675841
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Took 0.0003197193145751953s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26038914 0.38458976 0.3550211 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6430, 'bonus': 0.012470805721138074, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86303, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39912, 'bonus': 0.005005509091669591, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40616469047963627
Updated goal-option-3 on 6 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0002579689025878906s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 732 Step: 86309
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6347, 'bonus': 0.012552081511674501, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85051, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 290 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5493268948155197
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39911, 'bonus': 0.0050055717996666076, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81562, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4281015078130677
Updated goal-option-3 on 7 transitions
Took 0.0005011558532714844s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 733 Step: 86323
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86323, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6003, 'bonus': 0.012906718211039439, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 291 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5709519412598844
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39920, 'bonus': 0.005005007512521914, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5233794019641578
Updated goal-option-3 on 7 transitions
Took 0.0005078315734863281s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 734 Step: 86337
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86337, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6431, 'bonus': 0.01246983609817497, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 292 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5762640303214088
Updated goal-option-1 on 16 transitions
Took 0.0005793571472167969s to update distance table with 17 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26038914 0.38458976 0.3550211 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6433, 'bonus': 0.012467897530561517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39923, 'bonus': 0.005004819459211506, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84526, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4003060004823116
Updated goal-option-3 on 6 transitions
Took 0.0002593994140625s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 735 Step: 86359
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86359, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6427, 'bonus': 0.012473715947708236, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 293 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5533902684279851
Updated goal-option-1 on 27 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39921, 'bonus': 0.005004944825729799, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47576732281080925
Updated goal-option-3 on 6 transitions
Took 0.0011789798736572266s to update distance table with 34 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 736 Step: 86392
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34790526 0.32115703 0.33093772]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86392, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 7924, 'bonus': 0.011233827907252846, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.815985436240832
Updated goal-option-4 on 8 transitions
Took 0.00030517578125s to update distance table with 9 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25760393 0.38047605 0.36192002]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8715, 'bonus': 0.010711894933108056, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21022, 'bonus': 0.006897043801891763, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74464, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5897323499688614
Updated goal-option-2 on 248 transitions
Took 0.008894681930541992s to update distance table with 249 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 737 Step: 86648
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86648, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8114, 'bonus': 0.011101521345712146, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6815372683850661
Updated goal-option-4 on 25 transitions
Took 0.0008723735809326172s to update distance table with 26 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25853495 0.38185116 0.35961388]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8740, 'bonus': 0.010696563746013953, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 39918, 'bonus': 0.005005132893172824, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5670441816576192
Updated goal-option-3 on 76 transitions
Took 0.0038077831268310547s to update distance table with 77 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 738 Step: 86749
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86749, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8194, 'bonus': 0.011047195003791416, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8690515309422158
Updated goal-option-4 on 10 transitions
Took 0.00038242340087890625s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.25853495 0.38185116 0.35961388]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8811, 'bonus': 0.010653379535009885, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 20570, 'bonus': 0.00697240898952155, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3683908094641983
Updated goal-option-2 on 57 transitions
Took 0.0019876956939697266s to update distance table with 58 states and events {SE([5 2]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 739 Step: 86816
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6251, 'bonus': 0.012648098833237538, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84889, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 294 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.605235373858641
Updated goal-option-1 on 24 transitions
Took 0.0008502006530761719s to update distance table with 25 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26038914 0.38458976 0.3550211 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6435, 'bonus': 0.01246595986677943, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 9 transitions
Deleting edge from goal-option-2-0 to goal-option-4
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 21565, 'bonus': 0.0068096574947584055, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85263, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5063229400316873
Updated goal-option-2 on 13 transitions
Took 0.0008313655853271484s to update distance table with 23 states and events {SE([1 1]), SE([2 5]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21605, 'bonus': 0.006803350795100468, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86862, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8079, 'bonus': 0.011125542470338886, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.635115623130018
Updated goal-option-4 on 35 transitions
Took 0.0010581016540527344s to update distance table with 36 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8827, 'bonus': 0.010643719889333218, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86897, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 6360, 'bonus': 0.01253924656438798, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 295 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5490072943053016
Updated goal-option-1 on 11 transitions
Took 0.0004298686981201172s to update distance table with 12 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26231962 0.38358594 0.35409445]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6438, 'bonus': 0.012463055064254434, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 9 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 4] targeting {'count': 21397, 'bonus': 0.006836338469644604, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5122685378821439
Updated goal-option-2 on 155 transitions
Took 0.0055065155029296875s to update distance table with 165 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 740 Step: 87072
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87072, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6131, 'bonus': 0.012771277511566434, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 296 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7099821760929431
Updated goal-option-1 on 7 transitions
Took 0.00026535987854003906s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26038914 0.38458976 0.3550211 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6440, 'bonus': 0.012461119656980671, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 21605, 'bonus': 0.006803350795100468, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86862, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.710997084463675
Updated goal-option-2 on 9 transitions
Took 0.0004019737243652344s to update distance table with 10 states and events {SE([2 5]), None, SE([6 6])}
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-4 to goal-option-3
Adding edge from goal-option-2-0 to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 1.7741847038269043s to add potential edges.
================================================================================
[Consolidation] Episode: 741 Step: 87088
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87088, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6131, 'bonus': 0.012771277511566434, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 297 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5691995379537965
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48139, 'bonus': 0.004557760159660514, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5437080263345077
Updated goal-option-3 on 7 transitions
Deleting edge from goal-option-4 to goal-option-3
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0004067420959472656s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 742 Step: 87102
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87102, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6360, 'bonus': 0.01253924656438798, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 298 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6093914152737435
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Took 0.00020170211791992188s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26038914 0.38458976 0.3550211 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6442, 'bonus': 0.012459185151084207, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 21559, 'bonus': 0.00681060501325673, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85242, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1740713138909389
Updated goal-option-2 on 81 transitions
Took 0.002370595932006836s to update distance table with 82 states and events {SE([2 5]), None, SE([6 6])}
================================================================================
[Consolidation] Episode: 743 Step: 87190
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87190, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8154, 'bonus': 0.011074258236418257, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6430376032479556
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Deleting edge from goal-option-2-0 to goal-option-4
Took 0.0002727508544921875s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8832, 'bonus': 0.010640706634484357, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87197, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 6438, 'bonus': 0.012463055064254434, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 299 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6168776157769803
Updated goal-option-1 on 9 transitions
Took 0.0003643035888671875s to update distance table with 10 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26231962 0.38358594 0.35409445]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6465, 'bonus': 0.012437002894184188, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8832, 'bonus': 0.010640706634484357, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87197, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6750444571624646
Updated goal-option-4 on 17 transitions
Took 0.0006394386291503906s to update distance table with 18 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8835, 'bonus': 0.010638899909514296, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87223, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 20581, 'bonus': 0.006970545456416095, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9476578388458643
Updated goal-option-2 on 218 transitions
Took 0.007953166961669922s to update distance table with 224 states and events {SE([5 2]), SE([2 5]), None}
================================================================================
[Consolidation] Episode: 744 Step: 87446
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87446, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6427, 'bonus': 0.012473715947708236, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 300 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6270837231040604
Updated goal-option-1 on 17 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 39923, 'bonus': 0.005004819459211506, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84526, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47860287833633447
Updated goal-option-3 on 6 transitions
Took 0.0006291866302490234s to update distance table with 24 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 745 Step: 87469
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87469, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6434, 'bonus': 0.012466928585735454, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 301 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6004983387379483
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48139, 'bonus': 0.004557760159660514, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.572061393301988
Updated goal-option-3 on 7 transitions
Took 0.00048065185546875s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 746 Step: 87483
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6347, 'bonus': 0.012552081511674501, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85051, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 302 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6150880773278952
Updated goal-option-1 on 7 transitions
Took 0.00030541419982910156s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26231962 0.38358594 0.35409445]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6469, 'bonus': 0.012433157191280193, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8434, 'bonus': 0.010888879747610963, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6677415273830799
Updated goal-option-4 on 24 transitions
Took 0.0009171962738037109s to update distance table with 25 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8868, 'bonus': 0.010619086483530493, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 21302, 'bonus': 0.006851565436087111, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8762211757592666
Updated goal-option-2 on 4 transitions
Took 0.00034165382385253906s to update distance table with 10 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21620, 'bonus': 0.006800990296285958, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87523, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8114, 'bonus': 0.011101521345712146, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6909070646988894
Updated goal-option-4 on 13 transitions
Took 0.00040340423583984375s to update distance table with 14 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8871, 'bonus': 0.01061729074723905, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87536, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48141, 'bonus': 0.0045576654834490055, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42861927837889263
Updated goal-option-3 on 8 transitions
Took 0.00033402442932128906s to update distance table with 9 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 747 Step: 87544
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87544, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8434, 'bonus': 0.010888879747610963, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9680929634405014
Updated goal-option-4 on 7 transitions
Took 0.00029850006103515625s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8874, 'bonus': 0.010615495921641366, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87551, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 39918, 'bonus': 0.005005132893172824, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4695970032337135
Updated goal-option-3 on 7 transitions
Took 0.00028324127197265625s to update distance table with 8 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 748 Step: 87558
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87558, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6349, 'bonus': 0.012550104338863673, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85068, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 303 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6534662782375964
Updated goal-option-1 on 7 transitions
Took 0.00026869773864746094s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26231962 0.38358594 0.35409445]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6470, 'bonus': 0.01243219632283784, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87565, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 21411, 'bonus': 0.0068341030675394135, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.056953180393185
Updated goal-option-2 on 246 transitions
Took 0.008569955825805664s to update distance table with 250 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 749 Step: 87814
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6430, 'bonus': 0.012470805721138074, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86303, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 304 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5595477777471615
Updated goal-option-1 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48145, 'bonus': 0.004557476148724619, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86392, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.585018437020145
Updated goal-option-3 on 7 transitions
Took 0.0005023479461669922s to update distance table with 17 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 750 Step: 87830
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.35020012 0.32327545 0.32652443]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6465, 'bonus': 0.012437002894184188, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 305 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5980699919234602
Updated goal-option-1 on 7 transitions
Took 0.0002872943878173828s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26231962 0.38358594 0.35409445]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6473, 'bonus': 0.012429315053613891, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87837, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8827, 'bonus': 0.010643719889333218, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86897, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6976013776081711
Updated goal-option-4 on 12 transitions
Took 0.000476837158203125s to update distance table with 13 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26138941 0.38222571 0.35638489]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8890, 'bonus': 0.010605938867332436, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87849, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21402, 'bonus': 0.0068355398599588505, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83973, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0547645342230496
Updated goal-option-2 on 237 transitions
Took 0.008300304412841797s to update distance table with 238 states and events {SE([5 2]), None}
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-4 to goal-option-3
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 1.6049799919128418s to add potential edges.
================================================================================
[Consolidation] Episode: 751 Step: 88086
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88086, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6433, 'bonus': 0.012467897530561517, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 306 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5710967043098414
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48143, 'bonus': 0.0045575708131372445, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86337, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.438119730286233
Updated goal-option-3 on 7 transitions
Took 0.0004956722259521484s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 752 Step: 88100
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6472, 'bonus': 0.01243027525409071, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 307 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5556993652955166
Updated goal-option-1 on 6 transitions
Took 0.00025844573974609375s to update distance table with 7 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26238732 0.37986721 0.35774547]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6476, 'bonus': 0.012426435786739165, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8200, 'bonus': 0.011043152607484653, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85460, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7054442216952642
Updated goal-option-4 on 250 transitions
Took 0.011969804763793945s to update distance table with 251 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 753 Step: 88356
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34792794 0.32440586 0.3276662 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8811, 'bonus': 0.010653379535009885, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6191167866647185
Updated goal-option-4 on 7 transitions
Took 0.0002689361572265625s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26238732 0.37986721 0.35774547]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8896, 'bonus': 0.010602361620999637, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88363, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48138, 'bonus': 0.004557807499978866, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85747, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5120009266712644
Updated goal-option-3 on 13 transitions
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0004899501800537109s to update distance table with 14 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 754 Step: 88376
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6467, 'bonus': 0.012435079596732932, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 308 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5760171698699207
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48145, 'bonus': 0.004557476148724619, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86392, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3646202998562953
Updated goal-option-3 on 7 transitions
Took 0.0004968643188476562s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 755 Step: 88390
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6435, 'bonus': 0.01246595986677943, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 309 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6219834384678294
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48134, 'bonus': 0.004557996876004708, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84907, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6013476703462849
Updated goal-option-3 on 7 transitions
Deleting edge from goal-option-4 to goal-option-3
Took 0.0004918575286865234s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 756 Step: 88404
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88404, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8192, 'bonus': 0.011048543456039804, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85254, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6974993800757311
Updated goal-option-4 on 7 transitions
Took 0.0003209114074707031s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26238732 0.37986721 0.35774547]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8904, 'bonus': 0.010597597584982434, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88411, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48156, 'bonus': 0.004556955599874859, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4785172732072919
Updated goal-option-3 on 16 transitions
Took 0.0005979537963867188s to update distance table with 17 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 757 Step: 88427
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88427, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8194, 'bonus': 0.011047195003791416, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8733581224664618
Updated goal-option-4 on 7 transitions
Took 0.00027680397033691406s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26238732 0.37986721 0.35774547]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8905, 'bonus': 0.010597002531915626, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88434, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48160, 'bonus': 0.004556766353603058, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88427, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3522366067251845
Updated goal-option-3 on 6 transitions
Took 0.00029754638671875s to update distance table with 7 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 758 Step: 88440
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88440, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8715, 'bonus': 0.010711894933108056, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6042318197308912
Updated goal-option-4 on 7 transitions
Took 0.00027441978454589844s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26238732 0.37986721 0.35774547]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8906, 'bonus': 0.010596407579073907, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88447, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48139, 'bonus': 0.004557760159660514, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39348050503063536
Updated goal-option-3 on 7 transitions
Took 0.0002872943878173828s to update distance table with 8 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 759 Step: 88454
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8905, 'bonus': 0.010597002531915626, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88434, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6478456724324876
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.00031638145446777344s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26238732 0.37986721 0.35774547]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8908, 'bonus': 0.010595217973953226, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88461, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 9 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 1] targeting {'count': 21283, 'bonus': 0.00685462305724871, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78186, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3857190487229436
Updated goal-option-2 on 2 transitions
Took 0.00041103363037109375s to update distance table with 12 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 21632, 'bonus': 0.006799103665255265, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6472, 'bonus': 0.01243027525409071, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 310 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5684227747357423
Updated goal-option-1 on 7 transitions
Took 0.00027561187744140625s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26432732 0.37886812 0.35680456]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6573, 'bonus': 0.012334404417288482, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88479, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48142, 'bonus': 0.0045576181475556945, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86323, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5000227249215844
Updated goal-option-3 on 7 transitions
Took 0.00029730796813964844s to update distance table with 8 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 760 Step: 88486
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88486, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6573, 'bonus': 0.012334404417288482, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88479, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 311 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5776252807384007
Updated goal-option-1 on 18 transitions
Took 0.0006556510925292969s to update distance table with 19 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26432732 0.37886812 0.35680456]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6574, 'bonus': 0.012333466261408268, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8904, 'bonus': 0.010597597584982434, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88411, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7084345288206669
Updated goal-option-4 on 46 transitions
Took 0.0016977787017822266s to update distance table with 47 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26338284 0.37751438 0.35910278]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8920, 'bonus': 0.010588088747190668, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21184, 'bonus': 0.006870621374116408, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.0180447373668944
Updated goal-option-2 on 6 transitions
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6571, 'bonus': 0.012336281371482911, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 312 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5858185868756962
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48162, 'bonus': 0.004556671739308359, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3398517625974426
Updated goal-option-3 on 7 transitions
Took 0.0008101463317871094s to update distance table with 21 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-4 to goal-option-3
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([1 1]) to goal-option-4
Adding edge from SE([5 2]) to goal-option-3
Took 1.7625219821929932s to add potential edges.
================================================================================
[Consolidation] Episode: 761 Step: 88570
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88570, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8740, 'bonus': 0.010696563746013953, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86673, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.806638373083928
Updated goal-option-4 on 7 transitions
Took 0.0002918243408203125s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26338284 0.37751438 0.35910278]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8921, 'bonus': 0.010587495294355676, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88577, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 6442, 'bonus': 0.012459185151084207, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 313 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6657646129081366
Updated goal-option-1 on 35 transitions
Took 0.0014417171478271484s to update distance table with 36 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26432732 0.37886812 0.35680456]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6586, 'bonus': 0.012322225062419364, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88612, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8921, 'bonus': 0.010587495294355676, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88577, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7331718528899979
Updated goal-option-4 on 72 transitions
Took 0.0029828548431396484s to update distance table with 73 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26338284 0.37751438 0.35910278]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8950, 'bonus': 0.0105703284516338, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2-0, goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 6 transitions
Got plan [goal-option-2, goal-option-1, goal-option-3] and chose to execute goal-option-2
Rolling out goal-option-2, from [4 1] targeting {'count': 21397, 'bonus': 0.006836338469644604, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3533072086857327
Updated goal-option-2 on 3 transitions
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6440, 'bonus': 0.012461119656980671, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 314 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5665359523629606
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48157, 'bonus': 0.004556908286096416, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4805395924321092
Updated goal-option-3 on 7 transitions
Deleting edge from SE([5 2]) to goal-option-3
Took 0.0009326934814453125s to update distance table with 24 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 762 Step: 88707
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6585, 'bonus': 0.012323160655227547, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88563, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 315 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6492273458390126
Updated goal-option-1 on 18 transitions
Took 0.0006585121154785156s to update distance table with 19 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26432732 0.37886812 0.35680456]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6614, 'bonus': 0.012296114672722987, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48155, 'bonus': 0.00455700291512709, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3728525857606255
Updated goal-option-3 on 6 transitions
Deleting edge from goal-option-4 to goal-option-3
Took 0.0002613067626953125s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 763 Step: 88731
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6571, 'bonus': 0.012336281371482911, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 316 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.604316674154275
Updated goal-option-1 on 21 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48158, 'bonus': 0.004556860973791686, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4640749390699392
Updated goal-option-3 on 6 transitions
Took 0.0009171962738037109s to update distance table with 28 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 764 Step: 88758
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88758, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8920, 'bonus': 0.010588088747190668, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6080743768642752
Updated goal-option-4 on 7 transitions
Deleting edge from goal-option-2 to goal-option-4
Deleting edge from SE([1 1]) to goal-option-4
Took 0.00026726722717285156s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26338284 0.37751438 0.35910278]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8963, 'bonus': 0.010562660029637754, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88765, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48153, 'bonus': 0.004557097550053224, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87544, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4654006361567154
Updated goal-option-3 on 7 transitions
Took 0.0002810955047607422s to update distance table with 8 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 765 Step: 88772
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6585, 'bonus': 0.012323160655227547, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88563, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 317 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6527950549701292
Updated goal-option-1 on 18 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48146, 'bonus': 0.0045574288187302915, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86749, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36270073934304176
Updated goal-option-3 on 6 transitions
Took 0.0008969306945800781s to update distance table with 25 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 766 Step: 88796
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8835, 'bonus': 0.010638899909514296, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87223, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6032305262096909
Updated goal-option-4 on 7 transitions
Took 0.00027632713317871094s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26338284 0.37751438 0.35910278]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8971, 'bonus': 0.010557949287947496, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 21302, 'bonus': 0.006851565436087111, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6641952218997538
Updated goal-option-2 on 3 transitions
Took 0.00033473968505859375s to update distance table with 9 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34566266 0.32553284 0.3288045 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21640, 'bonus': 0.006797846783154636, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8921, 'bonus': 0.010587495294355676, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88577, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6444658091978023
Updated goal-option-4 on 10 transitions
Took 0.0003085136413574219s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26532755 0.37651772 0.35815473]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8974, 'bonus': 0.010556184384033912, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 2] targeting {'count': 21355, 'bonus': 0.006843057860368849, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81047, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0837855729001078
Updated goal-option-2 on 3 transitions
Took 0.00031304359436035156s to update distance table with 9 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34453546 0.32773227 0.32773227]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 21645, 'bonus': 0.0067970615857182145, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88829, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6586, 'bonus': 0.012322225062419364, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88612, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 318 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5790873612578383
Updated goal-option-1 on 15 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48165, 'bonus': 0.004556529828916095, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88707, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4705514504428053
Updated goal-option-3 on 6 transitions
Took 0.0006337165832519531s to update distance table with 22 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 767 Step: 88850
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34679727 0.32660137 0.32660137]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88850, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8974, 'bonus': 0.010556184384033912, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5993997369059321
Updated goal-option-4 on 7 transitions
Took 0.0002741813659667969s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26823477 0.3768558  0.35490943]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8977, 'bonus': 0.01055442036490715, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88857, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 5 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 6613, 'bonus': 0.012297044330205339, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 319 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5846283165534202
Updated goal-option-1 on 4 transitions
Took 0.0003681182861328125s to update distance table with 10 states and events {SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26728141 0.37551637 0.35720222]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6618, 'bonus': 0.012292398150143692, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48152, 'bonus': 0.004557144869727281, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47818105548252293
Updated goal-option-3 on 6 transitions
Took 0.00026297569274902344s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 768 Step: 88872
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34453546 0.32773227 0.32773227]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88872, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6574, 'bonus': 0.012333466261408268, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 320 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6065625293893897
Updated goal-option-1 on 7 transitions
Took 0.0002644062042236328s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26728141 0.37551637 0.35720222]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6619, 'bonus': 0.012291469545938393, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88879, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 8890, 'bonus': 0.010605938867332436, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87849, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 195 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.587682651933427
Updated goal-option-4 on 57 transitions
Took 0.0024230480194091797s to update distance table with 58 states and events {SE([2 5]), None, SE([5 2])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26728141 0.37551637 0.35720222]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (5, 2) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8980, 'bonus': 0.01055265722982818, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-2-0, goal-option-2, goal-option-1] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 4 transitions
Got plan [goal-option-2, goal-option-1] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 1] targeting {'count': 21402, 'bonus': 0.0068355398599588505, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83973, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4604575137297313
Updated goal-option-2 on 2 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6614, 'bonus': 0.012296114672722987, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 321 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5679654362958981
Updated goal-option-1 on 7 transitions
Took 0.0004763603210449219s to update distance table with 14 states and events {SE([1 1]), SE([5 2]), SE([2 5]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26728141 0.37551637 0.35720222]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6650, 'bonus': 0.012262786789699318, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88949, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 3 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 3] targeting {'count': 21397, 'bonus': 0.006836338469644604, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.913013787976667
Updated goal-option-2 on 176 transitions
Took 0.00613713264465332s to update distance table with 180 states and events {SE([2 5]), None, SE([5 2])}
================================================================================
[Consolidation] Episode: 769 Step: 89128
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34453546 0.32773227 0.32773227]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6472, 'bonus': 0.01243027525409071, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 322 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5779690597550903
Updated goal-option-1 on 25 transitions
Took 0.0009093284606933594s to update distance table with 26 states and events {SE([5 2]), None, SE([1 1]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26532755 0.37651772 0.35815473]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (2, 5) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6652, 'bonus': 0.012260943177452606, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [2 5] targeting {'count': 21302, 'bonus': 0.006851565436087111, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1327027032105381
Updated goal-option-2 on 231 transitions
Took 0.007837057113647461s to update distance table with 232 states and events {SE([2 5]), None}
[Episode=770 Seed=18] Took 0.061051368713378906s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 770 Step: 89384
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 32.0	IntrinsicReward: -324.01369852386415
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 771 Step: 89384
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 32.0	IntrinsicReward: -312.54145299154334
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 772 Step: 89384
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 22.0	IntrinsicReward: -179.3187247487367
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 773 Step: 89384
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 21.0	IntrinsicReward: -339.9480355158448
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 774 Step: 89384
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89384, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8908, 'bonus': 0.010595217973953226, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88461, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 196 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7326333411026832
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 32.0	IntrinsicReward: -329.8847439959645
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 775 Step: 89391
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8977, 'bonus': 0.01055442036490715, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88857, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 197 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6179699726150808
Updated goal-option-4 on 8 transitions
[RND Rollout] Reward: 30.0	IntrinsicReward: -288.4670501733199
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 776 Step: 89399
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8974, 'bonus': 0.010556184384033912, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 198 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.710761563991003
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 34.0	IntrinsicReward: -301.0072048790753
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 777 Step: 89406
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8950, 'bonus': 0.0105703284516338, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 199 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7227572682017537
Updated goal-option-4 on 20 transitions
[RND Rollout] Reward: 25.0	IntrinsicReward: -327.818143485114
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 778 Step: 89426
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6571, 'bonus': 0.012336281371482911, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 323 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5386367562091926
Updated goal-option-1 on 17 transitions
[RND Rollout] Reward: 27.0	IntrinsicReward: -275.99538475851296
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 779 Step: 89443
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 27.0	IntrinsicReward: -330.13043754175305
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 780 Step: 89443
================================================================================
Attempting to expand SE([2 5])
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89443, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6618, 'bonus': 0.012292398150143692, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 324 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5258311535216766
Updated goal-option-1 on 6 transitions
[RND Rollout] Reward: 30.0	IntrinsicReward: -318.5257715433836
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 781 Step: 89449
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89449, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8999, 'bonus': 0.010541511189673803, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 200 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6562792784704867
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 35.0	IntrinsicReward: -335.6586293205619
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 782 Step: 89456
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -316.26017126860097
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 783 Step: 89456
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89456, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8974, 'bonus': 0.010556184384033912, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 201 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6210951019860876
Updated goal-option-4 on 7 transitions
[RND Rollout] Reward: 35.0	IntrinsicReward: -300.17411209177226
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 784 Step: 89463
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -338.73682049289346
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 785 Step: 89463
================================================================================
Attempting to expand SE([5 2])
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8950, 'bonus': 0.0105703284516338, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 202 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6995919864413603
Updated goal-option-4 on 12 transitions
[RND Rollout] Reward: 34.0	IntrinsicReward: -327.7587611731142
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 786 Step: 89475
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 34.0	IntrinsicReward: -127.7643869863823
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 787 Step: 89475
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -336.64649335481226
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 788 Step: 89475
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 13.0	IntrinsicReward: -344.3567962497473
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153825b15670>
================================================================================
[Expansion] Episode: 789 Step: 89475
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 29.0	IntrinsicReward: -334.71155746653676
Took 112.89379358291626s to update distance table with 20131 states and events {SE([2 5]), None, SE([5 2]), SE([6 6]), SE([1 1])}
[Episode=790 Seed=18] Took 0.07404875755310059s to save gc logs
[SE([1 1]), SE([6 6]), SE([5 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 790 Step: 89475
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89475, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6618, 'bonus': 0.012292398150143692, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 325 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5382078407422317
Updated goal-option-1 on 6 transitions
Took 0.0002639293670654297s to update distance table with 7 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.26150524 0.3710936  0.36740116]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6709, 'bonus': 0.012208747282590686, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89481, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48160, 'bonus': 0.004556766353603058, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88427, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3654119217997058
Updated goal-option-3 on 6 transitions
Took 0.00025844573974609375s to update distance table with 7 states and events {SE([2 5]), None, SE([6 6])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-2-0 to goal-option-1
Adding edge from goal-option-4 to goal-option-2
Adding edge from goal-option-2-0 to goal-option-4
Took 1.6220738887786865s to add potential edges.
================================================================================
[Consolidation] Episode: 791 Step: 89487
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89487, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8920, 'bonus': 0.010588088747190668, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 203 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6179149062529307
Updated goal-option-4 on 12 transitions
Deleting edge from goal-option-4 to goal-option-2
Took 0.00035381317138671875s to update distance table with 13 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26437593 0.3751673  0.36045678]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 9014, 'bonus': 0.010532736588788925, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [5 2] targeting {'count': 21397, 'bonus': 0.006836338469644604, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.929618097180657
Updated goal-option-2 on 244 transitions
Took 0.008945226669311523s to update distance table with 245 states and events {SE([5 2]), None}
================================================================================
[Consolidation] Episode: 792 Step: 89743
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Planner goal: SE([2 5]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([2 5])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6709, 'bonus': 0.012208747282590686, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89481, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 326 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.607442042417709
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-2-0 to goal-option-1
Took 0.000194549560546875s to update distance table with 8 states and events {SE([2 5]), None, SE([1 1])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([5 2])] | Probabilities: [0.25957865 0.37206171 0.36835964]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (2, 5) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 6710, 'bonus': 0.012207837505974602, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89750, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [2 5] targeting {'count': 9014, 'bonus': 0.010532736588788925, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0722032480560948
Updated goal-option-4 on 249 transitions
Deleting edge from goal-option-2-0 to goal-option-4
Took 0.008334875106811523s to update distance table with 250 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 793 Step: 89999
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89999, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6615, 'bonus': 0.012295185226055291, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88752, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 327 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6490972903531204
Updated goal-option-1 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48166, 'bonus': 0.00455648252839831, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4913830107764194
Updated goal-option-3 on 6 transitions
Took 0.0004818439483642578s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 794 Step: 90011
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8963, 'bonus': 0.010562660029637754, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88765, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 204 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7452218026321278
Updated goal-option-4 on 7 transitions
Took 0.0002658367156982422s to update distance table with 8 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.2624357  0.37615681 0.36140749]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (5, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 9050, 'bonus': 0.010511766624552735, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90018, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-2-0, goal-option-2] and chose to execute goal-option-2-0
Rolling out goal-option-2-0, from [5 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2-0 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2-0 on 11 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 1] targeting {'count': 21393, 'bonus': 0.006836977558967273, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83358, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1542463678536083
Updated goal-option-2 on 2 transitions
Took 0.00046372413635253906s to update distance table with 14 states and events {SE([1 1]), SE([5 2]), None}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([5 2])
[Graph Consolidation] From (1, 1) to [5 2]
Planner goal: SE([5 2]), DSC goal: SE([5 2]) and Goal: SE([5 2])
True
False
[Planner] Rolling out from {'count': 21817, 'bonus': 0.0067702153663458725, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90031, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([5 2])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 8963, 'bonus': 0.010562660029637754, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88765, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 205 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8161493306116707
Updated goal-option-4 on 10 transitions
Took 0.00035119056701660156s to update distance table with 11 states and events {SE([5 2]), None, SE([1 1])}
DSG successfully reached SE([5 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([2 5])] | Probabilities: [0.26437593 0.3751673  0.36045678]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (5, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 9056, 'bonus': 0.010508283792729965, 'player_pos': (5, 2), 'player_x': 5, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90041, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 48155, 'bonus': 0.00455700291512709, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46191873432774294
Updated goal-option-3 on 7 transitions
Took 0.0002739429473876953s to update distance table with 8 states and events {SE([5 2]), None, SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 795 Step: 90048
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90048, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6585, 'bonus': 0.012323160655227547, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88563, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 328 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6027585294192118
Updated goal-option-1 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48162, 'bonus': 0.004556671739308359, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4975855308797275
Updated goal-option-3 on 7 transitions
Took 0.0004754066467285156s to update distance table with 15 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 796 Step: 90062
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6616, 'bonus': 0.012294255990122585, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 329 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5877377211623672
Updated goal-option-1 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 48163, 'bonus': 0.004556624434371043, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88486, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44602607378823905
Updated goal-option-3 on 6 transitions
Took 0.00043463706970214844s to update distance table with 13 states and events {SE([2 5]), None, SE([1 1]), SE([6 6])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 797 Step: 90074
================================================================================
Candidate events: [SE([6 6]), SE([5 2]), SE([2 5])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90074, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-3] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 6574, 'bonus': 0.012333466261408268, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88504, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 330 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
