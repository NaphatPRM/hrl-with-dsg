Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MinigridEmpty8x8 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/MinigridEmpty8x8/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8/18/initiation_set_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8/18/value_function_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8/18/accepted_events 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/MinigridEmpty8x8/18/rejected_events 
Creating classifier of type cnn
Creating rainbow with sigma=0.5
Created model-free option global-option with option_idx=0
[DSGTrainer] Adding new SalientEvent  SE([1 1])
[Seed=18] Device count: 1 Device Name: NVIDIA GeForce GTX 1080 Ti
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 0 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -32.12846235232427
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 1 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -114.60943352803588
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 2 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -129.58214111754205
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 3 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -125.69444519853278
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 4 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -162.53383333608508
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 5 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -170.58202363562305
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 6 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -167.67463352996856
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 7 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -192.5061074430123
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 8 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -191.71798853762448
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 9 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -195.8614505319856
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 10 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -161.18088059099318
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 11 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -228.1374927489087
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 12 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -207.8898007327225
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 13 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -232.6244407761842
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 14 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -211.56095026945695
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 15 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -224.3793360167183
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 16 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -236.85886460728943
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 17 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -220.81788329128176
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 18 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -234.28821051307023
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 19 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -235.2307472154498
Accepted New Salient Event:  SE([6 6])
[DSGTrainer] Adding new SalientEvent  SE([6 6])
Accepted New Salient Event:  SE([6 2])
[DSGTrainer] Adding new SalientEvent  SE([6 2])
Took 11.063313961029053s to update distance table with 20040 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 20 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -251.0108841508627
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 21 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -220.2456070742337
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 22 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -239.93963266722858
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 23 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -256.3681805226952
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 24 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -258.76353571005166
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 25 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -205.06607419651118
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 26 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -235.477881036466
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 27 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 3.0	IntrinsicReward: -274.7185591235757
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 28 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -247.1924160552444
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 29 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -263.500191481784
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 30 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -255.48297552391887
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 31 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -284.9376299669966
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 32 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -210.24727401928976
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 33 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -269.11304628802463
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 34 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -278.4162410609424
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 35 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -247.88408985607384
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 36 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -298.3282718854025
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 37 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -248.10123641300015
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 38 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -256.7977253369754
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 39 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -296.0481528090313
Accepted New Salient Event:  SE([3 2])
[DSGTrainer] Adding new SalientEvent  SE([3 2])
Took 17.637199640274048s to update distance table with 20040 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -233.95402160820322
Took 0.04961824417114258s to update distance table with 1001 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -293.58406706526875
Took 0.05617809295654297s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -300.3240295086034
Took 0.050980567932128906s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -269.0091806072742
Took 0.0828709602355957s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -307.6007227571681
Took 0.049355506896972656s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -281.76042961978965
Took 0.05493497848510742s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -289.38638611347415
Took 0.05523419380187988s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -227.1441563400731
Took 0.09752178192138672s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -306.6881317254156
Took 0.05353689193725586s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -278.9246821240522
Took 0.060605525970458984s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -326.2918378803879
Took 0.07460880279541016s to update distance table with 1001 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -270.09489958302584
Took 0.09451770782470703s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -302.799659877026
Took 0.06063580513000488s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -154.85622654628241
Took 0.060868263244628906s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -331.7648069001734
Took 0.06872844696044922s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -311.64290300616995
Took 0.05245375633239746s to update distance table with 1001 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -299.4128893818706
Took 0.06307101249694824s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -279.9012587140314
Took 0.06353950500488281s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -273.7322960905731
Took 0.05463290214538574s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -260.25221324991435
Took 0.05738210678100586s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -306.73433253820986
Took 0.08028292655944824s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -308.75322298612446
Took 0.0794820785522461s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -313.0153836202808
Took 0.0911097526550293s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -304.69250939111225
Took 0.05757308006286621s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -289.6503919677343
Took 0.06497812271118164s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -299.72062545566587
Took 0.06441760063171387s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -345.1427170485258
Took 0.06168985366821289s to update distance table with 1001 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -288.6579404110089
Took 0.07559514045715332s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -286.94140782079194
Took 0.07358908653259277s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -272.5096355744172
Took 0.09468483924865723s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -364.8535854704678
Took 0.09405994415283203s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -284.857567214407
Took 0.05069780349731445s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -320.75155662582256
Took 0.06708383560180664s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -298.42102969554253
Took 0.0674586296081543s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 2.0	IntrinsicReward: -295.8288661778788
Took 0.06283283233642578s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -301.98523003887385
Took 0.046151161193847656s to update distance table with 1001 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -258.8799000791041
Took 0.05235147476196289s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 2.0	IntrinsicReward: -331.27183781564236
Took 0.05646371841430664s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -218.03528068051673
Took 0.07478785514831543s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -323.844593711372
Took 0.058159828186035156s to update distance table with 1001 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -341.2351728891954
Took 0.08068346977233887s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -332.1195190162398
Took 0.054297685623168945s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -319.47818787256256
Took 0.06748056411743164s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -321.84273743309313
Took 0.08684778213500977s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -284.124351830018
Took 0.0713648796081543s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 1.0	IntrinsicReward: -328.74473093124107
Took 0.0707249641418457s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 2.0	IntrinsicReward: -280.5249408783857
Took 0.0623471736907959s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -352.66590882465243
Took 0.07570195198059082s to update distance table with 1001 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[RND Rollout] Reward: 4.0	IntrinsicReward: -224.69509440660477
Took 0.07990765571594238s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[RND Rollout] Reward: 3.0	IntrinsicReward: -365.9978598356247
Took 0.0722348690032959s to update distance table with 1001 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 90 Step: 0
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[DeepSkillGraphsAgent] Creating chain from SE([1 1]) -> SE([3 2])
Creating classifier of type cnn
Created model-free option goal-option-1 with option_idx=1
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 256 transitions
Took 0.006279945373535156s to update distance table with 257 states and events {SE([1 1]), None}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 91 Step: 256
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
33.7553383509318
Updated goal-option-1 on 9 transitions
Took 0.00034308433532714844s to update distance table with 10 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[4.99982357e-01 3.52866449e-05 4.99982357e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[DeepSkillGraphsAgent] Creating chain from SE([3 2]) -> SE([6 2])
Creating classifier of type cnn
Created model-free option goal-option-2 with option_idx=2
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2 on 55 transitions
Took 0.0018723011016845703s to update distance table with 56 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[DeepSkillGraphsAgent] Creating chain from SE([6 2]) -> SE([1 1])
Creating classifier of type cnn
Created model-free option goal-option-3 with option_idx=3
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 144 transitions
Took 0.004807233810424805s to update distance table with 145 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 92 Step: 464
================================================================================
[Random] Deep skill graphs target event: SE([3 2])
[Random] DSG selected event SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
20.280669555068016
Updated goal-option-1 on 131 transitions
Took 0.004582405090332031s to update distance table with 132 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[4.99982357e-01 3.52866449e-05 4.99982357e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2 on 5 transitions
Took 0.0002529621124267578s to update distance table with 6 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 120 transitions
Took 0.003916740417480469s to update distance table with 121 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 93 Step: 720
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2081, 'bonus': 0.021921181601070722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 595, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.273611912296878
Updated goal-option-1 on 81 transitions
Took 0.002730131149291992s to update distance table with 82 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[4.99982357e-01 3.52866449e-05 4.99982357e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2536, 'bonus': 0.01985753676973844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2 on 74 transitions
Took 0.002086162567138672s to update distance table with 75 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 96 transitions
Took 0.003468036651611328s to update distance table with 97 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 94 Step: 971
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2081, 'bonus': 0.021921181601070722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 595, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.6491017526104335
Updated goal-option-1 on 66 transitions
Took 0.0020017623901367188s to update distance table with 67 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[4.99982357e-01 3.52866449e-05 4.99982357e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2 on 36 transitions
Took 0.0012326240539550781s to update distance table with 37 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 154 transitions
Took 0.003870725631713867s to update distance table with 155 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 95 Step: 1227
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2081, 'bonus': 0.021921181601070722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 595, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.560525141104503
Updated goal-option-1 on 129 transitions
Took 0.004275798797607422s to update distance table with 130 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2575, 'bonus': 0.019706585563285865, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-2 on 11 transitions
Took 0.0004582405090332031s to update distance table with 12 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 60 transitions
Took 0.0019884109497070312s to update distance table with 61 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 96 Step: 1427
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.8216055781890947
Updated goal-option-1 on 178 transitions
Took 0.0058383941650390625s to update distance table with 179 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2536, 'bonus': 0.01985753676973844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.2634592510405045
Updated goal-option-2 on 78 transitions
Took 0.0027823448181152344s to update distance table with 79 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 97 Step: 1683
================================================================================
[Random] Deep skill graphs target event: SE([3 2])
[Random] DSG selected event SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2079, 'bonus': 0.021931723165325635, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8589026596905156
Updated goal-option-1 on 46 transitions
Took 0.0015368461608886719s to update distance table with 47 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([3 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
9.681477576714975
Updated goal-option-3 on 64 transitions
Took 0.0025522708892822266s to update distance table with 65 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2079, 'bonus': 0.021931723165325635, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2781836255572927
Updated goal-option-1 on 85 transitions
Took 0.0030248165130615234s to update distance table with 86 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2575, 'bonus': 0.019706585563285865, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.302570291967303
Updated goal-option-2 on 61 transitions
Took 0.0022346973419189453s to update distance table with 62 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 98 Step: 1939
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2090, 'bonus': 0.021873931962990357, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7216603548635566
Updated goal-option-1 on 117 transitions
Took 0.0037631988525390625s to update distance table with 118 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2575, 'bonus': 0.019706585563285865, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.627143840491772
Updated goal-option-2 on 100 transitions
Took 0.003729581832885742s to update distance table with 101 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.682447370254632
Updated goal-option-3 on 39 transitions
Took 0.0013005733489990234s to update distance table with 40 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 99 Step: 2195
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probs: [[1.77754509e-05 1.74421047e-04 9.99807804e-01]]
[BoltzmannClosest] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([3 2])
Planner goal: SE([1 1]), DSC goal: SE([3 2]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([3 2])
Rolling out goal-option-1, from [1 1] targeting {'count': 2081, 'bonus': 0.021921181601070722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 595, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.16281499065614
Updated goal-option-1 on 26 transitions
Expanding goal-option-1's pessimistic classifier to include SE([1 1])
Case 3: Adding edge from goal-option-1 to SE([3 2])
Case 2: Adding edge from SE([1 1]) to goal-option-1
Adding edge from SE([1 1]) to goal-option-1
Adding edge from SE([6 2]) to goal-option-1
Expanding goal-option-1's pessimistic classifier to include SE([1 1])
Took 0.0009016990661621094s to update distance table with 27 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2638, 'bonus': 0.019469849944497734, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.623157032455007
Updated goal-option-2 on 101 transitions
Took 0.004354000091552734s to update distance table with 102 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 2647, 'bonus': 0.019436722280931712, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [6 2] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1605, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9748430215309258
Updated goal-option-1 on 31 transitions
Took 0.0010750293731689453s to update distance table with 32 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.379166639768161
Updated goal-option-2 on 69 transitions
Took 0.0022058486938476562s to update distance table with 70 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 100 Step: 2422
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2])] | Probs: [[0.09248582 0.90751418]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2422, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1605, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5311991501435199
Updated goal-option-1 on 77 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2647, 'bonus': 0.019436722280931712, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.198395524256759
Updated goal-option-2 on 33 transitions
Took 0.003911495208740234s to update distance table with 111 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 2657, 'bonus': 0.019400111356958783, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [6 2] targeting {'count': 2090, 'bonus': 0.021873931962990357, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5488245632466778
Updated goal-option-1 on 103 transitions
Took 0.003819704055786133s to update distance table with 104 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2585, 'bonus': 0.019668431441216497, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.154007938380043
Updated goal-option-2 on 43 transitions
Took 0.001544952392578125s to update distance table with 44 states and events {SE([1 1]), None, SE([3 2])}
Adding edge from SE([3 2]) to goal-option-1
Took 0.018497943878173828s to add potential edges.
================================================================================
[Consolidation] Episode: 101 Step: 2678
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2])] | Probs: [[0.09248582 0.90751418]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7102271935641818
Updated goal-option-1 on 167 transitions
Took 0.0054929256439208984s to update distance table with 168 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 102 Step: 2845
================================================================================
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2845, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3151783591703228
Updated goal-option-1 on 256 transitions
Deleting edge from SE([6 2]) to goal-option-1
Took 0.008099079132080078s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 103 Step: 3101
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2])] | Probs: [[0.09248582 0.90751418]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2116, 'bonus': 0.021739130434782608, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2221, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0530144055684407
Updated goal-option-1 on 88 transitions
Took 0.0026824474334716797s to update distance table with 89 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 104 Step: 3189
================================================================================
Unconnected Events: [SE([6 6]), SE([6 2])] | Probs: [[0.09248582 0.90751418]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2102, 'bonus': 0.02181140511198411, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3266155213075146
Updated goal-option-1 on 54 transitions
Took 0.0016283988952636719s to update distance table with 55 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 105 Step: 3243
================================================================================
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3243, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2102, 'bonus': 0.02181140511198411, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7771494456647356
Updated goal-option-1 on 10 transitions
Took 0.00028324127197265625s to update distance table with 11 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2585, 'bonus': 0.019668431441216497, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.8423986814445406
Updated goal-option-2 on 220 transitions
Took 0.009931802749633789s to update distance table with 221 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
10.669238888555101
Updated goal-option-3 on 13 transitions
Took 0.0004680156707763672s to update distance table with 14 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 106 Step: 3486
================================================================================
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3486, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1605, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.99823357732523
Updated goal-option-1 on 102 transitions
Took 0.003440380096435547s to update distance table with 103 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probs: [[1.52671374e-02 1.07749014e-06 9.84731785e-01]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([6 2])
Planner goal: SE([3 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-2, from [3 2] targeting {'count': 2657, 'bonus': 0.019400111356958783, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.428330676074614
Updated goal-option-2 on 140 transitions
Expanding goal-option-2's pessimistic classifier to include SE([3 2])
Case 3: Adding edge from goal-option-2 to SE([6 2])
Case 2: Adding edge from SE([3 2]) to goal-option-2
Adding edge from SE([3 2]) to goal-option-2
Adding edge from goal-option-1 to goal-option-2
Expanding goal-option-2's pessimistic classifier to include SE([3 2])
Took 0.004489898681640625s to update distance table with 141 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 5.17555501e-17]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
7.892851536472638
Updated goal-option-3 on 14 transitions
Took 0.0005133152008056641s to update distance table with 15 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 107 Step: 3742
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3742, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2116, 'bonus': 0.021739130434782608, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2221, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8445162560376855
Updated goal-option-1 on 49 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2638, 'bonus': 0.019469849944497734, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.46818975135684
Updated goal-option-2 on 25 transitions
Took 0.0022802352905273438s to update distance table with 75 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 5.17555501e-17]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
6.654743191414263
Updated goal-option-3 on 43 transitions
Took 0.0016751289367675781s to update distance table with 44 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 7145, 'bonus': 0.01183038514149988, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3859, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2102, 'bonus': 0.02181140511198411, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1889882368656497
Updated goal-option-1 on 89 transitions
Deleting edge from SE([3 2]) to goal-option-1
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2681, 'bonus': 0.019313082381200473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3473, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9636502208290312
Updated goal-option-2 on 50 transitions
Took 0.005277156829833984s to update distance table with 140 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 108 Step: 3998
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3588, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1384917246271866
Updated goal-option-1 on 109 transitions
Took 0.0035140514373779297s to update distance table with 110 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2167, 'bonus': 0.021481793839053773, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.431881664455801
Updated goal-option-2 on 54 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7145, 'bonus': 0.01183038514149988, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3859, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
11.50373223282042
Updated goal-option-3 on 7 transitions
Took 0.00225067138671875s to update distance table with 62 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 109 Step: 4168
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.213145806604908
Updated goal-option-1 on 113 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.274290374790629
Updated goal-option-2 on 26 transitions
Took 0.0048525333404541016s to update distance table with 140 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.9408475233448876
Updated goal-option-3 on 117 transitions
Took 0.004072904586791992s to update distance table with 118 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 110 Step: 4424
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[DeepSkillGraphsAgent] Creating chain from SE([6 2]) -> SE([6 6])
Creating classifier of type cnn
Created model-free option goal-option-4 with option_idx=4
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1605, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7061518726663456
Updated goal-option-1 on 76 transitions
Took 0.00238037109375s to update distance table with 77 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([6 2]) to goal-option-2
Took 0.07920145988464355s to add potential edges.
================================================================================
[Consolidation] Episode: 111 Step: 4500
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2170, 'bonus': 0.021466939537054593, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4281, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.280244903344857
Updated goal-option-1 on 56 transitions
Took 0.0016589164733886719s to update distance table with 57 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2178, 'bonus': 0.021427478217774167, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4556, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2585, 'bonus': 0.019668431441216497, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2842943929613402
Updated goal-option-2 on 175 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
8.136258753637472
Updated goal-option-3 on 25 transitions
Took 0.007277727127075195s to update distance table with 201 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 112 Step: 4756
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2167, 'bonus': 0.021481793839053773, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7654317431151867
Updated goal-option-1 on 71 transitions
Took 0.0023446083068847656s to update distance table with 72 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2192, 'bonus': 0.021358941442919024, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2536, 'bonus': 0.01985753676973844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.502358654582942
Updated goal-option-2 on 107 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
8.370053048487064
Updated goal-option-3 on 78 transitions
Took 0.007717609405517578s to update distance table with 186 states and events {SE([6 2]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 113 Step: 5012
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2098, 'bonus': 0.021832187779978623, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1605, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0635530668182103
Updated goal-option-1 on 256 transitions
Took 0.00968170166015625s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 114 Step: 5268
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5268, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2116, 'bonus': 0.021739130434782608, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2221, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2457246353465412
Updated goal-option-1 on 17 transitions
Took 0.0005943775177001953s to update distance table with 18 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 2206, 'bonus': 0.021291058142914557, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2707, 'bonus': 0.01922011014307878, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3630612072135724
Updated goal-option-2 on 28 transitions
Took 0.0009889602661132812s to update distance table with 29 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([3 2])
[Random] DSG selected event SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.252764629167423
Updated goal-option-3 on 56 transitions
Took 0.0018999576568603516s to update distance table with 57 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 115 Step: 5369
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5369, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2647, 'bonus': 0.019436722280931712, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0163563553072599
Updated goal-option-2 on 38 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4 on 37 transitions
Took 0.002202272415161133s to update distance table with 76 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 116 Step: 5444
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2594, 'bonus': 0.019634281539316643, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7664507266227487
Updated goal-option-2 on 35 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4 on 11 transitions
Took 0.0013980865478515625s to update distance table with 47 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 117 Step: 5490
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2102, 'bonus': 0.02181140511198411, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7089805049720662
Updated goal-option-1 on 64 transitions
Took 0.0021371841430664062s to update distance table with 65 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 118 Step: 5554
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5554, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2647, 'bonus': 0.019436722280931712, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9689806199943026
Updated goal-option-2 on 90 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4709, 'bonus': 0.014572553378040145, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4 on 36 transitions
Took 0.004190206527709961s to update distance table with 127 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 119 Step: 5680
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5680, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7257219499670992
Updated goal-option-2 on 89 transitions
Took 0.0026183128356933594s to update distance table with 90 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 120 Step: 5769
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5769, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2090, 'bonus': 0.021873931962990357, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8498998944406155
Updated goal-option-1 on 226 transitions
Took 0.008585214614868164s to update distance table with 227 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Took 0.08047938346862793s to add potential edges.
================================================================================
[Consolidation] Episode: 121 Step: 5995
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5995, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2206, 'bonus': 0.021291058142914557, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0586831740003435
Updated goal-option-1 on 142 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2585, 'bonus': 0.019668431441216497, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8237289901290622
Updated goal-option-2 on 99 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4710, 'bonus': 0.014571006315731203, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.19392869869868
Updated goal-option-4 on 15 transitions
Took 0.008378982543945312s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 122 Step: 6251
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6251, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2707, 'bonus': 0.01922011014307878, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8125773463566024
Updated goal-option-2 on 152 transitions
Took 0.004918098449707031s to update distance table with 153 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 123 Step: 6403
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2763, 'bonus': 0.01902433818451165, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1516665896041351
Updated goal-option-2 on 94 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4710, 'bonus': 0.014571006315731203, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.092605756719907
Updated goal-option-4 on 84 transitions
Took 0.00643610954284668s to update distance table with 179 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 124 Step: 6581
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2706, 'bonus': 0.01922366120271981, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4161, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3450960068653028
Updated goal-option-2 on 196 transitions
Took 0.0065119266510009766s to update distance table with 197 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 125 Step: 6777
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6777, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2785, 'bonus': 0.018949048189527844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5920869527118546
Updated goal-option-2 on 48 transitions
Took 0.0016181468963623047s to update distance table with 49 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 126 Step: 6825
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8030295349484265
Updated goal-option-2 on 126 transitions
Deleting edge from SE([6 2]) to goal-option-2
Took 0.0038650035858154297s to update distance table with 127 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
8.077090731688909
Updated goal-option-3 on 83 transitions
Took 0.003035306930541992s to update distance table with 84 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7646, 'bonus': 0.011436229264294624, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2575, 'bonus': 0.019706585563285865, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9954122357346393
Updated goal-option-2 on 47 transitions
Took 0.0013599395751953125s to update distance table with 48 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 127 Step: 7081
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7081, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2112, 'bonus': 0.02175970699446223, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.127296112374299
Updated goal-option-1 on 176 transitions
Took 0.005986452102661133s to update distance table with 177 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 128 Step: 7257
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2109, 'bonus': 0.02177517781546711, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1878, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2877833833297092
Updated goal-option-1 on 60 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2681, 'bonus': 0.019313082381200473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3473, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8445980899791785
Updated goal-option-2 on 96 transitions
Took 0.005261421203613281s to update distance table with 157 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 5.17555501e-17]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7646, 'bonus': 0.011436229264294624, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.481295487194351
Updated goal-option-3 on 38 transitions
Took 0.0014698505401611328s to update distance table with 39 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 7714, 'bonus': 0.011385711699531493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3588, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2619376679261527
Updated goal-option-1 on 62 transitions
Took 0.0018677711486816406s to update distance table with 63 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 129 Step: 7513
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3814114713006551
Updated goal-option-2 on 215 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4709, 'bonus': 0.014572553378040145, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.2499054968357086
Updated goal-option-4 on 41 transitions
Took 0.008346319198608398s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 130 Step: 7769
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7769, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9407055063211187
Updated goal-option-2 on 256 transitions
Took 0.01394200325012207s to update distance table with 257 states and events {SE([1 1]), None}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([6 2]) to goal-option-1
Adding edge from goal-option-2 to goal-option-1
Adding edge from SE([6 2]) to goal-option-2
Took 0.09399747848510742s to add potential edges.
================================================================================
[Consolidation] Episode: 131 Step: 8025
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8025, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2206, 'bonus': 0.021291058142914557, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0296860233230412
Updated goal-option-1 on 103 transitions
Deleting edge from SE([3 2]) to goal-option-1
Deleting edge from SE([6 2]) to goal-option-1
Deleting edge from goal-option-2 to goal-option-1
Took 0.003321409225463867s to update distance table with 104 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 132 Step: 8128
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2210, 'bonus': 0.02127178149057585, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.291162974672553
Updated goal-option-1 on 198 transitions
Took 0.007391929626464844s to update distance table with 199 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 133 Step: 8326
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8326, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2112, 'bonus': 0.02175970699446223, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8884508993831419
Updated goal-option-1 on 233 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2657, 'bonus': 0.019400111356958783, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2015842891732853
Updated goal-option-2 on 23 transitions
Took 0.008951425552368164s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 134 Step: 8582
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2681, 'bonus': 0.019313082381200473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3473, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.758119975240567
Updated goal-option-2 on 256 transitions
Took 0.008809089660644531s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 135 Step: 8838
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8838, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2763, 'bonus': 0.01902433818451165, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8564140686282405
Updated goal-option-2 on 256 transitions
Took 0.008229494094848633s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 136 Step: 9094
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2681, 'bonus': 0.019313082381200473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3473, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.127786592461846
Updated goal-option-2 on 40 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.56149319310983
Updated goal-option-4 on 216 transitions
Took 0.010747671127319336s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 137 Step: 9350
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9350, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2729, 'bonus': 0.019142481328851556, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.353149800783112
Updated goal-option-2 on 55 transitions
Took 0.0016312599182128906s to update distance table with 56 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 5.17555501e-17]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7646, 'bonus': 0.011436229264294624, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.6431029393441148
Updated goal-option-3 on 87 transitions
Took 0.0031881332397460938s to update distance table with 88 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8109, 'bonus': 0.011104943410879493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2236, 'bonus': 0.021147746721890678, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7776679834078627
Updated goal-option-1 on 23 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2822, 'bonus': 0.018824415287446387, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0668297312413042
Updated goal-option-2 on 23 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4710, 'bonus': 0.014571006315731203, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.5767284989356996
Updated goal-option-4 on 52 transitions
Took 0.0033347606658935547s to update distance table with 99 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 138 Step: 9590
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2729, 'bonus': 0.019142481328851556, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8000752540294734
Updated goal-option-2 on 149 transitions
Took 0.004968404769897461s to update distance table with 150 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 139 Step: 9739
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2802, 'bonus': 0.0188914778984526, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0573909659352567
Updated goal-option-2 on 207 transitions
Took 0.007118701934814453s to update distance table with 208 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
[Episode=140 Seed=18] Took 0.06765317916870117s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 140 Step: 9946
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2764, 'bonus': 0.01902089642271334, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5407, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7995607635026338
Updated goal-option-2 on 42 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 141 Step: 9988
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2785, 'bonus': 0.018949048189527844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0832144068504768
Updated goal-option-2 on 138 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -374.72230622079223
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 142 Step: 10126
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2102, 'bonus': 0.02181140511198411, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1965583382468477
Updated goal-option-1 on 9 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -342.786233946681
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 143 Step: 10135
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10135, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2843, 'bonus': 0.018754762556128426, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9134, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.285014623327133
Updated goal-option-2 on 178 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 144 Step: 10313
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2823, 'bonus': 0.018821080876776804, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7728, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2380612436959992
Updated goal-option-2 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 145 Step: 10569
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10569, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2769, 'bonus': 0.01900371558963217, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5644, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9630519848536044
Updated goal-option-2 on 146 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 146 Step: 10715
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2223, 'bonus': 0.02120949209919259, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.420627725158034
Updated goal-option-1 on 63 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2681, 'bonus': 0.019313082381200473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3473, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2099318345963668
Updated goal-option-2 on 40 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -351.6262944629416
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 147 Step: 10818
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10818, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2143, 'bonus': 0.02160174894839516, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3588, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1078458747102156
Updated goal-option-1 on 104 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -318.12018307251856
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 148 Step: 10922
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2270, 'bonus': 0.020988774008055672, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10135, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6540518416672623
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 149 Step: 11178
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11178, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2146, 'bonus': 0.021586644588817278, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3791, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.048421595012769
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 150 Step: 11434
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11434, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2123, 'bonus': 0.021703261485649127, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 2499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3619767636060716
Updated goal-option-1 on 141 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 151 Step: 11575
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2318, 'bonus': 0.020770324619863195, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7465149184957662
Updated goal-option-1 on 75 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -341.4577768468298
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 152 Step: 11650
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2721, 'bonus': 0.01917060103747883, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6933364399841853
Updated goal-option-2 on 28 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -363.20450272690505
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 153 Step: 11678
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2721, 'bonus': 0.01917060103747883, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2121123331426469
Updated goal-option-2 on 146 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 154 Step: 11824
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11824, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2210, 'bonus': 0.02127178149057585, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6311298000315826
Updated goal-option-1 on 76 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 155 Step: 11900
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2791, 'bonus': 0.018928669210852442, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6497, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9123955743538367
Updated goal-option-2 on 65 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 156 Step: 11965
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11965, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2236, 'bonus': 0.021147746721890678, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1976812484039776
Updated goal-option-1 on 27 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -352.5695395004004
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 157 Step: 11992
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2802, 'bonus': 0.0188914778984526, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8047550923294491
Updated goal-option-2 on 45 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -309.5588569547981
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 158 Step: 12037
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2192, 'bonus': 0.021358941442919024, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9065374302472308
Updated goal-option-1 on 104 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -318.31061481684446
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 159 Step: 12141
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12141, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2802, 'bonus': 0.0188914778984526, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.371562567753193
Updated goal-option-2 on 232 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -338.83032381301746
Took 8.683691024780273s to update distance table with 12457 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=160 Seed=18] Took 0.08956575393676758s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 160 Step: 12373
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2763, 'bonus': 0.01902433818451165, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.23237708160001
Updated goal-option-2 on 46 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4710, 'bonus': 0.014571006315731203, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.6334163536778608
Updated goal-option-4 on 163 transitions
Took 0.007173061370849609s to update distance table with 210 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Took 0.1167750358581543s to add potential edges.
================================================================================
[Consolidation] Episode: 161 Step: 12582
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2802, 'bonus': 0.0188914778984526, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8524525222678979
Updated goal-option-2 on 174 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 6188, 'bonus': 0.012712320904523034, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7863571559771514
Updated goal-option-4 on 82 transitions
Took 0.009272098541259766s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 162 Step: 12838
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12838, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2843, 'bonus': 0.018754762556128426, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9134, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4258357016990582
Updated goal-option-2 on 16 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4712, 'bonus': 0.014567913668701625, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5680, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.1662607299430032
Updated goal-option-4 on 19 transitions
Took 0.0012369155883789062s to update distance table with 36 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 163 Step: 12873
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12873, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2318, 'bonus': 0.020770324619863195, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.653452205212285
Updated goal-option-1 on 119 transitions
Took 0.0037827491760253906s to update distance table with 120 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 164 Step: 12992
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3246, 'bonus': 0.01755196492081838, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7842720678478292
Updated goal-option-2 on 37 transitions
Took 0.0010271072387695312s to update distance table with 38 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 3299, 'bonus': 0.017410403735403916, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13029, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [6 2] targeting {'count': 2146, 'bonus': 0.021586644588817278, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3791, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.835240954885612
Updated goal-option-1 on 91 transitions
Took 0.0030977725982666016s to update distance table with 92 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 165 Step: 13120
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13120, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0184189588354347
Updated goal-option-1 on 123 transitions
Took 0.005738496780395508s to update distance table with 124 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13243, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3299, 'bonus': 0.017410403735403916, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13029, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.204925622457896
Updated goal-option-2 on 10 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7714, 'bonus': 0.011385711699531493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.741696707407633
Updated goal-option-3 on 39 transitions
Took 0.001821279525756836s to update distance table with 50 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 166 Step: 13292
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13292, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2785, 'bonus': 0.018949048189527844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0357302564762134
Updated goal-option-2 on 59 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4709, 'bonus': 0.014572553378040145, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.391529417037964
Updated goal-option-4 on 121 transitions
Took 0.006430387496948242s to update distance table with 181 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 167 Step: 13472
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2341, 'bonus': 0.0206680399887278, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8586059362986388
Updated goal-option-1 on 88 transitions
Took 0.0028324127197265625s to update distance table with 89 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2703, 'bonus': 0.01923432620282051, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2769, 'bonus': 0.01900371558963217, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5644, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3213033308001125
Updated goal-option-2 on 55 transitions
Took 0.0019605159759521484s to update distance table with 56 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 168 Step: 13615
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13615, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2894, 'bonus': 0.018588773540169683, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.232667951348641
Updated goal-option-2 on 256 transitions
Took 0.014100074768066406s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 169 Step: 13871
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13871, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2991, 'bonus': 0.01828486648462095, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10818, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0690411371037818
Updated goal-option-2 on 143 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4712, 'bonus': 0.014567913668701625, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5680, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8409806010769862
Updated goal-option-4 on 113 transitions
Took 0.010012149810791016s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 170 Step: 14127
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14127, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8297660628703074
Updated goal-option-1 on 71 transitions
Took 0.0025873184204101562s to update distance table with 72 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2719, 'bonus': 0.019177650348633602, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14198, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 2884, 'bonus': 0.01862097306809647, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9405, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8933866105145878
Updated goal-option-2 on 59 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7145, 'bonus': 0.01183038514149988, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3859, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.017957204653893
Updated goal-option-3 on 44 transitions
Took 0.003612518310546875s to update distance table with 104 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
Took 0.13103222846984863s to add potential edges.
================================================================================
[Consolidation] Episode: 171 Step: 14301
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14301, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3207, 'bonus': 0.017658366242304668, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1104306872292753
Updated goal-option-2 on 69 transitions
Took 0.0019729137420654297s to update distance table with 70 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 172 Step: 14370
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14370, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3238, 'bonus': 0.017573634021564907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1659693739320216
Updated goal-option-2 on 256 transitions
Took 0.0081634521484375s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 173 Step: 14626
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14626, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2167, 'bonus': 0.021481793839053773, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3175197995509262
Updated goal-option-1 on 57 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3238, 'bonus': 0.017573634021564907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9582759997823782
Updated goal-option-2 on 90 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 4709, 'bonus': 0.014572553378040145, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.7309878056625645
Updated goal-option-4 on 109 transitions
Took 0.009663820266723633s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 174 Step: 14882
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14882, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0078401647326423
Updated goal-option-1 on 113 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3280, 'bonus': 0.017460757394239454, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.117816991586652
Updated goal-option-2 on 39 transitions
Took 0.006154537200927734s to update distance table with 153 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 175 Step: 15034
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2167, 'bonus': 0.021481793839053773, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 4107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0340373112805306
Updated goal-option-1 on 256 transitions
Took 0.00878143310546875s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 176 Step: 15290
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15290, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 2894, 'bonus': 0.018588773540169683, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6755172707575703
Updated goal-option-2 on 18 transitions
Took 0.0005609989166259766s to update distance table with 19 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([1 1])
[Random] DSG selected event SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.9131920756328675
Updated goal-option-3 on 131 transitions
Took 0.005425691604614258s to update distance table with 132 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 9335, 'bonus': 0.010350059318947459, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2255, 'bonus': 0.021058465757133063, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9515, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.043102189840055
Updated goal-option-1 on 107 transitions
Took 0.0036513805389404297s to update distance table with 108 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 177 Step: 15546
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15546, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3207, 'bonus': 0.017658366242304668, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9308997711965016
Updated goal-option-2 on 189 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 6189, 'bonus': 0.012711293853751452, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12873, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.5234222665429114
Updated goal-option-4 on 48 transitions
Took 0.009247064590454102s to update distance table with 238 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 178 Step: 15783
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8275779515008131
Updated goal-option-2 on 256 transitions
Took 0.010171651840209961s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 179 Step: 16039
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2236, 'bonus': 0.021147746721890678, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1362623426225757
Updated goal-option-1 on 17 transitions
Took 0.00044465065002441406s to update distance table with 18 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2765, 'bonus': 0.0190174565282241, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3134, 'bonus': 0.0178628398242226, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8385866708291246
Updated goal-option-2 on 100 transitions
Took 0.0032863616943359375s to update distance table with 101 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 180 Step: 16156
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2270, 'bonus': 0.020988774008055672, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10135, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.21464512448658
Updated goal-option-1 on 107 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3299, 'bonus': 0.017410403735403916, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13029, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8779902352098508
Updated goal-option-2 on 53 transitions
Took 0.0051822662353515625s to update distance table with 161 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probs: [[1.00000000e+00 5.17555501e-17 3.33823780e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 8109, 'bonus': 0.011104943410879493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.793785025013818
Updated goal-option-3 on 96 transitions
Took 0.0038056373596191406s to update distance table with 97 states and events {None, SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Took 0.14368200302124023s to add potential edges.
================================================================================
[Consolidation] Episode: 181 Step: 16412
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16412, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9201448862249038
Updated goal-option-1 on 101 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.003169536590576172s to update distance table with 102 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 182 Step: 16513
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2515, 'bonus': 0.019940268657049436, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 11992, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9781499090758
Updated goal-option-1 on 133 transitions
Took 0.004279375076293945s to update distance table with 134 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2770, 'bonus': 0.01900028500641266, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16646, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3265, 'bonus': 0.01750082037018273, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8784846972960693
Updated goal-option-2 on 36 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7714, 'bonus': 0.011385711699531493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.1556852844453624
Updated goal-option-3 on 41 transitions
Took 0.0032782554626464844s to update distance table with 78 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 183 Step: 16723
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2236, 'bonus': 0.021147746721890678, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 8559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7775234918555487
Updated goal-option-1 on 37 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3359, 'bonus': 0.01725420676492063, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14773, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1243969971466365
Updated goal-option-2 on 219 transitions
Took 0.008927583694458008s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 184 Step: 16979
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16979, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2770, 'bonus': 0.01900028500641266, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16646, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1583417039831907
Updated goal-option-1 on 82 transitions
Took 0.0024809837341308594s to update distance table with 83 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 185 Step: 17061
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3309, 'bonus': 0.017384076178023157, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13253, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7164421043118591
Updated goal-option-2 on 21 transitions
Took 0.0005745887756347656s to update distance table with 22 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([3 2])
[Random] DSG selected event SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([3 2])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7714, 'bonus': 0.011385711699531493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.1097325164862357
Updated goal-option-3 on 138 transitions
True
False
[Planner] Rolling out from {'count': 9618, 'bonus': 0.01019665237674815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17220, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2691, 'bonus': 0.019277164398874676, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13243, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2804878506254642
Updated goal-option-1 on 26 transitions
Took 0.005477428436279297s to update distance table with 165 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2786, 'bonus': 0.018945647121890376, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3280, 'bonus': 0.017460757394239454, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1876307662438463
Updated goal-option-2 on 48 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 9335, 'bonus': 0.010350059318947459, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.22110850823046
Updated goal-option-3 on 10 transitions
Took 0.0024945735931396484s to update distance table with 59 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2210, 'bonus': 0.02127178149057585, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9731934940605833
Updated goal-option-1 on 13 transitions
Took 0.0004520416259765625s to update distance table with 14 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 186 Step: 17317
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3207, 'bonus': 0.017658366242304668, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5094206230658473
Updated goal-option-2 on 175 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 6193, 'bonus': 0.012707188138575309, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.772725108446497
Updated goal-option-4 on 81 transitions
Took 0.009534597396850586s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 187 Step: 17573
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17573, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2318, 'bonus': 0.020770324619863195, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 10922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.742712615006086
Updated goal-option-1 on 94 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3312, 'bonus': 0.017376201171422898, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13351, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7030320710756562
Updated goal-option-2 on 24 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4, from [6 2] targeting {'count': 6188, 'bonus': 0.012712320904523034, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.701992825321529
Updated goal-option-4 on 64 transitions
Creating goal-option-4-0 with parent goal-option-4
Creating classifier of type cnn
Created model-free option goal-option-4-0 with option_idx=5
Case 3: Adding edge from goal-option-4 to SE([6 6])
Took 0.006414890289306641s to update distance table with 183 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 188 Step: 17755
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3431, 'bonus': 0.017072205940667412, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17082, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3799120305283437
Updated goal-option-2 on 256 transitions
Took 0.008612632751464844s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 189 Step: 18011
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2719, 'bonus': 0.019177650348633602, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14198, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7835636201712198
Updated goal-option-1 on 38 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9798183398462875
Updated goal-option-2 on 139 transitions
True
False
[Planner] Rolling out from {'count': 3453, 'bonus': 0.017017733208518925, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18188, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4709, 'bonus': 0.014572553378040145, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.68251194636027
Updated goal-option-4 on 79 transitions
Took 0.01176595687866211s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 190 Step: 18267
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18267, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6198, 'bonus': 0.01270206158487549, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9245550288603859
Updated goal-option-4 on 44 transitions
Took 0.0016553401947021484s to update distance table with 45 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Took 0.563431978225708s to add potential edges.
================================================================================
[Consolidation] Episode: 191 Step: 18311
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2724, 'bonus': 0.019160041630983685, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14683, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0762348586963082
Updated goal-option-1 on 47 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3299, 'bonus': 0.017410403735403916, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13029, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.543144504747529
Updated goal-option-2 on 209 transitions
Took 0.00857853889465332s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 192 Step: 18567
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 6198, 'bonus': 0.01270206158487549, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3624234784926688
Updated goal-option-4 on 256 transitions
Took 0.014045238494873047s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 193 Step: 18823
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2651, 'bonus': 0.019422053054479065, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12141, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.019506197656342
Updated goal-option-1 on 256 transitions
Took 0.008805990219116211s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 194 Step: 19079
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2770, 'bonus': 0.01900028500641266, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16646, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2548055427721123
Updated goal-option-1 on 102 transitions
Deleting edge from SE([3 2]) to goal-option-1
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3453, 'bonus': 0.017017733208518925, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18188, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8868348276258534
Updated goal-option-2 on 75 transitions
True
False
[Planner] Rolling out from {'count': 3507, 'bonus': 0.01688620732191951, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6188, 'bonus': 0.012712320904523034, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5857695897420248
Updated goal-option-4 on 79 transitions
Took 0.012486696243286133s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 195 Step: 19335
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3345, 'bonus': 0.017290276521281022, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9081512575095655
Updated goal-option-2 on 111 transitions
True
False
[Planner] Rolling out from {'count': 3509, 'bonus': 0.016881394379731986, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19446, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4710, 'bonus': 0.014571006315731203, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.1761741875320357
Updated goal-option-4 on 50 transitions
Took 0.006658792495727539s to update distance table with 162 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 196 Step: 19496
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2766, 'bonus': 0.019014018499356047, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16263, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6753818675971184
Updated goal-option-1 on 41 transitions
Took 0.0013904571533203125s to update distance table with 42 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2847, 'bonus': 0.018741582819745837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3345, 'bonus': 0.017290276521281022, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6808142411212127
Updated goal-option-2 on 95 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 8109, 'bonus': 0.011104943410879493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.754447409919664
Updated goal-option-3 on 27 transitions
Took 0.0044248104095458984s to update distance table with 123 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 197 Step: 19659
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19659, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2765, 'bonus': 0.0190174565282241, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8487823211993927
Updated goal-option-1 on 15 transitions
Took 0.0003094673156738281s to update distance table with 16 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[9.99929429e-01 7.05707996e-05]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 2850, 'bonus': 0.01873171623163388, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19674, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3333, 'bonus': 0.017321374166049876, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14014, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1117969112562351
Updated goal-option-2 on 241 transitions
Took 0.007928609848022461s to update distance table with 242 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 198 Step: 19915
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19915, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2832, 'bonus': 0.018791150700070723, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19181, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.897220204510386
Updated goal-option-1 on 26 transitions
Took 0.0008969306945800781s to update distance table with 27 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 2862, 'bonus': 0.018692405136401476, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3453, 'bonus': 0.017017733208518925, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18188, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.089930461553054
Updated goal-option-2 on 70 transitions
Took 0.002371549606323242s to update distance table with 71 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 199 Step: 20011
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3443, 'bonus': 0.01704242881461586, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17691, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8733907566865285
Updated goal-option-2 on 111 transitions
Took 0.0034399032592773438s to update distance table with 112 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7646, 'bonus': 0.011436229264294624, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0750668588138765
Updated goal-option-3 on 15 transitions
Took 0.0007104873657226562s to update distance table with 16 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 200 Step: 20137
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3312, 'bonus': 0.017376201171422898, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 13351, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7641611730768566
Updated goal-option-2 on 50 transitions
True
False
[Planner] Rolling out from {'count': 3531, 'bonus': 0.01682872219399103, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4716, 'bonus': 0.014561734277683964, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 6581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6055852799121328
Updated goal-option-4 on 133 transitions
Took 0.007210493087768555s to update distance table with 184 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([6 6]) to goal-option-4
Took 0.509119987487793s to add potential edges.
================================================================================
[Consolidation] Episode: 201 Step: 20320
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3359, 'bonus': 0.01725420676492063, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14773, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1022870447926634
Updated goal-option-2 on 34 transitions
Took 0.0011317729949951172s to update distance table with 35 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 7714, 'bonus': 0.011385711699531493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8432908869925002
Updated goal-option-3 on 13 transitions
Took 0.0005404949188232422s to update distance table with 14 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 9928, 'bonus': 0.010036195573796253, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2816, 'bonus': 0.018844459036110227, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9095674656190962
Updated goal-option-1 on 30 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3507, 'bonus': 0.01688620732191951, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8267209017769619
Updated goal-option-2 on 85 transitions
True
False
[Planner] Rolling out from {'count': 3548, 'bonus': 0.016788356946826864, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20482, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6209, 'bonus': 0.012690804972196431, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.5021461058481065
Updated goal-option-4 on 94 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.008232593536376953s to update distance table with 210 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 202 Step: 20576
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.38698582 0.61301418]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3409, 'bonus': 0.017127205135811088, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7024738861404303
Updated goal-option-2 on 106 transitions
Took 0.0034227371215820312s to update distance table with 107 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[Random] Deep skill graphs target event: SE([6 6])
[Random] DSG selected event SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4-0, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-4-0 on 37 transitions
True
False
[Planner] Rolling out from {'count': 3398, 'bonus': 0.017154904816703558, 'player_pos': (4, 6), 'player_x': 4, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20719, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [4 6] targeting {'count': 6204, 'bonus': 0.01269591790297564, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2376589971008123
Updated goal-option-4 on 113 transitions
Took 0.004999876022338867s to update distance table with 151 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 203 Step: 20832
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2862, 'bonus': 0.018692405136401476, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9402183459404809
Updated goal-option-1 on 108 transitions
Took 0.0033805370330810547s to update distance table with 109 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 204 Step: 20940
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20940, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2826, 'bonus': 0.018811088266103344, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18358, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.191608768993197
Updated goal-option-1 on 136 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7131436870931976
Updated goal-option-2 on 120 transitions
Took 0.009523868560791016s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 205 Step: 21196
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21196, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2807, 'bonus': 0.018874645071534885, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17667, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0417370345633665
Updated goal-option-1 on 38 transitions
Took 0.001168966293334961s to update distance table with 39 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 206 Step: 21234
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.39651675 0.60348325]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21234, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2734, 'bonus': 0.019124969220777426, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14995, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6419736108787003
Updated goal-option-1 on 59 transitions
Deleting edge from SE([3 2]) to goal-option-1
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3443, 'bonus': 0.01704242881461586, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17691, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6697020029176528
Updated goal-option-2 on 101 transitions
Took 0.005042076110839844s to update distance table with 161 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([6 6]), SE([3 2])] | Probabilities: [0.5 0.5]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3569, 'bonus': 0.0167388927220441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6188, 'bonus': 0.012712320904523034, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.008864621052871
Updated goal-option-4 on 86 transitions
Took 0.004117250442504883s to update distance table with 87 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 207 Step: 21480
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3569, 'bonus': 0.0167388927220441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1065013263328576
Updated goal-option-2 on 90 transitions
Took 0.003164529800415039s to update distance table with 91 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 208 Step: 21570
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.39651675 0.60348325]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21570, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3345, 'bonus': 0.017290276521281022, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7365999488282378
Updated goal-option-2 on 73 transitions
Took 0.0022935867309570312s to update distance table with 74 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.864639278087351
Updated goal-option-3 on 24 transitions
Took 0.0012180805206298828s to update distance table with 25 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 209 Step: 21667
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21667, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3359, 'bonus': 0.01725420676492063, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14773, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9065980656827383
Updated goal-option-2 on 59 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4-0, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
24.694823265075684
Updated goal-option-4-0 on 197 transitions
Took 0.009720802307128906s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
[Episode=210 Seed=18] Took 0.06622862815856934s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 210 Step: 21923
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2862, 'bonus': 0.018692405136401476, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0839655605847376
Updated goal-option-1 on 129 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 211 Step: 22052
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -346.0526963509619
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 212 Step: 22052
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22052, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3527, 'bonus': 0.016838262286703987, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.90092864004629
Updated goal-option-2 on 28 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -336.79742780840024
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 213 Step: 22080
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2766, 'bonus': 0.019014018499356047, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 16263, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8111522187357364
Updated goal-option-1 on 43 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -353.33691737800837
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 214 Step: 22123
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -315.301255000697
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 215 Step: 22123
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 3.0	IntrinsicReward: -362.554278165102
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 216 Step: 22123
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 2.0	IntrinsicReward: -259.2853393225232
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 217 Step: 22123
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22123, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2724, 'bonus': 0.019160041630983685, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 14683, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8312664650953733
Updated goal-option-1 on 216 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 218 Step: 22339
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22339, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2877, 'bonus': 0.01864361255739157, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21076, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6921330680619618
Updated goal-option-1 on 21 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -220.8348416519002
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 219 Step: 22360
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22360, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2870, 'bonus': 0.018666334823663935, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.569682008328558
Updated goal-option-1 on 124 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -344.851196102798
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 220 Step: 22484
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22484, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3433, 'bonus': 0.0170672322461873, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17294, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8406076111410244
Updated goal-option-2 on 47 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -312.60634731454775
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 221 Step: 22531
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22531, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3509, 'bonus': 0.016881394379731986, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19446, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9234280729349398
Updated goal-option-2 on 151 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 222 Step: 22682
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3583, 'bonus': 0.01670615844038759, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9241662475935838
Updated goal-option-2 on 153 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -359.9292957931757
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 223 Step: 22835
================================================================================
Attempting to expand SE([6 6])
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22835, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3526, 'bonus': 0.01684064984606185, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19632, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8353849628676562
Updated goal-option-2 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 224 Step: 23091
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -260.6501163500361
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 225 Step: 23091
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2847, 'bonus': 0.018741582819745837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.920624630017714
Updated goal-option-1 on 221 transitions
[RND Rollout] Reward: 1.0	IntrinsicReward: -334.84655754547566
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 226 Step: 23312
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -373.003060845891
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 227 Step: 23312
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2807, 'bonus': 0.018874645071534885, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17667, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8518032208899332
Updated goal-option-1 on 52 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -360.28638026025146
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 228 Step: 23364
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2816, 'bonus': 0.018844459036110227, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7349642425455074
Updated goal-option-1 on 60 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -383.6314848586917
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 229 Step: 23424
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 2.0	IntrinsicReward: -317.44418719643727
Took 28.485769748687744s to update distance table with 17537 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[Episode=230 Seed=18] Took 0.10358762741088867s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 230 Step: 23424
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4061269 0.5938731]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3119, 'bonus': 0.01790574159082168, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.98523561946551
Updated goal-option-1 on 66 transitions
Took 0.0021686553955078125s to update distance table with 67 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3126, 'bonus': 0.017885682339724072, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3433, 'bonus': 0.0170672322461873, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17294, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6473209016263213
Updated goal-option-2 on 9 transitions
Took 0.00037670135498046875s to update distance table with 10 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4156, 'bonus': 0.01551180121394244, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6203, 'bonus': 0.012696941230902418, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1714828449946184
Updated goal-option-4 on 181 transitions
Took 0.008903026580810547s to update distance table with 182 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([6 6]) to goal-option-4
Took 0.5067908763885498s to add potential edges.
================================================================================
[Consolidation] Episode: 231 Step: 23680
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23680, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3583, 'bonus': 0.01670615844038759, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8367275655068256
Updated goal-option-2 on 256 transitions
Deleting edge from SE([6 2]) to goal-option-2
Took 0.00868082046508789s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 232 Step: 23936
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6816297697540897
Updated goal-option-2 on 152 transitions
Took 0.005340099334716797s to update distance table with 153 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 233 Step: 24088
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4061269 0.5938731]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24088, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2847, 'bonus': 0.018741582819745837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6828509762374749
Updated goal-option-1 on 81 transitions
Took 0.002687692642211914s to update distance table with 82 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.5938731 0.4061269]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3154, 'bonus': 0.017806114244894065, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24169, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8023846614029674
Updated goal-option-2 on 27 transitions
Took 0.0009706020355224609s to update distance table with 28 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4171, 'bonus': 0.015483883857556962, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24196, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4722, 'bonus': 0.014552479917500617, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.4627370057452436
Updated goal-option-4 on 14 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.0005383491516113281s to update distance table with 15 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 234 Step: 24210
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24210, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0527821859638942
Updated goal-option-2 on 256 transitions
Took 0.008731603622436523s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 235 Step: 24466
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24466, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4156, 'bonus': 0.01551180121394244, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9155642994044794
Updated goal-option-2 on 94 transitions
Took 0.0029566287994384766s to update distance table with 95 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 236 Step: 24560
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.41095957 0.58904043]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2816, 'bonus': 0.018844459036110227, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18049, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7726349383977649
Updated goal-option-1 on 56 transitions
Took 0.0016396045684814453s to update distance table with 57 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3164, 'bonus': 0.017777953363369448, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3527, 'bonus': 0.016838262286703987, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8941976316513555
Updated goal-option-2 on 139 transitions
Took 0.004620552062988281s to update distance table with 140 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 237 Step: 24755
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.41095957 0.58904043]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2847, 'bonus': 0.018741582819745837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7150914087622048
Updated goal-option-1 on 25 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.0008726119995117188s to update distance table with 26 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([3 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [3 2] targeting {'count': 8109, 'bonus': 0.011104943410879493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.037693216499416
Updated goal-option-3 on 50 transitions
Took 0.0021817684173583984s to update distance table with 51 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 238 Step: 24830
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3531, 'bonus': 0.01682872219399103, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8453470151831896
Updated goal-option-2 on 73 transitions
True
False
[Planner] Rolling out from {'count': 4173, 'bonus': 0.015480172920689397, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24903, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4710, 'bonus': 0.014571006315731203, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.907676951187413
Updated goal-option-4 on 183 transitions
Took 0.008920669555664062s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 239 Step: 25086
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.41580948 0.58419052]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25086, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3164, 'bonus': 0.017777953363369448, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0836759611926308
Updated goal-option-1 on 60 transitions
Took 0.0017235279083251953s to update distance table with 61 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 240 Step: 25146
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25146, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9212429848527103
Updated goal-option-2 on 131 transitions
Took 0.004017829895019531s to update distance table with 132 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([6 2]) to goal-option-2
Took 0.5300123691558838s to add potential edges.
================================================================================
[Consolidation] Episode: 241 Step: 25277
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2870, 'bonus': 0.018666334823663935, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.586225878344592
Updated goal-option-1 on 81 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3531, 'bonus': 0.01682872219399103, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20187, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9111506921440301
Updated goal-option-2 on 5 transitions
True
False
[Planner] Rolling out from {'count': 4189, 'bonus': 0.01545058116522741, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25363, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.101031695808507
Updated goal-option-4 on 170 transitions
Took 0.01290750503540039s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 242 Step: 25533
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.36779259 0.26441482 0.36779259]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25533, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4189, 'bonus': 0.01545058116522741, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25363, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8613691902408998
Updated goal-option-2 on 256 transitions
Took 0.008640050888061523s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 243 Step: 25789
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3668178  0.26636439 0.3668178 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7210454035688331
Updated goal-option-2 on 95 transitions
Took 0.0031461715698242188s to update distance table with 96 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 244 Step: 25884
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3668178  0.26636439 0.3668178 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25884, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3117, 'bonus': 0.017911485212971263, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6929606034313861
Updated goal-option-1 on 189 transitions
Took 0.005933523178100586s to update distance table with 190 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 245 Step: 26073
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3668178  0.26636439 0.3668178 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2850, 'bonus': 0.01873171623163388, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19674, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6444318543981623
Updated goal-option-1 on 19 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4156, 'bonus': 0.01551180121394244, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23499, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7732039893575485
Updated goal-option-2 on 157 transitions
Took 0.005873918533325195s to update distance table with 177 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 246 Step: 26249
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3668178  0.26636439 0.3668178 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26249, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2847, 'bonus': 0.018741582819745837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7249646632271922
Updated goal-option-1 on 58 transitions
Took 0.0018773078918457031s to update distance table with 59 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 247 Step: 26307
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3668178  0.26636439 0.3668178 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3526, 'bonus': 0.01684064984606185, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19632, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1108749261709174
Updated goal-option-2 on 92 transitions
Took 0.002887248992919922s to update distance table with 93 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 248 Step: 26399
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.36779259 0.26441482 0.36779259]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 4712, 'bonus': 0.014567913668701625, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5680, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.8236255433523287
Updated goal-option-4 on 256 transitions
Took 0.0123443603515625s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 249 Step: 26655
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26655, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4173, 'bonus': 0.015480172920689397, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24903, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6875629652156888
Updated goal-option-2 on 68 transitions
True
False
[Planner] Rolling out from {'count': 4240, 'bonus': 0.01535737792084878, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6205, 'bonus': 0.012694894822438666, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4336308206337085
Updated goal-option-4 on 141 transitions
Took 0.008293867111206055s to update distance table with 210 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 250 Step: 26864
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3569, 'bonus': 0.0167388927220441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6929975523362084
Updated goal-option-2 on 157 transitions
Took 0.005630970001220703s to update distance table with 158 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([6 6]) to goal-option-4
Took 0.6002421379089355s to add potential edges.
================================================================================
[Consolidation] Episode: 251 Step: 27021
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.42311474 0.57688526]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27021, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3164, 'bonus': 0.017777953363369448, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8515367005110362
Updated goal-option-1 on 77 transitions
Took 0.002395153045654297s to update distance table with 78 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 252 Step: 27098
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.42311474 0.57688526]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27098, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2877, 'bonus': 0.01864361255739157, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21076, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9290361856066044
Updated goal-option-1 on 256 transitions
Took 0.010083436965942383s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 253 Step: 27354
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.42311474 0.57688526]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3569, 'bonus': 0.0167388927220441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0344136378928728
Updated goal-option-2 on 228 transitions
Took 0.0075833797454833984s to update distance table with 229 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 254 Step: 27582
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3548, 'bonus': 0.016788356946826864, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20482, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.750405127600155
Updated goal-option-2 on 219 transitions
Took 0.007436990737915039s to update distance table with 220 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 255 Step: 27801
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.42067575 0.57932425]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27801, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2999, 'bonus': 0.018260462247539938, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22484, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9752208035677037
Updated goal-option-1 on 27 transitions
Took 0.0007317066192626953s to update distance table with 28 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 3.65268832e-21]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3221, 'bonus': 0.017619948616780765, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9384575225049757
Updated goal-option-2 on 3 transitions
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [6 2] targeting {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.325592342350218
Updated goal-option-3 on 77 transitions
Took 0.00324249267578125s to update distance table with 81 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 256 Step: 27908
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.42311474 0.57688526]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3119, 'bonus': 0.01790574159082168, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7416028973991883
Updated goal-option-1 on 119 transitions
Took 0.004273653030395508s to update distance table with 120 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 3.65268832e-21]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3222, 'bonus': 0.01761721408605633, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28027, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1588103881748195
Updated goal-option-2 on 137 transitions
Took 0.00480341911315918s to update distance table with 138 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 257 Step: 28164
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28164, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0914942115773643
Updated goal-option-2 on 28 transitions
False
False
Rolling out DSC with goal vertex SE([6 6])
Rolling out goal-option-4-0, from [6 2] targeting {'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
19.505539337793987
Updated goal-option-4-0 on 228 transitions
Took 0.00886082649230957s to update distance table with 257 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 258 Step: 28420
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28420, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3527, 'bonus': 0.016838262286703987, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7900950940166203
Updated goal-option-2 on 21 transitions
True
False
[Planner] Rolling out from {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28441, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4712, 'bonus': 0.014567913668701625, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5680, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0297721289010195
Updated goal-option-4 on 235 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.008370161056518555s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 259 Step: 28676
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28676, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3543, 'bonus': 0.01680019891553275, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7952543417782043
Updated goal-option-2 on 256 transitions
Took 0.009073495864868164s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 260 Step: 28932
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28932, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4275, 'bonus': 0.015294382258037451, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27831, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0830077838417742
Updated goal-option-2 on 81 transitions
True
False
[Planner] Rolling out from {'count': 4342, 'bonus': 0.015175922164473119, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6205, 'bonus': 0.012694894822438666, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5328785241866598
Updated goal-option-4 on 149 transitions
Took 0.009155750274658203s to update distance table with 231 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([6 6]) to goal-option-4
Took 0.5041866302490234s to add potential edges.
================================================================================
[Consolidation] Episode: 261 Step: 29162
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29162, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3570, 'bonus': 0.01673654817511446, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21643, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6733918966416762
Updated goal-option-2 on 204 transitions
True
False
[Planner] Rolling out from {'count': 4358, 'bonus': 0.015148038039558517, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9887, 'bonus': 0.010056983391594545, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.262876602169735
Updated goal-option-4 on 52 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.008899211883544922s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 262 Step: 29418
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3616, 'bonus': 0.016629752630943483, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8749959764120548
Updated goal-option-2 on 96 transitions
True
False
[Planner] Rolling out from {'count': 4364, 'bonus': 0.015137621049416815, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4709, 'bonus': 0.014572553378040145, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 5444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.1183881890150453
Updated goal-option-4 on 14 transitions
Took 0.0050487518310546875s to update distance table with 111 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 263 Step: 29528
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.43045378 0.56954622]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29528, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2847, 'bonus': 0.018741582819745837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.917724453671663
Updated goal-option-1 on 150 transitions
Took 0.0050067901611328125s to update distance table with 151 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 3.65268832e-21]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3256, 'bonus': 0.01752499093081954, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28441, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.89986876616657
Updated goal-option-2 on 32 transitions
Took 0.0011763572692871094s to update distance table with 33 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 264 Step: 29710
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29710, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28441, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.924648362638313
Updated goal-option-2 on 10 transitions
True
False
[Planner] Rolling out from {'count': 4365, 'bonus': 0.015135886972883327, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29720, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9876, 'bonus': 0.01006258262357622, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24210, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.493683286620386
Updated goal-option-4 on 133 transitions
Took 0.0066623687744140625s to update distance table with 144 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 265 Step: 29853
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29853, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3616, 'bonus': 0.016629752630943483, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8379087297218865
Updated goal-option-2 on 43 transitions
Took 0.0014581680297851562s to update distance table with 44 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 266 Step: 29896
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.43045378 0.56954622]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29896, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3221, 'bonus': 0.017619948616780765, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7814612372510735
Updated goal-option-1 on 254 transitions
Took 0.00869607925415039s to update distance table with 255 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3258, 'bonus': 0.017519611040921222, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30150, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 3569, 'bonus': 0.0167388927220441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0054451011499201
Updated goal-option-2 on 2 transitions
Took 0.00014328956604003906s to update distance table with 3 states and events {SE([3 2])}
================================================================================
[Consolidation] Episode: 267 Step: 30152
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.42800387 0.57199613]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30152, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3117, 'bonus': 0.017911485212971263, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6610501620437012
Updated goal-option-1 on 58 transitions
Took 0.0019719600677490234s to update distance table with 59 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 3.65268832e-21]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([3 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3, from [3 2] targeting {'count': 9618, 'bonus': 0.01019665237674815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17220, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.3892446991389362
Updated goal-option-3 on 125 transitions
Creating goal-option-3-0 with parent goal-option-3
Creating classifier of type cnn
Created model-free option goal-option-3-0 with option_idx=6
Case 3: Adding edge from goal-option-3 to SE([1 1])
Adding edge from goal-option-3 to goal-option-1
Took 0.0044023990631103516s to update distance table with 126 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 11429, 'bonus': 0.009353968081677544, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4173, 'bonus': 0.015480172920689397, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24903, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6775978005968541
Updated goal-option-2 on 73 transitions
Took 0.002393484115600586s to update distance table with 74 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 268 Step: 30408
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4171, 'bonus': 0.015483883857556962, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24196, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8987866113901989
Updated goal-option-2 on 158 transitions
True
False
[Planner] Rolling out from {'count': 4425, 'bonus': 0.015032920560056576, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30566, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6204, 'bonus': 0.01269591790297564, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.038270529589535
Updated goal-option-4 on 49 transitions
Took 0.008272886276245117s to update distance table with 208 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 269 Step: 30615
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.43045378 0.56954622]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30615, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3951, 'bonus': 0.015909131996778254, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22531, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8856839883474655
Updated goal-option-2 on 225 transitions
Took 0.0075359344482421875s to update distance table with 226 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4427, 'bonus': 0.015029524441056943, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9876, 'bonus': 0.01006258262357622, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24210, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8404223485426467
Updated goal-option-4 on 31 transitions
Took 0.0010323524475097656s to update distance table with 32 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
================================================================================
[Consolidation] Episode: 270 Step: 30871
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.43536371 0.56463629]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30871, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2933, 'bonus': 0.018464772811525407, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22123, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5632107073161959
Updated goal-option-1 on 171 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.006572723388671875s to update distance table with 172 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 2])] | Probabilities: [0.56463629 0.43536371]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3290, 'bonus': 0.017434201093860166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 9335, 'bonus': 0.010350059318947459, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.164641122023264
Updated goal-option-3 on 85 transitions
Took 0.0030698776245117188s to update distance table with 86 states and events {None, SE([3 2])}
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([3 2]) to goal-option-3
Adding edge from SE([1 1]) to goal-option-3
Took 0.8397493362426758s to add potential edges.
================================================================================
[Consolidation] Episode: 271 Step: 31127
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31127, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4240, 'bonus': 0.01535737792084878, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8201640716247391
Updated goal-option-2 on 26 transitions
True
False
[Planner] Rolling out from {'count': 4443, 'bonus': 0.015002438094301584, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6188, 'bonus': 0.012712320904523034, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3765443709858678
Updated goal-option-4 on 51 transitions
Took 0.003053426742553711s to update distance table with 78 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 272 Step: 31204
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4378235 0.5621765]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31204, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3117, 'bonus': 0.017911485212971263, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9564546747340096
Updated goal-option-1 on 37 transitions
Took 0.0012650489807128906s to update distance table with 38 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 273 Step: 31241
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31241, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 3951, 'bonus': 0.015909131996778254, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22531, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9016870016046843
Updated goal-option-2 on 242 transitions
True
False
[Planner] Rolling out from {'count': 4445, 'bonus': 0.01499906258788147, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6212, 'bonus': 0.012687740177229897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5493943174145206
Updated goal-option-4 on 14 transitions
Took 0.008581161499023438s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 274 Step: 31497
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31497, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4240, 'bonus': 0.01535737792084878, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9670121169183403
Updated goal-option-2 on 37 transitions
True
False
[Planner] Rolling out from {'count': 4446, 'bonus': 0.014997375688861584, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31534, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6204, 'bonus': 0.01269591790297564, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.90447655909479
Updated goal-option-4 on 187 transitions
Took 0.008949995040893555s to update distance table with 225 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 275 Step: 31721
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31721, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 9876, 'bonus': 0.01006258262357622, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24210, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5540214264002004
Updated goal-option-4 on 256 transitions
Took 0.010880470275878906s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 276 Step: 31977
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4358, 'bonus': 0.015148038039558517, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7737618062862825
Updated goal-option-2 on 168 transitions
True
False
[Planner] Rolling out from {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9894, 'bonus': 0.010053425106778415, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29528, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4095112186285756
Updated goal-option-4 on 88 transitions
Took 0.01012420654296875s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 277 Step: 32233
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4378235 0.5621765]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32233, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3290, 'bonus': 0.017434201093860166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.718574073864661
Updated goal-option-1 on 148 transitions
Took 0.00467228889465332s to update distance table with 149 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 2])] | Probabilities: [0.5621765 0.4378235]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3318, 'bonus': 0.017360483211470365, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32381, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0587145828387956
Updated goal-option-3 on 108 transitions
Took 0.0036313533782958984s to update distance table with 109 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 278 Step: 32489
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4378235 0.5621765]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32489, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4275, 'bonus': 0.015294382258037451, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27831, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6961466736773141
Updated goal-option-2 on 25 transitions
Took 0.0008487701416015625s to update distance table with 26 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 1 transitions
Rolling out goal-option-3, from [6 2] targeting {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4808980491714203
Updated goal-option-3 on 230 transitions
Took 0.01021122932434082s to update distance table with 232 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 279 Step: 32745
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4378235 0.5621765]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32745, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3167, 'bonus': 0.017769531118903073, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24780, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7861009369034133
Updated goal-option-1 on 189 transitions
Took 0.006554126739501953s to update distance table with 190 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
[Episode=280 Seed=18] Took 0.06182551383972168s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 280 Step: 32934
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4443, 'bonus': 0.015002438094301584, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7685324970976647
Updated goal-option-2 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 281 Step: 33190
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33190, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3290, 'bonus': 0.017434201093860166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5809444874402299
Updated goal-option-1 on 54 transitions
Deleting edge from goal-option-1 to goal-option-3
[RND Rollout] Reward: 2.0	IntrinsicReward: -303.52125497197267
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 282 Step: 33244
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2933, 'bonus': 0.018464772811525407, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22123, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6557447417424275
Updated goal-option-1 on 33 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -368.6644077450037
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 283 Step: 33277
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3084, 'bonus': 0.018007060151640494, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6408947641998847
Updated goal-option-1 on 172 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 284 Step: 33449
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -363.47107557952404
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 285 Step: 33449
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33449, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4443, 'bonus': 0.015002438094301584, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8237351040145765
Updated goal-option-2 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 286 Step: 33705
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33705, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4365, 'bonus': 0.015135886972883327, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29720, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6852021740873654
Updated goal-option-2 on 206 transitions
[RND Rollout] Reward: 2.0	IntrinsicReward: -317.8074557916261
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 287 Step: 33911
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -313.2508783059602
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 288 Step: 33911
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -346.42552042240277
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 289 Step: 33911
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 3.0	IntrinsicReward: -328.5222972946358
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 290 Step: 33911
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3126, 'bonus': 0.017885682339724072, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6274731066741784
Updated goal-option-1 on 100 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 291 Step: 34011
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3339, 'bonus': 0.01730580438837217, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6277735314642389
Updated goal-option-1 on 189 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 292 Step: 34200
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3117, 'bonus': 0.017911485212971263, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23364, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6077662822579651
Updated goal-option-1 on 133 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 293 Step: 34333
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34333, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3221, 'bonus': 0.017619948616780765, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.5848049014606816
Updated goal-option-1 on 199 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 294 Step: 34532
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3325, 'bonus': 0.0173421993904824, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8792114231923613
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 295 Step: 34788
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 34788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3290, 'bonus': 0.017434201093860166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9228569640965757
Updated goal-option-1 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 296 Step: 35044
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35044, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 2999, 'bonus': 0.018260462247539938, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 22484, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7843543966849169
Updated goal-option-1 on 15 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -356.82774368673563
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 297 Step: 35059
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -334.962452277774
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 298 Step: 35059
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -380.94920120574534
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 299 Step: 35059
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -299.12433065567166
Took 19.56768012046814s to update distance table with 13156 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=300 Seed=18] Took 0.10613155364990234s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 300 Step: 35059
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35059, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4427, 'bonus': 0.015029524441056943, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7831774179516344
Updated goal-option-2 on 173 transitions
Took 0.0053598880767822266s to update distance table with 174 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([6 6]) to goal-option-4
Took 0.8422389030456543s to add potential edges.
Deleting edge from SE([3 2]) to goal-option-3
================================================================================
[Consolidation] Episode: 301 Step: 35232
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4378235 0.5621765]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4576, 'bonus': 0.014782809899727065, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6889580939399392
Updated goal-option-2 on 85 transitions
Took 0.002635478973388672s to update distance table with 86 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4894, 'bonus': 0.014294468681971968, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 4722, 'bonus': 0.014552479917500617, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4322666750910382
Updated goal-option-4 on 171 transitions
Took 0.0057408809661865234s to update distance table with 172 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 302 Step: 35488
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
Expanding goal-option-4's pessimistic classifier to include SE([6 2])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4342, 'bonus': 0.015175922164473119, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.785755426129874
Updated goal-option-2 on 256 transitions
Took 0.00870823860168457s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 303 Step: 35744
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4894, 'bonus': 0.014294468681971968, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7265900019978243
Updated goal-option-2 on 123 transitions
True
False
[Planner] Rolling out from {'count': 4915, 'bonus': 0.01426389847107313, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6209, 'bonus': 0.012690804972196431, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9357305994307986
Updated goal-option-4 on 56 transitions
Took 0.005949258804321289s to update distance table with 180 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 304 Step: 35923
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28441, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7989347688853741
Updated goal-option-2 on 123 transitions
Took 0.0042264461517333984s to update distance table with 124 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 305 Step: 36046
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4482, 'bonus': 0.014937023831607362, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9365589404790594
Updated goal-option-2 on 122 transitions
True
False
[Planner] Rolling out from {'count': 4922, 'bonus': 0.014253751903120991, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6188, 'bonus': 0.012712320904523034, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 12582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9221859685520626
Updated goal-option-4 on 134 transitions
Took 0.009076356887817383s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 306 Step: 36302
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36302, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4482, 'bonus': 0.014937023831607362, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6697932400080076
Updated goal-option-2 on 99 transitions
Took 0.0030670166015625s to update distance table with 100 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 307 Step: 36401
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.43536371 0.56463629]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36401, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8814191500064713
Updated goal-option-2 on 243 transitions
Took 0.008450508117675781s to update distance table with 244 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 308 Step: 36644
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4329071 0.5670929]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36644, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3394, 'bonus': 0.01716501079979907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35059, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0122955557568776
Updated goal-option-1 on 141 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.00437164306640625s to update distance table with 142 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Unconnected Events: [SE([1 1]), SE([6 6])] | Probs: [[1.00000000e+00 3.65268832e-21]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3429, 'bonus': 0.017077183985952, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36785, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8074984570997236
Updated goal-option-2 on 15 transitions
True
False
[Planner] Rolling out from {'count': 4930, 'bonus': 0.014242182297397127, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [6 2] targeting {'count': 8109, 'bonus': 0.011104943410879493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.27319887005691
Updated goal-option-3 on 100 transitions
Took 0.004365444183349609s to update distance table with 116 states and events {SE([6 2]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 309 Step: 36900
================================================================================
[BoltzmannClosest] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([6 6])
Planner goal: SE([6 2]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28441, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.850873994965886
Updated goal-option-2 on 125 transitions
Took 0.003953218460083008s to update distance table with 126 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 310 Step: 37025
================================================================================
Candidate events: [SE([6 2]), SE([3 2])] | Probabilities: [0.4329071 0.5670929]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37025, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4576, 'bonus': 0.014782809899727065, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0255820370842645
Updated goal-option-2 on 93 transitions
Took 0.0027740001678466797s to update distance table with 94 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 4947, 'bonus': 0.014217690134308215, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37118, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3, goal-option-1] and chose to execute goal-option-3
Rolling out goal-option-3, from [6 2] targeting {'count': 9928, 'bonus': 0.010036195573796253, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.1294934402669776
Updated goal-option-3 on 93 transitions
Took 0.0032455921173095703s to update distance table with 94 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
Adding edge from goal-option-2 to goal-option-4
Adding edge from SE([6 2]) to goal-option-4
Took 0.8177618980407715s to add potential edges.
================================================================================
[Consolidation] Episode: 311 Step: 37211
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.36087383 0.27825234 0.36087383]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37211, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3126, 'bonus': 0.017885682339724072, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 23490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9065851954326568
Updated goal-option-1 on 256 transitions
Took 0.00847005844116211s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 312 Step: 37467
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.36087383 0.27825234 0.36087383]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37467, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3258, 'bonus': 0.017519611040921222, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30150, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8670284024100434
Updated goal-option-1 on 248 transitions
Took 0.009178638458251953s to update distance table with 249 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 313 Step: 37715
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.36087383 0.27825234 0.36087383]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4482, 'bonus': 0.014937023831607362, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6819581206922137
Updated goal-option-2 on 79 transitions
Took 0.0024085044860839844s to update distance table with 80 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4966, 'bonus': 0.014190465507408673, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9887, 'bonus': 0.010056983391594545, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1294434485228164
Updated goal-option-4 on 69 transitions
Took 0.0025005340576171875s to update distance table with 70 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
================================================================================
[Consolidation] Episode: 314 Step: 37863
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4966, 'bonus': 0.014190465507408673, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7810735948826079
Updated goal-option-2 on 131 transitions
Took 0.004086494445800781s to update distance table with 132 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 315 Step: 37994
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.36087383 0.27825234 0.36087383]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37994, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4446, 'bonus': 0.014997375688861584, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31534, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8109919051688901
Updated goal-option-2 on 83 transitions
Took 0.0028705596923828125s to update distance table with 84 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4977, 'bonus': 0.014174775185418742, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38077, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6198, 'bonus': 0.01270206158487549, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9386408231088094
Updated goal-option-4 on 173 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.00606083869934082s to update distance table with 174 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 316 Step: 38250
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38250, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4482, 'bonus': 0.014937023831607362, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8336387423433709
Updated goal-option-2 on 256 transitions
Took 0.00845789909362793s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 317 Step: 38506
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38506, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3394, 'bonus': 0.01716501079979907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35059, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6680012525726552
Updated goal-option-1 on 81 transitions
Took 0.0028624534606933594s to update distance table with 82 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35986747 0.35986747 0.28026507]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3458, 'bonus': 0.017005425596285893, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 9618, 'bonus': 0.01019665237674815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17220, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
5.860123000542323
Updated goal-option-3 on 61 transitions
Took 0.002068042755126953s to update distance table with 62 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 12681, 'bonus': 0.008880210257451365, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38648, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3339, 'bonus': 0.01730580438837217, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7657276507786343
Updated goal-option-1 on 114 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.003617525100708008s to update distance table with 115 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 318 Step: 38762
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38762, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4445, 'bonus': 0.01499906258788147, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7510266242540471
Updated goal-option-2 on 16 transitions
Took 0.0006282329559326172s to update distance table with 17 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5009, 'bonus': 0.01412942485863086, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6204, 'bonus': 0.01269591790297564, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 18311, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.37097361739035
Updated goal-option-4 on 65 transitions
Took 0.0023767948150634766s to update distance table with 66 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 319 Step: 38843
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38843, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4966, 'bonus': 0.014190465507408673, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7000990299383799
Updated goal-option-2 on 166 transitions
Took 0.005319118499755859s to update distance table with 167 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 320 Step: 39009
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39009, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3290, 'bonus': 0.017434201093860166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.978948295649611
Updated goal-option-1 on 85 transitions
Took 0.0031163692474365234s to update distance table with 86 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([6 6]) to goal-option-4
Took 0.9702744483947754s to add potential edges.
================================================================================
[Consolidation] Episode: 321 Step: 39094
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3256, 'bonus': 0.01752499093081954, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29678, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7325864141520936
Updated goal-option-1 on 35 transitions
Took 0.001026153564453125s to update distance table with 36 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 322 Step: 39129
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39129, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4966, 'bonus': 0.014190465507408673, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6049164738670915
Updated goal-option-2 on 107 transitions
Took 0.0036449432373046875s to update distance table with 108 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 24 transitions
Rolling out goal-option-3, from [5 2] targeting {'count': 9335, 'bonus': 0.010350059318947459, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3066727675688576
Updated goal-option-3 on 125 transitions
Took 0.005819559097290039s to update distance table with 150 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 323 Step: 39385
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39385, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9743207200315961
Updated goal-option-2 on 60 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13637, 'bonus': 0.008563288578040994, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5819870843190582
Updated goal-option-4 on 196 transitions
Took 0.008513689041137695s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 324 Step: 39641
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39641, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3167, 'bonus': 0.017769531118903073, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 24780, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7844867130120594
Updated goal-option-1 on 256 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.00833892822265625s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 325 Step: 39897
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39897, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3221, 'bonus': 0.017619948616780765, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 27828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0606729782582647
Updated goal-option-1 on 30 transitions
Took 0.0008165836334228516s to update distance table with 31 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3467, 'bonus': 0.01698333902511166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 9896, 'bonus': 0.010052409147490613, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29853, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8946061034997304
Updated goal-option-4 on 226 transitions
Took 0.00775146484375s to update distance table with 227 states and events {SE([6 2]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 326 Step: 40153
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40153, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [1 1] targeting {'count': 9887, 'bonus': 0.010056983391594545, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 26864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7667519605004944
Updated goal-option-4 on 256 transitions
Took 0.009656429290771484s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 327 Step: 40409
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40409, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3318, 'bonus': 0.017360483211470365, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32381, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6704644638475573
Updated goal-option-1 on 20 transitions
Took 0.0007641315460205078s to update distance table with 21 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3478, 'bonus': 0.016956460837017517, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40429, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4930, 'bonus': 0.014242182297397127, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8202833787496085
Updated goal-option-2 on 103 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6212, 'bonus': 0.012687740177229897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9777975349854199
Updated goal-option-4 on 103 transitions
Took 0.008338451385498047s to update distance table with 207 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 328 Step: 40635
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40635, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3339, 'bonus': 0.01730580438837217, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33277, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6492327434334816
Updated goal-option-1 on 129 transitions
Took 0.004132986068725586s to update distance table with 130 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 329 Step: 40764
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3222, 'bonus': 0.01761721408605633, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28027, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8334848571946655
Updated goal-option-1 on 38 transitions
Took 0.0010805130004882812s to update distance table with 39 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.55971365 0.44028635]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3484, 'bonus': 0.01694185368929243, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40802, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4922, 'bonus': 0.014253751903120991, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.765902037894915
Updated goal-option-2 on 72 transitions
Took 0.0024318695068359375s to update distance table with 73 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 330 Step: 40874
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40874, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3318, 'bonus': 0.017360483211470365, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32381, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7942590512670912
Updated goal-option-1 on 18 transitions
Took 0.0005140304565429688s to update distance table with 19 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.55971365 0.44028635]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3485, 'bonus': 0.016939422832878557, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4894, 'bonus': 0.014294468681971968, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6977463335395712
Updated goal-option-2 on 238 transitions
Took 0.008659839630126953s to update distance table with 239 states and events {None, SE([3 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-3
Took 0.8908791542053223s to add potential edges.
================================================================================
[Consolidation] Episode: 331 Step: 41130
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35885667 0.28228666 0.35885667]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41130, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4445, 'bonus': 0.01499906258788147, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6873505210392495
Updated goal-option-2 on 256 transitions
Took 0.010906696319580078s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 332 Step: 41386
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4425, 'bonus': 0.015032920560056576, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30566, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8088021253125143
Updated goal-option-2 on 256 transitions
Took 0.011154651641845703s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 333 Step: 41642
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35986747 0.28026507 0.35986747]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41642, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3325, 'bonus': 0.0173421993904824, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7827826991784104
Updated goal-option-1 on 67 transitions
Took 0.002022266387939453s to update distance table with 68 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35986747 0.35986747 0.28026507]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3519, 'bonus': 0.016857391247472455, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41709, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Reverting to the DSC policy over options targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 4 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 11429, 'bonus': 0.009353968081677544, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.652557967218963
Updated goal-option-3 on 68 transitions
Took 0.0024356842041015625s to update distance table with 73 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41273925 0.32144165 0.26581911]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 13175, 'bonus': 0.008712136837380643, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3478, 'bonus': 0.016956460837017517, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40429, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7515323889170978
Updated goal-option-1 on 117 transitions
Took 0.0038390159606933594s to update distance table with 118 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 334 Step: 41898
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41163954 0.3205852  0.26777526]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5039, 'bonus': 0.014087301864593216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.74029256149854
Updated goal-option-2 on 256 transitions
Took 0.010625600814819336s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 335 Step: 42154
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41163954 0.3205852  0.26777526]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3458, 'bonus': 0.017005425596285893, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8666668284357639
Updated goal-option-1 on 72 transitions
Took 0.0022776126861572266s to update distance table with 73 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 336 Step: 42226
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41273925 0.32144165 0.26581911]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42226, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5009, 'bonus': 0.01412942485863086, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1830915672343478
Updated goal-option-2 on 86 transitions
Took 0.0026051998138427734s to update distance table with 87 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 40 transitions
Rolling out goal-option-3, from [5 1] targeting {'count': 13175, 'bonus': 0.008712136837380643, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.100015597993677
Updated goal-option-3 on 130 transitions
Took 0.006633281707763672s to update distance table with 171 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 337 Step: 42482
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41141017 0.3236267  0.26496313]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42482, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3181, 'bonus': 0.017730384976049764, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25358, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7932063631622371
Updated goal-option-1 on 256 transitions
Took 0.009151697158813477s to update distance table with 257 states and events {SE([1 1]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 338 Step: 42738
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41141017 0.3236267  0.26496313]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42738, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4445, 'bonus': 0.01499906258788147, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9325956012203486
Updated goal-option-2 on 73 transitions
Took 0.002328157424926758s to update distance table with 74 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9894, 'bonus': 0.010053425106778415, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29528, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.93581066566209
Updated goal-option-4 on 183 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.006538867950439453s to update distance table with 184 states and events {None, SE([6 2])}
================================================================================
[Consolidation] Episode: 339 Step: 42994
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41007639 0.32581947 0.26410413]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42994, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5039, 'bonus': 0.014087301864593216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9344899559562857
Updated goal-option-2 on 50 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6205, 'bonus': 0.012694894822438666, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3094420924844075
Updated goal-option-4 on 122 transitions
Took 0.006562232971191406s to update distance table with 173 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 340 Step: 43166
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41007639 0.32581947 0.26410413]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43166, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4445, 'bonus': 0.01499906258788147, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31483, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8363254490853008
Updated goal-option-2 on 61 transitions
Took 0.0021462440490722656s to update distance table with 62 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
Took 0.6972658634185791s to add potential edges.
================================================================================
[Consolidation] Episode: 341 Step: 43227
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41141017 0.3236267  0.26496313]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3485, 'bonus': 0.016939422832878557, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40892, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6757387596379192
Updated goal-option-1 on 8 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.0003147125244140625s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.55971365 0.44028635]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3541, 'bonus': 0.016804942724441503, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43235, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 4576, 'bonus': 0.014782809899727065, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 33911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7290654265758943
Updated goal-option-2 on 34 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6205, 'bonus': 0.012694894822438666, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 19496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.949314362073998
Updated goal-option-4 on 55 transitions
Took 0.003152132034301758s to update distance table with 90 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 342 Step: 43324
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41249769 0.32448217 0.26302014]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5128, 'bonus': 0.013964519336948639, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7431200740710605
Updated goal-option-2 on 256 transitions
Took 0.007990598678588867s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 343 Step: 43580
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41249769 0.32448217 0.26302014]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43580, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5128, 'bonus': 0.013964519336948639, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.719155695770056
Updated goal-option-2 on 49 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6198, 'bonus': 0.01270206158487549, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.888778990390254
Updated goal-option-4 on 85 transitions
Took 0.0048732757568359375s to update distance table with 135 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 344 Step: 43714
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41249769 0.32448217 0.26302014]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43714, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3394, 'bonus': 0.01716501079979907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 35059, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7775655197356032
Updated goal-option-1 on 49 transitions
Took 0.0014214515686035156s to update distance table with 50 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.55971365 0.44028635]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3550, 'bonus': 0.01678362716593378, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43763, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5056, 'bonus': 0.0140635987615753, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6047239460211287
Updated goal-option-2 on 4 transitions
Took 0.00022983551025390625s to update distance table with 5 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 38 transitions
Rolling out goal-option-3, from [5 3] targeting {'count': 8109, 'bonus': 0.011104943410879493, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 9492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3088459606059113
Updated goal-option-3 on 45 transitions
Took 0.003258943557739258s to update distance table with 84 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 345 Step: 43850
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41223221 0.32753234 0.26023545]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43850, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3541, 'bonus': 0.016804942724441503, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43235, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8077453743039129
Updated goal-option-1 on 40 transitions
Took 0.0012416839599609375s to update distance table with 41 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.55724785 0.44275215]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43890, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 13646, 'bonus': 0.008560464222592578, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38843, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2698187064523845
Updated goal-option-4 on 68 transitions
Took 0.0024547576904296875s to update distance table with 69 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 346 Step: 43958
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41330241 0.32838265 0.25831494]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 32145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9432831948002179
Updated goal-option-2 on 142 transitions
Took 0.0046803951263427734s to update distance table with 143 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 347 Step: 44100
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41330241 0.32838265 0.25831494]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3290, 'bonus': 0.017434201093860166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8137455283581806
Updated goal-option-1 on 130 transitions
Took 0.0043370723724365234s to update distance table with 131 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35784147 0.35784147 0.28431707]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44230, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 9928, 'bonus': 0.010036195573796253, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.031202753556186
Updated goal-option-3 on 77 transitions
Took 0.0026140213012695312s to update distance table with 78 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41436745 0.32922886 0.25640369]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 13472, 'bonus': 0.00861556895994472, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3222, 'bonus': 0.01761721408605633, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 28027, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7427646762072132
Updated goal-option-1 on 38 transitions
Took 0.0011363029479980469s to update distance table with 39 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35784147 0.35784147 0.28431707]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3557, 'bonus': 0.016767104359008654, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 13472, 'bonus': 0.00861556895994472, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.5071674431192466
Updated goal-option-3 on 7 transitions
Took 0.0003383159637451172s to update distance table with 8 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41542731 0.33007096 0.25450173]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 13484, 'bonus': 0.008611734421236894, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44352, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5039, 'bonus': 0.014087301864593216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7482490570346515
Updated goal-option-2 on 4 transitions
Took 0.0001475811004638672s to update distance table with 5 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 348 Step: 44356
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41542731 0.33007096 0.25450173]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44356, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5235, 'bonus': 0.013821069695442011, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6969294596916784
Updated goal-option-2 on 193 transitions
Took 0.006638050079345703s to update distance table with 194 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 8 transitions
Rolling out goal-option-3, from [5 3] targeting {'count': 9928, 'bonus': 0.010036195573796253, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.768509547577964
Updated goal-option-3 on 37 transitions
Took 0.0017881393432617188s to update distance table with 46 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 349 Step: 44594
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.41542731 0.33007096 0.25450173]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44594, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5056, 'bonus': 0.0140635987615753, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9341334814453628
Updated goal-option-2 on 30 transitions
Took 0.0011379718780517578s to update distance table with 31 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5281, 'bonus': 0.013760744025013568, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6212, 'bonus': 0.012687740177229897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 21480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0723432353274387
Updated goal-option-4 on 168 transitions
Took 0.005953073501586914s to update distance table with 169 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
DSG successfully reached SE([6 6])
[Episode=350 Seed=18] Took 0.041942596435546875s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 350 Step: 44792
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3519, 'bonus': 0.016857391247472455, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41709, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8734763520283731
Updated goal-option-1 on 19 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 351 Step: 44811
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3478, 'bonus': 0.016956460837017517, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40429, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6721554340130119
Updated goal-option-1 on 246 transitions
[RND Rollout] Reward: 0.0	IntrinsicReward: -297.9412079084432
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 352 Step: 45057
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45057, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5277, 'bonus': 0.013765958403383741, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44549, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8246819233409376
Updated goal-option-2 on 31 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 353 Step: 45088
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45088, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5277, 'bonus': 0.013765958403383741, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44549, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8936579595204273
Updated goal-option-2 on 256 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 354 Step: 45344
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6453233027272652
Updated goal-option-2 on 46 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -320.7444317517802
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 355 Step: 45390
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -387.3210453968495
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 356 Step: 45390
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -322.16942469216883
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 357 Step: 45390
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3484, 'bonus': 0.01694185368929243, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40802, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6386349652191102
Updated goal-option-1 on 169 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -260.01121554500423
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 358 Step: 45559
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -370.9567671956029
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 359 Step: 45559
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43890, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6760289158267097
Updated goal-option-1 on 164 transitions
Deleting edge from SE([3 2]) to goal-option-1
[RND Rollout] Reward: 2.0	IntrinsicReward: -271.30210380374047
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 360 Step: 45723
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3618, 'bonus': 0.01662515560179388, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7834170362090364
Updated goal-option-1 on 80 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -316.196548926644
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 361 Step: 45803
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4930, 'bonus': 0.014242182297397127, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8456744465459954
Updated goal-option-2 on 11 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -342.2693861317821
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 362 Step: 45814
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 4966, 'bonus': 0.014190465507408673, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37794, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7456355400412239
Updated goal-option-2 on 84 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13646, 'bonus': 0.008560464222592578, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38843, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3750269594933657
Updated goal-option-4 on 69 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 363 Step: 45967
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45967, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3557, 'bonus': 0.016767104359008654, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7594507434751995
Updated goal-option-1 on 159 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -374.22692826623097
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 364 Step: 46126
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -245.23842175712343
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 365 Step: 46126
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3429, 'bonus': 0.017077183985952, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36785, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.663281459566266
Updated goal-option-1 on 6 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -355.1917567048222
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 366 Step: 46132
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5056, 'bonus': 0.0140635987615753, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7324995541944177
Updated goal-option-2 on 23 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 6209, 'bonus': 0.012690804972196431, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0566371969687633
Updated goal-option-4 on 222 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 367 Step: 46377
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46377, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3618, 'bonus': 0.01662515560179388, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6431667792240394
Updated goal-option-1 on 20 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -369.4697154350579
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 368 Step: 46397
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3484, 'bonus': 0.01694185368929243, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40802, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6980498710121864
Updated goal-option-1 on 35 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -342.08130022650585
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 369 Step: 46432
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3557, 'bonus': 0.016767104359008654, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5855003574774379
Updated goal-option-1 on 68 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -350.6831521485001
Took 35.90720009803772s to update distance table with 16743 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
[Episode=370 Seed=18] Took 0.09115076065063477s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 370 Step: 46500
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40548721 0.32541111 0.26910169]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3684, 'bonus': 0.01647556015797342, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6830146657569068
Updated goal-option-1 on 12 transitions
Took 0.0003135204315185547s to update distance table with 13 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([3 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([3 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 5 transitions
Rolling out goal-option-3, from [5 2] targeting {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9172010127041073
Updated goal-option-3 on 12 transitions
Took 0.0007157325744628906s to update distance table with 18 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40439352 0.3245334  0.27107308]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 14065, 'bonus': 0.00843199095011761, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46529, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3665, 'bonus': 0.016518211042472374, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6311360604053585
Updated goal-option-1 on 58 transitions
Took 0.0017788410186767578s to update distance table with 59 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([6 6]) to goal-option-4
Took 0.8214893341064453s to add potential edges.
================================================================================
[Consolidation] Episode: 371 Step: 46587
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40439352 0.3245334  0.27107308]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5398, 'bonus': 0.013610797100201476, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.779259148628319
Updated goal-option-2 on 50 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13657, 'bonus': 0.008557016024768865, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43714, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5961513943355996
Updated goal-option-4 on 206 transitions
Took 0.009738445281982422s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 372 Step: 46843
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40439352 0.3245334  0.27107308]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46843, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3579, 'bonus': 0.016715491490523635, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45057, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7987773317913964
Updated goal-option-1 on 20 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.0007007122039794922s to update distance table with 21 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3833, 'bonus': 0.01615215934480992, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5039, 'bonus': 0.014087301864593216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7332788776919132
Updated goal-option-2 on 27 transitions
True
False
[Planner] Rolling out from {'count': 5618, 'bonus': 0.013341637380878256, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46890, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [6 2] targeting {'count': 9335, 'bonus': 0.010350059318947459, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.057078963307483
Updated goal-option-3 on 86 transitions
Took 0.003800630569458008s to update distance table with 114 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 373 Step: 46976
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40329481 0.32365167 0.27305352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46976, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5206, 'bonus': 0.013859511338876255, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43044, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6932333318614119
Updated goal-option-2 on 43 transitions
Took 0.001468658447265625s to update distance table with 44 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 374 Step: 47019
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40329481 0.32365167 0.27305352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5281, 'bonus': 0.013760744025013568, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7537382576012551
Updated goal-option-2 on 23 transitions
Took 0.0007925033569335938s to update distance table with 24 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 39 transitions
Rolling out goal-option-3, from [4 1] targeting {'count': 13472, 'bonus': 0.00861556895994472, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.746989171351156
Updated goal-option-3 on 5 transitions
Took 0.0017642974853515625s to update distance table with 45 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40329481 0.32365167 0.27305352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 14083, 'bonus': 0.00842660060836907, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47086, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5039, 'bonus': 0.014087301864593216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 39236, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6599169637234706
Updated goal-option-2 on 19 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9899, 'bonus': 0.010050885785905706, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31204, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9783702730498417
Updated goal-option-4 on 37 transitions
Took 0.0020067691802978516s to update distance table with 57 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 375 Step: 47142
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40329481 0.32365167 0.27305352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5009, 'bonus': 0.01412942485863086, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.714165818216956
Updated goal-option-2 on 33 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13657, 'bonus': 0.008557016024768865, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43714, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0702263150654785
Updated goal-option-4 on 14 transitions
Took 0.0016243457794189453s to update distance table with 48 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 376 Step: 47189
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40329481 0.32365167 0.27305352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5222, 'bonus': 0.013838262554683773, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43269, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.654525316510331
Updated goal-option-2 on 110 transitions
Took 0.003887176513671875s to update distance table with 111 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 377 Step: 47299
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40459777 0.32146653 0.2739357 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47299, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5398, 'bonus': 0.013610797100201476, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6510339616399716
Updated goal-option-2 on 79 transitions
Took 0.002179384231567383s to update distance table with 80 states and events {SE([1 1]), SE([6 6]), None}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 378 Step: 47378
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40459777 0.32146653 0.2739357 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47378, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7155526122929138
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9896, 'bonus': 0.010052409147490613, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29853, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9546076088620906
Updated goal-option-4 on 7 transitions
Took 0.0007033348083496094s to update distance table with 23 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 379 Step: 47400
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40459777 0.32146653 0.2739357 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3744, 'bonus': 0.016343011261515335, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5967317561958438
Updated goal-option-1 on 135 transitions
Took 0.004525423049926758s to update distance table with 136 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35784147 0.35784147 0.28431707]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3836, 'bonus': 0.016145842093015665, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47535, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5281, 'bonus': 0.013760744025013568, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7751088801909377
Updated goal-option-2 on 21 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13659, 'bonus': 0.008556389527273807, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9125241347485118
Updated goal-option-4 on 59 transitions
Took 0.0027184486389160156s to update distance table with 81 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 380 Step: 47615
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40348693 0.32058393 0.27592914]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47615, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5620, 'bonus': 0.013339263212805203, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7015096869085987
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13646, 'bonus': 0.008560464222592578, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38843, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4971833101048093
Updated goal-option-4 on 27 transitions
Took 0.0013446807861328125s to update distance table with 42 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Took 0.869746208190918s to add potential edges.
================================================================================
[Consolidation] Episode: 381 Step: 47656
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40348693 0.32058393 0.27592914]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47656, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5398, 'bonus': 0.013610797100201476, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7072650608150105
Updated goal-option-2 on 26 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9896, 'bonus': 0.010052409147490613, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 29853, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0350493392379014
Updated goal-option-4 on 5 transitions
Took 0.0008325576782226562s to update distance table with 32 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 382 Step: 47687
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40348693 0.32058393 0.27592914]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47687, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5235, 'bonus': 0.013821069695442011, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5970588422429285
Updated goal-option-2 on 37 transitions
Took 0.0009133815765380859s to update distance table with 38 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5644, 'bonus': 0.013310871701625052, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9899, 'bonus': 0.010050885785905706, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31204, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1529293674411194
Updated goal-option-4 on 64 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.0021691322326660156s to update distance table with 65 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 383 Step: 47788
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.4021911  0.32276592 0.27504298]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5641, 'bonus': 0.01331441072903769, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8375789095739741
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 9901, 'bonus': 0.010049870596186849, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31721, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0411132978399593
Updated goal-option-4 on 41 transitions
Took 0.001760244369506836s to update distance table with 53 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 384 Step: 47840
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.4021911  0.32276592 0.27504298]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5641, 'bonus': 0.01331441072903769, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7485068602092338
Updated goal-option-2 on 195 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18495, 'bonus': 0.007353139955648427, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8592691795759074
Updated goal-option-4 on 13 transitions
Took 0.00717473030090332s to update distance table with 209 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 385 Step: 48048
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.4021911  0.32276592 0.27504298]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48048, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5419, 'bonus': 0.013584398854238598, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6596212109291192
Updated goal-option-2 on 8 transitions
Took 0.0003151893615722656s to update distance table with 9 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 14 transitions
True
False
[Planner] Rolling out from {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (2, 2), 'player_x': 2, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 13472, 'bonus': 0.00861556895994472, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5056354124394673
Updated goal-option-3 on 58 transitions
Took 0.002441883087158203s to update distance table with 73 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.4021911  0.32276592 0.27504298]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 14161, 'bonus': 0.008403361344537815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3484, 'bonus': 0.01694185368929243, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40802, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5940434866326619
Updated goal-option-1 on 12 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5314, 'bonus': 0.01371795029627971, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45390, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7623770964095451
Updated goal-option-2 on 51 transitions
Took 0.002122163772583008s to update distance table with 64 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.37259748 0.37259748 0.25480504]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5661, 'bonus': 0.013290870380481665, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48191, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13644, 'bonus': 0.008561091615625236, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2377048100378647
Updated goal-option-4 on 12 transitions
Took 0.0004527568817138672s to update distance table with 13 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 386 Step: 48203
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.40089067 0.32495566 0.27415366]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48203, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5277, 'bonus': 0.013765958403383741, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44549, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.891658803114105
Updated goal-option-2 on 14 transitions
Took 0.0004901885986328125s to update distance table with 15 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5663, 'bonus': 0.013288523206886237, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48217, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13656, 'bonus': 0.008557329325126855, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 43324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9904909924744002
Updated goal-option-4 on 20 transitions
Took 0.000720977783203125s to update distance table with 21 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 387 Step: 48237
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39958568 0.32715309 0.27326123]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48237, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5628, 'bonus': 0.013329779199368197, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47393, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.713549332272622
Updated goal-option-2 on 256 transitions
Took 0.008094072341918945s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 388 Step: 48493
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39958568 0.32715309 0.27326123]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48493, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3744, 'bonus': 0.016343011261515335, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5850231122271515
Updated goal-option-1 on 125 transitions
Took 0.004163503646850586s to update distance table with 126 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35476961 0.35476961 0.29046079]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3848, 'bonus': 0.016120647005479025, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5398, 'bonus': 0.013610797100201476, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7188851846293325
Updated goal-option-2 on 39 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 13646, 'bonus': 0.008560464222592578, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 38843, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8075615011788662
Updated goal-option-4 on 4 transitions
Took 0.0014638900756835938s to update distance table with 44 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 389 Step: 48661
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3984913  0.32625708 0.27525162]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48661, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3787, 'bonus': 0.016249961914196396, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6064261253665669
Updated goal-option-1 on 41 transitions
Took 0.0013668537139892578s to update distance table with 42 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35476961 0.35476961 0.29046079]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3849, 'bonus': 0.016118552734992048, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48702, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5663, 'bonus': 0.013288523206886237, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48217, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7160764939533116
Updated goal-option-2 on 35 transitions
Took 0.0012505054473876953s to update distance table with 36 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 37 transitions
Creating goal-option-3-0-0 with parent goal-option-3-0
Creating classifier of type cnn
Created model-free option goal-option-3-0-0 with option_idx=7
Case 1: Adding edge from goal-option-3-0 to goal-option-3
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from goal-option-3-0 to goal-option-2
Adding edge from goal-option-3-0 to goal-option-3
True
False
[Planner] Rolling out from {'count': 3854, 'bonus': 0.01610809361200701, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48774, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14083, 'bonus': 0.00842660060836907, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47086, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9083822366518852
Updated goal-option-3 on 143 transitions
Took 0.00618433952331543s to update distance table with 181 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 390 Step: 48917
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39499974 0.32664864 0.27835161]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5664, 'bonus': 0.013287350086318348, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48657, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6906488771573392
Updated goal-option-2 on 60 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18492, 'bonus': 0.007353736389924108, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47189, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.974513459959432
Updated goal-option-4 on 17 transitions
Took 0.0023584365844726562s to update distance table with 78 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([1 1]) to goal-option-2
Adding edge from SE([6 6]) to goal-option-4
Took 0.9751660823822021s to add potential edges.
================================================================================
[Consolidation] Episode: 391 Step: 48994
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39499974 0.32664864 0.27835161]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48994, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5643, 'bonus': 0.013312051063847861, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47682, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6137944838674948
Updated goal-option-2 on 9 transitions
Deleting edge from SE([1 1]) to goal-option-2
Took 0.00031065940856933594s to update distance table with 10 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.3697284 0.3697284 0.2605432]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5684, 'bonus': 0.013263952726932276, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49003, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18505, 'bonus': 0.00735115288901151, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48994, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.114413434209732
Updated goal-option-4 on 29 transitions
Took 0.0010826587677001953s to update distance table with 30 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 392 Step: 49032
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39499974 0.32664864 0.27835161]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3557, 'bonus': 0.016767104359008654, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7677079043159747
Updated goal-option-1 on 251 transitions
Deleting edge from goal-option-1 to goal-option-3
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.008732318878173828s to update distance table with 252 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35373698 0.35373698 0.29252603]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3862, 'bonus': 0.01609140128253687, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49283, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9673651915330153
Updated goal-option-3 on 5 transitions
Took 0.0002281665802001953s to update distance table with 6 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 393 Step: 49288
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39389782 0.3257374  0.28036478]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5618, 'bonus': 0.013341637380878256, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46890, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7694619109617994
Updated goal-option-2 on 21 transitions
Deleting edge from goal-option-3-0 to goal-option-2
Took 0.0007600784301757812s to update distance table with 22 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36876279 0.36876279 0.26247441]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5696, 'bonus': 0.0132499735000795, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18504, 'bonus': 0.007351351523187181, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48661, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1725618897531278
Updated goal-option-4 on 4 transitions
Took 0.00017213821411132812s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 394 Step: 49313
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39389782 0.3257374  0.28036478]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5664, 'bonus': 0.013287350086318348, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48657, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6896490541857717
Updated goal-option-2 on 62 transitions
Took 0.0020422935485839844s to update distance table with 63 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 395 Step: 49375
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39517865 0.32354491 0.28127644]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3557, 'bonus': 0.016767104359008654, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44345, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6586950042031028
Updated goal-option-1 on 91 transitions
Took 0.0030248165130615234s to update distance table with 92 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35476961 0.35476961 0.29046079]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3863, 'bonus': 0.016089318388051083, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49466, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 8 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 3] targeting {'count': 13472, 'bonus': 0.00861556895994472, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.3663934914033806
Updated goal-option-3 on 78 transitions
Took 0.003063201904296875s to update distance table with 87 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39406468 0.32263287 0.28330245]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 14212, 'bonus': 0.008388269992021519, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5628, 'bonus': 0.013329779199368197, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47393, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6517471934340973
Updated goal-option-2 on 79 transitions
Took 0.003045320510864258s to update distance table with 80 states and events {SE([1 1])}
================================================================================
[Consolidation] Episode: 396 Step: 49631
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3953338  0.32045135 0.28421485]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49631, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3665, 'bonus': 0.016518211042472374, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5996979210111829
Updated goal-option-1 on 56 transitions
Took 0.0016632080078125s to update distance table with 57 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35579791 0.35579791 0.28840418]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3868, 'bonus': 0.016078916034608287, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49687, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5684, 'bonus': 0.013263952726932276, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49003, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6629929888344691
Updated goal-option-2 on 200 transitions
Took 0.006564140319824219s to update distance table with 201 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 397 Step: 49887
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3953338  0.32045135 0.28421485]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49887, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3620, 'bonus': 0.01662056238286334, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5994700041609317
Updated goal-option-1 on 38 transitions
Took 0.0013866424560546875s to update distance table with 39 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35579791 0.35579791 0.28840418]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3869, 'bonus': 0.016076837984062016, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49925, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5620, 'bonus': 0.013339263212805203, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7968892869136738
Updated goal-option-2 on 3 transitions
Took 0.00017261505126953125s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.3668178  0.3668178  0.26636439]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5709, 'bonus': 0.013234879103074857, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 31 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 3] targeting {'count': 7145, 'bonus': 0.01183038514149988, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 3859, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.786309795889688
Updated goal-option-3 on 10 transitions
Took 0.0014078617095947266s to update distance table with 42 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39420778 0.31953862 0.2862536 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 14310, 'bonus': 0.008359497709591985, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49969, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-1, goal-option-2, goal-option-4] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3645, 'bonus': 0.01656346649999844, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5755326863189953
Updated goal-option-1 on 5 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 18501, 'bonus': 0.00735194752233877, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48048, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0194637997755926
Updated goal-option-4 on 56 transitions
Took 0.0020461082458496094s to update distance table with 62 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 398 Step: 50030
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39420778 0.31953862 0.2862536 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50030, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5661, 'bonus': 0.013290870380481665, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48191, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7007710746518468
Updated goal-option-2 on 9 transitions
Took 0.0003147125244140625s to update distance table with 10 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.3668178  0.3668178  0.26636439]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5729, 'bonus': 0.013211757353930011, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 37 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 4] targeting {'count': 9335, 'bonus': 0.010350059318947459, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 15439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8420894822636666
Updated goal-option-3 on 103 transitions
Took 0.005179405212402344s to update distance table with 141 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39420778 0.31953862 0.2862536 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 14313, 'bonus': 0.008358621589722726, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50179, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5628, 'bonus': 0.013329779199368197, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47393, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7601756934345382
Updated goal-option-2 on 43 transitions
Took 0.0014295578002929688s to update distance table with 44 states and events {SE([1 1]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 399 Step: 50222
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39420778 0.31953862 0.2862536 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50222, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5709, 'bonus': 0.013234879103074857, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7076340649259961
Updated goal-option-2 on 39 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18491, 'bonus': 0.007353935233603991, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1717698325713475
Updated goal-option-4 on 5 transitions
Took 0.0010848045349121094s to update distance table with 45 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 400 Step: 50266
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39420778 0.31953862 0.2862536 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50266, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3618, 'bonus': 0.01662515560179388, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7705074061470096
Updated goal-option-1 on 30 transitions
Took 0.0010228157043457031s to update distance table with 31 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35579791 0.35579791 0.28840418]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3882, 'bonus': 0.016049896438377346, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 18 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 3] targeting {'count': 14212, 'bonus': 0.008388269992021519, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.208126141201882
Updated goal-option-3 on 208 transitions
Took 0.007392406463623047s to update distance table with 227 states and events {None, SE([3 2])}
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from goal-option-3-0 to goal-option-2
Adding edge from SE([3 2]) to goal-option-3
Took 1.146056890487671s to add potential edges.
================================================================================
[Consolidation] Episode: 401 Step: 50522
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3919413  0.31770144 0.29035726]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50522, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5628, 'bonus': 0.013329779199368197, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47393, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7585901278926402
Updated goal-option-2 on 224 transitions
Took 0.0069904327392578125s to update distance table with 225 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36485455 0.36485455 0.2702909 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5738, 'bonus': 0.013201392028167044, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50746, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [6 2] targeting {'count': 14310, 'bonus': 0.008359497709591985, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49969, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.5382984443200893
Updated goal-option-3 on 32 transitions
Deleting edge from SE([3 2]) to goal-option-3
Took 0.0011153221130371094s to update distance table with 33 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 402 Step: 50778
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3919413  0.31770144 0.29035726]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5681, 'bonus': 0.013267454452533899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6589444843052471
Updated goal-option-2 on 39 transitions
Deleting edge from goal-option-3-0 to goal-option-2
Took 0.0013184547424316406s to update distance table with 40 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36485455 0.36485455 0.2702909 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5746, 'bonus': 0.013192198857116066, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 18 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 4] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 1793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7402482336318048
Updated goal-option-3 on 17 transitions
Took 0.0011970996856689453s to update distance table with 36 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39069383 0.31987306 0.28943311]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 14379, 'bonus': 0.008339416376359687, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3684, 'bonus': 0.01647556015797342, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6961638602623194
Updated goal-option-1 on 165 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5634, 'bonus': 0.01332267944962386, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47556, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.624176960413319
Updated goal-option-2 on 17 transitions
Took 0.0064105987548828125s to update distance table with 183 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 403 Step: 51034
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.39069383 0.31987306 0.28943311]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5681, 'bonus': 0.013267454452533899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6299409176315274
Updated goal-option-2 on 18 transitions
Took 0.0005600452423095703s to update distance table with 19 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36485455 0.36485455 0.2702909 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 5753, 'bonus': 0.013184170567565755, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51052, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 13 transitions
Got plan [goal-option-3, goal-option-1] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 3] targeting {'count': 11429, 'bonus': 0.009353968081677544, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 30335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.552690022521549
Updated goal-option-3 on 7 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3830, 'bonus': 0.016158484017509977, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46512, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7049815898949879
Updated goal-option-1 on 31 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00180816650390625s to update distance table with 52 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35476961 0.35476961 0.29046079]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3902, 'bonus': 0.016008711108909703, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51103, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5644, 'bonus': 0.013310871701625052, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7625099565725465
Updated goal-option-2 on 78 transitions
Took 0.002649545669555664s to update distance table with 79 states and events {SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 404 Step: 51181
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38956066 0.31894529 0.29149405]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51181, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5665, 'bonus': 0.01328617727638744, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.770635538774988
Updated goal-option-2 on 100 transitions
Took 0.0032858848571777344s to update distance table with 101 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36386612 0.36386612 0.27226776]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 5760, 'bonus': 0.013176156917368247, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51281, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 3849, 'bonus': 0.016118552734992048, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48702, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6506154821125527
Updated goal-option-1 on 57 transitions
Took 0.002185344696044922s to update distance table with 64 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35373698 0.35373698 0.29252603]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3904, 'bonus': 0.016004609991611997, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5641, 'bonus': 0.01331441072903769, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6339683757634917
Updated goal-option-2 on 83 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18497, 'bonus': 0.007352742413412813, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47656, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.142272063771134
Updated goal-option-4 on 7 transitions
Took 0.003108501434326172s to update distance table with 91 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 405 Step: 51434
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38718527 0.3201864  0.29262833]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51434, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5681, 'bonus': 0.013267454452533899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6662987891017207
Updated goal-option-2 on 18 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18499, 'bonus': 0.007352344935648736, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47788, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3434572741857862
Updated goal-option-4 on 4 transitions
Took 0.0007538795471191406s to update distance table with 23 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 406 Step: 51456
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38718527 0.3201864  0.29262833]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51456, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3833, 'bonus': 0.01615215934480992, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5696630959061609
Updated goal-option-1 on 49 transitions
Took 0.0015649795532226562s to update distance table with 50 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35373698 0.35373698 0.29252603]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3906, 'bonus': 0.01600051202457731, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51505, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 7646, 'bonus': 0.011436229264294624, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 7034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.563144896212999
Updated goal-option-3 on 135 transitions
Took 0.004827737808227539s to update distance table with 136 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38604991 0.3192475  0.29470259]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 14507, 'bonus': 0.008302544164800623, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51640, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3845, 'bonus': 0.016126934718260072, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48140, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5511062180497085
Updated goal-option-1 on 26 transitions
Took 0.0009281635284423828s to update distance table with 27 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35373698 0.35373698 0.29252603]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3910, 'bonus': 0.015992325525180033, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5762, 'bonus': 0.013173869985663552, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51427, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6551783370392739
Updated goal-option-2 on 17 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18503, 'bonus': 0.007351550173465498, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48237, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.747976175269241
Updated goal-option-4 on 7 transitions
Took 0.0009114742279052734s to update distance table with 25 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 407 Step: 51690
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38376521 0.31735815 0.29887665]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51690, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3787, 'bonus': 0.016249961914196396, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6590509006223283
Updated goal-option-1 on 67 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5746, 'bonus': 0.013192198857116066, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7360398776450957
Updated goal-option-2 on 4 transitions
Took 0.002333402633666992s to update distance table with 72 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35986747 0.35986747 0.28026507]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5795, 'bonus': 0.013136306707967735, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 9627, 'bonus': 0.010191884986612974, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 17304, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.216993097410216
Updated goal-option-3 on 84 transitions
Took 0.0034356117248535156s to update distance table with 91 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38376521 0.31735815 0.29887665]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 14513, 'bonus': 0.008300827758311938, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51851, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5762, 'bonus': 0.013173869985663552, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51427, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.670598104661494
Updated goal-option-2 on 95 transitions
Took 0.0029435157775878906s to update distance table with 96 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 408 Step: 51946
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38376521 0.31735815 0.29887665]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5661, 'bonus': 0.013290870380481665, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48191, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5924198843467513
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18514, 'bonus': 0.007349365905690683, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51456, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0727937186115712
Updated goal-option-4 on 5 transitions
Took 0.0005593299865722656s to update distance table with 20 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 409 Step: 51965
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38376521 0.31735815 0.29887665]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51965, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3910, 'bonus': 0.015992325525180033, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5529123703191038
Updated goal-option-1 on 15 transitions
Took 0.0005774497985839844s to update distance table with 16 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35373698 0.35373698 0.29252603]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3923, 'bonus': 0.015965805928921335, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 3 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 9928, 'bonus': 0.010036195573796253, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 20367, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9255592263581456
Updated goal-option-3 on 27 transitions
Took 0.001065969467163086s to update distance table with 31 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 410 Step: 52010
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38261592 0.31640773 0.30097634]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52010, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3869, 'bonus': 0.016076837984062016, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49925, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6224481034786143
Updated goal-option-1 on 96 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5664, 'bonus': 0.013287350086318348, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48657, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6469086149514047
Updated goal-option-2 on 17 transitions
Took 0.0037870407104492188s to update distance table with 114 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2])}
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from goal-option-3-0 to goal-option-2
Took 1.1706483364105225s to add potential edges.
================================================================================
[Consolidation] Episode: 411 Step: 52123
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38382432 0.31424878 0.3019269 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52123, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5663, 'bonus': 0.013288523206886237, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48217, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8162097418185296
Updated goal-option-2 on 50 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18509, 'bonus': 0.007350358513291769, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50030, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.07008284460347
Updated goal-option-4 on 8 transitions
Took 0.0018410682678222656s to update distance table with 59 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 412 Step: 52181
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.38382432 0.31424878 0.3019269 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52181, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5665, 'bonus': 0.01328617727638744, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7954141047835609
Updated goal-option-2 on 65 transitions
Took 0.0020532608032226562s to update distance table with 66 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35885667 0.35885667 0.28228666]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 5816, 'bonus': 0.013112569439434401, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 17 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 3906, 'bonus': 0.01600051202457731, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51505, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7732322560134509
Updated goal-option-1 on 8 transitions
Took 0.0009047985076904297s to update distance table with 26 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35373698 0.35373698 0.29252603]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3931, 'bonus': 0.015949551604596525, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5766, 'bonus': 0.013169299692382678, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6882947004610491
Updated goal-option-2 on 166 transitions
Took 0.005568504333496094s to update distance table with 167 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 413 Step: 52437
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30190144 0.35428463 0.34381393]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52437, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5709, 'bonus': 0.013234879103074857, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6642170088906442
Updated goal-option-2 on 17 transitions
Took 0.0005402565002441406s to update distance table with 18 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.39885021 0.28106499 0.32008479]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5824, 'bonus': 0.013103560459023979, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18519, 'bonus': 0.007348373700112362, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52181, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.108433881374163
Updated goal-option-4 on 12 transitions
Took 0.00044155120849609375s to update distance table with 13 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 414 Step: 52466
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30401318 0.35321292 0.3427739 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52466, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3849, 'bonus': 0.016118552734992048, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48702, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4987854770259232
Updated goal-option-1 on 8 transitions
Took 0.0003571510314941406s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.39389782 0.28036478 0.3257374 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 3941, 'bonus': 0.015929303339984276, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52474, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5799, 'bonus': 0.013131775384373805, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7021819076322156
Updated goal-option-2 on 5 transitions
Took 0.00023889541625976562s to update distance table with 6 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.39645497 0.28218488 0.32136015]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 5828, 'bonus': 0.013099062926556151, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52479, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 10 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 14507, 'bonus': 0.008302544164800623, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51640, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6300265334901356
Updated goal-option-3 on 9 transitions
Took 0.0006883144378662109s to update distance table with 20 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30190144 0.35428463 0.34381393]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 14610, 'bonus': 0.008273226074410304, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3869, 'bonus': 0.016076837984062016, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49925, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6933000074657029
Updated goal-option-1 on 31 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.0008344650268554688s to update distance table with 32 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.39261252 0.27944994 0.32793754]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3945, 'bonus': 0.01592122559943443, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52529, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14610, 'bonus': 0.008273226074410304, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.846024785286341
Updated goal-option-3 on 193 transitions
Took 0.0067446231842041016s to update distance table with 194 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 415 Step: 52722
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30190144 0.35428463 0.34381393]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52722, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3849, 'bonus': 0.016118552734992048, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48702, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7435508224007616
Updated goal-option-1 on 15 transitions
Took 0.0005784034729003906s to update distance table with 16 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.39261252 0.27944994 0.32793754]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 3963, 'bonus': 0.015885027237483865, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5696, 'bonus': 0.0132499735000795, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7735497196579081
Updated goal-option-2 on 54 transitions
Deleting edge from goal-option-3-0 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18496, 'bonus': 0.007352941176470588, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47615, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9288011780583565
Updated goal-option-4 on 8 transitions
Took 0.0022020339965820312s to update distance table with 63 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 416 Step: 52799
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30508541 0.35093175 0.34398284]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3902, 'bonus': 0.016008711108909703, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51103, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49920771607669323
Updated goal-option-1 on 52 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5729, 'bonus': 0.013211757353930011, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7277258009864734
Updated goal-option-2 on 4 transitions
Took 0.0017576217651367188s to update distance table with 57 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.39294587 0.28533726 0.32171687]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 5839, 'bonus': 0.013086718550955518, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52855, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 9 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 3863, 'bonus': 0.016089318388051083, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49466, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.525916506244049
Updated goal-option-1 on 2 transitions
Took 0.00042319297790527344s to update distance table with 12 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.38913324 0.28256873 0.32829803]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 3977, 'bonus': 0.01585704302280871, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 56 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 3] targeting {'count': 14161, 'bonus': 0.008403361344537815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48128, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.040103184680144
Updated goal-option-3 on 52 transitions
Took 0.003681182861328125s to update distance table with 109 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30192252 0.35078392 0.34729356]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 14648, 'bonus': 0.008262487859315822, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52974, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5816, 'bonus': 0.013112569439434401, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.622722654281079
Updated goal-option-2 on 24 transitions
Took 0.0007636547088623047s to update distance table with 25 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.39040856 0.2834948  0.32609664]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5844, 'bonus': 0.013081118996315122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18509, 'bonus': 0.007350358513291769, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50030, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9352197589605679
Updated goal-option-4 on 4 transitions
Took 0.00023174285888671875s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 417 Step: 53002
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30403434 0.34972273 0.34624293]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53002, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5735, 'bonus': 0.013204844425565953, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50261, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.67956302667421
Updated goal-option-2 on 154 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18521, 'bonus': 0.007347976930386628, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8819832467462545
Updated goal-option-4 on 7 transitions
Took 0.004945993423461914s to update distance table with 162 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 418 Step: 53163
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30403434 0.34972273 0.34624293]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53163, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5709, 'bonus': 0.013234879103074857, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6862484096286167
Updated goal-option-2 on 52 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18500, 'bonus': 0.007352146220938078, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3983370750958537
Updated goal-option-4 on 4 transitions
Took 0.001596689224243164s to update distance table with 57 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 419 Step: 53219
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3082828  0.34758788 0.34412932]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5845, 'bonus': 0.01307999994768, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7026297323303895
Updated goal-option-2 on 20 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18504, 'bonus': 0.007351351523187181, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48661, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9507900344760412
Updated goal-option-4 on 7 transitions
Took 0.0008502006530761719s to update distance table with 28 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
[Episode=420 Seed=18] Took 0.07766556739807129s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 420 Step: 53246
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3931, 'bonus': 0.015949551604596525, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6160177340420584
Updated goal-option-1 on 33 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -344.68154317792505
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 421 Step: 53279
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53279, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3945, 'bonus': 0.01592122559943443, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52529, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6466223854970474
Updated goal-option-1 on 17 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -347.97519817523926
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 422 Step: 53296
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5760, 'bonus': 0.013176156917368247, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51281, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7106440305367284
Updated goal-option-2 on 57 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -369.6272030547261
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 423 Step: 53353
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -391.7380515271798
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 424 Step: 53353
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5795, 'bonus': 0.013136306707967735, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6813450559275225
Updated goal-option-2 on 206 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 425 Step: 53559
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53559, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5816, 'bonus': 0.013112569439434401, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6596859787623582
Updated goal-option-2 on 71 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -299.5573552195274
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 426 Step: 53630
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 5.0	IntrinsicReward: -380.97848000377417
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 427 Step: 53630
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53630, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3963, 'bonus': 0.015885027237483865, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.607535956938004
Updated goal-option-1 on 31 transitions
[RND Rollout] Reward: 11.0	IntrinsicReward: -332.1063938107691
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 428 Step: 53661
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53661, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3926, 'bonus': 0.015959704735425923, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5127029377859806
Updated goal-option-1 on 34 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5824, 'bonus': 0.013103560459023979, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6401119694744225
Updated goal-option-2 on 21 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -345.6825597230345
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 429 Step: 53716
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53716, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3882, 'bonus': 0.016049896438377346, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5683734130948944
Updated goal-option-1 on 46 transitions
[RND Rollout] Reward: 6.0	IntrinsicReward: -334.39080473966897
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 430 Step: 53762
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 8.0	IntrinsicReward: -363.3657240308821
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 431 Step: 53762
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -301.92767371743685
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 432 Step: 53762
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53762, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3906, 'bonus': 0.01600051202457731, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51505, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6930880787623983
Updated goal-option-1 on 34 transitions
[RND Rollout] Reward: 8.0	IntrinsicReward: -334.1847737636417
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 433 Step: 53796
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3941, 'bonus': 0.015929303339984276, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52474, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4773199505711693
Updated goal-option-1 on 38 transitions
[RND Rollout] Reward: 9.0	IntrinsicReward: -362.85781276086345
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 434 Step: 53834
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -363.27131478967203
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 435 Step: 53834
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3977, 'bonus': 0.01585704302280871, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6727711911264218
Updated goal-option-1 on 27 transitions
[RND Rollout] Reward: 7.0	IntrinsicReward: -311.01063227048144
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 436 Step: 53861
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53861, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3993, 'bonus': 0.015825241450517984, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.5468996496524517
Updated goal-option-1 on 88 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 437 Step: 53949
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53949, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3977, 'bonus': 0.01585704302280871, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46631097501516344
Updated goal-option-1 on 33 transitions
[RND Rollout] Reward: 3.0	IntrinsicReward: -284.22726560221054
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 438 Step: 53982
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -334.1507258452475
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 439 Step: 53982
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3931, 'bonus': 0.015949551604596525, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52271, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7569803600112598
Updated goal-option-1 on 6 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -377.1738028926775
Took 74.25556015968323s to update distance table with 18780 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=440 Seed=18] Took 0.06663656234741211s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 440 Step: 53988
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.29851137 0.3332217  0.36826693]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53988, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3963, 'bonus': 0.015885027237483865, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52737, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5341503198835112
Updated goal-option-1 on 76 transitions
Took 0.0025310516357421875s to update distance table with 77 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.38233267 0.29186492 0.32580241]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4303, 'bonus': 0.015244540097646505, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54064, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 21 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [1 2] targeting {'count': 13472, 'bonus': 0.00861556895994472, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1015315470381528
Updated goal-option-3 on 20 transitions
Took 0.0014274120330810547s to update distance table with 42 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.29741061 0.33199294 0.37059644]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 15350, 'bonus': 0.008071343122712616, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5949, 'bonus': 0.012965164026406899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53716, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6454059479474531
Updated goal-option-2 on 39 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18522, 'bonus': 0.007347778569623423, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53002, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7861912770920209
Updated goal-option-4 on 10 transitions
Took 0.0015845298767089844s to update distance table with 50 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-3-0 to goal-option-1
Took 1.259749174118042s to add potential edges.
================================================================================
[Consolidation] Episode: 441 Step: 54154
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.29950441 0.33100357 0.36949202]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5834, 'bonus': 0.013092325302659108, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52791, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6313771398098041
Updated goal-option-2 on 18 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18507, 'bonus': 0.0073507556689594, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4825364661143825
Updated goal-option-4 on 5 transitions
Took 0.0005991458892822266s to update distance table with 24 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 442 Step: 54177
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30371719 0.32901291 0.3672699 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54177, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5791, 'bonus': 0.013140842725612582, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51683, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.558543976484201
Updated goal-option-2 on 20 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18524, 'bonus': 0.007347381896285503, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0171608772208565
Updated goal-option-4 on 6 transitions
Took 0.0008120536804199219s to update distance table with 27 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 443 Step: 54203
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30583607 0.32801168 0.36615225]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54203, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 3911, 'bonus': 0.015990280862955328, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51757, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6157229737546993
Updated goal-option-1 on 79 transitions
Took 0.002358675003051758s to update distance table with 80 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.37783222 0.3002004  0.32196738]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4313, 'bonus': 0.015226857061770712, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54282, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5816, 'bonus': 0.013112569439434401, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7227578806112973
Updated goal-option-2 on 4 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18507, 'bonus': 0.0073507556689594, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.855970069043564
Updated goal-option-4 on 7 transitions
Took 0.0004584789276123047s to update distance table with 12 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 444 Step: 54293
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30796318 0.32700656 0.36503025]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6522, 'bonus': 0.012382536099092283, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54144, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5925316328529444
Updated goal-option-2 on 28 transitions
Took 0.0006933212280273438s to update distance table with 29 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36314141 0.2914278  0.34543079]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6538, 'bonus': 0.012367375351320617, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54321, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 10 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [4 2] targeting {'count': 4227, 'bonus': 0.015380975347800065, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53861, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.804626084707697
Updated goal-option-1 on 2 transitions
Took 0.0004761219024658203s to update distance table with 13 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.37548436 0.30133326 0.32318238]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4317, 'bonus': 0.015219801057192683, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54333, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 15350, 'bonus': 0.008071343122712616, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.451756782284597
Updated goal-option-3 on 216 transitions
Took 0.007940053939819336s to update distance table with 217 states and events {SE([6 2]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 445 Step: 54549
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30583607 0.32801168 0.36615225]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54549, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5828, 'bonus': 0.013099062926556151, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52479, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7192923872300039
Updated goal-option-2 on 64 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18513, 'bonus': 0.007349564395040393, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51434, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8845610851591283
Updated goal-option-4 on 5 transitions
Took 0.0019440650939941406s to update distance table with 70 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 446 Step: 54618
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30796318 0.32700656 0.36503025]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5850, 'bonus': 0.013074409009212268, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53239, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6940903382009668
Updated goal-option-2 on 112 transitions
Took 0.005362033843994141s to update distance table with 113 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.36083189 0.29248464 0.34668347]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6576, 'bonus': 0.01233159059167475, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 53 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [3 3] targeting {'count': 4158, 'bonus': 0.015508070173307846, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53762, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6562077005997574
Updated goal-option-1 on 2 transitions
Took 0.001903533935546875s to update distance table with 56 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.37435066 0.30344275 0.3222066 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4333, 'bonus': 0.015191674812676982, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54785, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5834, 'bonus': 0.013092325302659108, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52791, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6830390779659002
Updated goal-option-2 on 24 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18525, 'bonus': 0.007347183583706451, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0616459279349355
Updated goal-option-4 on 5 transitions
Took 0.0010073184967041016s to update distance table with 30 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 447 Step: 54814
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30683751 0.32581129 0.3673512 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5871, 'bonus': 0.013051005112921494, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.682963415935456
Updated goal-option-2 on 251 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25692, 'bonus': 0.006238799710505724, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8051745015111836
Updated goal-option-4 on 5 transitions
Took 0.009788274765014648s to update distance table with 257 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 448 Step: 55070
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30683751 0.32581129 0.3673512 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5839, 'bonus': 0.013086718550955518, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52855, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6533840047457371
Updated goal-option-2 on 11 transitions
Took 0.00029730796813964844s to update distance table with 12 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35957903 0.2914691  0.34895187]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6583, 'bonus': 0.012325032480354957, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55081, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 53 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 3] targeting {'count': 15350, 'bonus': 0.008071343122712616, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54105, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4522932409530593
Updated goal-option-3 on 77 transitions
Took 0.004673957824707031s to update distance table with 131 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.30583607 0.32801168 0.36615225]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 15665, 'bonus': 0.007989779618950697, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55211, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-1, goal-option-2] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4224, 'bonus': 0.01538643637241659, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.583927676484986
Updated goal-option-1 on 5 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6574, 'bonus': 0.012333466261408268, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54613, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7058933266973221
Updated goal-option-2 on 3 transitions
Took 0.0003218650817871094s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35957903 0.2914691  0.34895187]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6587, 'bonus': 0.01232128968267365, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Took 0.0002796649932861328s to update distance table with 7 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.37314234 0.3024633  0.32439436]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4353, 'bonus': 0.015156735311928956, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6587, 'bonus': 0.01232128968267365, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7654940488042535
Updated goal-option-2 on 5 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25691, 'bonus': 0.006238921129271085, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7805677392371783
Updated goal-option-4 on 33 transitions
Took 0.001589059829711914s to update distance table with 39 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 449 Step: 55263
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3089685  0.32480965 0.36622186]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55263, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5845, 'bonus': 0.01307999994768, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6391286329851972
Updated goal-option-2 on 17 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18524, 'bonus': 0.007347381896285503, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8854031775678908
Updated goal-option-4 on 5 transitions
Took 0.0007853507995605469s to update distance table with 23 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 450 Step: 55285
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3089685  0.32480965 0.36622186]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4317, 'bonus': 0.015219801057192683, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54333, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5479462003396228
Updated goal-option-1 on 25 transitions
Took 0.0007801055908203125s to update distance table with 26 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.37087622 0.30669948 0.3224243 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4359, 'bonus': 0.015146300381045252, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55310, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 17 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14310, 'bonus': 0.008359497709591985, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49969, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4917065670677259
Updated goal-option-3 on 79 transitions
Took 0.0037038326263427734s to update distance table with 97 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3089685  0.32480965 0.36622186]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 15671, 'bonus': 0.007988249937781768, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6620, 'bonus': 0.012290541152149845, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55280, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6703077752347016
Updated goal-option-2 on 100 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18521, 'bonus': 0.007347976930386628, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7175357648659321
Updated goal-option-4 on 5 transitions
Took 0.0034177303314208984s to update distance table with 106 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-3-0 to goal-option-2
Took 1.2515158653259277s to add potential edges.
================================================================================
[Consolidation] Episode: 451 Step: 55511
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31110763 0.32380418 0.36508819]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 5849, 'bonus': 0.013075526623353663, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53215, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5752805804774638
Updated goal-option-2 on 26 transitions
Took 0.0007560253143310547s to update distance table with 27 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35518063 0.2966718  0.34814758]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6624, 'bonus': 0.012286829679574762, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 4224, 'bonus': 0.01538643637241659, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6735955051152535
Updated goal-option-1 on 6 transitions
Took 0.0005311965942382812s to update distance table with 14 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.36973655 0.30882993 0.32143352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4378, 'bonus': 0.015113398071880555, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6583, 'bonus': 0.012325032480354957, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55081, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7177561967825842
Updated goal-option-2 on 3 transitions
Deleting edge from goal-option-3-0 to goal-option-2
Took 0.0001633167266845703s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35518063 0.2966718  0.34814758]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6627, 'bonus': 0.012284048280630335, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55553, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 13175, 'bonus': 0.008712136837380643, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.97031792721083
Updated goal-option-3 on 9 transitions
Took 0.0005700588226318359s to update distance table with 17 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31009848 0.32599757 0.36390394]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 15717, 'bonus': 0.007976551497926348, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55569, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4313, 'bonus': 0.015226857061770712, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54282, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5009971193406576
Updated goal-option-1 on 15 transitions
Took 0.0005044937133789062s to update distance table with 16 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.36854598 0.30783548 0.32361854]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4380, 'bonus': 0.015109947130387486, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55584, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6534, 'bonus': 0.012371160317086759, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.595266541007847
Updated goal-option-2 on 3 transitions
Took 0.00017523765563964844s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35518063 0.2966718  0.34814758]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6630, 'bonus': 0.012281268769726867, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Got plan [goal-option-3, goal-option-1] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 3] targeting {'count': 14379, 'bonus': 0.008339416376359687, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2066611286780844
Updated goal-option-3 on 34 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4224, 'bonus': 0.01538643637241659, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5331630776442277
Updated goal-option-1 on 9 transitions
Took 0.0016491413116455078s to update distance table with 50 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3673512  0.30683751 0.32581129]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4382, 'bonus': 0.01510649855174383, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55636, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 5876, 'bonus': 0.013045451257138733, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53630, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5851377744582438
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25690, 'bonus': 0.006239042555125833, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54203, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.884262286215311
Updated goal-option-4 on 6 transitions
Took 0.00035452842712402344s to update distance table with 10 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 452 Step: 55645
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3112254  0.32718227 0.36159233]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55645, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4382, 'bonus': 0.01510649855174383, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55636, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5187950130785738
Updated goal-option-1 on 47 transitions
Took 0.0011103153228759766s to update distance table with 48 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.36622186 0.3089685  0.32480965]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4383, 'bonus': 0.015104775147648125, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 8 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 13175, 'bonus': 0.008712136837380643, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.15960153909435
Updated goal-option-3 on 156 transitions
Took 0.005722999572753906s to update distance table with 165 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3112254  0.32718227 0.36159233]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 15765, 'bonus': 0.007964399060478126, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55856, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6579, 'bonus': 0.01232877869092182, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5597373394389534
Updated goal-option-2 on 25 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25697, 'bonus': 0.006238192722995605, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8956855527080951
Updated goal-option-4 on 4 transitions
Deleting edge from SE([6 6]) to goal-option-4
Took 0.0007874965667724609s to update distance table with 30 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 453 Step: 55885
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31337308 0.32616208 0.36046484]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6579, 'bonus': 0.01232877869092182, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5997070401201586
Updated goal-option-2 on 20 transitions
Took 0.00042557716369628906s to update distance table with 21 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35306465 0.30086185 0.3460735 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6636, 'bonus': 0.012275715403505907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55905, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25691, 'bonus': 0.006238921129271085, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54293, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7595142148940611
Updated goal-option-4 on 6 transitions
Took 0.00023984909057617188s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 454 Step: 55911
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3123492  0.32836369 0.35928711]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6534, 'bonus': 0.012371160317086759, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6992601961219792
Updated goal-option-2 on 52 transitions
Took 0.0015439987182617188s to update distance table with 53 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35306465 0.30086185 0.3460735 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6639, 'bonus': 0.012272941543928408, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55963, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 5 transitions
Took 0.0002224445343017578s to update distance table with 6 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.36271557 0.30908582 0.32819862]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4408, 'bonus': 0.01506188082821945, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55968, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6622, 'bonus': 0.012288684995505242, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55506, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.583195209254821
Updated goal-option-2 on 7 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18521, 'bonus': 0.007347976930386628, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.205653772593248
Updated goal-option-4 on 5 transitions
Took 0.00047659873962402344s to update distance table with 13 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 455 Step: 55980
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3123492  0.32836369 0.35928711]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4157, 'bonus': 0.015509935357050633, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53695, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5766532095462007
Updated goal-option-1 on 6 transitions
Took 0.00023603439331054688s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.36159233 0.3112254  0.32718227]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4413, 'bonus': 0.015053345733281098, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55986, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 1 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14610, 'bonus': 0.008273226074410304, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.409686357445187
Updated goal-option-3 on 45 transitions
Took 0.0016260147094726562s to update distance table with 47 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3123492  0.32836369 0.35928711]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 15802, 'bonus': 0.007955069372286065, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6636, 'bonus': 0.012275715403505907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55905, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6657997153459057
Updated goal-option-2 on 28 transitions
Took 0.0008404254913330078s to update distance table with 29 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.35078392 0.30192252 0.34729356]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6644, 'bonus': 0.012268322620297912, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 4378, 'bonus': 0.015113398071880555, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4594143975425411
Updated goal-option-1 on 135 transitions
Took 0.004866123199462891s to update distance table with 143 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.36159233 0.3112254  0.32718227]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4421, 'bonus': 0.015039719710363528, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56202, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6583, 'bonus': 0.012325032480354957, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55081, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6285020647423009
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25693, 'bonus': 0.006238678298829063, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3862922661511947
Updated goal-option-4 on 5 transitions
Took 0.0006237030029296875s to update distance table with 18 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 456 Step: 56219
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3145011  0.32733613 0.35816277]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6632, 'bonus': 0.012279416810315037, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55639, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5528597294645236
Updated goal-option-2 on 27 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25694, 'bonus': 0.00623855689424041, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': True, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0783751649578763
Updated goal-option-4 on 7 transitions
Took 0.0008542537689208984s to update distance table with 35 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 457 Step: 56253
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31666099 0.32630475 0.35703426]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56253, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4380, 'bonus': 0.015109947130387486, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55584, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6916129368132559
Updated goal-option-1 on 53 transitions
Took 0.0018057823181152344s to update distance table with 54 states and events {SE([3 2]), SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35933314 0.31552879 0.32513807]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4425, 'bonus': 0.015032920560056576, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6632, 'bonus': 0.012279416810315037, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55639, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6306070923718096
Updated goal-option-2 on 4 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25690, 'bonus': 0.006239042555125833, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54203, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9066687195252349
Updated goal-option-4 on 8 transitions
Took 0.0004649162292480469s to update distance table with 13 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 458 Step: 56318
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31666099 0.32630475 0.35703426]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56318, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6644, 'bonus': 0.012268322620297912, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6034587851795209
Updated goal-option-2 on 34 transitions
Took 0.0009381771087646484s to update distance table with 35 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34865738 0.30615445 0.34518818]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6668, 'bonus': 0.012246224152725615, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56352, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25700, 'bonus': 0.006237828615518053, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8080900945858649
Updated goal-option-4 on 9 transitions
Took 0.0003330707550048828s to update distance table with 10 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 459 Step: 56361
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31666099 0.32630475 0.35703426]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56361, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4413, 'bonus': 0.015053345733281098, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55986, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5342004798807716
Updated goal-option-1 on 22 transitions
Took 0.0006322860717773438s to update distance table with 23 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35933314 0.31552879 0.32513807]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4428, 'bonus': 0.015027827244457205, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6644, 'bonus': 0.012268322620297912, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.744770878728613
Updated goal-option-2 on 3 transitions
Took 0.0001735687255859375s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34865738 0.30615445 0.34518818]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6674, 'bonus': 0.012240718169313816, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 18524, 'bonus': 0.007347381896285503, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8132051193313292
Updated goal-option-4 on 5 transitions
Took 0.00020694732666015625s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 460 Step: 56391
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31562592 0.32850686 0.35586723]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6630, 'bonus': 0.012281268769726867, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5816115165246282
Updated goal-option-2 on 101 transitions
Took 0.003854990005493164s to update distance table with 102 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34865738 0.30615445 0.34518818]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6676, 'bonus': 0.012238884491201616, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25696, 'bonus': 0.00623831410632437, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8664204164990905
Updated goal-option-4 on 6 transitions
Took 0.00023794174194335938s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([6 6]) to goal-option-4
Adding edge from SE([3 2]) to goal-option-3
Took 1.359572410583496s to add potential edges.
================================================================================
[Consolidation] Episode: 461 Step: 56498
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3167475  0.32967421 0.35357829]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6630, 'bonus': 0.012281268769726867, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55587, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6197523636737935
Updated goal-option-2 on 48 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25706, 'bonus': 0.00623710059179029, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.120476412427598
Updated goal-option-4 on 4 transitions
Took 0.0013043880462646484s to update distance table with 53 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 462 Step: 56550
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3167475  0.32967421 0.35357829]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4425, 'bonus': 0.015032920560056576, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5819346011443295
Updated goal-option-1 on 7 transitions
Took 0.00020241737365722656s to update distance table with 8 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35586723 0.31562592 0.32850686]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4430, 'bonus': 0.015024434575434523, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56557, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 15802, 'bonus': 0.007955069372286065, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.046778660663318
Updated goal-option-3 on 23 transitions
Took 0.0008091926574707031s to update distance table with 24 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3167475  0.32967421 0.35357829]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 15997, 'bonus': 0.007906435413489298, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56580, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6635, 'bonus': 0.01227664044140357, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7036219501615602
Updated goal-option-2 on 9 transitions
Took 0.00032210350036621094s to update distance table with 10 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6680, 'bonus': 0.012235219605809911, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56589, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 25 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [1 2] targeting {'count': 14379, 'bonus': 0.008339416376359687, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9522055388588608
Updated goal-option-3 on 5 transitions
Took 0.0011553764343261719s to update distance table with 31 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3167475  0.32967421 0.35357829]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 16000, 'bonus': 0.007905694150420948, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56619, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6590, 'bonus': 0.012318484821002975, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55230, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5605886256272309
Updated goal-option-2 on 28 transitions
Took 0.0007278919219970703s to update distance table with 29 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6692, 'bonus': 0.012224244671977023, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56647, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 23 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 4333, 'bonus': 0.015191674812676982, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54785, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.491568699384312
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.001088857650756836s to update distance table with 31 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35469618 0.31458729 0.33071653]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4440, 'bonus': 0.015007505629691604, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56677, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [1 2] targeting {'count': 14379, 'bonus': 0.008339416376359687, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0985618461203832
Updated goal-option-3 on 84 transitions
Took 0.0034449100494384766s to update distance table with 97 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 16022, 'bonus': 0.007900264584291466, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56773, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6636, 'bonus': 0.012275715403505907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55905, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.6410508730093866
Updated goal-option-2 on 33 transitions
Took 0.0008873939514160156s to update distance table with 34 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 463 Step: 56806
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31354514 0.33293369 0.35352116]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56806, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6644, 'bonus': 0.012268322620297912, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6678200958736077
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25697, 'bonus': 0.006238192722995605, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6739401152168495
Updated goal-option-4 on 5 transitions
Took 0.0005085468292236328s to update distance table with 20 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 464 Step: 56825
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4227, 'bonus': 0.015380975347800065, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53861, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5872912133564754
Updated goal-option-1 on 10 transitions
Took 0.00022912025451660156s to update distance table with 11 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35469618 0.31458729 0.33071653]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4451, 'bonus': 0.014988949722867606, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56835, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14379, 'bonus': 0.008339416376359687, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1127990813965494
Updated goal-option-3 on 38 transitions
Deleting edge from SE([3 2]) to goal-option-3
Took 0.0013148784637451172s to update distance table with 39 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 16063, 'bonus': 0.007890175628190443, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56873, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6632, 'bonus': 0.012279416810315037, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55639, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6932556696577986
Updated goal-option-2 on 33 transitions
Took 0.0008835792541503906s to update distance table with 34 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6713, 'bonus': 0.012205109395953727, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56906, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 5 transitions
Took 0.00022149085998535156s to update distance table with 6 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35469618 0.31458729 0.33071653]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4454, 'bonus': 0.014983900955063837, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14507, 'bonus': 0.008302544164800623, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51640, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3650108087570108
Updated goal-option-3 on 16 transitions
Took 0.0005879402160644531s to update distance table with 17 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 16090, 'bonus': 0.007883552750988976, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6656, 'bonus': 0.012257258446136503, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.602244846374221
Updated goal-option-2 on 23 transitions
Took 0.0006990432739257812s to update distance table with 24 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 465 Step: 56950
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3167475  0.32967421 0.35357829]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56950, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4430, 'bonus': 0.015024434575434523, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56557, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46850931247830846
Updated goal-option-1 on 8 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.00022172927856445312s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35586723 0.31562592 0.32850686]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4455, 'bonus': 0.014982219165849825, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6668, 'bonus': 0.012246224152725615, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56352, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.609033254412652
Updated goal-option-2 on 3 transitions
Took 0.00015974044799804688s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6716, 'bonus': 0.012202383114084501, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56961, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25692, 'bonus': 0.006238799710505724, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.751915102419646
Updated goal-option-4 on 5 transitions
Took 0.00020551681518554688s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 466 Step: 56966
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3167475  0.32967421 0.35357829]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56966, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6635, 'bonus': 0.01227664044140357, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6540774328097926
Updated goal-option-2 on 23 transitions
Took 0.0005605220794677734s to update distance table with 24 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6718, 'bonus': 0.012200566607470181, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56989, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 14 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [5 2] targeting {'count': 4382, 'bonus': 0.01510649855174383, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55636, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5226099358727573
Updated goal-option-1 on 5 transitions
Took 0.0007839202880859375s to update distance table with 20 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35586723 0.31562592 0.32850686]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6656, 'bonus': 0.012257258446136503, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6186211901257662
Updated goal-option-2 on 5 transitions
Took 0.00023984909057617188s to update distance table with 6 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6721, 'bonus': 0.012197843367986657, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 8 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 15720, 'bonus': 0.007975790340283704, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55627, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1449393684872322
Updated goal-option-3 on 46 transitions
Took 0.0019752979278564453s to update distance table with 55 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 16111, 'bonus': 0.00787841313857205, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6636, 'bonus': 0.012275715403505907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55905, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6095332747028052
Updated goal-option-2 on 11 transitions
Took 0.00036716461181640625s to update distance table with 12 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6725, 'bonus': 0.012194215216993848, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57078, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 15671, 'bonus': 0.007988249937781768, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.1679515528822275
Updated goal-option-3 on 27 transitions
Took 0.001140594482421875s to update distance table with 34 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 16116, 'bonus': 0.00787719090223795, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57111, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6679, 'bonus': 0.012236135518496437, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56546, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6292715229241774
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25704, 'bonus': 0.006237343238042665, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56318, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8464351269645968
Updated goal-option-4 on 5 transitions
Took 0.0004482269287109375s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 467 Step: 57124
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57124, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6642, 'bonus': 0.012270169563871839, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55975, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6732347764060771
Updated goal-option-2 on 31 transitions
Took 0.0010528564453125s to update distance table with 32 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6730, 'bonus': 0.012189684577707985, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57155, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 14394, 'bonus': 0.008335069987167616, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51072, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0790199904012032
Updated goal-option-3 on 44 transitions
Took 0.0016827583312988281s to update distance table with 51 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31570149 0.33188785 0.35241065]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 16118, 'bonus': 0.007876702166955815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6725, 'bonus': 0.012194215216993848, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57078, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5911173356111061
Updated goal-option-2 on 22 transitions
Took 0.0006060600280761719s to update distance table with 23 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6733, 'bonus': 0.012186968616908324, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25692, 'bonus': 0.006238799710505724, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8268284204191175
Updated goal-option-4 on 7 transitions
Took 0.0002682209014892578s to update distance table with 8 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 468 Step: 57234
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31465196 0.33410895 0.35123909]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57234, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6716, 'bonus': 0.012202383114084501, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56961, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5207059473245778
Updated goal-option-2 on 18 transitions
Took 0.00048041343688964844s to update distance table with 19 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34758788 0.3082828  0.34412932]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6737, 'bonus': 0.012183350158213093, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25701, 'bonus': 0.006237707260526154, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.965726431416369
Updated goal-option-4 on 4 transitions
Took 0.0001742839813232422s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 469 Step: 57256
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31681241 0.33305573 0.35013186]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6654, 'bonus': 0.012259100396473165, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 195 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5450410866893632
Updated goal-option-2 on 24 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25709, 'bonus': 0.006236736675502887, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.827023867860265
Updated goal-option-4 on 4 transitions
Took 0.0006303787231445312s to update distance table with 29 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 470 Step: 57284
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31898079 0.33199864 0.34902057]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57284, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4333, 'bonus': 0.015191674812676982, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54785, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5673447336685219
Updated goal-option-1 on 4 transitions
Took 0.0001761913299560547s to update distance table with 5 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35129604 0.3178658  0.33083815]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4479, 'bonus': 0.014942025346507818, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 3 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [5 2] targeting {'count': 14610, 'bonus': 0.008273226074410304, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6774170606831709
Updated goal-option-3 on 117 transitions
Took 0.0040395259857177734s to update distance table with 121 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31898079 0.33199864 0.34902057]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 16150, 'bonus': 0.007868894753646338, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6733, 'bonus': 0.012186968616908324, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 196 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5080273440238141
Updated goal-option-2 on 20 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25699, 'bonus': 0.006237949977593136, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0111042192612572
Updated goal-option-4 on 5 transitions
Took 0.0007166862487792969s to update distance table with 26 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-3
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([3 2]) to goal-option-3
Took 1.5337917804718018s to add potential edges.
================================================================================
[Consolidation] Episode: 471 Step: 57433
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.31898079 0.33199864 0.34902057]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6739, 'bonus': 0.01218154213710672, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57428, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 197 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6165507987703349
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25716, 'bonus': 0.00623588778516133, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8011301971715072
Updated goal-option-4 on 6 transitions
Took 0.0006458759307861328s to update distance table with 20 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 472 Step: 57452
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.32115703 0.33093772 0.34790526]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4406100124534633
Updated goal-option-1 on 20 transitions
Took 0.0006694793701171875s to update distance table with 21 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35017736 0.32003801 0.32978462]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4483, 'bonus': 0.014935357775740083, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6716, 'bonus': 0.012202383114084501, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56961, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 198 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5673121820087762
Updated goal-option-2 on 3 transitions
Took 0.0001609325408935547s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34435487 0.31471665 0.34092848]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6744, 'bonus': 0.012177025603587077, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57475, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 5 transitions
Took 0.00021910667419433594s to update distance table with 6 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.35017736 0.32003801 0.32978462]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4484, 'bonus': 0.014933692277237473, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6713, 'bonus': 0.012205109395953727, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56906, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 199 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5497995715595269
Updated goal-option-2 on 5 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25708, 'bonus': 0.006236857973854118, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.188780995727944
Updated goal-option-4 on 11 transitions
Took 0.0006029605865478516s to update distance table with 17 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 473 Step: 57496
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.32115703 0.33093772 0.34790526]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6738, 'bonus': 0.012182446047035401, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57280, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 200 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5514019256930336
Updated goal-option-2 on 15 transitions
Deleting edge from SE([6 2]) to goal-option-2
Took 0.0003826618194580078s to update distance table with 16 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34435487 0.31471665 0.34092848]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6755, 'bonus': 0.012167106887317211, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 5 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 15802, 'bonus': 0.007955069372286065, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0116746850808462
Updated goal-option-3 on 4 transitions
Took 0.00033926963806152344s to update distance table with 10 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.32115703 0.33093772 0.34790526]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 16175, 'bonus': 0.007862811339707515, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57520, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6721, 'bonus': 0.012197843367986657, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 201 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6374053729273956
Updated goal-option-2 on 30 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25716, 'bonus': 0.00623588778516133, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57433, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9167849905045963
Updated goal-option-4 on 5 transitions
Took 0.0010564327239990234s to update distance table with 36 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 474 Step: 57555
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.32334107 0.32987299 0.34678594]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57555, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4707777385722916
Updated goal-option-1 on 21 transitions
Took 0.0006461143493652344s to update distance table with 22 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.34905465 0.32221806 0.32872729]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4490, 'bonus': 0.01492371097349751, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6737, 'bonus': 0.012183350158213093, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 202 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5535724671281598
Updated goal-option-2 on 5 transitions
Took 0.0002560615539550781s to update distance table with 6 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34326912 0.31687734 0.33985354]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6760, 'bonus': 0.012162606385262998, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25718, 'bonus': 0.006235645308723592, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57496, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9751681252422495
Updated goal-option-4 on 5 transitions
Took 0.00020933151245117188s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 475 Step: 57586
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.32773227 0.32773227 0.34453546]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57586, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6738, 'bonus': 0.012182446047035401, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57280, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 203 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.592229062843102
Updated goal-option-2 on 10 transitions
Took 0.00032639503479003906s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.34108572 0.32122243 0.33769186]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6762, 'bonus': 0.012160807582267837, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57596, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25707, 'bonus': 0.006236979279283023, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8334384816154795
Updated goal-option-4 on 6 transitions
Took 0.00023627281188964844s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 476 Step: 57602
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.32993929 0.32665634 0.34340437]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6713, 'bonus': 0.012205109395953727, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56906, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.5919415934790014
Updated goal-option-2 on 48 transitions
Took 0.0015282630920410156s to update distance table with 49 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 477 Step: 57650
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33101518 0.32446064 0.34452417]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6721, 'bonus': 0.012197843367986657, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 204 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6139540094497359
Updated goal-option-2 on 25 transitions
Took 0.0008530616760253906s to update distance table with 26 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33998812 0.3234067  0.33660518]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6765, 'bonus': 0.012158110873601292, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 14610, 'bonus': 0.008273226074410304, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52498, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0260832440538377
Updated goal-option-3 on 31 transitions
Took 0.0012810230255126953s to update distance table with 39 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33101518 0.32446064 0.34452417]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 16211, 'bonus': 0.00785407595840826, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57713, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6711, 'bonus': 0.01220692793271357, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56820, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 205 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5720496909390139
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25703, 'bonus': 0.006237464571789149, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56253, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9741150545703489
Updated goal-option-4 on 5 transitions
Took 0.0005331039428710938s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 478 Step: 57731
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33101518 0.32446064 0.34452417]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4428, 'bonus': 0.015027827244457205, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5006966574012108
Updated goal-option-1 on 5 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.00018477439880371094s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.34678594 0.32987299 0.32334107]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4498, 'bonus': 0.014910433647938832, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57736, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6725, 'bonus': 0.012194215216993848, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57078, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 206 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5555414094275789
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25711, 'bonus': 0.006236494100030692, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56966, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6688969258197958
Updated goal-option-4 on 5 transitions
Took 0.00032210350036621094s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 479 Step: 57744
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33323336 0.32338482 0.34338182]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6758, 'bonus': 0.012164405986720691, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 207 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6302800097335607
Updated goal-option-2 on 30 transitions
Took 0.0006821155548095703s to update distance table with 31 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33888664 0.3255987  0.33551466]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6774, 'bonus': 0.012150031498997491, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57774, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25721, 'bonus': 0.006235281647096236, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8291713496049246
Updated goal-option-4 on 7 transitions
Took 0.0002646446228027344s to update distance table with 8 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 480 Step: 57781
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33215383 0.32557675 0.34226942]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6760, 'bonus': 0.012162606385262998, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 208 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5295996325609347
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25724, 'bonus': 0.006234918049087485, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6031818216045698
Updated goal-option-4 on 6 transitions
Took 0.0005991458892822266s to update distance table with 23 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([6 2]) to goal-option-2
Adding edge from goal-option-3-0 to goal-option-2
Took 1.5059173107147217s to add potential edges.
================================================================================
[Consolidation] Episode: 481 Step: 57803
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33437582 0.32449352 0.34113066]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6721, 'bonus': 0.012197843367986657, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 209 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5720565403705318
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25717, 'bonus': 0.00623576654340672, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57452, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.766973372934913
Updated goal-option-4 on 5 transitions
Took 0.0005605220794677734s to update distance table with 20 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 482 Step: 57822
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33437582 0.32449352 0.34113066]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57822, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4425, 'bonus': 0.015032920560056576, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4432894374362957
Updated goal-option-1 on 31 transitions
Took 0.0008947849273681641s to update distance table with 32 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.34338182 0.33323336 0.32338482]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4501, 'bonus': 0.014905463779355262, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57853, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 25708, 'bonus': 0.006236857973854118, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7880017667180962
Updated goal-option-4 on 89 transitions
Took 0.003264904022216797s to update distance table with 90 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 483 Step: 57942
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33437582 0.32449352 0.34113066]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57942, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6737, 'bonus': 0.012183350158213093, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 210 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6575084405600047
Updated goal-option-2 on 12 transitions
Deleting edge from goal-option-3-0 to goal-option-2
Took 0.0003218650817871094s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33778131 0.32779836 0.33442033]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6785, 'bonus': 0.012140178546918843, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57954, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25711, 'bonus': 0.006236494100030692, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56966, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6748891272892554
Updated goal-option-4 on 5 transitions
Took 0.00020956993103027344s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 484 Step: 57959
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33328889 0.32668933 0.34002178]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57959, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6755, 'bonus': 0.012167106887317211, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 211 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5943424956421817
Updated goal-option-2 on 20 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25719, 'bonus': 0.006235524081111261, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57555, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7012085644502614
Updated goal-option-4 on 6 transitions
Took 0.0006594657897949219s to update distance table with 27 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 485 Step: 57985
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33551466 0.3255987  0.33888664]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57985, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6787, 'bonus': 0.012138389675097902, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57979, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 212 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.671572222698318
Updated goal-option-2 on 53 transitions
Took 0.0014498233795166016s to update distance table with 54 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6790, 'bonus': 0.012135707849456652, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 20 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16000, 'bonus': 0.007905694150420948, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56619, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.0228536121206346
Updated goal-option-3 on 22 transitions
Deleting edge from SE([3 2]) to goal-option-3
Took 0.0015575885772705078s to update distance table with 43 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33551466 0.3255987  0.33888664]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 16318, 'bonus': 0.007828283327484668, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6785, 'bonus': 0.012140178546918843, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57954, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 213 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5795166430613553
Updated goal-option-2 on 152 transitions
Took 0.007132291793823242s to update distance table with 153 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6808, 'bonus': 0.012119654139092991, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 15671, 'bonus': 0.007988249937781768, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.990386612080281
Updated goal-option-3 on 2 transitions
Took 0.0004086494445800781s to update distance table with 10 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 486 Step: 58241
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33551466 0.3255987  0.33888664]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58241, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6787, 'bonus': 0.012138389675097902, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57979, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 214 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6374859874715676
Updated goal-option-2 on 7 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25712, 'bonus': 0.006236372822908353, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57124, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7225955739083698
Updated goal-option-4 on 4 transitions
Took 0.00040078163146972656s to update distance table with 12 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 487 Step: 58252
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6772, 'bonus': 0.01215182552359184, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 215 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6159147479579792
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25711, 'bonus': 0.006236494100030692, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56966, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7365031415601736
Updated goal-option-4 on 4 transitions
Took 0.0005974769592285156s to update distance table with 18 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 488 Step: 58269
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58269, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6762, 'bonus': 0.012160807582267837, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57596, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 216 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5171163843761462
Updated goal-option-2 on 41 transitions
Took 0.0009331703186035156s to update distance table with 42 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6815, 'bonus': 0.012113428212804355, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58310, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 10 transitions
Took 0.00041961669921875s to update distance table with 11 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33998812 0.33660518 0.3234067 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4529, 'bonus': 0.014859316721917632, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58320, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6765, 'bonus': 0.012158110873601292, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57675, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 217 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7050123257449025
Updated goal-option-2 on 7 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25727, 'bonus': 0.006234554514678793, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57822, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6477145771021356
Updated goal-option-4 on 6 transitions
Took 0.0005006790161132812s to update distance table with 14 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 489 Step: 58333
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58333, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4490, 'bonus': 0.01492371097349751, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5026575836135929
Updated goal-option-1 on 5 transitions
Took 0.00020956993103027344s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33998812 0.33660518 0.3234067 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4534, 'bonus': 0.01485112119058882, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6808, 'bonus': 0.012119654139092991, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 218 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5633253870885753
Updated goal-option-2 on 3 transitions
Took 0.00016379356384277344s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6825, 'bonus': 0.01210455065337605, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58341, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25725, 'bonus': 0.006234796863885496, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6216900580498427
Updated goal-option-4 on 8 transitions
Took 0.0002956390380859375s to update distance table with 9 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
[Episode=490 Seed=18] Took 0.05843687057495117s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 490 Step: 58349
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58349, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4428, 'bonus': 0.015027827244457205, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4828494868140096
Updated goal-option-1 on 12 transitions
Deleting edge from SE([3 2]) to goal-option-1
[RND Rollout] Reward: 6.0	IntrinsicReward: -332.3911733273417
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 491 Step: 58361
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58361, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4483, 'bonus': 0.014935357775740083, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4423807530051165
Updated goal-option-1 on 14 transitions
[RND Rollout] Reward: 9.0	IntrinsicReward: -350.50502542592585
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 492 Step: 58375
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 10.0	IntrinsicReward: -381.03583866357803
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 493 Step: 58375
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6774, 'bonus': 0.012150031498997491, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57774, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 219 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4998791957934911
Updated goal-option-2 on 28 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25728, 'bonus': 0.0062344333506727054, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57942, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7236467281895909
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 494 Step: 58408
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6825, 'bonus': 0.01210455065337605, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58341, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 220 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5292216085824525
Updated goal-option-2 on 87 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25724, 'bonus': 0.006234918049087485, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7357153332705706
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 495 Step: 58500
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6758, 'bonus': 0.012164405986720691, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57550, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 221 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5462865290687756
Updated goal-option-2 on 42 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25734, 'bonus': 0.006233706514954623, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58349, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8076741530921291
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 496 Step: 58547
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58547, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4440, 'bonus': 0.015007505629691604, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56677, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4432112674845095
Updated goal-option-1 on 20 transitions
Deleting edge from goal-option-3-0 to goal-option-1
[RND Rollout] Reward: 10.0	IntrinsicReward: -383.12903361208737
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 497 Step: 58567
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 5.0	IntrinsicReward: -306.21018079284113
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 498 Step: 58567
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4425, 'bonus': 0.015032920560056576, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56306, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5869042828420576
Updated goal-option-1 on 35 transitions
[RND Rollout] Reward: 5.0	IntrinsicReward: -362.42798962490633
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 499 Step: 58602
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -371.5835677878931
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 500 Step: 58602
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6785, 'bonus': 0.012140178546918843, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57954, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 222 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5610015006928609
Updated goal-option-2 on 27 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25734, 'bonus': 0.006233706514954623, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58349, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5668925683075041
Updated goal-option-4 on 6 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 501 Step: 58635
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58635, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6884, 'bonus': 0.012052567410047378, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 223 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5384445056660886
Updated goal-option-2 on 25 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25720, 'bonus': 0.006235402860569037, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57586, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7346045407176341
Updated goal-option-4 on 4 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 502 Step: 58664
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58664, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6882, 'bonus': 0.012054318600381364, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 224 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.529262513256482
Updated goal-option-2 on 35 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25719, 'bonus': 0.006235524081111261, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57555, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6130524764700633
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 503 Step: 58704
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58704, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6814, 'bonus': 0.012114317043433485, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 225 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5209420443944167
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 27022, 'bonus': 0.00608332830614049, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8033643484842486
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 504 Step: 58723
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6882, 'bonus': 0.012054318600381364, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 226 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49219976541564225
Updated goal-option-2 on 86 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 27022, 'bonus': 0.00608332830614049, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7443270999887771
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 505 Step: 58814
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6886, 'bonus': 0.012050816982703888, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 227 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5826243222385566
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25732, 'bonus': 0.0062339487652807585, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58269, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7260013853390052
Updated goal-option-4 on 4 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 506 Step: 58833
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58833, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6815, 'bonus': 0.012113428212804355, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58310, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.5703252031098901
Updated goal-option-2 on 29 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 507 Step: 58862
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58862, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6785, 'bonus': 0.012140178546918843, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57954, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 228 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5215895959249883
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29517, 'bonus': 0.005820548231825709, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6818848623623771
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 508 Step: 58882
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58882, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6813, 'bonus': 0.012115206069746899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58248, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 229 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5798424317747252
Updated goal-option-2 on 33 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25729, 'bonus': 0.006234312193730544, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57959, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8542350016293986
Updated goal-option-4 on 8 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 509 Step: 58923
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6790, 'bonus': 0.012135707849456652, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 230 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5385961706890035
Updated goal-option-2 on 75 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25728, 'bonus': 0.0062344333506727054, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57942, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7644354973028423
Updated goal-option-4 on 5 transitions
Took 12.444413185119629s to update distance table with 7681 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=510 Seed=18] Took 0.07527875900268555s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 510 Step: 59003
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59003, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6922, 'bonus': 0.012019439133170468, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 231 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5277729560854315
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 25729, 'bonus': 0.006234312193730544, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57959, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6201685705085596
Updated goal-option-4 on 4 transitions
Took 0.0004730224609375s to update distance table with 17 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-3
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.6562573909759521s to add potential edges.
================================================================================
[Consolidation] Episode: 511 Step: 59019
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4479, 'bonus': 0.014942025346507818, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4552185206501573
Updated goal-option-1 on 19 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.0005559921264648438s to update distance table with 20 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33998812 0.33660518 0.3234067 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4589, 'bonus': 0.014761856225269075, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16000, 'bonus': 0.007905694150420948, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56619, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0789353790117313
Updated goal-option-3 on 26 transitions
Took 0.0009350776672363281s to update distance table with 27 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 16916, 'bonus': 0.00768866894674349, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59064, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6814, 'bonus': 0.012114317043433485, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 232 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6232660445135635
Updated goal-option-2 on 44 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 27024, 'bonus': 0.006083103193615902, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58547, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7620796282688777
Updated goal-option-4 on 5 transitions
Took 0.0016362667083740234s to update distance table with 50 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 512 Step: 59113
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59113, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6920, 'bonus': 0.012021175920858624, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58718, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 233 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6206649280892512
Updated goal-option-2 on 23 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 27022, 'bonus': 0.00608332830614049, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7938304126858711
Updated goal-option-4 on 5 transitions
Took 0.0006742477416992188s to update distance table with 29 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 513 Step: 59141
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59141, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6920, 'bonus': 0.012021175920858624, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58718, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 234 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4677503153299674
Updated goal-option-2 on 54 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29517, 'bonus': 0.005820548231825709, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6554899464448293
Updated goal-option-4 on 5 transitions
Took 0.0015833377838134766s to update distance table with 60 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 514 Step: 59200
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6939, 'bonus': 0.012004706767760328, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59195, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 235 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5240721420177717
Updated goal-option-2 on 44 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 27023, 'bonus': 0.006083215746754294, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6493899621168772
Updated goal-option-4 on 5 transitions
Took 0.0013086795806884766s to update distance table with 50 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 515 Step: 59249
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33774776 0.32450448 0.33774776]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59249, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6934, 'bonus': 0.012009034191846582, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59015, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 236 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5741277052482375
Updated goal-option-2 on 21 transitions
Took 0.0005049705505371094s to update distance table with 22 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6943, 'bonus': 0.012001248194721752, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59270, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29522, 'bonus': 0.005820055311740492, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5968099741077927
Updated goal-option-4 on 5 transitions
Took 0.00020551681518554688s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 516 Step: 59275
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33664984 0.32670033 0.33664984]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6922, 'bonus': 0.012019439133170468, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 237 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5393385594431074
Updated goal-option-2 on 20 transitions
Took 0.0006728172302246094s to update distance table with 21 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 6945, 'bonus': 0.01199952002879808, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59295, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 14 transitions
Took 0.0005376338958740234s to update distance table with 15 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4599, 'bonus': 0.014745798506793625, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6935, 'bonus': 0.0120081683326442, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 238 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4856351194895356
Updated goal-option-2 on 4 transitions
Took 0.00020122528076171875s to update distance table with 5 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6956, 'bonus': 0.011990028442779207, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59313, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29525, 'bonus': 0.005819759619793254, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59113, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6828296278559026
Updated goal-option-4 on 5 transitions
Took 0.00022602081298828125s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 517 Step: 59318
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33664984 0.32670033 0.33664984]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59318, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6935, 'bonus': 0.0120081683326442, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 239 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4549702935580966
Updated goal-option-2 on 53 transitions
Took 0.0013742446899414062s to update distance table with 54 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6958, 'bonus': 0.01198830511852413, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29515, 'bonus': 0.005820745434930298, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58664, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6932259528409866
Updated goal-option-4 on 5 transitions
Took 0.0002472400665283203s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 518 Step: 59376
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33664984 0.32670033 0.33664984]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6886, 'bonus': 0.012050816982703888, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 240 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5593553625455888
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29522, 'bonus': 0.005820055311740492, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.725280333803129
Updated goal-option-4 on 5 transitions
Took 0.00044417381286621094s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 519 Step: 59389
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33664984 0.32670033 0.33664984]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59389, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4421, 'bonus': 0.015039719710363528, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56202, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6885682259628801
Updated goal-option-1 on 14 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.000446319580078125s to update distance table with 15 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33888664 0.33551466 0.3255987 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4603, 'bonus': 0.014739390076023, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6943, 'bonus': 0.012001248194721752, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59270, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 241 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49405289501706257
Updated goal-option-2 on 3 transitions
Took 0.0001609325408935547s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6962, 'bonus': 0.011984860698077075, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 15 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 16111, 'bonus': 0.00787841313857205, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0713824797899296
Updated goal-option-3 on 224 transitions
Took 0.007869720458984375s to update distance table with 240 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 520 Step: 59645
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59645, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4421, 'bonus': 0.015039719710363528, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56202, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5461002420198726
Updated goal-option-1 on 23 transitions
Took 0.0007829666137695312s to update distance table with 24 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33778131 0.33442033 0.32779836]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4606, 'bonus': 0.014734589232268476, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59668, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6925, 'bonus': 0.012016835362522193, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 242 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5115257241429156
Updated goal-option-2 on 3 transitions
Took 0.0001780986785888672s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6973, 'bonus': 0.011975403828652899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59671, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 5 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16175, 'bonus': 0.007862811339707515, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57520, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7534889115227593
Updated goal-option-3 on 10 transitions
Took 0.0005366802215576172s to update distance table with 16 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33444259 0.33111483 0.33444259]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 17083, 'bonus': 0.0076509952009797995, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59686, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6927, 'bonus': 0.012015100455220504, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58915, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 243 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4928753571365317
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29521, 'bonus': 0.0058201538857390895, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58882, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.72772416116528
Updated goal-option-4 on 5 transitions
Took 0.0005819797515869141s to update distance table with 20 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from goal-option-3-0 to goal-option-2
Took 1.5886287689208984s to add potential edges.
================================================================================
[Consolidation] Episode: 521 Step: 59705
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33444259 0.33111483 0.33444259]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59705, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4038667661484842
Updated goal-option-1 on 22 transitions
Took 0.0007369518280029297s to update distance table with 23 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.33667217 0.33332222 0.33000561]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4609, 'bonus': 0.014729793076583796, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59727, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16090, 'bonus': 0.007883552750988976, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3617489494430195
Updated goal-option-3 on 29 transitions
Took 0.0010328292846679688s to update distance table with 30 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 522 Step: 59756
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33444259 0.33111483 0.33444259]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59756, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6973, 'bonus': 0.011975403828652899, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59671, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 244 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5373365897120851
Updated goal-option-2 on 21 transitions
Deleting edge from goal-option-3-0 to goal-option-2
Took 0.000469207763671875s to update distance table with 22 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33555925 0.33222038 0.33222038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59777, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29519, 'bonus': 0.005820351048763104, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58833, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6051839787777015
Updated goal-option-4 on 6 transitions
Took 0.00023937225341796875s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 523 Step: 59783
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33444259 0.33111483 0.33444259]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6941, 'bonus': 0.012002977107529789, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 245 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5474373383633636
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29528, 'bonus': 0.005819463972909941, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59249, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7694263443389903
Updated goal-option-4 on 6 transitions
Took 0.00048470497131347656s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 524 Step: 59799
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33444259 0.33111483 0.33444259]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59799, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6988, 'bonus': 0.011962544100747777, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59777, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 246 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.561961133086211
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29532, 'bonus': 0.005819069847145179, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59389, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5791299122916119
Updated goal-option-4 on 5 transitions
Took 0.00048470497131347656s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 525 Step: 59816
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6943, 'bonus': 0.012001248194721752, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59270, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 247 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47402387838717086
Updated goal-option-2 on 25 transitions
Took 0.0005180835723876953s to update distance table with 26 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 6996, 'bonus': 0.011955702496470261, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59841, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 10 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16150, 'bonus': 0.007868894753646338, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9604865452767903
Updated goal-option-3 on 56 transitions
Took 0.0027539730072021484s to update distance table with 67 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 526 Step: 59907
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59907, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6941, 'bonus': 0.012002977107529789, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59244, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 248 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5123589096854451
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29529, 'bonus': 0.005819365433961062, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7070606063630951
Updated goal-option-4 on 5 transitions
Took 0.0005443096160888672s to update distance table with 22 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 527 Step: 59928
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4451, 'bonus': 0.014988949722867606, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56835, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5717608426131454
Updated goal-option-1 on 18 transitions
Took 0.0003581047058105469s to update distance table with 19 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4617, 'bonus': 0.014717026189611597, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6935, 'bonus': 0.0120081683326442, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 249 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5562649276060867
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29524, 'bonus': 0.0058198581787679985, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8515564846654063
Updated goal-option-4 on 5 transitions
Took 0.0003159046173095703s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 528 Step: 59954
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59954, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4534, 'bonus': 0.01485112119058882, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5801607479087745
Updated goal-option-1 on 26 transitions
Took 0.0005028247833251953s to update distance table with 27 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4618, 'bonus': 0.014715432661786062, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29530, 'bonus': 0.0058192669000175935, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59318, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1121469956318226
Updated goal-option-4 on 9 transitions
Took 0.00034618377685546875s to update distance table with 10 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 529 Step: 59989
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59989, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.385798275914619
Updated goal-option-1 on 9 transitions
Took 0.0003440380096435547s to update distance table with 10 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4619, 'bonus': 0.014713839651479712, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16916, 'bonus': 0.00768866894674349, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59064, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1509766714808383
Updated goal-option-3 on 18 transitions
Took 0.0006589889526367188s to update distance table with 19 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 530 Step: 60016
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7033, 'bonus': 0.01192421207037253, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59949, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 250 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4775431906987439
Updated goal-option-2 on 22 transitions
Took 0.000507354736328125s to update distance table with 23 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7040, 'bonus': 0.011918282365569905, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 16 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16116, 'bonus': 0.00787719090223795, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57111, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5043203273305188
Updated goal-option-3 on 13 transitions
Took 0.001031637191772461s to update distance table with 30 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 17192, 'bonus': 0.007626702374631812, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6991, 'bonus': 0.011959977122977639, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 251 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48543054763227705
Updated goal-option-2 on 14 transitions
Took 0.00039696693420410156s to update distance table with 15 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7054, 'bonus': 0.011906449446326092, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60081, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29531, 'bonus': 0.005819168371079106, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7199707633117214
Updated goal-option-4 on 7 transitions
Took 0.00026702880859375s to update distance table with 8 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Took 1.532344102859497s to add potential edges.
================================================================================
[Consolidation] Episode: 531 Step: 60088
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60088, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4455, 'bonus': 0.014982219165849825, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6013994893973523
Updated goal-option-1 on 41 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.0009877681732177734s to update distance table with 42 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4623, 'bonus': 0.014707472779848216, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60129, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29524, 'bonus': 0.0058198581787679985, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59019, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5070673039794277
Updated goal-option-4 on 25 transitions
Took 0.0009016990661621094s to update distance table with 26 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 532 Step: 60154
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4459, 'bonus': 0.014975497667455975, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5665952413734319
Updated goal-option-1 on 18 transitions
Took 0.0006091594696044922s to update distance table with 19 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4628, 'bonus': 0.014699525800946368, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60172, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29522, 'bonus': 0.005820055311740492, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6195957455879603
Updated goal-option-4 on 35 transitions
Took 0.001310586929321289s to update distance table with 36 states and events {SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 533 Step: 60207
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60207, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7040, 'bonus': 0.011918282365569905, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 252 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4976184341061743
Updated goal-option-2 on 159 transitions
Took 0.008129596710205078s to update distance table with 160 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7060, 'bonus': 0.011901388973144479, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 6 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 2] targeting {'count': 4618, 'bonus': 0.014715432661786062, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44832866715384273
Updated goal-option-1 on 3 transitions
Took 0.0003631114959716797s to update distance table with 10 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4633, 'bonus': 0.014691591690258264, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7031, 'bonus': 0.011925907898023908, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59923, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 253 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5891506370113758
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29529, 'bonus': 0.005819365433961062, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5655818893633423
Updated goal-option-4 on 6 transitions
Took 0.0003540515899658203s to update distance table with 10 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 534 Step: 60384
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60384, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4498, 'bonus': 0.014910433647938832, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57736, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4908033361037572
Updated goal-option-1 on 11 transitions
Took 0.00032019615173339844s to update distance table with 12 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4634, 'bonus': 0.014690006409251194, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60395, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7063, 'bonus': 0.011898861155004214, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60378, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 254 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5301552620927987
Updated goal-option-2 on 3 transitions
Took 0.00019025802612304688s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7066, 'bonus': 0.01189633494688226, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60398, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 18 transitions
Got plan [goal-option-3, goal-option-1] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 16090, 'bonus': 0.007883552750988976, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56927, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8276667462758697
Updated goal-option-3 on 4 transitions
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4623, 'bonus': 0.014707472779848216, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60129, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5878431726915024
Updated goal-option-1 on 36 transitions
Took 0.0021066665649414062s to update distance table with 59 states and events {SE([1 1]), SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4636, 'bonus': 0.014686837386151166, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60456, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 12 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [4 2] targeting {'count': 17192, 'bonus': 0.007626702374631812, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1807421370657212
Updated goal-option-3 on 10 transitions
Took 0.0008184909820556641s to update distance table with 23 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 17402, 'bonus': 0.007580544784814, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7066, 'bonus': 0.01189633494688226, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60398, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 255 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5438801292923253
Updated goal-option-2 on 65 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29531, 'bonus': 0.005819168371079106, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7580315394862615
Updated goal-option-4 on 4 transitions
Took 0.0024869441986083984s to update distance table with 70 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 535 Step: 60547
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60547, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7040, 'bonus': 0.011918282365569905, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 256 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5360647409527314
Updated goal-option-2 on 19 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29535, 'bonus': 0.005818774305366521, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59783, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6867899412796393
Updated goal-option-4 on 6 transitions
Took 0.0007300376892089844s to update distance table with 26 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 536 Step: 60572
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60572, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4623, 'bonus': 0.014707472779848216, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60129, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45717154064948984
Updated goal-option-1 on 49 transitions
Took 0.0012047290802001953s to update distance table with 50 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4645, 'bonus': 0.01467260211960279, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60621, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29537, 'bonus': 0.005818577302529115, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7614445829563272
Updated goal-option-4 on 71 transitions
Took 0.0024220943450927734s to update distance table with 72 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 537 Step: 60692
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4534, 'bonus': 0.01485112119058882, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5573289656773511
Updated goal-option-1 on 8 transitions
Took 0.00025844573974609375s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4651, 'bonus': 0.014663134905721362, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 6962, 'bonus': 0.011984860698077075, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 257 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4966865075450919
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29544, 'bonus': 0.00581788795013956, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6493127217194191
Updated goal-option-4 on 5 transitions
Took 0.00031685829162597656s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 538 Step: 60708
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7060, 'bonus': 0.011901388973144479, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 258 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5048088859690071
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29539, 'bonus': 0.005818380319699784, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59928, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5379495079206643
Updated goal-option-4 on 4 transitions
Took 0.0004055500030517578s to update distance table with 14 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 539 Step: 60721
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60721, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7060, 'bonus': 0.011901388973144479, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 259 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6806914448615454
Updated goal-option-2 on 22 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29545, 'bonus': 0.005817789491226377, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60207, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7192159704023734
Updated goal-option-4 on 5 transitions
Took 0.0007452964782714844s to update distance table with 28 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 540 Step: 60748
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60748, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4651, 'bonus': 0.014663134905721362, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45424979415145655
Updated goal-option-1 on 11 transitions
Took 0.000286102294921875s to update distance table with 12 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4653, 'bonus': 0.01465998323778475, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 30 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 17402, 'bonus': 0.007580544784814, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5376517424085832
Updated goal-option-3 on 215 transitions
Deleting edge from SE([1 1]) to goal-option-3
Took 0.009440183639526367s to update distance table with 246 states and events {SE([6 2]), None, SE([3 2])}
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.609515905380249s to add potential edges.
================================================================================
[Consolidation] Episode: 541 Step: 61004
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61004, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6991, 'bonus': 0.011959977122977639, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59793, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 260 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5245933622452132
Updated goal-option-2 on 16 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.0003921985626220703s to update distance table with 17 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7137, 'bonus': 0.011837013737140583, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 26 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 17192, 'bonus': 0.007626702374631812, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8459394405640308
Updated goal-option-3 on 45 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.0029273033142089844s to update distance table with 72 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 542 Step: 61091
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6976, 'bonus': 0.011972828565264392, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 261 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4745796320503799
Updated goal-option-2 on 35 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29546, 'bonus': 0.005817691037311827, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60384, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.043413393330156
Updated goal-option-4 on 6 transitions
Took 0.0010516643524169922s to update distance table with 42 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 543 Step: 61132
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 6996, 'bonus': 0.011955702496470261, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59841, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 262 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5065437625862317
Updated goal-option-2 on 18 transitions
Took 0.0004100799560546875s to update distance table with 19 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7169, 'bonus': 0.011810565970567408, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61150, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29546, 'bonus': 0.005817691037311827, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60384, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7429605528378666
Updated goal-option-4 on 6 transitions
Took 0.0002548694610595703s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 544 Step: 61156
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4541, 'bonus': 0.014839670194962734, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4525801013356873
Updated goal-option-1 on 13 transitions
Took 0.00026726722717285156s to update distance table with 14 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4671, 'bonus': 0.01463170937687157, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61169, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 17192, 'bonus': 0.007626702374631812, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9122547493220079
Updated goal-option-3 on 25 transitions
Took 0.0009722709655761719s to update distance table with 26 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 545 Step: 61194
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61194, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7033, 'bonus': 0.01192421207037253, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59949, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 263 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.532933106586402
Updated goal-option-2 on 17 transitions
Took 0.0004062652587890625s to update distance table with 18 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7191, 'bonus': 0.01179248562795375, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61211, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29552, 'bonus': 0.005817100418772143, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60748, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.563091567462653
Updated goal-option-4 on 5 transitions
Took 0.00020837783813476562s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 546 Step: 61216
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4653, 'bonus': 0.01465998323778475, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6132661530881056
Updated goal-option-1 on 11 transitions
Took 0.00026798248291015625s to update distance table with 12 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4673, 'bonus': 0.014628577924855639, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16118, 'bonus': 0.007876702166955815, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57205, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4525654823110816
Updated goal-option-3 on 46 transitions
Took 0.0015783309936523438s to update distance table with 47 states and events {SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 547 Step: 61273
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61273, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4628, 'bonus': 0.014699525800946368, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60172, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4783592841025632
Updated goal-option-1 on 14 transitions
Took 0.0002815723419189453s to update distance table with 15 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4674, 'bonus': 0.014627012952620635, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61287, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7063, 'bonus': 0.011898861155004214, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60378, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 264 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6395485792203527
Updated goal-option-2 on 3 transitions
Took 0.0001621246337890625s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7193, 'bonus': 0.011790846074851915, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61290, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Took 0.0003058910369873047s to update distance table with 8 states and events {SE([3 2]), None, SE([6 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4675, 'bonus': 0.014625448482542613, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61297, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16318, 'bonus': 0.007828283327484668, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8425258905127428
Updated goal-option-3 on 29 transitions
Took 0.0009970664978027344s to update distance table with 30 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 17615, 'bonus': 0.007534573542491668, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61326, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7087, 'bonus': 0.011878696427357682, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 265 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5453629916398722
Updated goal-option-2 on 12 transitions
Took 0.00039577484130859375s to update distance table with 13 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7198, 'bonus': 0.011786750182111923, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0 on 7 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 17083, 'bonus': 0.0076509952009797995, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59686, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0419057856427978
Updated goal-option-3 on 123 transitions
Took 0.005140781402587891s to update distance table with 131 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 548 Step: 61468
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3355481 0.3289038 0.3355481]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61468, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7082, 'bonus': 0.011882888957904122, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60566, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 266 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.481478603959035
Updated goal-option-2 on 13 transitions
Took 0.0004405975341796875s to update distance table with 14 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33333333 0.33333333 0.33333333]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7223, 'bonus': 0.011766334553487256, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61481, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.3481643324400014
Updated goal-option-3-0 on 243 transitions
Took 0.02328205108642578s to update distance table with 244 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 549 Step: 61724
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7033, 'bonus': 0.01192421207037253, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59949, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 267 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4386447783226404
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29551, 'bonus': 0.005817198842703774, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60721, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5732273436637957
Updated goal-option-4 on 5 transitions
Took 0.00058746337890625s to update distance table with 18 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 550 Step: 61741
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7089, 'bonus': 0.011877020657238974, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 268 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5897795732549536
Updated goal-option-2 on 8 transitions
Took 0.0002837181091308594s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7395, 'bonus': 0.011628693150774139, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61749, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29550, 'bonus': 0.005817297271631501, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7929666449329748
Updated goal-option-4 on 5 transitions
Took 0.0002052783966064453s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
Adding edge from goal-option-1 to goal-option-3-0
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from goal-option-4 to goal-option-3-0
Adding edge from SE([1 1]) to goal-option-3
Adding edge from goal-option-3 to goal-option-3-0
Adding edge from SE([6 6]) to goal-option-3-0
Took 1.9961700439453125s to add potential edges.
================================================================================
[Consolidation] Episode: 551 Step: 61754
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61754, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4645, 'bonus': 0.01467260211960279, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60621, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4886803452460226
Updated goal-option-1 on 7 transitions
Took 0.0002334117889404297s to update distance table with 8 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4707, 'bonus': 0.014575648981554203, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7063, 'bonus': 0.011898861155004214, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60378, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 269 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49303162692160146
Updated goal-option-2 on 3 transitions
Took 0.00016307830810546875s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7397, 'bonus': 0.011627120962143852, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29541, 'bonus': 0.005818183356875141, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59989, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.528969286139749
Updated goal-option-4 on 5 transitions
Took 0.00021266937255859375s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 552 Step: 61769
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61769, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4651, 'bonus': 0.014663134905721362, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4179617673088191
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00020241737365722656s to update distance table with 8 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4708, 'bonus': 0.014574100933227224, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61776, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 17083, 'bonus': 0.0076509952009797995, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59686, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1835718964662205
Updated goal-option-3 on 122 transitions
Took 0.004475116729736328s to update distance table with 123 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 553 Step: 61898
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7066, 'bonus': 0.01189633494688226, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60398, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 270 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6246344383083895
Updated goal-option-2 on 18 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29552, 'bonus': 0.005817100418772143, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60748, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7479579603046548
Updated goal-option-4 on 6 transitions
Took 0.0007750988006591797s to update distance table with 25 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 554 Step: 61922
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33667217 0.33000561 0.33332222]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7090, 'bonus': 0.011876183038093588, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60743, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 271 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.510913594696136
Updated goal-option-2 on 14 transitions
Took 0.000514984130859375s to update distance table with 15 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33444259 0.33444259 0.33111483]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7428, 'bonus': 0.011602833293707725, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29549, 'bonus': 0.005817395705555747, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.655358646478918
Updated goal-option-4 on 4 transitions
Took 0.0001785755157470703s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 555 Step: 61940
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33779249 0.33110375 0.33110375]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61940, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7393, 'bonus': 0.01163026597733855, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61736, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 272 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4685924704816542
Updated goal-option-2 on 12 transitions
Took 0.0003452301025390625s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7429, 'bonus': 0.011602052352546233, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61952, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29561, 'bonus': 0.005816214828142087, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61754, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.940106619986487
Updated goal-option-4 on 6 transitions
Took 0.0002589225769042969s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 556 Step: 61958
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33890904 0.33219819 0.32889277]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61958, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4589, 'bonus': 0.014761856225269075, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59038, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5524388158575018
Updated goal-option-1 on 14 transitions
Deleting edge from goal-option-1 to goal-option-3-0
Deleting edge from SE([3 2]) to goal-option-1
Took 0.0003864765167236328s to update distance table with 15 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.3355481 0.3355481 0.3289038]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4712, 'bonus': 0.014567913668701625, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7087, 'bonus': 0.011878696427357682, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 273 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4765926523128084
Updated goal-option-2 on 3 transitions
Took 0.0001780986785888672s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33664984 0.33664984 0.32670033]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7432, 'bonus': 0.011599710474839776, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61975, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29549, 'bonus': 0.005817395705555747, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49212279437500756
Updated goal-option-4 on 5 transitions
Took 0.0002090930938720703s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 557 Step: 61980
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.33890904 0.33219819 0.32889277]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61980, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7429, 'bonus': 0.011602052352546233, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61952, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 274 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4370331163375658
Updated goal-option-2 on 56 transitions
Took 0.0015780925750732422s to update distance table with 57 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33664984 0.33664984 0.32670033]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7434, 'bonus': 0.011598150010653683, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29544, 'bonus': 0.00581788795013956, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5169834330970166
Updated goal-option-4 on 5 transitions
Took 0.0002110004425048828s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 558 Step: 62041
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62041, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7087, 'bonus': 0.011878696427357682, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 275 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5433351881173719
Updated goal-option-2 on 55 transitions
Took 0.0014657974243164062s to update distance table with 56 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33774776 0.33774776 0.32450448]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7436, 'bonus': 0.011596590176067833, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62096, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29550, 'bonus': 0.005817297271631501, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5308080473823437
Updated goal-option-4 on 5 transitions
Took 0.00020933151245117188s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 559 Step: 62101
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7137, 'bonus': 0.011837013737140583, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 276 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4568340731963802
Updated goal-option-2 on 25 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29550, 'bonus': 0.005817297271631501, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7597229073700659
Updated goal-option-4 on 5 transitions
Took 0.0007433891296386719s to update distance table with 31 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
[Episode=560 Seed=18] Took 0.043209075927734375s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 560 Step: 62131
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7397, 'bonus': 0.011627120962143852, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61764, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 277 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46614721096117057
Updated goal-option-2 on 28 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29568, 'bonus': 0.005815526314990443, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62041, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8966834986326742
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 561 Step: 62164
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62164, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7434, 'bonus': 0.011598150010653683, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 278 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47194827498673053
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29568, 'bonus': 0.005815526314990443, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62041, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8296639935052309
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 562 Step: 62181
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62181, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7434, 'bonus': 0.011598150010653683, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62036, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 279 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4761701341201529
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29548, 'bonus': 0.005817494144476934, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60572, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5178387012251102
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 563 Step: 62202
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62202, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7438, 'bonus': 0.01159503097065896, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 280 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4900013680378215
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29554, 'bonus': 0.0058169035858954814, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5550576406021188
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 564 Step: 62219
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7444, 'bonus': 0.011590357125267592, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62197, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 281 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46686234734744997
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29574, 'bonus': 0.005814936355433765, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7809631942324975
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 565 Step: 62239
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62239, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7395, 'bonus': 0.011628693150774139, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61749, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 282 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4313874400646623
Updated goal-option-2 on 17 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29569, 'bonus': 0.005815427975927827, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6961761822158112
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 566 Step: 62261
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62261, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7438, 'bonus': 0.01159503097065896, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 283 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4840163863426636
Updated goal-option-2 on 22 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29561, 'bonus': 0.005816214828142087, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61754, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6587519178679888
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 567 Step: 62288
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7429, 'bonus': 0.011602052352546233, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61952, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 284 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49804430572951675
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29554, 'bonus': 0.0058169035858954814, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4130496409168278
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 568 Step: 62307
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7198, 'bonus': 0.011786750182111923, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61338, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 285 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42190540962121315
Updated goal-option-2 on 32 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29555, 'bonus': 0.005816805176949604, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61156, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5732678257216866
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 569 Step: 62344
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7393, 'bonus': 0.01163026597733855, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61736, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 286 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49765103745846573
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29578, 'bonus': 0.005814543148796035, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5374637337194549
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 570 Step: 62362
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62362, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7432, 'bonus': 0.011599710474839776, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61975, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 287 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5660925044893185
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29578, 'bonus': 0.005814543148796035, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62307, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5910002470724173
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 571 Step: 62382
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62382, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7432, 'bonus': 0.011599710474839776, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61975, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 288 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5272276840910738
Updated goal-option-2 on 52 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29573, 'bonus': 0.005815034669558114, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62202, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7743246589811871
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 572 Step: 62439
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7454, 'bonus': 0.01158257992709921, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62302, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 289 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4600191158991234
Updated goal-option-2 on 19 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29579, 'bonus': 0.005814444859599411, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6510341632351887
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 573 Step: 62463
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7429, 'bonus': 0.011602052352546233, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61952, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 290 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4085553042730535
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29582, 'bonus': 0.005814150021913546, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6688628982154015
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 574 Step: 62484
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62484, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7448, 'bonus': 0.011587244366483038, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62234, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 291 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4516537775036315
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29576, 'bonus': 0.005814739742143809, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62261, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6612602998134044
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 575 Step: 62502
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62502, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7452, 'bonus': 0.011584134114281932, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62283, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 292 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5111838546316201
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29577, 'bonus': 0.005814641442977359, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6415524128469682
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 576 Step: 62522
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62522, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7444, 'bonus': 0.011590357125267592, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62197, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 293 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45624393396294743
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29581, 'bonus': 0.005814248296158588, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62382, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6683888673427559
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 577 Step: 62540
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62540, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7454, 'bonus': 0.01158257992709921, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62302, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 294 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4561685478935639
Updated goal-option-2 on 36 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29582, 'bonus': 0.005814150021913546, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.546664043161131
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 578 Step: 62581
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7440, 'bonus': 0.011593472394004208, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62159, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 295 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5101779889092486
Updated goal-option-2 on 21 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29569, 'bonus': 0.005815427975927827, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7259071056864091
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 579 Step: 62607
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62607, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7444, 'bonus': 0.011590357125267592, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62197, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 296 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4305911601724417
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29571, 'bonus': 0.005815231312767665, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62164, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7383311474792048
Updated goal-option-4 on 5 transitions
Took 0.04808950424194336s to update distance table with 512 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=580 Seed=18] Took 0.07291245460510254s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 580 Step: 62623
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62623, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7444, 'bonus': 0.011590357125267592, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62197, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 297 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43172448874675023
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29577, 'bonus': 0.005814641442977359, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.711374492175331
Updated goal-option-4 on 5 transitions
Took 0.0005116462707519531s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.889223575592041s to add potential edges.
================================================================================
[Consolidation] Episode: 581 Step: 62638
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62638, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7454, 'bonus': 0.01158257992709921, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62302, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 298 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.500684482321339
Updated goal-option-2 on 21 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.00047779083251953125s to update distance table with 22 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33774776 0.33774776 0.32450448]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7482, 'bonus': 0.01156088678177274, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62659, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29587, 'bonus': 0.0058136587254251785, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62540, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5657797005758499
Updated goal-option-4 on 5 transitions
Took 0.00023174285888671875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 582 Step: 62664
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62664, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7458, 'bonus': 0.011579473428470962, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62357, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 299 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46635791221863515
Updated goal-option-2 on 33 transitions
Took 0.0007867813110351562s to update distance table with 34 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.33774776 0.33774776 0.32450448]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7484, 'bonus': 0.01155934193152441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62697, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29577, 'bonus': 0.005814641442977359, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.683726896719025
Updated goal-option-4 on 5 transitions
Took 0.00021123886108398438s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 583 Step: 62702
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62702, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7448, 'bonus': 0.011587244366483038, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62234, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 300 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45325754761672865
Updated goal-option-2 on 10 transitions
Took 0.0003070831298828125s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.2624357  0.37615681 0.36140749]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7486, 'bonus': 0.011557797700413179, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62712, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29575, 'bonus': 0.005814838046295804, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62239, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5729102991503745
Updated goal-option-4 on 5 transitions
Took 0.00021123886108398438s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 584 Step: 62717
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4653, 'bonus': 0.01465998323778475, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5440286655533821
Updated goal-option-1 on 10 transitions
Took 0.0002593994140625s to update distance table with 11 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26053357 0.37343043 0.36603601]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4740, 'bonus': 0.014524822344353169, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62727, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7450, 'bonus': 0.011585688927269844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 301 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46919224276149896
Updated goal-option-2 on 3 transitions
Took 0.00021123886108398438s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.2624357  0.37615681 0.36140749]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7488, 'bonus': 0.011556254088025606, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29577, 'bonus': 0.005814641442977359, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5377468879688794
Updated goal-option-4 on 5 transitions
Took 0.00021338462829589844s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 585 Step: 62735
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34002178 0.33328889 0.32668933]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62735, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7450, 'bonus': 0.011585688927269844, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 302 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.500947786642782
Updated goal-option-2 on 26 transitions
Took 0.0006988048553466797s to update distance table with 27 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.2624357  0.37615681 0.36140749]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7490, 'bonus': 0.011554711093948627, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29592, 'bonus': 0.005813167553459632, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62664, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6811882271453249
Updated goal-option-4 on 4 transitions
Took 0.00017952919006347656s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 586 Step: 62765
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34113066 0.33437582 0.32449352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62765, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7474, 'bonus': 0.011567072382419582, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 303 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4082003227998264
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29585, 'bonus': 0.00581385522907484, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62502, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9770963600543744
Updated goal-option-4 on 6 transitions
Took 0.0006031990051269531s to update distance table with 20 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 587 Step: 62784
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34113066 0.33437582 0.32449352]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4673, 'bonus': 0.014628577924855639, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.480281669326188
Updated goal-option-1 on 5 transitions
Took 0.00019788742065429688s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26053357 0.37343043 0.36603601]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4741, 'bonus': 0.014523290432484293, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 15802, 'bonus': 0.007955069372286065, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56032, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.384951022391518
Updated goal-option-3 on 152 transitions
Took 0.005747079849243164s to update distance table with 153 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34113066 0.33437582 0.32449352]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 18055, 'bonus': 0.007442198571595894, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4634, 'bonus': 0.014690006409251194, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60395, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4448970218306436
Updated goal-option-1 on 5 transitions
Took 0.00019598007202148438s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26246473 0.37245519 0.36508008]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4772, 'bonus': 0.014476040267536081, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16211, 'bonus': 0.00785407595840826, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57713, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2578443708966989
Updated goal-option-3 on 50 transitions
Took 0.0017693042755126953s to update distance table with 51 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34113066 0.33437582 0.32449352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 18057, 'bonus': 0.0074417864098493035, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62996, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7491, 'bonus': 0.011553939828647636, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 304 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47031658058879017
Updated goal-option-2 on 30 transitions
Took 0.0008132457733154297s to update distance table with 31 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26728141 0.37551637 0.35720222]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7494, 'bonus': 0.011551626959076139, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29583, 'bonus': 0.005814051752651521, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7349941968358178
Updated goal-option-4 on 5 transitions
Took 0.00021505355834960938s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 588 Step: 63031
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63031, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4617, 'bonus': 0.014717026189611597, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.471228065765578
Updated goal-option-1 on 6 transitions
Took 0.00020766258239746094s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26344104 0.37012086 0.3664381 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4782, 'bonus': 0.014460896377767018, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63037, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7472, 'bonus': 0.011568620334568689, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62535, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 305 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4425878168522626
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29579, 'bonus': 0.005814444859599411, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62344, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46052661263536954
Updated goal-option-4 on 5 transitions
Took 0.0003311634063720703s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 589 Step: 63045
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63045, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7494, 'bonus': 0.011551626959076139, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 306 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.424233429910351
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29582, 'bonus': 0.005814150021913546, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4917630098569088
Updated goal-option-4 on 5 transitions
Took 0.0005347728729248047s to update distance table with 22 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 590 Step: 63066
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63066, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4772, 'bonus': 0.014476040267536081, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42412723777256245
Updated goal-option-1 on 5 transitions
Took 0.0001823902130126953s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26344104 0.37012086 0.3664381 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4784, 'bonus': 0.014457873299156005, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63071, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7491, 'bonus': 0.011553939828647636, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 307 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45574736259449483
Updated goal-option-2 on 3 transitions
Took 0.0001652240753173828s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26823477 0.3768558  0.35490943]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7500, 'bonus': 0.011547005383792516, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63074, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29581, 'bonus': 0.005814248296158588, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62382, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43272859806364233
Updated goal-option-4 on 5 transitions
Took 0.00020742416381835938s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.8881402015686035s to add potential edges.
================================================================================
[Consolidation] Episode: 591 Step: 63079
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7482, 'bonus': 0.01156088678177274, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62659, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 308 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5591058948031203
Updated goal-option-2 on 33 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29587, 'bonus': 0.0058136587254251785, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62540, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7325023656194305
Updated goal-option-4 on 5 transitions
Took 0.0010218620300292969s to update distance table with 39 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 592 Step: 63117
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63117, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4674, 'bonus': 0.014627012952620635, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61287, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4645660303515588
Updated goal-option-1 on 5 transitions
Took 0.0001823902130126953s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26344104 0.37012086 0.3664381 ]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4786, 'bonus': 0.014454852115694089, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16111, 'bonus': 0.00787841313857205, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0652892621875132
Updated goal-option-3 on 147 transitions
Took 0.005341291427612305s to update distance table with 148 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 593 Step: 63269
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63269, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7472, 'bonus': 0.011568620334568689, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62535, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 309 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42191199002422336
Updated goal-option-2 on 20 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.0004379749298095703s to update distance table with 21 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26722268 0.37920703 0.35357029]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7516, 'bonus': 0.011534708249969794, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29586, 'bonus': 0.005813756974759342, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62522, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7550182970878961
Updated goal-option-4 on 5 transitions
Took 0.00022554397583007812s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 594 Step: 63294
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63294, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4673, 'bonus': 0.014628577924855639, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5124794260244554
Updated goal-option-1 on 11 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00027942657470703125s to update distance table with 12 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26150524 0.3710936  0.36740116]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4798, 'bonus': 0.014436764702416779, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63305, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29586, 'bonus': 0.005813756974759342, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62522, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5223543315954592
Updated goal-option-4 on 78 transitions
Took 0.002953052520751953s to update distance table with 79 states and events {SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 595 Step: 63383
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63383, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7472, 'bonus': 0.011568620334568689, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62535, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 310 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4642408104497185
Updated goal-option-2 on 23 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29588, 'bonus': 0.005813560481071926, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5682138871872562
Updated goal-option-4 on 5 transitions
Took 0.0007078647613525391s to update distance table with 29 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 596 Step: 63411
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63411, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4772, 'bonus': 0.014476040267536081, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5086696918161823
Updated goal-option-1 on 6 transitions
Took 0.0001926422119140625s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.26150524 0.3710936  0.36740116]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4799, 'bonus': 0.014435260481031878, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63417, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29593, 'bonus': 0.005813069334004632, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62702, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7784946834728054
Updated goal-option-4 on 13 transitions
Took 0.0005202293395996094s to update distance table with 14 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 597 Step: 63430
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7518, 'bonus': 0.011533173869085058, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 311 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47699501506854114
Updated goal-option-2 on 23 transitions
Took 0.0005037784576416016s to update distance table with 24 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26526909 0.380218   0.35451291]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7522, 'bonus': 0.011530106943390869, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63453, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29598, 'bonus': 0.00581257831139705, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63031, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7255296370686461
Updated goal-option-4 on 5 transitions
Took 0.000213623046875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 598 Step: 63458
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34217939 0.33877465 0.31904595]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63458, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4633, 'bonus': 0.014691591690258264, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5793272035860876
Updated goal-option-1 on 14 transitions
Took 0.0004057884216308594s to update distance table with 15 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25957865 0.37206171 0.36835964]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4806, 'bonus': 0.01442474408026385, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7488, 'bonus': 0.011556254088025606, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 312 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47559812096999105
Updated goal-option-2 on 3 transitions
Took 0.0001800060272216797s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26526909 0.380218   0.35451291]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7524, 'bonus': 0.01152857439776791, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63475, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29600, 'bonus': 0.005812381937190964, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63066, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 195 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4310978740351657
Updated goal-option-4 on 5 transitions
Took 0.00020956993103027344s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 599 Step: 63480
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63480, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7498, 'bonus': 0.01154854529249894, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 313 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43668772049400967
Updated goal-option-2 on 15 transitions
Took 0.000530242919921875s to update distance table with 16 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26620813 0.38156395 0.35222792]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7526, 'bonus': 0.011527042463086008, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29607, 'bonus': 0.005811694784174143, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 196 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39393145022871295
Updated goal-option-4 on 5 transitions
Took 0.00021648406982421875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 600 Step: 63500
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34326912 0.33985354 0.31687734]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7476, 'bonus': 0.011565525051480625, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 314 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.503349693679305
Updated goal-option-2 on 38 transitions
Took 0.0008893013000488281s to update distance table with 39 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26425929 0.38257733 0.35316338]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7528, 'bonus': 0.011525511138939352, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63538, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29604, 'bonus': 0.005811989248480778, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63294, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 197 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5475078221733712
Updated goal-option-4 on 5 transitions
Took 0.00021004676818847656s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.9058198928833008s to add potential edges.
================================================================================
[Consolidation] Episode: 601 Step: 63543
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34435487 0.34092848 0.31471665]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4674, 'bonus': 0.014627012952620635, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61287, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4294584595756224
Updated goal-option-1 on 9 transitions
Took 0.0002281665802001953s to update distance table with 10 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4808, 'bonus': 0.014421743613444026, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7486, 'bonus': 0.011557797700413179, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62712, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 315 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46846588057601707
Updated goal-option-2 on 3 transitions
Took 0.00017642974853515625s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26519118 0.38392646 0.35088236]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7530, 'bonus': 0.011523980424922517, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63555, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29595, 'bonus': 0.0058128729100293776, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62735, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 198 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4643821413554843
Updated goal-option-4 on 5 transitions
Took 0.00021195411682128906s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 602 Step: 63560
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7484, 'bonus': 0.01155934193152441, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62697, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 316 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45249439001601477
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29611, 'bonus': 0.005811302234711744, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 199 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5665356973333964
Updated goal-option-4 on 6 transitions
Took 0.0005953311920166016s to update distance table with 23 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 603 Step: 63582
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63582, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4651, 'bonus': 0.014663134905721362, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4988519727486616
Updated goal-option-1 on 11 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.0002605915069580078s to update distance table with 12 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4810, 'bonus': 0.01441874501821181, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63593, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29607, 'bonus': 0.005811694784174143, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 200 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43271259810809076
Updated goal-option-4 on 25 transitions
Took 0.0011355876922607422s to update distance table with 26 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 604 Step: 63618
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7526, 'bonus': 0.011527042463086008, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 317 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4612683699259796
Updated goal-option-2 on 11 transitions
Took 0.00033283233642578125s to update distance table with 12 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.2661203  0.38527157 0.34860813]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7537, 'bonus': 0.011518627724791373, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29611, 'bonus': 0.005811302234711744, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63543, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 201 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5564272241448766
Updated goal-option-4 on 5 transitions
Took 0.000225067138671875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 605 Step: 63634
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7486, 'bonus': 0.011557797700413179, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62712, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 318 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43428665638352054
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29597, 'bonus': 0.005812676505964312, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 202 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6851252009001402
Updated goal-option-4 on 4 transitions
Took 0.0005266666412353516s to update distance table with 16 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 606 Step: 63649
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63649, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7532, 'bonus': 0.011522450320630448, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 319 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4614482192601607
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29614, 'bonus': 0.005811007874810091, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 203 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6675483315914601
Updated goal-option-4 on 5 transitions
Took 0.0005373954772949219s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 607 Step: 63666
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7516, 'bonus': 0.011534708249969794, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 320 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4166080559091607
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29602, 'bonus': 0.005812185582886661, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63117, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 204 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7328476065090572
Updated goal-option-4 on 5 transitions
Took 0.00047469139099121094s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 608 Step: 63679
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.3454366  0.34199945 0.31256396]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63679, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7494, 'bonus': 0.011551626959076139, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63026, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 321 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4531420292634099
Updated goal-option-2 on 10 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.0003025531768798828s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.2661203  0.38527157 0.34860813]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7544, 'bonus': 0.0115132824764626, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63689, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29601, 'bonus': 0.0058122837575513, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63079, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 205 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6178021784663467
Updated goal-option-4 on 5 transitions
Took 0.00021648406982421875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 609 Step: 63694
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4806, 'bonus': 0.01442474408026385, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4378202776869624
Updated goal-option-1 on 5 transitions
Took 0.00020384788513183594s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4833, 'bonus': 0.01438439506673677, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63699, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29619, 'bonus': 0.005810517374359755, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 206 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41896581287852075
Updated goal-option-4 on 18 transitions
Took 0.0006568431854248047s to update distance table with 19 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 610 Step: 63717
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4707, 'bonus': 0.014575648981554203, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5627418271372299
Updated goal-option-1 on 5 transitions
Took 0.0002295970916748047s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4836, 'bonus': 0.014379932713576269, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63722, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7498, 'bonus': 0.01154854529249894, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 322 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4408487188470113
Updated goal-option-2 on 3 transitions
Took 0.00016546249389648438s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26704661 0.38661262 0.34634078]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7548, 'bonus': 0.011510231387903271, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29607, 'bonus': 0.005811694784174143, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 207 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5027578230036629
Updated goal-option-4 on 5 transitions
Took 0.00021386146545410156s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.9083354473114014s to add potential edges.
================================================================================
[Consolidation] Episode: 611 Step: 63730
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4653, 'bonus': 0.01465998323778475, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60759, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 195 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7197260057210645
Updated goal-option-1 on 8 transitions
Took 0.00023674964904785156s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4837, 'bonus': 0.014378446185147881, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63738, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7516, 'bonus': 0.011534708249969794, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63289, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 323 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46716234480050417
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29617, 'bonus': 0.005810713559634543, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63666, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 208 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5088921403719319
Updated goal-option-4 on 5 transitions
Took 0.00031828880310058594s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 612 Step: 63746
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63746, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7548, 'bonus': 0.011510231387903271, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 324 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46027056649103537
Updated goal-option-2 on 7 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29621, 'bonus': 0.00581032120895485, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 209 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6830717953791221
Updated goal-option-4 on 4 transitions
Took 0.0004165172576904297s to update distance table with 12 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 613 Step: 63757
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63757, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7502, 'bonus': 0.01154546609092641, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 325 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40436910810480425
Updated goal-option-2 on 10 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.0002982616424560547s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26704661 0.38661262 0.34634078]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7553, 'bonus': 0.011506420936119473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29615, 'bonus': 0.005810909764782567, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 210 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4722758996321095
Updated goal-option-4 on 5 transitions
Took 0.00022077560424804688s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 614 Step: 63772
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34651428 0.3430664  0.31041932]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4806, 'bonus': 0.01442474408026385, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 196 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48809687319127
Updated goal-option-1 on 6 transitions
Took 0.00019478797912597656s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4839, 'bonus': 0.014375474510798661, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7518, 'bonus': 0.011533173869085058, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 326 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46671862711755185
Updated goal-option-2 on 3 transitions
Took 0.00022673606872558594s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26704661 0.38661262 0.34634078]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7555, 'bonus': 0.011504897814670467, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29612, 'bonus': 0.0058112041097742595, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 211 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4525196837382206
Updated goal-option-4 on 5 transitions
Took 0.0002231597900390625s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 615 Step: 63786
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63786, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7537, 'bonus': 0.011518627724791373, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 327 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4148415730631307
Updated goal-option-2 on 10 transitions
Took 0.00037169456481933594s to update distance table with 11 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26704661 0.38661262 0.34634078]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7557, 'bonus': 0.011503375297914687, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29614, 'bonus': 0.005811007874810091, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63618, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 212 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48179075298686963
Updated goal-option-4 on 5 transitions
Took 0.00021147727966308594s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 616 Step: 63801
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63801, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4798, 'bonus': 0.014436764702416779, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63305, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 197 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4317986345509204
Updated goal-option-1 on 8 transitions
Took 0.00030159950256347656s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25670848 0.37164576 0.37164576]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4840, 'bonus': 0.014373989364401724, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29625, 'bonus': 0.005809928937741267, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63786, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 213 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5619507429369709
Updated goal-option-4 on 56 transitions
Took 0.0019292831420898438s to update distance table with 57 states and events {SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 617 Step: 63865
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63865, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7532, 'bonus': 0.011522450320630448, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 328 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47639813252379387
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29621, 'bonus': 0.00581032120895485, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63730, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 214 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6162531254612309
Updated goal-option-4 on 5 transitions
Took 0.00054931640625s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 618 Step: 63881
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4799, 'bonus': 0.014435260481031878, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63417, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 198 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6369783177487248
Updated goal-option-1 on 5 transitions
Took 0.0002167224884033203s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25670848 0.37164576 0.37164576]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4843, 'bonus': 0.014369536685468597, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63886, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29618, 'bonus': 0.005810615464513204, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63679, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 215 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46815306235567417
Updated goal-option-4 on 13 transitions
Took 0.0004968643188476562s to update distance table with 14 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 619 Step: 63899
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63899, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7518, 'bonus': 0.011533173869085058, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 329 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3947319883162772
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29624, 'bonus': 0.0058100269980961815, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 216 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6244961840703207
Updated goal-option-4 on 5 transitions
Took 0.0004553794860839844s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 620 Step: 63914
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4707, 'bonus': 0.014575648981554203, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 199 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.505771194220143
Updated goal-option-1 on 7 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.0002503395080566406s to update distance table with 8 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25670848 0.37164576 0.37164576]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4845, 'bonus': 0.014366570530687187, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63921, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29619, 'bonus': 0.005810517374359755, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 217 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6054994217971319
Updated goal-option-4 on 41 transitions
Took 0.0014302730560302734s to update distance table with 42 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
Adding edge from goal-option-1 to goal-option-3-0
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.7601852416992188s to add potential edges.
================================================================================
[Consolidation] Episode: 621 Step: 63962
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7555, 'bonus': 0.011504897814670467, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 330 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4367134566787736
Updated goal-option-2 on 10 transitions
Took 0.0003006458282470703s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26900849 0.38557778 0.34541374]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7567, 'bonus': 0.011495771770546864, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29612, 'bonus': 0.0058112041097742595, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63560, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 218 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4770607814032544
Updated goal-option-4 on 5 transitions
Took 0.00025916099548339844s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 622 Step: 63977
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7524, 'bonus': 0.01152857439776791, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63475, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 331 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43898278752673187
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29615, 'bonus': 0.005810909764782567, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 219 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5178273854877359
Updated goal-option-4 on 5 transitions
Took 0.00046515464782714844s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 623 Step: 63990
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63990, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4798, 'bonus': 0.014436764702416779, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63305, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 200 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4901314274203487
Updated goal-option-1 on 5 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00018477439880371094s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25862121 0.37068939 0.37068939]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4852, 'bonus': 0.014356203435505359, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63995, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29628, 'bonus': 0.005809634786464582, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 220 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6070480488990685
Updated goal-option-4 on 45 transitions
Took 0.0015685558319091797s to update distance table with 46 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 624 Step: 64040
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34532365 0.34532365 0.30935271]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64040, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4840, 'bonus': 0.014373989364401724, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 201 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48250473146671774
Updated goal-option-1 on 7 transitions
Deleting edge from goal-option-1 to goal-option-3-0
Took 0.0002796649932861328s to update distance table with 8 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25862121 0.37068939 0.37068939]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4853, 'bonus': 0.014354724253240289, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64047, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7540, 'bonus': 0.011516335992621968, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63661, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 332 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4347853954931546
Updated goal-option-2 on 3 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.0001678466796875s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26900849 0.38557778 0.34541374]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7573, 'bonus': 0.011491216884901288, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29630, 'bonus': 0.00580943871043265, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 221 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3755109242920916
Updated goal-option-4 on 7 transitions
Took 0.0002846717834472656s to update distance table with 8 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 625 Step: 64057
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34638987 0.34638987 0.30722026]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64057, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7555, 'bonus': 0.011504897814670467, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 333 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5535280807200739
Updated goal-option-2 on 13 transitions
Took 0.0003993511199951172s to update distance table with 14 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26993624 0.38690755 0.34315621]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7577, 'bonus': 0.011488183300665509, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29623, 'bonus': 0.005810125063416471, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63757, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 222 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4209717409942307
Updated goal-option-4 on 5 transitions
Took 0.0002295970916748047s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 626 Step: 64075
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34638987 0.34638987 0.30722026]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64075, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7532, 'bonus': 0.011522450320630448, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63576, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 334 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5391649965594101
Updated goal-option-2 on 12 transitions
Took 0.00032639503479003906s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26993624 0.38690755 0.34315621]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7579, 'bonus': 0.011486667409215924, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64087, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29634, 'bonus': 0.005809046617919773, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64040, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 223 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42569955274652527
Updated goal-option-4 on 5 transitions
Took 0.00021147727966308594s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 627 Step: 64092
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34638987 0.34638987 0.30722026]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64092, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7555, 'bonus': 0.011504897814670467, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63781, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 335 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4555251661083839
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29625, 'bonus': 0.005809928937741267, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63786, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 224 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.590258654325631
Updated goal-option-4 on 5 transitions
Took 0.0004973411560058594s to update distance table with 15 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 628 Step: 64106
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34638987 0.34638987 0.30722026]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7553, 'bonus': 0.011506420936119473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 336 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4973592088901482
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29629, 'bonus': 0.005809536745966976, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63899, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 225 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45980845637745243
Updated goal-option-4 on 5 transitions
Took 0.0004744529724121094s to update distance table with 14 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 629 Step: 64119
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34638987 0.34638987 0.30722026]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7548, 'bonus': 0.011510231387903271, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 337 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.459246407490268
Updated goal-option-2 on 11 transitions
Took 0.0003314018249511719s to update distance table with 12 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26993624 0.38690755 0.34315621]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7585, 'bonus': 0.011482123332789982, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64130, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29632, 'bonus': 0.005809242654252164, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 226 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48074030520921013
Updated goal-option-4 on 4 transitions
Took 0.0001938343048095703s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
[Episode=630 Seed=18] Took 0.03762459754943848s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 630 Step: 64134
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 5.0	IntrinsicReward: -342.0706347630112
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 631 Step: 64134
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 4.0	IntrinsicReward: -371.63350866921246
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 632 Step: 64134
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -343.01065853540786
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 633 Step: 64134
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 10.0	IntrinsicReward: -348.6995821560704
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 634 Step: 64134
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64134, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4810, 'bonus': 0.01441874501821181, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63593, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 202 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5281581651609115
Updated goal-option-1 on 11 transitions
[RND Rollout] Reward: 4.0	IntrinsicReward: -349.6778707555495
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 635 Step: 64145
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 10.0	IntrinsicReward: -381.77223780192435
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 636 Step: 64145
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4843, 'bonus': 0.014369536685468597, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63886, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 203 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40922105682728066
Updated goal-option-1 on 10 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -270.16982721110253
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 637 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 7.0	IntrinsicReward: -353.4272746085189
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 638 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 12.0	IntrinsicReward: -376.2209044992924
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 639 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 5.0	IntrinsicReward: -404.37028427422047
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 640 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 12.0	IntrinsicReward: -375.6965270168148
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 641 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -374.1979889255017
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 642 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 6.0	IntrinsicReward: -386.99455855746055
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 643 Step: 64155
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 14.0	IntrinsicReward: -327.79756997316144
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 644 Step: 64155
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64155, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7573, 'bonus': 0.011491216884901288, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 338 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4146709356376792
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29626, 'bonus': 0.0058098308823513085, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63801, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 227 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8709633126068971
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 645 Step: 64170
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64170, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7581, 'bonus': 0.011485152117683809, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 339 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4522420186701534
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29633, 'bonus': 0.005809144633605165, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63990, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 228 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48766216561826975
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 646 Step: 64185
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7563, 'bonus': 0.011498811371808483, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63909, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 340 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37656428685652577
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29632, 'bonus': 0.005809242654252164, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 229 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48194773343330644
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 647 Step: 64203
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64203, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7557, 'bonus': 0.011503375297914687, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63796, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 341 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.459138228253082
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29631, 'bonus': 0.005809340679861186, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 230 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6412889048832018
Updated goal-option-4 on 6 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 648 Step: 64220
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64220, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7836, 'bonus': 0.011296730973114205, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64165, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 342 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38548674418004575
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29631, 'bonus': 0.005809340679861186, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63962, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 231 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5370954181257034
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 649 Step: 64235
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64235, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7581, 'bonus': 0.011485152117683809, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 343 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3675217663584289
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29633, 'bonus': 0.005809144633605165, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63990, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 232 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5213072812126117
Updated goal-option-4 on 4 transitions
Took 59.70154094696045s to update distance table with 14148 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=650 Seed=18] Took 0.0649118423461914s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])]
================================================================================
[Consolidation] Episode: 650 Step: 64248
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.347452   0.347452   0.30509601]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64248, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7581, 'bonus': 0.011485152117683809, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 344 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4598818371473025
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37435, 'bonus': 0.005168459068863817, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64170, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 233 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5539702206568898
Updated goal-option-4 on 4 transitions
Took 0.0004329681396484375s to update distance table with 14 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.8080501556396484s to add potential edges.
================================================================================
[Consolidation] Episode: 651 Step: 64261
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.347452   0.347452   0.30509601]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64261, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7567, 'bonus': 0.011495771770546864, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63972, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 345 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41408520578855484
Updated goal-option-2 on 13 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.00039577484130859375s to update distance table with 14 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.27086108 0.38823316 0.34090576]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7849, 'bonus': 0.011287371923446516, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64274, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29638, 'bonus': 0.005808654604785884, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 234 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.642083064278986
Updated goal-option-4 on 4 transitions
Took 0.00019288063049316406s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 652 Step: 64278
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.347452   0.347452   0.30509601]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64278, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7836, 'bonus': 0.011296730973114205, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64165, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 346 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4075257220143414
Updated goal-option-2 on 8 transitions
Took 0.0003142356872558594s to update distance table with 9 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.27086108 0.38823316 0.34090576]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7850, 'bonus': 0.011286652959662007, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37441, 'bonus': 0.005168044923983905, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64261, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 235 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47585800682815416
Updated goal-option-4 on 4 transitions
Took 0.00018286705017089844s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 653 Step: 64290
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64290, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7577, 'bonus': 0.011488183300665509, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 347 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4543073881516415
Updated goal-option-2 on 11 transitions
Took 0.00035762786865234375s to update distance table with 12 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.27178299 0.38955455 0.33866246]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7851, 'bonus': 0.011285934133245988, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64301, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29632, 'bonus': 0.005809242654252164, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 236 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.562184947465236
Updated goal-option-4 on 4 transitions
Took 0.00018072128295898438s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 654 Step: 64305
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64305, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7579, 'bonus': 0.011486667409215924, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64087, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 348 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4579663118384701
Updated goal-option-2 on 7 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37444, 'bonus': 0.005167837888873729, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64305, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 237 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46265744523455704
Updated goal-option-4 on 4 transitions
Took 0.0003917217254638672s to update distance table with 12 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 655 Step: 64316
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7581, 'bonus': 0.011485152117683809, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 349 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3830516526504331
Updated goal-option-2 on 7 transitions
Took 0.00026345252990722656s to update distance table with 8 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.27178299 0.38955455 0.33866246]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7853, 'bonus': 0.011284496892344491, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64323, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37443, 'bonus': 0.005167906897812444, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64290, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 238 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5143544404689843
Updated goal-option-4 on 4 transitions
Took 0.0002193450927734375s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 656 Step: 64327
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7836, 'bonus': 0.011296730973114205, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64165, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 350 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48063547710248705
Updated goal-option-2 on 8 transitions
Took 0.0003199577331542969s to update distance table with 9 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.27178299 0.38955455 0.33866246]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7854, 'bonus': 0.011283778477771594, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37443, 'bonus': 0.005167906897812444, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64290, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 239 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.575120129777161
Updated goal-option-4 on 5 transitions
Took 0.00020933151245117188s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 657 Step: 64340
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64340, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7848, 'bonus': 0.011288091024643272, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 351 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40447483477886986
Updated goal-option-2 on 26 transitions
Took 0.0008656978607177734s to update distance table with 27 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.27178299 0.38955455 0.33866246]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7856, 'bonus': 0.011282342060163104, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29634, 'bonus': 0.005809046617919773, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64040, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 240 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.600521895945589
Updated goal-option-4 on 5 transitions
Took 0.00022530555725097656s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 658 Step: 64371
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4784, 'bonus': 0.014457873299156005, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63071, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 204 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4890034548946867
Updated goal-option-1 on 8 transitions
Deleting edge from SE([3 2]) to goal-option-1
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00030732154846191406s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25862121 0.37068939 0.37068939]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4875, 'bonus': 0.014322297480788657, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64379, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 29637, 'bonus': 0.00580875260062904, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64092, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 241 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3580698354890875
Updated goal-option-4 on 9 transitions
Took 0.0003521442413330078s to update distance table with 10 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 659 Step: 64388
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64388, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7850, 'bonus': 0.011286652959662007, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 352 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4245994314879573
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37446, 'bonus': 0.005167699879289406, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64327, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 242 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5244637313713445
Updated goal-option-4 on 5 transitions
Took 0.00046825408935546875s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 660 Step: 64403
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7845, 'bonus': 0.011290249153144905, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64230, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 353 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5303996205766559
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 29638, 'bonus': 0.005808654604785884, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 243 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5762801735196751
Updated goal-option-4 on 5 transitions
Took 0.0004787445068359375s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Took 1.9383654594421387s to add potential edges.
================================================================================
[Consolidation] Episode: 661 Step: 64419
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7840, 'bonus': 0.011293848786315641, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64198, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 354 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45599541518386905
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37440, 'bonus': 0.0051681139412170195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64248, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 244 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3947522044871692
Updated goal-option-4 on 6 transitions
Took 0.0005774497985839844s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 662 Step: 64437
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64437, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7845, 'bonus': 0.011290249153144905, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64230, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 355 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4146338912892586
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37451, 'bonus': 0.0051673549036964405, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 245 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4124235638758405
Updated goal-option-4 on 5 transitions
Took 0.0004839897155761719s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 663 Step: 64453
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64453, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7860, 'bonus': 0.011279470869873538, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64398, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 356 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4618870408453963
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37436, 'bonus': 0.005168390037803012, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 246 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4515083360911151
Updated goal-option-4 on 5 transitions
Took 0.00047016143798828125s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 664 Step: 64468
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64468, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7867, 'bonus': 0.011274451557073644, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 357 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4472957237114561
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37442, 'bonus': 0.005167975909515774, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64278, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 247 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39537379467560924
Updated goal-option-4 on 5 transitions
Took 0.0004973411560058594s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 665 Step: 64485
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64485, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4808, 'bonus': 0.014421743613444026, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 205 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5104475328322787
Updated goal-option-1 on 5 transitions
Took 0.00019025802612304688s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25670848 0.37164576 0.37164576]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4884, 'bonus': 0.014309095175803562, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.1875704725295383
Updated goal-option-3-0 on 173 transitions
Deleting edge from goal-option-4 to goal-option-3-0
Deleting edge from SE([6 6]) to goal-option-3-0
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 17192, 'bonus': 0.007626702374631812, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8590052634080253
Updated goal-option-3 on 65 transitions
Took 0.009690284729003906s to update distance table with 239 states and events {SE([1 1]), SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34956382 0.34956382 0.30087237]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 18485, 'bonus': 0.007355128634509844, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64728, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7854, 'bonus': 0.011283778477771594, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64335, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.4348573426992505
Updated goal-option-2 on 13 transitions
Took 0.0003268718719482422s to update distance table with 14 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 666 Step: 64741
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7862, 'bonus': 0.011278036096494982, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64414, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 358 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4056003783359104
Updated goal-option-2 on 26 transitions
Took 0.0008552074432373047s to update distance table with 27 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7906, 'bonus': 0.011246608955715614, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37444, 'bonus': 0.005167837888873729, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64305, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 248 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6700743255992547
Updated goal-option-4 on 5 transitions
Took 0.00020647048950195312s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 667 Step: 64772
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7840, 'bonus': 0.011293848786315641, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64198, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 359 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.384951922153238
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37439, 'bonus': 0.005168182961215302, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64235, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 249 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5678264084510155
Updated goal-option-4 on 4 transitions
Took 0.0006268024444580078s to update distance table with 18 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 668 Step: 64789
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7906, 'bonus': 0.011246608955715614, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 360 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3938205188211965
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37440, 'bonus': 0.0051681139412170195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64248, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 250 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4492369571011247
Updated goal-option-4 on 6 transitions
Took 0.0005424022674560547s to update distance table with 21 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 669 Step: 64809
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7856, 'bonus': 0.011282342060163104, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 361 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4496163211129849
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37447, 'bonus': 0.005167630878643428, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64340, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 251 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41406365365155634
Updated goal-option-4 on 5 transitions
Took 0.0004303455352783203s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 670 Step: 64822
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64822, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4833, 'bonus': 0.01438439506673677, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63699, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 206 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4944593811186402
Updated goal-option-1 on 5 transitions
Took 0.00019931793212890625s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4919, 'bonus': 0.014258097780117078, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7852, 'bonus': 0.011285215444154723, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 362 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42478108673898224
Updated goal-option-2 on 3 transitions
Took 0.0001628398895263672s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7914, 'bonus': 0.011240923106537388, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37450, 'bonus': 0.005167423893288018, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 252 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5036759199174635
Updated goal-option-4 on 5 transitions
Took 0.00021338462829589844s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.9979898929595947s to add potential edges.
================================================================================
[Consolidation] Episode: 671 Step: 64835
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64835, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7909, 'bonus': 0.011244475751329648, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 363 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4641852568511082
Updated goal-option-2 on 7 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.00026416778564453125s to update distance table with 8 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7916, 'bonus': 0.011239502991174948, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64842, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37454, 'bonus': 0.005167147951499805, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64468, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 253 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40109486014741225
Updated goal-option-4 on 4 transitions
Took 0.0001888275146484375s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 672 Step: 64846
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64846, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7914, 'bonus': 0.011240923106537388, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 364 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39714544089376064
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37454, 'bonus': 0.005167147951499805, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64468, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 254 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4216031354465863
Updated goal-option-4 on 4 transitions
Took 0.0004379749298095703s to update distance table with 13 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 673 Step: 64858
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64858, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4840, 'bonus': 0.014373989364401724, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 207 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4593929175132357
Updated goal-option-1 on 8 transitions
Took 0.0002562999725341797s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4920, 'bonus': 0.014256648712805027, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7916, 'bonus': 0.011239502991174948, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64842, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 365 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44599532435877604
Updated goal-option-2 on 3 transitions
Took 0.00017547607421875s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7918, 'bonus': 0.01123808341390485, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64869, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37456, 'bonus': 0.00516700999718195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 255 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6131279487162828
Updated goal-option-4 on 6 transitions
Took 0.0002353191375732422s to update distance table with 7 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 674 Step: 64875
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64875, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4852, 'bonus': 0.014356203435505359, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63995, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 208 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5162080344369356
Updated goal-option-1 on 5 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.0001823902130126953s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4921, 'bonus': 0.014255200087214454, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16000, 'bonus': 0.007905694150420948, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56619, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8055131260960746
Updated goal-option-3 on 118 transitions
Took 0.004056215286254883s to update distance table with 119 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 675 Step: 64998
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7853, 'bonus': 0.011284496892344491, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64323, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 366 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4486923558772474
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37450, 'bonus': 0.005167423893288018, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64403, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 256 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4506543187719838
Updated goal-option-4 on 5 transitions
Took 0.0004417896270751953s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 676 Step: 65011
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7856, 'bonus': 0.011282342060163104, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 367 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3874005576836744
Updated goal-option-2 on 9 transitions
Took 0.0003337860107421875s to update distance table with 10 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7926, 'bonus': 0.011232410478957853, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37465, 'bonus': 0.005166389339460047, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 257 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.579155696866826
Updated goal-option-4 on 4 transitions
Took 0.0001761913299560547s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 677 Step: 65024
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7869, 'bonus': 0.011273018698002334, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 368 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4041912483262869
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37448, 'bonus': 0.005167561880761327, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 258 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5328994008402029
Updated goal-option-4 on 5 transitions
Took 0.0004918575286865234s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 678 Step: 65040
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65040, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4919, 'bonus': 0.014258097780117078, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 209 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3825463226129269
Updated goal-option-1 on 5 transitions
Took 0.00020623207092285156s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([6 6]), SE([6 2])] | Probabilities: [0.50249998 0.49750002]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4932, 'bonus': 0.01423929429527935, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65045, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 37459, 'bonus': 0.005166803086421333, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64822, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 259 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49294922772168864
Updated goal-option-4 on 22 transitions
Took 0.0008122920989990234s to update distance table with 23 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 679 Step: 65067
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7914, 'bonus': 0.011240923106537388, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 369 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3974614509181113
Updated goal-option-2 on 13 transitions
Took 0.00037670135498046875s to update distance table with 14 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7931, 'bonus': 0.01122886925421618, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37468, 'bonus': 0.005166182503249429, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 260 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4320121791258633
Updated goal-option-4 on 5 transitions
Took 0.0002372264862060547s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 680 Step: 65085
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65085, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7906, 'bonus': 0.011246608955715614, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 370 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39987823956284513
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37451, 'bonus': 0.0051673549036964405, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 261 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5001765585927122
Updated goal-option-4 on 5 transitions
Took 0.00046753883361816406s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-3
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.9202566146850586s to add potential edges.
================================================================================
[Consolidation] Episode: 681 Step: 65101
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4808, 'bonus': 0.014421743613444026, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63552, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 210 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4230694753556758
Updated goal-option-1 on 5 transitions
Took 0.00018477439880371094s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.2576613  0.37302518 0.36931352]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4940, 'bonus': 0.014227759830611805, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7933, 'bonus': 0.011227453701830573, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65096, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 371 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43086173662762617
Updated goal-option-2 on 3 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.00016045570373535156s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 7935, 'bonus': 0.01122603868465918, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37470, 'bonus': 0.005166044626242685, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 262 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4971944110984185
Updated goal-option-4 on 5 transitions
Took 0.00020885467529296875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 682 Step: 65114
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65114, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4839, 'bonus': 0.014375474510798661, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63778, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 211 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4676328124414231
Updated goal-option-1 on 5 transitions
Deleting edge from goal-option-1 to goal-option-3
Took 0.00018334388732910156s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 6]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4941, 'bonus': 0.014226319992543996, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7867, 'bonus': 0.011274451557073644, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 372 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42317512007309244
Updated goal-option-2 on 3 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37454, 'bonus': 0.005167147951499805, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64468, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 263 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39356636048769617
Updated goal-option-4 on 5 transitions
Took 0.0003185272216796875s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 683 Step: 65127
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65127, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7906, 'bonus': 0.011246608955715614, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64767, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 373 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49017151627526
Updated goal-option-2 on 14 transitions
Took 0.0003523826599121094s to update distance table with 15 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0-0 on 10 transitions
Rolling out goal-option-3-0, from [4 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.33532742445675945
Updated goal-option-3-0 on 1 transitions
True
False
[Planner] Rolling out from {'count': 4943, 'bonus': 0.01422344162731625, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65152, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16111, 'bonus': 0.00787841313857205, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57067, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0354164293967187
Updated goal-option-3 on 47 transitions
Deleting edge from goal-option-3 to goal-option-3-0
Took 0.0021088123321533203s to update distance table with 59 states and events {SE([3 2]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 684 Step: 65199
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65199, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7869, 'bonus': 0.011273018698002334, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64463, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 374 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4670864681896329
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37459, 'bonus': 0.005166803086421333, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64822, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 264 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40191466376155677
Updated goal-option-4 on 5 transitions
Took 0.0004584789276123047s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 685 Step: 65214
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4836, 'bonus': 0.014379932713576269, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63722, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 212 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5175205712512836
Updated goal-option-1 on 5 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.00018477439880371094s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25575322 0.37398399 0.37026279]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4947, 'bonus': 0.014217690134308215, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 37454, 'bonus': 0.005167147951499805, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64468, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 265 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6309822055821618
Updated goal-option-4 on 34 transitions
Took 0.0015866756439208984s to update distance table with 35 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 686 Step: 65253
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65253, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7912, 'bonus': 0.011242343760332197, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 375 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4221633532521875
Updated goal-option-2 on 9 transitions
Took 0.0003552436828613281s to update distance table with 10 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Unconnected Events: [SE([1 1]), SE([3 2])] | Probs: [[1.0000000e+00 3.3382378e-15]]
[BoltzmannClosest] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Revised planner goal vertex to SE([6 2]) and dsc goal vertex to SE([1 1])
Planner goal: SE([6 2]), DSC goal: SE([1 1]) and Goal: SE([1 1])
False
False
Rolling out DSC with goal vertex SE([1 1])
Rolling out goal-option-3-0-0, from [6 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-3-0-0 on 10 transitions
Rolling out goal-option-3-0, from [4 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.26558926430885227
Updated goal-option-3-0 on 3 transitions
True
False
[Planner] Rolling out from {'count': 4978, 'bonus': 0.014173351371926586, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16318, 'bonus': 0.007828283327484668, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58080, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0763037957442112
Updated goal-option-3 on 234 transitions
Took 0.008743762969970703s to update distance table with 248 states and events {SE([3 2]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 687 Step: 65509
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65509, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4947, 'bonus': 0.014217690134308215, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 213 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.427095776229653
Updated goal-option-1 on 5 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00014400482177734375s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25385444 0.37493813 0.37120743]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 4982, 'bonus': 0.014167660405476751, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.23493323151376988
Updated goal-option-3-0 on 9 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [4 2] targeting {'count': 16916, 'bonus': 0.00768866894674349, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59064, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3276331017490561
Updated goal-option-3 on 242 transitions
Took 0.008381366729736328s to update distance table with 252 states and events {SE([6 2]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 688 Step: 65765
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65765, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7914, 'bonus': 0.011240923106537388, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 376 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40087414116480913
Updated goal-option-2 on 21 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37456, 'bonus': 0.00516700999718195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 266 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4523007759440039
Updated goal-option-4 on 6 transitions
Took 0.0006613731384277344s to update distance table with 28 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 689 Step: 65792
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7939, 'bonus': 0.011223210254610594, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65141, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 377 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43839293520330386
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37457, 'bonus': 0.00516694102416644, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 267 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4735333066108445
Updated goal-option-4 on 4 transitions
Took 0.00043010711669921875s to update distance table with 14 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 690 Step: 65805
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65805, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7935, 'bonus': 0.01122603868465918, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 378 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4871932915568779
Updated goal-option-2 on 19 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37456, 'bonus': 0.00516700999718195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64772, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 268 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48472608005007106
Updated goal-option-4 on 5 transitions
Took 0.0007846355438232422s to update distance table with 25 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-1 to goal-option-4
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-4
Adding edge from goal-option-4 to goal-option-3-0
Adding edge from SE([1 1]) to goal-option-3-0
Adding edge from SE([6 6]) to goal-option-3-0
Took 2.0090320110321045s to add potential edges.
================================================================================
[Consolidation] Episode: 691 Step: 65829
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65829, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7912, 'bonus': 0.011242343760332197, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 379 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3653286648888172
Updated goal-option-2 on 7 transitions
Took 0.0002646446228027344s to update distance table with 8 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26484102 0.39509638 0.3400626 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7992, 'bonus': 0.011185934253567072, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37465, 'bonus': 0.005166389339460047, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 269 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4853412739899647
Updated goal-option-4 on 4 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0002048015594482422s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 692 Step: 65840
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65840, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4840, 'bonus': 0.014373989364401724, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 214 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5261645566283769
Updated goal-option-1 on 8 transitions
Took 0.0002162456512451172s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25196498 0.37588758 0.37214744]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4987, 'bonus': 0.014160556328208415, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65848, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 37472, 'bonus': 0.005165906760274492, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65127, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 270 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5958094048429523
Updated goal-option-4 on 17 transitions
Took 0.0006859302520751953s to update distance table with 18 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 693 Step: 65865
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65865, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7933, 'bonus': 0.011227453701830573, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65096, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 380 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45694837484705947
Updated goal-option-2 on 8 transitions
Took 0.00029754638671875s to update distance table with 9 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26484102 0.39509638 0.3400626 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7995, 'bonus': 0.011183835382312352, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65873, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37472, 'bonus': 0.005165906760274492, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65127, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 271 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.361585259540429
Updated goal-option-4 on 4 transitions
Took 0.00017714500427246094s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 694 Step: 65877
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35184091 0.34834004 0.29981905]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4919, 'bonus': 0.014258097780117078, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 215 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48903454226555826
Updated goal-option-1 on 6 transitions
Took 0.00019097328186035156s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25196498 0.37588758 0.37214744]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4997, 'bonus': 0.014146380174561475, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65883, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 7954, 'bonus': 0.01121262265099487, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65262, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 381 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41533555585000986
Updated goal-option-2 on 3 transitions
Took 0.00017595291137695312s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26484102 0.39509638 0.3400626 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 7996, 'bonus': 0.01118313602106461, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65886, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37465, 'bonus': 0.005166389339460047, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 272 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3761832924694348
Updated goal-option-4 on 5 transitions
Took 0.00020885467529296875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 695 Step: 65891
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65891, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7954, 'bonus': 0.01121262265099487, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65262, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 382 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40296860217920466
Updated goal-option-2 on 17 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37466, 'bonus': 0.005166320391296195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 273 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5143491807667648
Updated goal-option-4 on 5 transitions
Took 0.0005600452423095703s to update distance table with 23 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 696 Step: 65913
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.35078392 0.34729356 0.30192252]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65913, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4982, 'bonus': 0.014167660405476751, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 216 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5804528320999178
Updated goal-option-1 on 5 transitions
Took 0.00018548965454101562s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25196498 0.37588758 0.37214744]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 4999, 'bonus': 0.014143550049460722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65918, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 37462, 'bonus': 0.005166596200515691, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64858, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.45891987760396963
Updated goal-option-4 on 251 transitions
Took 0.008260965347290039s to update distance table with 252 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 697 Step: 66169
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66169, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7935, 'bonus': 0.01122603868465918, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 383 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3989013396123748
Updated goal-option-2 on 11 transitions
Took 0.00030922889709472656s to update distance table with 12 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26588629 0.39270895 0.34140476]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8000, 'bonus': 0.011180339887498949, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66180, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37480, 'bonus': 0.005165355406757765, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65865, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 274 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4753529989307986
Updated goal-option-4 on 5 transitions
Took 0.0002570152282714844s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 698 Step: 66185
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34850999 0.34850999 0.30298003]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7917, 'bonus': 0.011238793135299597, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64854, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.40805127243339706
Updated goal-option-2 on 109 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Took 0.003562450408935547s to update distance table with 110 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 699 Step: 66294
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34972273 0.34624293 0.30403434]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66294, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7926, 'bonus': 0.011232410478957853, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65020, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 384 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4105148908034147
Updated goal-option-2 on 15 transitions
Took 0.0004858970642089844s to update distance table with 16 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26588629 0.39270895 0.34140476]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 8002, 'bonus': 0.011178942606997647, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66309, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37465, 'bonus': 0.005166389339460047, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65011, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 275 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5443856897114149
Updated goal-option-4 on 5 transitions
Took 0.00020885467529296875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
[Episode=700 Seed=18] Took 0.044037818908691406s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 700 Step: 66314
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7986, 'bonus': 0.011190135543575704, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65786, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 385 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5096007825704744
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37482, 'bonus': 0.005165217595960232, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65891, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 276 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49935425605711553
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 701 Step: 66331
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66331, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7998, 'bonus': 0.011181737692078706, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 386 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44748808464682693
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37466, 'bonus': 0.005166320391296195, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 277 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38889739096395726
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 702 Step: 66348
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66348, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7939, 'bonus': 0.011223210254610594, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65141, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 387 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4039905168855866
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37470, 'bonus': 0.005166044626242685, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 278 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5171460974222036
Updated goal-option-4 on 5 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 703 Step: 66366
================================================================================
Attempting to expand SE([6 6])
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66366, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7992, 'bonus': 0.011185934253567072, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 388 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43865996294952164
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37488, 'bonus': 0.0051648042297400545, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66348, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 279 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5534745139141758
Updated goal-option-4 on 6 transitions
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 704 Step: 66381
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66381, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8008, 'bonus': 0.011174753906691854, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66361, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 389 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3708056285186432
Updated goal-option-2 on 10 transitions
[RND Rollout] Reward: 10.0	IntrinsicReward: -343.388797882013
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 705 Step: 66391
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4982, 'bonus': 0.014167660405476751, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 217 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4372150746841817
Updated goal-option-1 on 6 transitions
[RND Rollout] Reward: 18.0	IntrinsicReward: -333.3069990351796
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 706 Step: 66397
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 12.0	IntrinsicReward: -346.1008107631933
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 707 Step: 66397
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4932, 'bonus': 0.01423929429527935, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65045, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 218 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5024094899486937
Updated goal-option-1 on 7 transitions
[RND Rollout] Reward: 14.0	IntrinsicReward: -358.2232500035316
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 708 Step: 66404
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66404, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4941, 'bonus': 0.014226319992543996, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 219 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49599643959886963
Updated goal-option-1 on 9 transitions
[RND Rollout] Reward: 14.0	IntrinsicReward: -345.981517074164
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 709 Step: 66413
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 19.0	IntrinsicReward: -394.9964528863784
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 710 Step: 66413
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 17.0	IntrinsicReward: -266.3860055700643
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 711 Step: 66413
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4863, 'bonus': 0.014339957533712639, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64155, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 220 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4433545143903997
Updated goal-option-1 on 5 transitions
Deleting edge from SE([3 2]) to goal-option-1
[RND Rollout] Reward: 22.0	IntrinsicReward: -306.9953444849234
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 712 Step: 66418
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7935, 'bonus': 0.01122603868465918, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65109, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 390 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4309502848281326
Updated goal-option-2 on 11 transitions
[RND Rollout] Reward: 26.0	IntrinsicReward: -367.4942429102957
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 713 Step: 66429
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 17.0	IntrinsicReward: -314.81434525130317
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 714 Step: 66429
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 25.0	IntrinsicReward: -355.79390235603205
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 715 Step: 66429
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 22.0	IntrinsicReward: -332.96756190015003
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 716 Step: 66429
================================================================================
Attempting to expand SE([6 2])
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66429, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7950, 'bonus': 0.011215443081840885, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65209, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 391 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4497131004108715
Updated goal-option-2 on 10 transitions
[RND Rollout] Reward: 27.0	IntrinsicReward: -346.8294675243087
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 717 Step: 66439
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4947, 'bonus': 0.014217690134308215, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 221 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47429611461832527
Updated goal-option-1 on 6 transitions
[RND Rollout] Reward: 31.0	IntrinsicReward: -381.8297177106142
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 718 Step: 66445
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 25.0	IntrinsicReward: -365.22668471280485
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 719 Step: 66445
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 26.0	IntrinsicReward: -301.74419240653515
Accepted New Salient Event:  SE([2 5])
[DSGTrainer] Adding new SalientEvent  SE([2 5])
Took 61.49450421333313s to update distance table with 16167 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2]), SE([2 5])}
[Episode=720 Seed=18] Took 0.08780527114868164s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 720 Step: 66445
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[DeepSkillGraphsAgent] Creating chain from SE([6 6]) -> SE([2 5])
Creating classifier of type cnn
Created model-free option goal-option-5 with option_idx=8
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7986, 'bonus': 0.011190135543575704, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65786, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 392 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38786618084788826
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37486, 'bonus': 0.005164942007452849, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 280 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48567336392884997
Updated goal-option-4 on 5 transitions
Took 0.0006465911865234375s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.9608585834503174s to add potential edges.
================================================================================
[Consolidation] Episode: 721 Step: 66462
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66462, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7992, 'bonus': 0.011185934253567072, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65836, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 393 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4043544974910532
Updated goal-option-2 on 11 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37483, 'bonus': 0.005165148694697703, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65913, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 281 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48632381008022785
Updated goal-option-4 on 5 transitions
Took 0.0005366802215576172s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 722 Step: 66478
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8357, 'bonus': 0.010938928884083116, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66457, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 394 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40061611458764185
Updated goal-option-2 on 12 transitions
Took 0.0003612041473388672s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8361, 'bonus': 0.01093631191541311, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66490, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37481, 'bonus': 0.005165286499980192, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 282 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35819840399630953
Updated goal-option-4 on 5 transitions
Took 0.0002372264862060547s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 723 Step: 66495
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7989, 'bonus': 0.011188034306951495, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65801, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 395 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41046303626033104
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44882, 'bonus': 0.00472023802683612, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 283 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3849003492151129
Updated goal-option-4 on 5 transitions
Took 0.0005548000335693359s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 724 Step: 66508
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8357, 'bonus': 0.010938928884083116, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66457, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 396 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4131515986075214
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44883, 'bonus': 0.004720185442736138, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 284 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6205442088916612
Updated goal-option-4 on 5 transitions
Took 0.0005512237548828125s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 725 Step: 66525
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66525, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8363, 'bonus': 0.010935004135209283, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66503, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 397 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39429618374728787
Updated goal-option-2 on 12 transitions
Took 0.0003616809844970703s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26406508 0.39001905 0.34591587]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 8367, 'bonus': 0.01093238998166124, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66537, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37477, 'bonus': 0.005165562143637999, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65805, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 285 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47684177051216253
Updated goal-option-4 on 5 transitions
Took 0.00023746490478515625s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 726 Step: 66542
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7995, 'bonus': 0.011183835382312352, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65873, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 398 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41730294470058066
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37482, 'bonus': 0.005165217595960232, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65891, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 286 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.531744945259101
Updated goal-option-4 on 5 transitions
Took 0.0005059242248535156s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 727 Step: 66555
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66555, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8213, 'bonus': 0.011034409283607301, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66429, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 399 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4210426444181225
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37481, 'bonus': 0.005165286499980192, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 287 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3993118090169901
Updated goal-option-4 on 5 transitions
Took 0.0005230903625488281s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 728 Step: 66570
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66570, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8004, 'bonus': 0.011177545850247397, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66326, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 400 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4057904612086027
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44883, 'bonus': 0.004720185442736138, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 288 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37115800502020346
Updated goal-option-4 on 5 transitions
Took 0.0006234645843505859s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 729 Step: 66586
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66586, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 7998, 'bonus': 0.011181737692078706, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 401 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41675326218228553
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44885, 'bonus': 0.004720080279808104, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66525, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 289 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3753166607377075
Updated goal-option-4 on 5 transitions
Took 0.0006010532379150391s to update distance table with 22 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 730 Step: 66607
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66607, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8279, 'bonus': 0.01099033824440432, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 402 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47942469658262254
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37483, 'bonus': 0.005165148694697703, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65913, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 290 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.460879573431753
Updated goal-option-4 on 5 transitions
Took 0.0005116462707519531s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-4
Took 1.8062477111816406s to add potential edges.
================================================================================
[Consolidation] Episode: 731 Step: 66621
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66621, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8010, 'bonus': 0.011173358719233181, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 403 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.409693936824507
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44882, 'bonus': 0.00472023802683612, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 291 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.6212617086441744
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0005125999450683594s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 732 Step: 66634
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8357, 'bonus': 0.010938928884083116, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66457, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 404 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4539045894806157
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44881, 'bonus': 0.004720290612693544, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66462, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 292 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.47535270697324344
Updated goal-option-4 on 5 transitions
Took 0.0005602836608886719s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 733 Step: 66650
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34865738 0.34518818 0.30615445]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8008, 'bonus': 0.011174753906691854, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66361, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 405 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.520290596860057
Updated goal-option-2 on 17 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44886, 'bonus': 0.004720027700979857, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 293 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5482398733200337
Updated goal-option-4 on 5 transitions
Took 0.0006194114685058594s to update distance table with 23 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 734 Step: 66672
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66672, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8010, 'bonus': 0.011173358719233181, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66375, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 406 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39707033823515747
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 37490, 'bonus': 0.005164666463052564, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66381, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 294 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4782714371456567
Updated goal-option-4 on 5 transitions
Took 0.0005638599395751953s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 735 Step: 66690
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66690, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8279, 'bonus': 0.01099033824440432, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66439, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 407 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4050781284951988
Updated goal-option-2 on 8 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44887, 'bonus': 0.00471997512390866, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66555, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 295 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3863998467850527
Updated goal-option-4 on 5 transitions
Took 0.0005183219909667969s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 736 Step: 66703
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8379, 'bonus': 0.010924558755741037, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66629, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 408 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36394388650698883
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44896, 'bonus': 0.00471950200931897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 296 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44267345653762186
Updated goal-option-4 on 5 transitions
Took 0.0005865097045898438s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 737 Step: 66720
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66720, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8363, 'bonus': 0.010935004135209283, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66503, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 409 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4090498463874819
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44896, 'bonus': 0.00471950200931897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 297 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36614178597450037
Updated goal-option-4 on 5 transitions
Took 0.0005524158477783203s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 738 Step: 66734
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66734, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8389, 'bonus': 0.010918045574004427, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 410 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45291420574713914
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44889, 'bonus': 0.004719869975037023, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66586, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 298 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45287064862790083
Updated goal-option-4 on 5 transitions
Took 0.0005319118499755859s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 739 Step: 66749
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66749, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8391, 'bonus': 0.010916744335030258, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 411 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42563090480217136
Updated goal-option-2 on 29 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44886, 'bonus': 0.004720027700979857, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 299 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43065243747555376
Updated goal-option-4 on 6 transitions
Took 0.0015566349029541016s to update distance table with 36 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 740 Step: 66784
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8357, 'bonus': 0.010938928884083116, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66457, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 412 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35089900109165667
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44898, 'bonus': 0.004719396892062777, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66734, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 300 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42649046321120637
Updated goal-option-4 on 5 transitions
Took 0.0005552768707275391s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-4
Took 1.8379647731781006s to add potential edges.
================================================================================
[Consolidation] Episode: 741 Step: 66801
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34865738 0.34518818 0.30615445]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66801, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4920, 'bonus': 0.014256648712805027, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64866, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 222 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5073823673742903
Updated goal-option-1 on 5 transitions
Took 0.0002105236053466797s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25385444 0.37493813 0.37120743]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5156, 'bonus': 0.01392655009388382, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66806, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 44893, 'bonus': 0.004719659698374038, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 301 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36622641730127614
Updated goal-option-4 on 8 transitions
Took 0.0003581047058105469s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 742 Step: 66814
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8359, 'bonus': 0.010937620164944128, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66473, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 413 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4332937374478691
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44896, 'bonus': 0.00471950200931897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 302 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4422098221082924
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0005583763122558594s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 743 Step: 66832
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8393, 'bonus': 0.010915443561199601, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66744, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 414 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3534549487417211
Updated goal-option-2 on 16 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44896, 'bonus': 0.00471950200931897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 303 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3314417986903856
Updated goal-option-4 on 5 transitions
Took 0.0006284713745117188s to update distance table with 22 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 744 Step: 66853
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66853, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8375, 'bonus': 0.010927167294163062, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 415 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40055327533212953
Updated goal-option-2 on 14 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44902, 'bonus': 0.004719186678620118, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 304 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40507408344511237
Updated goal-option-4 on 5 transitions
Took 0.0005917549133300781s to update distance table with 20 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 745 Step: 66872
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34865738 0.34518818 0.30615445]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66872, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5026, 'bonus': 0.014105508853773261, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 223 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4522471163036202
Updated goal-option-1 on 5 transitions
Took 0.00020813941955566406s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25385444 0.37493813 0.37120743]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 5160, 'bonus': 0.013921151159742613, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 8406, 'bonus': 0.010906999850061473, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 416 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4464295229998599
Updated goal-option-2 on 3 transitions
Took 0.0001811981201171875s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8408, 'bonus': 0.010905702555992054, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44903, 'bonus': 0.00471913412964841, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 305 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4963132867809908
Updated goal-option-4 on 5 transitions
Took 0.00023365020751953125s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 746 Step: 66885
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8375, 'bonus': 0.010927167294163062, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 417 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40045812451444546
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44888, 'bonus': 0.004719922548594414, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66570, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 306 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4565592316608855
Updated goal-option-4 on 5 transitions
Took 0.0005211830139160156s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 747 Step: 66898
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8381, 'bonus': 0.010923255186885403, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66645, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 418 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4350508809058873
Updated goal-option-2 on 16 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44901, 'bonus': 0.004719239229347311, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66801, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 307 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4762385726821378
Updated goal-option-4 on 5 transitions
Took 0.0008563995361328125s to update distance table with 22 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 748 Step: 66919
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66919, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8404, 'bonus': 0.010908297607202133, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66848, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 419 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39039078123929083
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44906, 'bonus': 0.004718976493265215, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 308 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4883074542986159
Updated goal-option-4 on 5 transitions
Took 0.0005524158477783203s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 749 Step: 66934
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8391, 'bonus': 0.010916744335030258, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 420 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38812020723258983
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44890, 'bonus': 0.004719817403236387, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66607, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 309 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3715080017886459
Updated goal-option-4 on 5 transitions
Took 0.0005228519439697266s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 750 Step: 66949
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66949, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8402, 'bonus': 0.010909595827689586, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 421 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41757783551037925
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44900, 'bonus': 0.004719291781830087, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 310 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42699386679201073
Updated goal-option-4 on 5 transitions
Took 0.0005450248718261719s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-3-0
Took 2.1049132347106934s to add potential edges.
================================================================================
[Consolidation] Episode: 751 Step: 66964
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66964, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8391, 'bonus': 0.010916744335030258, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66729, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 422 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3993283564359256
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44909, 'bonus': 0.0047188188726778645, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 311 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36996057537142873
Updated goal-option-4 on 5 transitions
Took 0.0005626678466796875s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 752 Step: 66982
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8383, 'bonus': 0.010921952084562021, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66667, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 423 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40011531876499756
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44900, 'bonus': 0.004719291781830087, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 312 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4442060635597618
Updated goal-option-4 on 5 transitions
Took 0.0005362033843994141s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 753 Step: 66998
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66998, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5020, 'bonus': 0.014113935923440919, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66397, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 224 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41242348196622736
Updated goal-option-1 on 6 transitions
Took 0.0002167224884033203s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25385444 0.37493813 0.37120743]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67004, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 44896, 'bonus': 0.00471950200931897, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66703, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 313 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37287184376180393
Updated goal-option-4 on 27 transitions
Took 0.0011570453643798828s to update distance table with 28 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 754 Step: 67031
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67031, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8404, 'bonus': 0.010908297607202133, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66848, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 424 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3773134940588752
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44895, 'bonus': 0.004719554570581124, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66690, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 314 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4684826123766587
Updated goal-option-4 on 5 transitions
Took 0.0005290508270263672s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 755 Step: 67046
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8389, 'bonus': 0.010918045574004427, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 425 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3640967318673192
Updated goal-option-2 on 10 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44909, 'bonus': 0.0047188188726778645, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 315 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4246181160225284
Updated goal-option-4 on 5 transitions
Took 0.0005185604095458984s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 756 Step: 67061
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8414, 'bonus': 0.010901813449459119, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66929, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 426 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39261178556169285
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44906, 'bonus': 0.004718976493265215, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 316 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3755349935545896
Updated goal-option-4 on 5 transitions
Took 0.0005538463592529297s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 757 Step: 67078
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67078, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8389, 'bonus': 0.010918045574004427, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 427 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3848913512858807
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44903, 'bonus': 0.00471913412964841, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66832, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 317 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4810809445149067
Updated goal-option-4 on 5 transitions
Took 0.0005514621734619141s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 758 Step: 67094
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8422, 'bonus': 0.010896634440402259, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66993, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 428 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35557425230951506
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44900, 'bonus': 0.004719291781830087, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 318 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3864778607483312
Updated goal-option-4 on 5 transitions
Took 0.0005023479461669922s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 759 Step: 67107
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4932, 'bonus': 0.01423929429527935, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65045, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 225 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4730120790687278
Updated goal-option-1 on 5 transitions
Took 0.00020766258239746094s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5184, 'bonus': 0.013888888888888888, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67112, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 44916, 'bonus': 0.004718451152720848, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 319 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41208722466816666
Updated goal-option-4 on 22 transitions
Took 0.0009200572967529297s to update distance table with 23 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 760 Step: 67134
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67134, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8418, 'bonus': 0.010899223022085146, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66959, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 429 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4056043357440764
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44902, 'bonus': 0.004719186678620118, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 320 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48703362526735106
Updated goal-option-4 on 5 transitions
Took 0.0005369186401367188s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.8455531597137451s to add potential edges.
Deleting edge from SE([3 2]) to goal-option-3-0
================================================================================
[Consolidation] Episode: 761 Step: 67150
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67150, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8414, 'bonus': 0.010901813449459119, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66929, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 430 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3993233289783363
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44907, 'bonus': 0.004718923951314468, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 321 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5290778838068967
Updated goal-option-4 on 5 transitions
Took 0.0005443096160888672s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 762 Step: 67166
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67166, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4982, 'bonus': 0.014167660405476751, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 226 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5868814809252075
Updated goal-option-1 on 5 transitions
Took 0.00020956993103027344s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5187, 'bonus': 0.01388487185658827, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67171, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 44909, 'bonus': 0.0047188188726778645, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 322 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.577768477651736
Updated goal-option-4 on 35 transitions
Took 0.0014791488647460938s to update distance table with 36 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 763 Step: 67206
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8438, 'bonus': 0.01088629852682144, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 431 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4045544659188471
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44907, 'bonus': 0.004718923951314468, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 323 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3658288078793006
Updated goal-option-4 on 5 transitions
Took 0.0005333423614501953s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 764 Step: 67220
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67220, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8412, 'bonus': 0.01090310935596586, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 432 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4593215243460454
Updated goal-option-2 on 13 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44909, 'bonus': 0.0047188188726778645, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66934, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 324 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.33497049560820735
Updated goal-option-4 on 5 transitions
Took 0.0005812644958496094s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 765 Step: 67238
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34758788 0.34412932 0.3082828 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8428, 'bonus': 0.010892755023757477, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 433 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4529282297296595
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44919, 'bonus': 0.004718293584767264, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 325 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44099515728182626
Updated goal-option-4 on 5 transitions
Took 0.0005254745483398438s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 766 Step: 67252
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34985903 0.34293136 0.30720961]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5026, 'bonus': 0.014105508853773261, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 227 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5135803304173373
Updated goal-option-1 on 5 transitions
Took 0.00023484230041503906s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25290146 0.37728464 0.3698139 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 5192, 'bonus': 0.013878184541334222, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 8432, 'bonus': 0.010890171046725803, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67089, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 434 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37780716430370503
Updated goal-option-2 on 3 transitions
Took 0.00018334388732910156s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8450, 'bonus': 0.010878565864408423, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67260, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44919, 'bonus': 0.004718293584767264, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 326 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.30638980566112844
Updated goal-option-4 on 5 transitions
Took 0.0002377033233642578s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 767 Step: 67265
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34985903 0.34293136 0.30720961]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8446, 'bonus': 0.010881141587390987, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67233, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 435 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3948258725558819
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44915, 'bonus': 0.004718503678880146, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67046, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 327 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3965299997733139
Updated goal-option-4 on 5 transitions
Took 0.0006892681121826172s to update distance table with 21 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 768 Step: 67285
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34985903 0.34293136 0.30720961]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8446, 'bonus': 0.010881141587390987, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67233, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 436 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40541875441302594
Updated goal-option-2 on 12 transitions
Took 0.0003612041473388672s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8454, 'bonus': 0.010875991969692543, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67297, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44927, 'bonus': 0.004717873480718817, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 328 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40678547879540794
Updated goal-option-4 on 5 transitions
Took 0.00023603439331054688s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 769 Step: 67302
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67302, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8418, 'bonus': 0.010899223022085146, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66959, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 437 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4202100235946067
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44918, 'bonus': 0.004718346105664504, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 329 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32811255395866423
Updated goal-option-4 on 5 transitions
Took 0.0005784034729003906s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=770 Seed=18] Took 0.05812811851501465s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 770 Step: 67319
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67319, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5124, 'bonus': 0.013969968905677815, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 228 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.440809979277142
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 25.0	IntrinsicReward: -384.2621315186843
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 771 Step: 67324
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 23.0	IntrinsicReward: -364.58381553698564
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 772 Step: 67324
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 28.0	IntrinsicReward: -343.76552417036146
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 773 Step: 67324
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 21.0	IntrinsicReward: -388.87948748096824
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 774 Step: 67324
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 26.0	IntrinsicReward: -346.4550028722733
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 775 Step: 67324
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4999, 'bonus': 0.014143550049460722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65918, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 229 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39337565188774953
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 31.0	IntrinsicReward: -369.6171169250447
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 776 Step: 67329
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 24.0	IntrinsicReward: -409.7215071693063
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 777 Step: 67329
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 27.0	IntrinsicReward: -341.91023343941197
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 778 Step: 67329
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 25.0	IntrinsicReward: -359.19518815912306
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 779 Step: 67329
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 25.0	IntrinsicReward: -305.10193429142237
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 780 Step: 67329
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -374.89708509482443
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 781 Step: 67329
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 25.0	IntrinsicReward: -390.6276896595955
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 782 Step: 67329
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67329, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5192, 'bonus': 0.013878184541334222, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67257, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 230 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46717131274231405
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 31.0	IntrinsicReward: -377.39860358704755
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 783 Step: 67334
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 32.0	IntrinsicReward: -383.5421699071303
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 784 Step: 67334
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 29.0	IntrinsicReward: -399.5834083138034
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 785 Step: 67334
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 32.0	IntrinsicReward: -261.5636369116837
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 786 Step: 67334
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 9.0	IntrinsicReward: -391.64300251193345
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 787 Step: 67334
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 26.0	IntrinsicReward: -385.5368039049208
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 788 Step: 67334
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67334, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4947, 'bonus': 0.014217690134308215, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 231 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5436627324523226
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 31.0	IntrinsicReward: -363.6481105014682
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 789 Step: 67339
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -395.93811561353505
Took 117.48713612556458s to update distance table with 20060 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2]), SE([2 5])}
[Episode=790 Seed=18] Took 0.07007408142089844s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 790 Step: 67339
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67339, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8420, 'bonus': 0.010897928500669323, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 438 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4072868247493738
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44930, 'bonus': 0.004717715970628552, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67319, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 330 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48030354120638413
Updated goal-option-4 on 5 transitions
Took 0.0008296966552734375s to update distance table with 21 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Took 1.9117169380187988s to add potential edges.
================================================================================
[Consolidation] Episode: 791 Step: 67359
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67359, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8454, 'bonus': 0.010875991969692543, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67297, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 439 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42902690767838053
Updated goal-option-2 on 12 transitions
Took 0.0003707408905029297s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8864, 'bonus': 0.010621482216552184, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44922, 'bonus': 0.004718136032598099, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67166, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 331 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43336533021355406
Updated goal-option-4 on 5 transitions
Took 0.00023698806762695312s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 792 Step: 67376
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8420, 'bonus': 0.010897928500669323, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66977, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 440 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3613954989724164
Updated goal-option-2 on 11 transitions
Took 0.0005030632019042969s to update distance table with 12 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8866, 'bonus': 0.01062028414737951, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44914, 'bonus': 0.00471855620679366, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67031, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 332 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4995753347422138
Updated goal-option-4 on 4 transitions
Took 0.00022459030151367188s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 793 Step: 67391
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8438, 'bonus': 0.01088629852682144, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 441 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39952990525302007
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44923, 'bonus': 0.00471808351871557, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 333 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4122992577479485
Updated goal-option-4 on 5 transitions
Took 0.0005216598510742188s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 794 Step: 67406
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8426, 'bonus': 0.010894047702219722, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67041, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 442 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46304273153475767
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44919, 'bonus': 0.004718293584767264, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67107, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 334 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38283017458337726
Updated goal-option-4 on 5 transitions
Took 0.0005590915679931641s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 795 Step: 67424
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8440, 'bonus': 0.010885008604602703, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67161, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 443 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44222757554589176
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55152, 'bonus': 0.004258134419229966, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 335 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45668737038491886
Updated goal-option-4 on 5 transitions
Took 0.0007398128509521484s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 796 Step: 67442
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67442, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8428, 'bonus': 0.010892755023757477, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67056, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 444 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3993100474806008
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55153, 'bonus': 0.004258095816128405, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 336 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36233684507575475
Updated goal-option-4 on 4 transitions
Took 0.0005002021789550781s to update distance table with 13 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 797 Step: 67454
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8862, 'bonus': 0.010622680691277189, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 445 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4518538138423211
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55150, 'bonus': 0.004258211628582912, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67359, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 337 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.351277181403117
Updated goal-option-4 on 5 transitions
Took 0.0005297660827636719s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 798 Step: 67469
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67469, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8862, 'bonus': 0.010622680691277189, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 446 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43077885696432405
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44924, 'bonus': 0.004718031006586475, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67220, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 338 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49228314554701885
Updated goal-option-4 on 5 transitions
Took 0.0005960464477539062s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 799 Step: 67487
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67487, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5124, 'bonus': 0.013969968905677815, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 232 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4171874263949987
Updated goal-option-1 on 5 transitions
Took 0.0002155303955078125s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25290146 0.37728464 0.3698139 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 5305, 'bonus': 0.013729581703773907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 8866, 'bonus': 0.01062028414737951, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 447 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42379662132122703
Updated goal-option-2 on 3 transitions
Took 0.00018310546875s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8878, 'bonus': 0.010613104236149338, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67495, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55154, 'bonus': 0.004258057214076721, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 339 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4299992935877319
Updated goal-option-4 on 5 transitions
Took 0.00023174285888671875s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 800 Step: 67500
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8864, 'bonus': 0.010621482216552184, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 448 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36576590498890543
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44922, 'bonus': 0.004718136032598099, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67166, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 340 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3796023122589798
Updated goal-option-4 on 5 transitions
Took 0.0005869865417480469s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Took 2.323807716369629s to add potential edges.
================================================================================
[Consolidation] Episode: 801 Step: 67514
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8866, 'bonus': 0.01062028414737951, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 449 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3841863896774131
Updated goal-option-2 on 27 transitions
Took 0.0006110668182373047s to update distance table with 28 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26030255 0.38832577 0.35137169]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8882, 'bonus': 0.010610714166479093, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67541, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44926, 'bonus': 0.0047179259875881965, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 341 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49729572015447987
Updated goal-option-4 on 5 transitions
Took 0.00023412704467773438s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 802 Step: 67546
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67546, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5022, 'bonus': 0.014111125222243389, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66404, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 233 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5278224567884849
Updated goal-option-1 on 5 transitions
Took 0.00021219253540039062s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5308, 'bonus': 0.013725701281150703, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67551, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 55156, 'bonus': 0.004257980013122792, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 342 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.29891930773486325
Updated goal-option-4 on 16 transitions
Took 0.0006957054138183594s to update distance table with 17 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 803 Step: 67567
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8869, 'bonus': 0.010618487803530948, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67419, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 450 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4100379187323817
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 44927, 'bonus': 0.004717873480718817, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67265, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 343 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3451482943099853
Updated goal-option-4 on 5 transitions
Took 0.0006129741668701172s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 804 Step: 67580
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67580, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 4997, 'bonus': 0.014146380174561475, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65883, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 234 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5486887096435771
Updated goal-option-1 on 5 transitions
Took 0.00021386146545410156s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25290146 0.37728464 0.3698139 ]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 5310, 'bonus': 0.013723116159876972, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67585, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 55151, 'bonus': 0.0042581730233814535, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67376, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 344 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35398901598364635
Updated goal-option-4 on 12 transitions
Took 0.0005156993865966797s to update distance table with 13 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 805 Step: 67597
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67597, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8862, 'bonus': 0.010622680691277189, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67354, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 451 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35812822356570256
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55153, 'bonus': 0.004258095816128405, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67406, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 345 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4360263450561386
Updated goal-option-4 on 5 transitions
Took 0.0005421638488769531s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 806 Step: 67614
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67614, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8450, 'bonus': 0.010878565864408423, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67260, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 452 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40314985795220143
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55160, 'bonus': 0.0042578256238113635, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 346 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39931211991791143
Updated goal-option-4 on 5 transitions
Took 0.0006639957427978516s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 807 Step: 67631
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67631, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67004, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 235 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5127173613941481
Updated goal-option-1 on 6 transitions
Took 0.00021791458129882812s to update distance table with 7 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5317, 'bonus': 0.013714079724757678, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67637, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 55152, 'bonus': 0.004258134419229966, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 347 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.30730517741227353
Updated goal-option-4 on 14 transitions
Took 0.0006132125854492188s to update distance table with 15 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 808 Step: 67651
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67651, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8864, 'bonus': 0.010621482216552184, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 453 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3690059101420992
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55156, 'bonus': 0.004257980013122792, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67454, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 348 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.334488945774227
Updated goal-option-4 on 5 transitions
Took 0.0005440711975097656s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 809 Step: 67668
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67668, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8876, 'bonus': 0.010614299876803856, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67482, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 454 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41312470619717595
Updated goal-option-2 on 8 transitions
Took 0.00035309791564941406s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8898, 'bonus': 0.010601170009686967, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67676, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55158, 'bonus': 0.004257902816367799, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67487, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 349 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4582626449617104
Updated goal-option-4 on 5 transitions
Took 0.00023293495178222656s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 810 Step: 67681
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67681, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8886, 'bonus': 0.010608325710812036, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67575, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 455 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4238325823110864
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55168, 'bonus': 0.004257516895563572, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67668, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 350 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38410094448318133
Updated goal-option-4 on 5 transitions
Took 0.0005595684051513672s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Took 2.041646718978882s to add potential edges.
================================================================================
[Consolidation] Episode: 811 Step: 67697
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67697, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8866, 'bonus': 0.01062028414737951, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67387, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 456 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3793602277317601
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55162, 'bonus': 0.004257748435453104, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67567, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 351 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.48582486655416024
Updated goal-option-4 on 5 transitions
Took 0.0005412101745605469s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 812 Step: 67711
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67711, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8900, 'bonus': 0.0105999788000636, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67692, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 457 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3706790031067176
Updated goal-option-2 on 15 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55152, 'bonus': 0.004258134419229966, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 352 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42696230840272476
Updated goal-option-4 on 5 transitions
Took 0.0008938312530517578s to update distance table with 21 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 813 Step: 67731
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8864, 'bonus': 0.010621482216552184, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 458 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37098927207291127
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55164, 'bonus': 0.004257671251292639, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67597, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 353 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42863386830625433
Updated goal-option-4 on 5 transitions
Took 0.0005645751953125s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 814 Step: 67747
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67747, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8864, 'bonus': 0.010621482216552184, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67371, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 459 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3797665171474218
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55159, 'bonus': 0.004257864219564786, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 354 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3108794223711205
Updated goal-option-4 on 5 transitions
Took 0.0005197525024414062s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 815 Step: 67762
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67762, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8896, 'bonus': 0.010602361620999637, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67663, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 460 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3896282923916579
Updated goal-option-2 on 12 transitions
Took 0.0003590583801269531s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8910, 'bonus': 0.010594028769395471, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67774, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55160, 'bonus': 0.0042578256238113635, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67514, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 355 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.409837611333286
Updated goal-option-4 on 5 transitions
Took 0.0002491474151611328s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 816 Step: 67779
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8873, 'bonus': 0.010616094095699918, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67450, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 461 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4604873105893512
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55171, 'bonus': 0.004257401139783156, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67711, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 356 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2845270984589509
Updated goal-option-4 on 5 transitions
Took 0.0006146430969238281s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 817 Step: 67797
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67797, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8912, 'bonus': 0.010592839965175894, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 462 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.395060097731917
Updated goal-option-2 on 10 transitions
Took 0.00033664703369140625s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8914, 'bonus': 0.01059165156106993, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67807, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55172, 'bonus': 0.004257362556621122, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 357 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3342446594182176
Updated goal-option-4 on 5 transitions
Took 0.00027632713317871094s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 818 Step: 67812
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67812, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8876, 'bonus': 0.010614299876803856, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67482, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 463 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37469047680249806
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55168, 'bonus': 0.004257516895563572, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67668, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 358 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4636567003240033
Updated goal-option-4 on 5 transitions
Took 0.0005328655242919922s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 819 Step: 67828
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8906, 'bonus': 0.010596407579073907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67742, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 464 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4417289963034124
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55161, 'bonus': 0.004257787029107485, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67546, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 359 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3639970497197644
Updated goal-option-4 on 6 transitions
Took 0.0005731582641601562s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 820 Step: 67844
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67844, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8898, 'bonus': 0.010601170009686967, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67676, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 465 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44505640539242547
Updated goal-option-2 on 14 transitions
Took 0.0005016326904296875s to update distance table with 15 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.25938656 0.38695928 0.35365415]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8921, 'bonus': 0.010587495294355676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67858, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55174, 'bonus': 0.004257285393443927, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67762, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 360 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49301581849280685
Updated goal-option-4 on 5 transitions
Took 0.0002372264862060547s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.9471912384033203s to add potential edges.
================================================================================
[Consolidation] Episode: 821 Step: 67863
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8876, 'bonus': 0.010614299876803856, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67482, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 466 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39741169842487145
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55176, 'bonus': 0.004257208234462245, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67797, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 361 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5406832632535102
Updated goal-option-4 on 5 transitions
Took 0.0007398128509521484s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 822 Step: 67881
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8880, 'bonus': 0.010611908999450222, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67509, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 467 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3508380297226486
Updated goal-option-2 on 17 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55163, 'bonus': 0.004257709842848171, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67580, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 362 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3473224922705012
Updated goal-option-4 on 5 transitions
Took 0.0008480548858642578s to update distance table with 23 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 823 Step: 67903
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67903, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8896, 'bonus': 0.010602361620999637, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67663, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 468 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4092722489059996
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55167, 'bonus': 0.004257555482921975, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67651, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 363 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3144868860770132
Updated goal-option-4 on 5 transitions
Took 0.0005497932434082031s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 824 Step: 67919
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67919, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8898, 'bonus': 0.010601170009686967, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67676, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 469 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3604605157678277
Updated goal-option-2 on 12 transitions
Took 0.0003943443298339844s to update distance table with 13 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8929, 'bonus': 0.010582751261275851, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67931, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55181, 'bonus': 0.0042570153553609155, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 364 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43060630188878024
Updated goal-option-4 on 5 transitions
Took 0.0002334117889404297s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 825 Step: 67936
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67936, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8906, 'bonus': 0.010596407579073907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67742, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 470 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38911944947915506
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55175, 'bonus': 0.004257246813428671, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 365 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3539225384274609
Updated goal-option-4 on 5 transitions
Took 0.0005364418029785156s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 826 Step: 67951
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67951, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8906, 'bonus': 0.010596407579073907, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67742, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 471 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39257384196404804
Updated goal-option-2 on 12 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55181, 'bonus': 0.0042570153553609155, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67881, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 366 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42963425345145745
Updated goal-option-4 on 5 transitions
Took 0.0005517005920410156s to update distance table with 18 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 827 Step: 67968
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67968, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8927, 'bonus': 0.01058393667167008, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67914, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 472 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3797256572856733
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55179, 'bonus': 0.004257092503855478, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67844, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 367 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3601710020604297
Updated goal-option-4 on 5 transitions
Took 0.0005500316619873047s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 828 Step: 67981
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67981, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8921, 'bonus': 0.010587495294355676, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67858, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 473 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37180833944042213
Updated goal-option-2 on 11 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55169, 'bonus': 0.004257478309254333, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67681, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 368 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46623078355422387
Updated goal-option-4 on 5 transitions
Took 0.0005350112915039062s to update distance table with 17 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 829 Step: 67997
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67997, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8912, 'bonus': 0.010592839965175894, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67792, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 474 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3820621818891879
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55183, 'bonus': 0.004256938211060535, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67919, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 369 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34591213212709643
Updated goal-option-4 on 5 transitions
Took 0.0005335807800292969s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 830 Step: 68012
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5305, 'bonus': 0.013729581703773907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67492, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 236 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45829042123194347
Updated goal-option-1 on 5 transitions
Took 0.0002429485321044922s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 5348, 'bonus': 0.013674274718610486, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68017, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 55175, 'bonus': 0.004257246813428671, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 370 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32743983997703613
Updated goal-option-4 on 18 transitions
Took 0.0007741451263427734s to update distance table with 19 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-4
Took 1.8013615608215332s to add potential edges.
================================================================================
[Consolidation] Episode: 831 Step: 68035
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8904, 'bonus': 0.010597597584982434, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 475 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4323539679489153
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55175, 'bonus': 0.004257246813428671, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67779, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 371 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36408620279561094
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.008425474166870117s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 832 Step: 68050
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68050, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8904, 'bonus': 0.010597597584982434, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 476 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35478108863662844
Updated goal-option-2 on 7 transitions
Took 0.0003113746643066406s to update distance table with 8 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.25938656 0.38695928 0.35365415]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8945, 'bonus': 0.010573282295048069, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68057, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55182, 'bonus': 0.004256976782686476, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67903, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 372 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3526357682142976
Updated goal-option-4 on 4 transitions
Took 0.00020432472229003906s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 833 Step: 68061
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68061, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8918, 'bonus': 0.010589275952301446, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67838, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 477 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4109267145150837
Updated goal-option-2 on 10 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55187, 'bonus': 0.0042567839350408036, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67981, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 373 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2900766413501273
Updated goal-option-4 on 5 transitions
Took 0.0005161762237548828s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 834 Step: 68076
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68076, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8935, 'bonus': 0.010579197418473024, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67976, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 478 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39173560445575806
Updated goal-option-2 on 10 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55180, 'bonus': 0.0042570539290839, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 374 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3215269360584152
Updated goal-option-4 on 5 transitions
Took 0.000530242919921875s to update distance table with 16 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 835 Step: 68091
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8910, 'bonus': 0.010594028769395471, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67774, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 479 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3560284131213905
Updated goal-option-2 on 10 transitions
Took 0.0003428459167480469s to update distance table with 11 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.25938656 0.38695928 0.35365415]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8950, 'bonus': 0.0105703284516338, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55178, 'bonus': 0.0042571310796756965, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67828, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 375 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44339877350630896
Updated goal-option-4 on 5 transitions
Took 0.00026726722717285156s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 836 Step: 68106
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68106, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5308, 'bonus': 0.013725701281150703, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67551, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 237 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39012248136382155
Updated goal-option-1 on 5 transitions
Took 0.00021386146545410156s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25479554 0.37632813 0.36887633]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 5361, 'bonus': 0.01365768513932884, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68111, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 8910, 'bonus': 0.010594028769395471, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67774, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 480 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3980062165827171
Updated goal-option-2 on 3 transitions
Took 0.0001811981201171875s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26131223 0.38595315 0.35273462]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8952, 'bonus': 0.010569147607251896, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68114, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55193, 'bonus': 0.004256552552458077, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68076, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 376 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3544659251615077
Updated goal-option-4 on 5 transitions
Took 0.0002357959747314453s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 837 Step: 68119
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8916, 'bonus': 0.010590463556853185, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67823, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 481 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3760681122580462
Updated goal-option-2 on 13 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55190, 'bonus': 0.004256668239032909, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 377 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3435971426489067
Updated goal-option-4 on 5 transitions
Took 0.0005736351013183594s to update distance table with 19 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 838 Step: 68137
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5042, 'bonus': 0.014083110254721722, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 238 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4570449780501367
Updated goal-option-1 on 5 transitions
Took 0.0002307891845703125s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25479554 0.37632813 0.36887633]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 5363, 'bonus': 0.013655138251635026, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 8925, 'bonus': 0.010585122480499264, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 482 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3827485574693581
Updated goal-option-2 on 3 transitions
Took 0.00019311904907226562s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26131223 0.38595315 0.35273462]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 8956, 'bonus': 0.010566787105244287, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68145, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55196, 'bonus': 0.0042564368753150285, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 378 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36838195157497616
Updated goal-option-4 on 5 transitions
Took 0.000232696533203125s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 839 Step: 68150
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68150, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8952, 'bonus': 0.010569147607251896, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68114, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 483 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3844462007238625
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55190, 'bonus': 0.004256668239032909, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68035, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 379 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3765077859740265
Updated goal-option-4 on 5 transitions
Took 0.0005500316619873047s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
[Episode=840 Seed=18] Took 0.05314826965332031s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 840 Step: 68163
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68163, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5187, 'bonus': 0.01388487185658827, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67171, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 239 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.512597267985277
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 32.0	IntrinsicReward: -397.4968273770064
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 841 Step: 68168
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 33.0	IntrinsicReward: -366.2366540620569
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 842 Step: 68168
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68168, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67004, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 240 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.425278975021023
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 33.0	IntrinsicReward: -398.4039596733637
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 843 Step: 68173
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 30.0	IntrinsicReward: -375.0894174046116
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 844 Step: 68173
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 26.0	IntrinsicReward: -361.7910853499052
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 845 Step: 68173
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 22.0	IntrinsicReward: -310.99643686879426
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 846 Step: 68173
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68173, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5160, 'bonus': 0.013921151159742613, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66877, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 241 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44684326669617264
Updated goal-option-1 on 5 transitions
Deleting edge from SE([3 2]) to goal-option-1
[RND Rollout] Reward: 39.0	IntrinsicReward: -397.47877661138773
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 847 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 24.0	IntrinsicReward: -381.0213085860014
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 848 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 34.0	IntrinsicReward: -302.838212917035
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 849 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 19.0	IntrinsicReward: -354.7241417755722
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 850 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 32.0	IntrinsicReward: -404.4432268626988
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 851 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 36.0	IntrinsicReward: -361.5546823346813
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 852 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 34.0	IntrinsicReward: -397.6242573959753
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 853 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 29.0	IntrinsicReward: -279.85595628991723
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 854 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 35.0	IntrinsicReward: -413.75328281131806
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 855 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 29.0	IntrinsicReward: -364.1732232545037
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 856 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 36.0	IntrinsicReward: -393.8882076134905
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 857 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 34.0	IntrinsicReward: -417.51301811635494
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 858 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 33.0	IntrinsicReward: -385.181892182678
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 859 Step: 68178
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 33.0	IntrinsicReward: -328.83837073959876
Took 140.42851495742798s to update distance table with 20055 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2]), SE([2 5])}
[Episode=860 Seed=18] Took 0.08065462112426758s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 860 Step: 68178
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.010971784591674805s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.8983917236328125s to add potential edges.
================================================================================
[Consolidation] Episode: 861 Step: 68434
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68434, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8918, 'bonus': 0.010589275952301446, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67838, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 484 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3793025214590278
Updated goal-option-2 on 9 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55196, 'bonus': 0.0042564368753150285, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 380 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39079119533814666
Updated goal-option-4 on 5 transitions
Took 0.0005521774291992188s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 862 Step: 68448
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8925, 'bonus': 0.010585122480499264, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67898, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 485 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35907917778232906
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55194, 'bonus': 0.004256513992362481, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 381 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36306339028561285
Updated goal-option-4 on 5 transitions
Took 0.0005774497985839844s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 863 Step: 68461
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.013063430786132812s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 864 Step: 68717
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.01565265655517578s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 865 Step: 68973
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68973, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8954, 'bonus': 0.010567967158529026, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 486 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34984853167745383
Updated goal-option-2 on 9 transitions
Took 0.00033593177795410156s to update distance table with 10 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.26223261 0.38731253 0.35045487]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 9075, 'bonus': 0.01049727762162956, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55197, 'bonus': 0.004256398318363075, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 382 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37462552765406154
Updated goal-option-4 on 5 transitions
Took 0.00023221969604492188s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 866 Step: 68987
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.01451730728149414s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 867 Step: 69243
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69243, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8931, 'bonus': 0.010581566249093505, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67946, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 487 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36890907013583485
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55187, 'bonus': 0.0042567839350408036, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67981, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 383 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40020639244061423
Updated goal-option-4 on 5 transitions
Took 0.00055694580078125s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 868 Step: 69256
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.016900300979614258s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 869 Step: 69512
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.020578622817993164s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 870 Step: 69768
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69768, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8950, 'bonus': 0.0105703284516338, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 488 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34217984349371483
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55187, 'bonus': 0.0042567839350408036, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67981, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 384 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.431488381124646
Updated goal-option-4 on 5 transitions
Took 0.0005245208740234375s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 1.8798308372497559s to add potential edges.
================================================================================
[Consolidation] Episode: 871 Step: 69782
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69782, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8939, 'bonus': 0.010576830178027529, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68007, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 489 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34977868913027343
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55193, 'bonus': 0.004256552552458077, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68076, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 385 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3799828840120571
Updated goal-option-4 on 5 transitions
Took 0.0005452632904052734s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 872 Step: 69795
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69795, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9075, 'bonus': 0.01049727762162956, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 490 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3729413234153374
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67105, 'bonus': 0.0038603133582139153, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68461, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 386 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40523693581422177
Updated goal-option-4 on 5 transitions
Took 0.0005049705505371094s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 873 Step: 69808
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8950, 'bonus': 0.0105703284516338, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68101, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 491 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36809758137436194
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55196, 'bonus': 0.0042564368753150285, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68119, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 387 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2595265696120138
Updated goal-option-4 on 5 transitions
Took 0.0005502700805664062s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 874 Step: 69821
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8939, 'bonus': 0.010576830178027529, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68007, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 492 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4265881470079573
Updated goal-option-2 on 8 transitions
Took 0.0003256797790527344s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9087, 'bonus': 0.0104903441482036, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69829, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67107, 'bonus': 0.0038602558330359006, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69256, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 388 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3651503371602545
Updated goal-option-4 on 5 transitions
Took 0.00023221969604492188s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 875 Step: 69834
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34661611 0.33975266 0.31363123]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5187, 'bonus': 0.01388487185658827, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67171, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 242 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3647482042436298
Updated goal-option-1 on 5 transitions
Took 0.00024080276489257812s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 6277, 'bonus': 0.012621876767740804, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69839, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 18055, 'bonus': 0.007442198571595894, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.222944557293316
Updated goal-option-3 on 251 transitions
Took 0.026799678802490234s to update distance table with 252 states and events {None, SE([3 2])}
================================================================================
[Consolidation] Episode: 876 Step: 70090
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.016388416290283203s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 877 Step: 70346
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.012293577194213867s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 878 Step: 70602
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70602, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9087, 'bonus': 0.0104903441482036, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69829, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 493 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37809165594512334
Updated goal-option-2 on 7 transitions
Took 0.00032138824462890625s to update distance table with 8 states and events {SE([1 1]), None, SE([6 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9089, 'bonus': 0.010489189904469216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70609, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67106, 'bonus': 0.003860284595303448, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 389 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4332789476029575
Updated goal-option-4 on 4 transitions
Took 0.00020647048950195312s to update distance table with 5 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 879 Step: 70613
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70613, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8952, 'bonus': 0.010569147607251896, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68114, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 494 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.36633553765496313
Updated goal-option-2 on 7 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67112, 'bonus': 0.0038601120313411516, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 390 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46511060020886363
Updated goal-option-4 on 4 transitions
Took 0.00048089027404785156s to update distance table with 12 states and events {SE([1 1]), SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 880 Step: 70624
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9081, 'bonus': 0.01049380916700931, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 495 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.33374966422000285
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55197, 'bonus': 0.004256398318363075, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68137, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 391 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.33706465112314143
Updated goal-option-4 on 5 transitions
Took 0.0005517005920410156s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
Adding edge from SE([3 2]) to goal-option-1
Took 1.7520592212677002s to add potential edges.
================================================================================
[Consolidation] Episode: 881 Step: 70637
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70637, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9083, 'bonus': 0.010492653779263776, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 496 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38669618430285296
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55194, 'bonus': 0.004256513992362481, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 392 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37344020464440586
Updated goal-option-4 on 5 transitions
Took 0.0005478858947753906s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 882 Step: 70650
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.009326696395874023s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 883 Step: 70906
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.009410381317138672s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 884 Step: 71162
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.008241891860961914s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 885 Step: 71418
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9081, 'bonus': 0.01049380916700931, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 497 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3674634507484009
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67111, 'bonus': 0.00386014079039445, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 393 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32552741944888736
Updated goal-option-4 on 5 transitions
Took 0.0005018711090087891s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 886 Step: 71431
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.017253875732421875s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 887 Step: 71687
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71687, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8954, 'bonus': 0.010567967158529026, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 498 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3636365983147179
Updated goal-option-2 on 8 transitions
Took 0.0003247261047363281s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9097, 'bonus': 0.010484576736613559, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71695, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67111, 'bonus': 0.00386014079039445, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 394 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4373645759712646
Updated goal-option-4 on 5 transitions
Took 0.0002315044403076172s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 888 Step: 71700
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.01980423927307129s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 889 Step: 71956
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.011490106582641602s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 890 Step: 72212
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72212, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5168, 'bonus': 0.013910372101866431, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67004, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 243 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38066864352864976
Updated goal-option-1 on 5 transitions
Took 0.00022339820861816406s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 7333, 'bonus': 0.011677749568838153, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72217, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 67104, 'bonus': 0.003860342121767329, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 395 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32599963697263074
Updated goal-option-4 on 8 transitions
Took 0.0003654956817626953s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
Took 1.7344346046447754s to add potential edges.
================================================================================
[Consolidation] Episode: 891 Step: 72225
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72225, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9090, 'bonus': 0.010488612925459209, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70620, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 499 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37901168367606436
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 55199, 'bonus': 0.00425632120760248, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68163, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 396 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34269835023215595
Updated goal-option-4 on 5 transitions
Took 0.0005156993865966797s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 892 Step: 72238
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 8954, 'bonus': 0.010567967158529026, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68132, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 500 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3373802664114048
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67105, 'bonus': 0.0038603133582139153, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68461, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 397 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4614975215442995
Updated goal-option-4 on 5 transitions
Took 0.0005214214324951172s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 893 Step: 72251
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.00921630859375s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 894 Step: 72507
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.012331485748291016s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 895 Step: 72763
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.010590553283691406s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 896 Step: 73019
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.009220123291015625s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 897 Step: 73275
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73275, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9075, 'bonus': 0.01049727762162956, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68982, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 501 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4340690620219438
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67114, 'bonus': 0.0038600545151628624, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 398 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5875063124773624
Updated goal-option-4 on 5 transitions
Took 0.000530242919921875s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 898 Step: 73288
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9089, 'bonus': 0.010489189904469216, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70609, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 502 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3307165647210566
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67104, 'bonus': 0.003860342121767329, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 399 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3358553412632585
Updated goal-option-4 on 5 transitions
Took 0.0005083084106445312s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 899 Step: 73301
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73301, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9091, 'bonus': 0.010488036041652408, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70632, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 503 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38077479786328605
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67106, 'bonus': 0.003860284595303448, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68987, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 400 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3049359044491364
Updated goal-option-4 on 5 transitions
Took 0.0005071163177490234s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 900 Step: 73314
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34443386 0.33761361 0.31795253]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9091, 'bonus': 0.010488036041652408, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70632, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 504 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3781225056139612
Updated goal-option-2 on 8 transitions
Took 0.0003237724304199219s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.25655591 0.386583   0.35686109]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (6, 2) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'count': 9116, 'bonus': 0.010473644811127697, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-4, goal-option-3-0, goal-option-3, goal-option-1] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67121, 'bonus': 0.0038598532287835866, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72251, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 401 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35529053280334955
Updated goal-option-4 on 5 transitions
Took 0.00023555755615234375s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([3 2]) to goal-option-4
Took 1.6642179489135742s to add potential edges.
================================================================================
[Consolidation] Episode: 901 Step: 73327
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 256 transitions
Took 0.01866912841796875s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 902 Step: 73583
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73583, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9091, 'bonus': 0.010488036041652408, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70632, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 505 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3454562309426701
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67113, 'bonus': 0.00386008327293063, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70613, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 402 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.43674725054630215
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0005125999450683594s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 903 Step: 73596
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73596, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5370, 'bonus': 0.013646235352373378, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68178, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 244 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44147292292891466
Updated goal-option-1 on 5 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.00020933151245117188s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 7834, 'bonus': 0.011298172894234777, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73601, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 67118, 'bonus': 0.0038599394905188527, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 403 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41159044075543166
Updated goal-option-4 on 8 transitions
Took 0.00039386749267578125s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 904 Step: 73609
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.039419922033946
Updated goal-option-5 on 85 transitions
Took 0.003236055374145508s to update distance table with 86 states and events {None, SE([1 1]), SE([3 2]), SE([6 2]), SE([2 5])}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.18653493 0.28107414 0.2755085  0.25688243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2732, 'bonus': 0.019131968294834524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3-0, goal-option-3, goal-option-1, goal-option-2, goal-option-4] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3118971408577415
Updated goal-option-3-0 on 8 transitions
Got plan [goal-option-1, goal-option-2, goal-option-4] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 3] targeting {'count': 5367, 'bonus': 0.013650048747823636, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68173, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 245 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41619271977800104
Updated goal-option-1 on 72 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 67116, 'bonus': 0.003859997001555494, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 404 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2828053155262632
Updated goal-option-4 on 8 transitions
Took 0.003652334213256836s to update distance table with 89 states and events {None, SE([6 6]), SE([3 2]), SE([6 2]), SE([2 5])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 905 Step: 73782
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73782, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9116, 'bonus': 0.010473644811127697, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 506 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3567653342043869
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67124, 'bonus': 0.0038597669728313803, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 405 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3080969329716431
Updated goal-option-4 on 5 transitions
Took 0.0005171298980712891s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 906 Step: 73795
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73795, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9101, 'bonus': 0.010482272434006255, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72233, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 507 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.355722878077851
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67128, 'bonus': 0.003859651973889861, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73782, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 406 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3020090078021966
Updated goal-option-4 on 5 transitions
Took 0.0005047321319580078s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 907 Step: 73808
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.345527  0.3386851 0.3157879]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5363, 'bonus': 0.013655138251635026, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 246 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42766783831848043
Updated goal-option-1 on 5 transitions
Deleting edge from SE([3 2]) to goal-option-1
Took 0.00021719932556152344s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25101671 0.37823644 0.37074685]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 7842, 'bonus': 0.011292408519933923, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73813, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3687940634618849
Updated goal-option-3-0 on 3 transitions
Deleting edge from SE([1 1]) to goal-option-3-0
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 2] targeting {'count': 18055, 'bonus': 0.007442198571595894, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62941, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0231046381226758
Updated goal-option-3 on 5 transitions
Took 0.0003829002380371094s to update distance table with 9 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34443386 0.33761361 0.31795253]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 19621, 'bonus': 0.007139033684392702, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9085, 'bonus': 0.01049149877306519, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 508 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38986029358956603
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67115, 'bonus': 0.0038600257580378257, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70637, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 407 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4074418630779666
Updated goal-option-4 on 5 transitions
Took 0.0005848407745361328s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 908 Step: 73835
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.811359448965653
Updated goal-option-5 on 256 transitions
Took 0.014948129653930664s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 909 Step: 74091
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74091, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9103, 'bonus': 0.010481120852301707, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 509 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35379386175917693
Updated goal-option-2 on 8 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67115, 'bonus': 0.0038600257580378257, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70637, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 408 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3116698503433689
Updated goal-option-4 on 5 transitions
Took 0.0005154609680175781s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=910 Seed=18] Took 0.0773932933807373s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 910 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 40.0	IntrinsicReward: -415.4284666143358
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 911 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 38.0	IntrinsicReward: -262.414678794099
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 912 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 35.0	IntrinsicReward: -416.15153116360307
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 913 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 30.0	IntrinsicReward: -375.5826521907002
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 914 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 36.0	IntrinsicReward: -344.9447085361171
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 915 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 37.0	IntrinsicReward: -409.5399110428989
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 916 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 38.0	IntrinsicReward: -347.85312352153414
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 917 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 40.0	IntrinsicReward: -317.8677996196493
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 918 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 39.0	IntrinsicReward: -420.97040081210434
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 919 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 37.0	IntrinsicReward: -407.85752116236836
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 920 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 37.0	IntrinsicReward: -306.5533136520535
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 921 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 38.0	IntrinsicReward: -359.0240801409818
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 922 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 39.0	IntrinsicReward: -425.1711428575218
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 923 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 36.0	IntrinsicReward: -414.10265923663974
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 924 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 38.0	IntrinsicReward: -350.02023127209395
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 925 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 37.0	IntrinsicReward: -396.8341525532305
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 926 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 37.0	IntrinsicReward: -418.63695191964507
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 927 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 31.0	IntrinsicReward: -393.0219362026546
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 928 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 35.0	IntrinsicReward: -374.12405341817066
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 929 Step: 74104
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 26.0	IntrinsicReward: -414.2127541160444
Took 171.39285826683044s to update distance table with 20040 states and events {SE([6 2]), None, SE([6 6]), SE([1 1]), SE([3 2]), SE([2 5])}
[Episode=930 Seed=18] Took 0.06904745101928711s to save gc logs
[SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2]), SE([2 5])]
================================================================================
[Consolidation] Episode: 930 Step: 74104
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2732, 'bonus': 0.019131968294834524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.960985181379054
Updated goal-option-5 on 256 transitions
Took 0.018323659896850586s to update distance table with 257 states and events {SE([1 1]), None}
Took 2.0876312255859375s to add potential edges.
================================================================================
[Consolidation] Episode: 931 Step: 74360
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34443386 0.33761361 0.31795253]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74360, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5363, 'bonus': 0.013655138251635026, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68142, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 247 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4742073048734003
Updated goal-option-1 on 5 transitions
Took 0.0002079010009765625s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25290146 0.37728464 0.3698139 ]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 7929, 'bonus': 0.011230285342153486, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74365, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 9126, 'bonus': 0.010467904883688794, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 510 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38413901837300535
Updated goal-option-2 on 3 transitions
Took 0.00017976760864257812s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9140, 'bonus': 0.0104598848163826, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74368, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67114, 'bonus': 0.0038600545151628624, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70624, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 409 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3600365211142273
Updated goal-option-4 on 5 transitions
Took 0.0002799034118652344s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 932 Step: 74373
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5317, 'bonus': 0.013714079724757678, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67637, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 248 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5185145178354449
Updated goal-option-1 on 5 transitions
Took 0.00020813941955566406s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 7930, 'bonus': 0.011229577231219767, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74378, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 67126, 'bonus': 0.0038597094720757355, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73596, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 410 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40346208851996473
Updated goal-option-4 on 8 transitions
Took 0.00035381317138671875s to update distance table with 9 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 933 Step: 74386
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9128, 'bonus': 0.010466758030233293, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 511 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3896444518708815
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67120, 'bonus': 0.0038598819820527476, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 411 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3647301061790649
Updated goal-option-4 on 5 transitions
Took 0.0005354881286621094s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 934 Step: 74399
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9097, 'bonus': 0.010484576736613559, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71695, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 512 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35271569095319016
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67117, 'bonus': 0.0038599682457158445, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71431, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 412 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5051379403896874
Updated goal-option-4 on 5 transitions
Took 0.0005035400390625s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 935 Step: 74412
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.630861416988903
Updated goal-option-5 on 256 transitions
Took 0.012025833129882812s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 936 Step: 74668
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.604378146001662
Updated goal-option-5 on 256 transitions
Took 0.014749765396118164s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 937 Step: 74924
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2732, 'bonus': 0.019131968294834524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.632847858545108
Updated goal-option-5 on 256 transitions
Took 0.016622543334960938s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 938 Step: 75180
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75180, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9101, 'bonus': 0.010482272434006255, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72233, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 513 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3727542085138819
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67129, 'bonus': 0.003859623225760528, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73795, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 413 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3053167932712048
Updated goal-option-4 on 5 transitions
Took 0.0005071163177490234s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 939 Step: 75193
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75193, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9130, 'bonus': 0.010465611553639655, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 514 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3181438424511452
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67123, 'bonus': 0.003859795724172927, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73301, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 414 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.318067550026242
Updated goal-option-4 on 5 transitions
Took 0.0005016326904296875s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 940 Step: 75206
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9128, 'bonus': 0.010466758030233293, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 515 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38115567037346426
Updated goal-option-2 on 8 transitions
Took 0.0003180503845214844s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9160, 'bonus': 0.010448459488214323, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67131, 'bonus': 0.0038595657314289505, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73835, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 415 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34721913139154753
Updated goal-option-4 on 5 transitions
Took 0.00025272369384765625s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
Adding edge from SE([3 2]) to goal-option-1
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Took 2.389948844909668s to add potential edges.
================================================================================
[Consolidation] Episode: 941 Step: 75219
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9126, 'bonus': 0.010467904883688794, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 516 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3389922197979803
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79960, 'bonus': 0.003536418121003692, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 416 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3282211094425575
Updated goal-option-4 on 5 transitions
Took 0.0005319118499755859s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 942 Step: 75232
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34333674 0.33653821 0.32012505]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9116, 'bonus': 0.010473644811127697, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 517 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3407618134019849
Updated goal-option-2 on 8 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79961, 'bonus': 0.0035363960075410175, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 417 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4744365056511764
Updated goal-option-4 on 5 transitions
Took 0.0005133152008056641s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 943 Step: 75245
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75245, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9103, 'bonus': 0.010481120852301707, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72246, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 518 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3754087705451708
Updated goal-option-2 on 9 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67122, 'bonus': 0.003859824476156987, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73288, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 418 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.28463128611337446
Updated goal-option-4 on 5 transitions
Took 0.0005586147308349609s to update distance table with 15 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 944 Step: 75259
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2732, 'bonus': 0.019131968294834524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
4.5431327557572665
Updated goal-option-5 on 94 transitions
Took 0.00385284423828125s to update distance table with 95 states and events {SE([2 5]), SE([1 1]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.18557192 0.27962308 0.27408617 0.26071883]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (2, 5) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 2759, 'bonus': 0.01903812393862834, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-3-0, goal-option-3, goal-option-1, goal-option-2, goal-option-4] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [2 5] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.27250678893178704
Updated goal-option-3-0 on 120 transitions
Got plan [goal-option-1, goal-option-2, goal-option-4] and chose to execute goal-option-1
Rolling out goal-option-1, from [2 3] targeting {'count': 5361, 'bonus': 0.01365768513932884, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68111, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.47768275070910815
Updated goal-option-1 on 42 transitions
Took 0.00668644905090332s to update distance table with 163 states and events {SE([2 5]), None}
================================================================================
[Consolidation] Episode: 945 Step: 75515
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75515, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9112, 'bonus': 0.010475943427376403, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73296, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 519 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35036516469145224
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79965, 'bonus': 0.0035363075578384493, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 419 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2837782797348144
Updated goal-option-4 on 5 transitions
Took 0.0005352497100830078s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 946 Step: 75528
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2732, 'bonus': 0.019131968294834524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.106642168242337
Updated goal-option-5 on 256 transitions
Took 0.01300358772277832s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 947 Step: 75784
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75784, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 7842, 'bonus': 0.011292408519933923, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73813, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 249 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.41513197785181716
Updated goal-option-1 on 5 transitions
Took 0.00020647048950195312s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25196498 0.37588758 0.37214744]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (3, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 8093, 'bonus': 0.011115915322569907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [3 2] targeting {'count': 67124, 'bonus': 0.0038597669728313803, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73314, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 420 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32257329784150857
Updated goal-option-4 on 20 transitions
Took 0.0008587837219238281s to update distance table with 21 states and events {SE([6 2]), SE([6 6]), None, SE([3 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 948 Step: 75809
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 8093, 'bonus': 0.011115915322569907, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75789, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 250 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.49326826965489795
Updated goal-option-1 on 5 transitions
Deleting edge from goal-option-3-0 to goal-option-1
Took 0.0002357959747314453s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25196498 0.37588758 0.37214744]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (3, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 8106, 'bonus': 0.011106998169600174, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3-0, goal-option-3] and chose to execute goal-option-3-0
Rolling out goal-option-3-0, from [3 2] targeting {'player_x': 1, 'player_y': 1, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3-0 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.19276795843839553
Updated goal-option-3-0 on 3 transitions
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 17615, 'bonus': 0.007534573542491668, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61326, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8399719996584786
Updated goal-option-3 on 99 transitions
Took 0.006787776947021484s to update distance table with 103 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([1 1])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2759, 'bonus': 0.01903812393862834, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.312101224172124
Updated goal-option-5 on 149 transitions
Took 0.00625300407409668s to update distance table with 150 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 949 Step: 76065
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76065, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9136, 'bonus': 0.01046217438296718, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74099, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 520 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3944587011035634
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79965, 'bonus': 0.0035363075578384493, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75206, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 421 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.30154393932435847
Updated goal-option-4 on 5 transitions
Took 0.0005083084106445312s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 950 Step: 76078
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2759, 'bonus': 0.01903812393862834, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.915726720925638
Updated goal-option-5 on 256 transitions
Took 0.010206222534179688s to update distance table with 257 states and events {SE([1 1]), None}
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-4
Took 1.9494538307189941s to add potential edges.
================================================================================
[Consolidation] Episode: 951 Step: 76334
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76334, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9126, 'bonus': 0.010467904883688794, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73790, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 521 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.38597817799542405
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79971, 'bonus': 0.0035361748957275538, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 422 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.46025276201096577
Updated goal-option-4 on 5 transitions
Took 0.0004968643188476562s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 952 Step: 76347
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76347, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 5295, 'bonus': 0.013742540254750817, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67339, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 251 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.44287396399982715
Updated goal-option-1 on 5 transitions
Took 0.00021529197692871094s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2])] | Probabilities: [0.25196498 0.37588758 0.37214744]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (3, 2) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 8206, 'bonus': 0.011039114645521096, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76352, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [3 2] targeting {'count': 9164, 'bonus': 0.010446178912068371, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75240, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 522 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3674352594519255
Updated goal-option-2 on 3 transitions
Took 0.00018215179443359375s to update distance table with 4 states and events {SE([6 2]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9176, 'bonus': 0.010439346133241541, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76355, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79966, 'bonus': 0.003536285446449774, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 423 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3668009896826425
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0002460479736328125s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 953 Step: 76360
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76360, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9176, 'bonus': 0.010439346133241541, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76355, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 523 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3173829906240657
Updated goal-option-2 on 8 transitions
Took 0.00031948089599609375s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9178, 'bonus': 0.010438208639788614, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76368, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79974, 'bonus': 0.003536108570270678, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76360, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 424 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.37436817591437926
Updated goal-option-4 on 5 transitions
Took 0.0002315044403076172s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 954 Step: 76373
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9128, 'bonus': 0.010466758030233293, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73803, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 524 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3339544354651318
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67129, 'bonus': 0.003859623225760528, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73795, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 425 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2501023915882981
Updated goal-option-4 on 5 transitions
Took 0.0005512237548828125s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 955 Step: 76386
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9164, 'bonus': 0.010446178912068371, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75240, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 525 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32836966272229434
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 67130, 'bonus': 0.0038595944782735658, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 426 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.45285201754474474
Updated goal-option-4 on 5 transitions
Took 0.0005044937133789062s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 956 Step: 76399
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9166, 'bonus': 0.010445039183854617, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75254, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 526 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.31632683874411216
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79976, 'bonus': 0.003536064355372736, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 427 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3274381468830069
Updated goal-option-4 on 5 transitions
Took 0.0005328655242919922s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 957 Step: 76412
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76412, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9162, 'bonus': 0.01044731901345371, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 527 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34263811911259817
Updated goal-option-2 on 8 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79967, 'bonus': 0.0035362633354758598, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 428 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.29069974319427233
Updated goal-option-4 on 5 transitions
Took 0.0005013942718505859s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 958 Step: 76425
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2759, 'bonus': 0.01903812393862834, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.7335669905309445
Updated goal-option-5 on 256 transitions
Took 0.010320901870727539s to update distance table with 257 states and events {SE([1 1]), None}
================================================================================
[Consolidation] Episode: 959 Step: 76681
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2759, 'bonus': 0.01903812393862834, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8633389856151443
Updated goal-option-5 on 50 transitions
Took 0.0014004707336425781s to update distance table with 51 states and events {SE([1 1]), SE([6 6]), None}
================================================================================
[Consolidation] Episode: 960 Step: 76731
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76731, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9144, 'bonus': 0.010457596752302643, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 528 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4167450109462285
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79975, 'bonus': 0.003536086462614385, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76373, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 429 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2965289576008679
Updated goal-option-4 on 5 transitions
Took 0.0005130767822265625s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
Adding edge from goal-option-1 to goal-option-4
Adding edge from goal-option-3-0 to goal-option-1
Adding edge from SE([1 1]) to goal-option-2
Adding edge from goal-option-3 to goal-option-2
Adding edge from SE([3 2]) to goal-option-4
Took 1.8628265857696533s to add potential edges.
================================================================================
[Consolidation] Episode: 961 Step: 76744
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.3904589906553357
Updated goal-option-5 on 256 transitions
Took 0.011556625366210938s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 962 Step: 77000
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2759, 'bonus': 0.01903812393862834, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75353, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.030410759408707
Updated goal-option-5 on 21 transitions
Took 0.000850677490234375s to update distance table with 22 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 963 Step: 77021
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77021, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9172, 'bonus': 0.010441622236208354, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 529 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3390734234668371
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79976, 'bonus': 0.003536064355372736, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 430 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3308713957371693
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0004980564117431641s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 964 Step: 77034
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9162, 'bonus': 0.01044731901345371, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 530 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3126015549350255
Updated goal-option-2 on 8 transitions
Took 0.00036263465881347656s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (6, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 9194, 'bonus': 0.010429122058184137, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77042, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79967, 'bonus': 0.0035362633354758598, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75232, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 431 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39623748591494934
Updated goal-option-4 on 5 transitions
Took 0.00022745132446289062s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 965 Step: 77047
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77047, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9160, 'bonus': 0.010448459488214323, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 531 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40371227655891545
Updated goal-option-2 on 8 transitions
Deleting edge from SE([1 1]) to goal-option-2
Deleting edge from goal-option-3 to goal-option-2
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79971, 'bonus': 0.0035361748957275538, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75809, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 432 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42436213313291465
Updated goal-option-4 on 5 transitions
Took 0.0005536079406738281s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 966 Step: 77060
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9146, 'bonus': 0.01045645328318848, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74407, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 532 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.352890173579207
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79973, 'bonus': 0.0035361306783416287, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76347, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 433 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.5800869248713267
Updated goal-option-4 on 5 transitions
Took 0.0004992485046386719s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 967 Step: 77073
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9188, 'bonus': 0.010432526744729437, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 533 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.40598804134461614
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79973, 'bonus': 0.0035361306783416287, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76347, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 434 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.29329794336045617
Updated goal-option-4 on 5 transitions
Took 0.0005168914794921875s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 968 Step: 77086
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2732, 'bonus': 0.019131968294834524, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73694, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.14757850965573
Updated goal-option-5 on 213 transitions
Took 0.011715412139892578s to update distance table with 214 states and events {SE([2 5]), SE([1 1]), None}
DSG successfully reached SE([2 5])
Candidate events: [SE([1 1]), SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.18608968 0.27761318 0.27485089 0.26144625]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (2, 5) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 2761, 'bonus': 0.019031227316797756, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77299, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-3, goal-option-1, goal-option-2] and chose to execute goal-option-3
Rolling out goal-option-3, from [2 5] targeting {'count': 19621, 'bonus': 0.007139033684392702, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73821, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.205261508329415
Updated goal-option-3 on 9 transitions
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9174, 'bonus': 0.010440483998647202, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76342, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 534 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32240923400554394
Updated goal-option-2 on 8 transitions
Took 0.0007717609405517578s to update distance table with 18 states and events {None, SE([1 1]), SE([3 2]), SE([6 2]), SE([2 5])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.25662264 0.382836   0.36054136]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (6, 2) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'count': 9202, 'bonus': 0.010424587657074937, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79976, 'bonus': 0.003536064355372736, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76386, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 435 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4167589204147529
Updated goal-option-4 on 5 transitions
Took 0.0002491474151611328s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 969 Step: 77321
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77321, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9180, 'bonus': 0.010437071518085823, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76381, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 535 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3913060388973535
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79977, 'bonus': 0.003536042248545718, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76399, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 436 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32957063294876526
Updated goal-option-4 on 5 transitions
Took 0.0005166530609130859s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 970 Step: 77334
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([3 2])
[Graph Consolidation] From (1, 1) to [3 2]
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77334, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 7930, 'bonus': 0.011229577231219767, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74378, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 252 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.3786853412770727
Updated goal-option-1 on 5 transitions
Took 0.00021386146545410156s to update distance table with 6 states and events {SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([3 2])
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (3, 2) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'count': 8263, 'bonus': 0.01100097362925119, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77339, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-3] and chose to execute goal-option-3
Rolling out goal-option-3, from [3 2] targeting {'count': 16175, 'bonus': 0.007862811339707515, 'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57520, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-3 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1851461683526452
Updated goal-option-3 on 6 transitions
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2761, 'bonus': 0.019031227316797756, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77299, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.167207396461911
Updated goal-option-5 on 245 transitions
Took 0.029639720916748047s to update distance table with 252 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
Adding edge from goal-option-1 to goal-option-4
Adding edge from SE([3 2]) to goal-option-4
Took 1.8841986656188965s to add potential edges.
================================================================================
[Consolidation] Episode: 971 Step: 77590
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77590, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9204, 'bonus': 0.01042345498062708, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77329, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 536 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4067263377898849
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79986, 'bonus': 0.003535843305758826, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77073, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 437 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.29599328490690685
Updated goal-option-4 on 5 transitions
Deleting edge from goal-option-1 to goal-option-4
Deleting edge from SE([3 2]) to goal-option-4
Took 0.0005030632019042969s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 972 Step: 77603
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'count': 2761, 'bonus': 0.019031227316797756, 'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77299, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.151351616465807
Updated goal-option-5 on 256 transitions
Took 0.03136038780212402s to update distance table with 257 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 973 Step: 77859
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 2])
[Graph Consolidation] From (1, 1) to [6 2]
Planner goal: SE([6 2]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77859, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 2])
Got plan [goal-option-2] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9164, 'bonus': 0.010446178912068371, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75240, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 537 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.35232017474917104
Updated goal-option-2 on 8 transitions
Took 0.00031876564025878906s to update distance table with 9 states and events {SE([6 2]), SE([1 1]), None, SE([3 2])}
DSG successfully reached SE([6 2])
Candidate events: [SE([1 1]), SE([6 6]), SE([3 2])] | Probabilities: [0.25662264 0.382836   0.36054136]
[CompetenceConnected] DSG selected event: SE([1 1])
[Graph Consolidation] From (6, 2) to [1 1]
Planner goal: SE([1 1]), DSC goal: SE([1 1]) and Goal: SE([1 1])
True
False
[Planner] Rolling out from {'count': 9660, 'bonus': 0.010174461594455996, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([1 1])
Got plan [goal-option-4, goal-option-3-0, goal-option-3] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79989, 'bonus': 0.003535776998958026, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77334, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 438 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.29426985984351833
Updated goal-option-4 on 5 transitions
Took 0.00022649765014648438s to update distance table with 6 states and events {SE([6 6]), None, SE([6 2])}
================================================================================
[Consolidation] Episode: 974 Step: 77872
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77872, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9660, 'bonus': 0.010174461594455996, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77867, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 538 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.32725196892022895
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79990, 'bonus': 0.0035357548975200356, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77603, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 439 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2799455447930772
Updated goal-option-4 on 5 transitions
Took 0.0005052089691162109s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 975 Step: 77885
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([1 1]) and dsc goal vertex to SE([2 5])
Planner goal: SE([1 1]), DSC goal: SE([2 5]) and Goal: SE([2 5])
False
False
Rolling out DSC with goal vertex SE([2 5])
Rolling out goal-option-5, from [1 1] targeting {'player_pos': (2, 5), 'player_x': 2, 'player_y': 5, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2594900271032943
Updated goal-option-5 on 256 transitions
Took 0.011794328689575195s to update distance table with 257 states and events {SE([1 1]), None, SE([3 2])}
================================================================================
[Consolidation] Episode: 976 Step: 78141
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78141, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9662, 'bonus': 0.010173408501083154, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 539 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.34509328334623524
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79988, 'bonus': 0.003535799100810479, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77321, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 440 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.299654785559788
Updated goal-option-4 on 5 transitions
Took 0.0004999637603759766s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
================================================================================
[Consolidation] Episode: 977 Step: 78154
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9182, 'bonus': 0.010435934767930727, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76394, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 540 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.33744138318182787
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79992, 'bonus': 0.003535710695887391, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77885, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 441 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.42168494436667303
Updated goal-option-4 on 5 transitions
Took 0.0005464553833007812s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 978 Step: 78167
================================================================================
Candidate events: [SE([6 6]), SE([6 2]), SE([3 2])] | Probabilities: [0.34108572 0.33769186 0.32122243]
[CompetenceConnected] DSG selected event: SE([6 6])
[Graph Consolidation] From (1, 1) to [6 6]
Planner goal: SE([6 6]), DSC goal: SE([6 6]) and Goal: SE([6 6])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78167, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9176, 'bonus': 0.010439346133241541, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76355, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 541 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4446386141746124
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79973, 'bonus': 0.0035361306783416287, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76347, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 442 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.29743668985012367
Updated goal-option-4 on 5 transitions
Took 0.0005457401275634766s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
DSG successfully reached SE([6 6])
================================================================================
[Consolidation] Episode: 979 Step: 78180
================================================================================
[BoltzmannClosest] DSG selected event: SE([2 5])
[Graph Consolidation] From (1, 1) to [2 5]
Revised planner goal vertex to SE([6 6]) and dsc goal vertex to SE([2 5])
Planner goal: SE([6 6]), DSC goal: SE([2 5]) and Goal: SE([2 5])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78180, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([6 6])
Got plan [goal-option-2, goal-option-4] and chose to execute goal-option-2
Rolling out goal-option-2, from [1 1] targeting {'count': 9200, 'bonus': 0.010425720702853738, 'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77081, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-2 reached term set 542 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.39993245124398263
Updated goal-option-2 on 8 transitions
Got plan [goal-option-4] and chose to execute goal-option-4
Rolling out goal-option-4, from [6 2] targeting {'count': 79979, 'bonus': 0.003535998036135524, 'player_pos': (6, 6), 'player_x': 6, 'player_y': 6, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': True, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76425, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-4 reached term set 443 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.2631400721395426
Updated goal-option-4 on 5 transitions
Took 0.0005009174346923828s to update distance table with 14 states and events {None, SE([6 6]), SE([1 1]), SE([3 2]), SE([6 2])}
[Episode=980 Seed=18] Took 0.05849003791809082s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 980 Step: 78193
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 38.0	IntrinsicReward: -420.04895708709955
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 981 Step: 78193
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 44.0	IntrinsicReward: -271.7598546497684
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 982 Step: 78193
================================================================================
Attempting to expand SE([3 2])
Planner goal: SE([3 2]), DSC goal: SE([3 2]) and Goal: SE([3 2])
True
False
[Planner] Rolling out from {'player_pos': (1, 1), 'player_x': 1, 'player_y': 1, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78193, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([3 2])
Got plan [goal-option-1] and chose to execute goal-option-1
Rolling out goal-option-1, from [1 1] targeting {'count': 8106, 'bonus': 0.011106998169600174, 'player_pos': (3, 2), 'player_x': 3, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75814, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-1 reached term set 253 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.4083243500445411
Updated goal-option-1 on 5 transitions
[RND Rollout] Reward: 38.0	IntrinsicReward: -412.1347853690386
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x150370209070>
================================================================================
[Expansion] Episode: 983 Step: 78198
================================================================================
Attempting to expand SE([1 1])
