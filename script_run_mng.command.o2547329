Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/initiation_set_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/value_function_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/accepted_events 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/rejected_events 
Creating classifier of type cnn
Creating rainbow with sigma=0.5
Created model-free option global-option with option_idx=0
[DSGTrainer] Adding new SalientEvent  SE([ 8 16])
[Seed=18] Device count: 1 Device Name: NVIDIA GeForce GTX 1080 Ti
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 0 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: 17.385731933369243
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 1 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -55.33815276023233
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 2 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -61.308529528818326
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 3 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -83.00526064017322
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 4 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -70.77324671743554
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 5 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -100.61234208010137
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 6 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -111.0307346592599
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 7 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -96.428175476256
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 8 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -108.28004334593425
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 9 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -143.77925692498684
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 10 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -159.8137878133275
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 11 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -122.45063749223482
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 12 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -171.26193030551076
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 13 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -126.23198290623259
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 14 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -121.25232353809406
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 15 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -166.60255085257813
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 16 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -172.11483399290591
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 17 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -172.99342566161067
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 18 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -122.47376526737935
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 19 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -213.91892968676984
Accepted New Salient Event:  SE([15  7])
[DSGTrainer] Adding new SalientEvent  SE([15  7])
Took 2.6951546669006348s to update distance table with 20040 states and events {SE([15  7]), None, SE([ 8 16])}
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 20 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -189.5260570347309
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 21 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -185.7859684068244
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 22 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -148.42130243326392
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 23 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -193.08292885217816
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 24 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -221.66325572924688
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 25 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -168.33503906260012
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 26 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -221.92108611715958
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 27 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -214.9724751841277
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 28 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -217.66016626823694
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 29 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -213.5020639486611
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 30 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -128.02973956316418
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 31 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -221.04561844840646
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 32 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -229.98837921582162
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 33 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -215.99903192941565
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 34 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -228.34371585201006
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 35 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -211.10392936482094
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 36 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -254.49415765330195
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 37 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -204.27333075605566
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 38 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -223.72179661039263
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 39 Step: 0
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -256.9855575740803
Accepted New Salient Event:  SE([6 4])
[DSGTrainer] Adding new SalientEvent  SE([6 4])
Took 2.823808431625366s to update distance table with 20040 states and events {SE([6 4]), None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -223.20194552704925
Took 0.02615976333618164s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -54.243308497723774
Took 0.024817466735839844s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -186.79360789552447
Took 0.02015066146850586s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -231.82816448342055
Took 0.025321483612060547s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -249.99039489403367
Took 0.025898218154907227s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -241.71458470914513
Took 0.025210142135620117s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -51.299177255888935
Took 0.025896787643432617s to update distance table with 1001 states and events {SE([6 4]), None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -94.15988219558494
Took 0.02473592758178711s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -73.6257865492953
Took 0.025499820709228516s to update distance table with 1001 states and events {SE([6 4]), None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -252.6486633233726
Took 0.02489018440246582s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -264.2004511170089
Took 0.024626970291137695s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -270.4905278426595
Took 0.02594137191772461s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -261.8099111430347
Took 0.03174328804016113s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -273.9435587748885
Took 0.020943880081176758s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -289.1020106486976
Took 0.03456282615661621s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -267.2078589887824
Took 0.025002241134643555s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: 72.51969317393377
Took 0.02528071403503418s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -142.66741077961342
Took 0.02130746841430664s to update distance table with 1001 states and events {SE([6 4]), None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -94.54307019415137
Took 0.024993419647216797s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -213.4648079083563
Took 0.026323556900024414s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -293.546410149429
Took 0.0253298282623291s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -289.88081075134687
Took 0.024871110916137695s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -268.2608072459698
Took 0.02545905113220215s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -289.6023723920807
Took 0.029309511184692383s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -270.79660717190563
Took 0.022672653198242188s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -69.6772935025383
Took 0.025243759155273438s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -233.56038059608545
Took 0.02511000633239746s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -307.9285258203745
Took 0.03356456756591797s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -298.8908155236277
Took 0.025127172470092773s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -277.3026915061055
Took 0.027058839797973633s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -309.0809554979205
Took 0.025051355361938477s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -321.6345549374819
Took 0.025652647018432617s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -238.0603845778387
Took 0.025470256805419922s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -306.5723249553703
Took 0.02900099754333496s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -308.08999662287533
Took 0.027744293212890625s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -293.42257317434996
Took 0.02474069595336914s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -294.2725510606542
Took 0.02499842643737793s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -240.48921483452432
Took 0.02649068832397461s to update distance table with 1001 states and events {SE([6 4]), None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -283.7678256279323
Took 0.027521371841430664s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -334.2092658979818
Took 0.02480912208557129s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -314.289175292477
Took 0.026726961135864258s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -298.13489799248055
Took 0.024858951568603516s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -201.5608813802246
Took 0.020442485809326172s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -320.93847916089
Took 0.024960041046142578s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -329.9247155599296
Took 0.025873184204101562s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -323.3131145313382
Took 0.03176283836364746s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -316.52709128148854
Took 0.025325298309326172s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: 114.01640085941472
Took 0.02643108367919922s to update distance table with 1001 states and events {SE([15  7]), None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -121.46240188658703
Took 0.025042295455932617s to update distance table with 1001 states and events {None, SE([ 8 16])}
[RND Rollout] Reward: 0.0	IntrinsicReward: -60.1367413255648
Took 0.025400876998901367s to update distance table with 1001 states and events {None, SE([ 8 16])}
[SE([ 8 16]), SE([15  7]), SE([6 4])]
================================================================================
[Consolidation] Episode: 90 Step: 0
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([6 4])
Creating classifier of type cnn
Created model-free option goal-option-1 with option_idx=1
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024139881134033203s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 1.5020370483398438e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 91 Step: 100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024018287658691406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 92 Step: 200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024576187133789062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 93 Step: 300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024166107177734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 94 Step: 400
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024139881134033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 95 Step: 500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([15  7])
Creating classifier of type cnn
Created model-free option goal-option-2 with option_idx=2
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0023741722106933594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 96 Step: 600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.001840829849243164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 97 Step: 700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002492189407348633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 98 Step: 800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024559497833251953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 99 Step: 900
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0025141239166259766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 100 Step: 1000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024750232696533203s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 101 Step: 1100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002410411834716797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 102 Step: 1200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002715587615966797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 103 Step: 1300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.001844167709350586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 104 Step: 1400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002433300018310547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 105 Step: 1500
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024461746215820312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 106 Step: 1600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024535655975341797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 107 Step: 1700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002504587173461914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 108 Step: 1800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0027129650115966797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 109 Step: 1900
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002364635467529297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 110 Step: 2000
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002420663833618164s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 111 Step: 2100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024139881134033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 112 Step: 2200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026030540466308594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 113 Step: 2300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0019078254699707031s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 114 Step: 2400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024535655975341797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 115 Step: 2500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002458810806274414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 116 Step: 2600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0024995803833007812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 117 Step: 2700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0024271011352539062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 118 Step: 2800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024175643920898438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 119 Step: 2900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0025234222412109375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 120 Step: 3000
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0018401145935058594s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.86102294921875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 121 Step: 3100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002521038055419922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 122 Step: 3200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002357959747314453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 123 Step: 3300
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0019257068634033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 124 Step: 3400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026662349700927734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 125 Step: 3500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0025920867919921875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 126 Step: 3600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0028095245361328125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 127 Step: 3700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.001971006393432617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 128 Step: 3800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026807785034179688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 129 Step: 3900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002462148666381836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 130 Step: 4000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0023920536041259766s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.337860107421875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 131 Step: 4100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002531766891479492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 132 Step: 4200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024406909942626953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 133 Step: 4300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024259090423583984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 134 Step: 4400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002479076385498047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 135 Step: 4500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002553224563598633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 136 Step: 4600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024335384368896484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 137 Step: 4700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0019192695617675781s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 138 Step: 4800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0028219223022460938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 139 Step: 4900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0024399757385253906s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=140 Seed=18] Took 0.0167996883392334s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 140 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -95.85092541677295
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 141 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -328.27553216717206
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 142 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -359.2347460538149
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 143 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -365.9045769944787
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 144 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -170.05337710602907
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 145 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -350.265980117023
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 146 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -335.2832182748243
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 147 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -336.0841042213142
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 148 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -331.02716663945466
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 149 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -354.86092234402895
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 150 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -360.53552657179534
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 151 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -167.89575006417
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 152 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -209.4121256970102
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 153 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -369.9112909063697
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 154 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -362.02906564995646
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 155 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -177.04080018796958
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 156 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -361.37106376700103
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 157 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -392.6337811499834
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 158 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -380.02859080955386
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 159 Step: 5000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -333.57732426933944
Took 3.5717666149139404s to update distance table with 20040 states and events {None, SE([ 8 16])}
[Episode=160 Seed=18] Took 0.013421773910522461s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4])]
================================================================================
[Consolidation] Episode: 160 Step: 5000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0028717517852783203s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 1.0013580322265625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 161 Step: 5100
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0026781558990478516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 162 Step: 5200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0020122528076171875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 163 Step: 5300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026960372924804688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 164 Step: 5400
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030820369720458984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 165 Step: 5500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00284576416015625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 166 Step: 5600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002747774124145508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 167 Step: 5700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002644062042236328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 168 Step: 5800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002759218215942383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 169 Step: 5900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0020380020141601562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 170 Step: 6000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026721954345703125s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 171 Step: 6100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002608060836791992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 172 Step: 6200
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0030488967895507812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 173 Step: 6300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0027360916137695312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 174 Step: 6400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027513504028320312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 175 Step: 6500
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027899742126464844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 176 Step: 6600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0020754337310791016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 177 Step: 6700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002689838409423828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 178 Step: 6800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0026426315307617188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 179 Step: 6900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00276947021484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 180 Step: 7000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0028028488159179688s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 181 Step: 7100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002722024917602539s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 182 Step: 7200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002705097198486328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 183 Step: 7300
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026276111602783203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 184 Step: 7400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002724885940551758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 185 Step: 7500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003088712692260742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 186 Step: 7600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0021021366119384766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 187 Step: 7700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002743244171142578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 188 Step: 7800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002835512161254883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 189 Step: 7900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027620792388916016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 190 Step: 8000
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027916431427001953s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 191 Step: 8100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002669811248779297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 192 Step: 8200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027015209197998047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 193 Step: 8300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0020427703857421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 194 Step: 8400
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002778768539428711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 195 Step: 8500
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030143260955810547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 196 Step: 8600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002798318862915039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 197 Step: 8700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027930736541748047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 198 Step: 8800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002741098403930664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 199 Step: 8900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027208328247070312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 200 Step: 9000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002069234848022461s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.337860107421875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 201 Step: 9100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0028951168060302734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 202 Step: 9200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0028171539306640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 203 Step: 9300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026388168334960938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 204 Step: 9400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002786874771118164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 205 Step: 9500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0026051998138427734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 206 Step: 9600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027053356170654297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 207 Step: 9700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002015829086303711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 208 Step: 9800
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00276947021484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 209 Step: 9900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4])] | Probs: [[0.45623964 0.54376036]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0027871131896972656s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=210 Seed=18] Took 0.011066913604736328s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 210 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -375.6602252498269
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 211 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -254.72100314800628
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 212 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -293.57392312871525
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 213 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -340.0028556936886
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 214 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -346.60275808908045
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 215 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -337.52830196078867
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 216 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -367.4708100128919
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 217 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -239.49135575536638
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 218 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -366.37864903965965
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 219 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -379.0137634128332
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 220 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -384.4703030437231
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 221 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -371.589623473119
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 222 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -378.5691617108532
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 223 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -396.1120692845434
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 224 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -149.98661184642697
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 225 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -353.81293702259427
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 226 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -371.9676198735833
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 227 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -410.1424562484026
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 228 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -413.7144517824054
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 229 Step: 10000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -405.38196708261967
Accepted New Salient Event:  SE([6 2])
[DSGTrainer] Adding new SalientEvent  SE([6 2])
Took 5.225075960159302s to update distance table with 20040 states and events {SE([6 2]), None, SE([ 8 16])}
[Episode=230 Seed=18] Took 0.012325286865234375s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2])]
================================================================================
[Consolidation] Episode: 230 Step: 10000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003087282180786133s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 231 Step: 10100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030825138092041016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 232 Step: 10200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003209829330444336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 233 Step: 10300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([6 2])
Creating classifier of type cnn
Created model-free option goal-option-3 with option_idx=3
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003360271453857422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 234 Step: 10400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003242015838623047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 235 Step: 10500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032808780670166016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 236 Step: 10600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031213760375976562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 237 Step: 10700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0023436546325683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 238 Step: 10800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003022432327270508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 239 Step: 10900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031652450561523438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 240 Step: 11000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003157377243041992s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 1.0013580322265625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 241 Step: 11100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0029747486114501953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 242 Step: 11200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031371116638183594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 243 Step: 11300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003000974655151367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 244 Step: 11400
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002333402633666992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 245 Step: 11500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003191232681274414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 246 Step: 11600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003170013427734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 247 Step: 11700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003103017807006836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 248 Step: 11800
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030684471130371094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 249 Step: 11900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031392574310302734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 250 Step: 12000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033109188079833984s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 251 Step: 12100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0025420188903808594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 252 Step: 12200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002986907958984375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 253 Step: 12300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031599998474121094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 254 Step: 12400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030493736267089844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 255 Step: 12500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003031015396118164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 256 Step: 12600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003270864486694336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 257 Step: 12700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003025054931640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 258 Step: 12800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0023474693298339844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 259 Step: 12900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003113269805908203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 260 Step: 13000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003261566162109375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.337860107421875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 261 Step: 13100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003071308135986328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 262 Step: 13200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033075809478759766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 263 Step: 13300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003084421157836914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 264 Step: 13400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0030274391174316406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 265 Step: 13500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003020763397216797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 266 Step: 13600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0029833316802978516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 267 Step: 13700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030558109283447266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 268 Step: 13800
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0024182796478271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 269 Step: 13900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032935142517089844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 270 Step: 14000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003182649612426758s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 271 Step: 14100
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003021717071533203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 272 Step: 14200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031828880310058594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 273 Step: 14300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0030558109283447266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 274 Step: 14400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032248497009277344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 275 Step: 14500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002321481704711914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 276 Step: 14600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0029540061950683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 277 Step: 14700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030808448791503906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 278 Step: 14800
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031952857971191406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 279 Step: 14900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031807422637939453s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=280 Seed=18] Took 0.010789632797241211s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 280 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -397.0969265252352
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 281 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -400.2296402743086
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 282 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -416.377073854208
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 283 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -355.23299983084144
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 284 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -402.158538389951
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 285 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -419.3854718655348
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 286 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -402.0450763311237
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 287 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -416.15080969035625
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 288 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -399.34795804321766
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 289 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -408.2375476658344
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 290 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -413.6402845233679
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 291 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -313.9369049430825
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 292 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -429.7388227581978
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 293 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -410.323176458478
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 294 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -391.09709507162916
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 295 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.59200154803693
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 296 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -424.526718840003
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 297 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -407.63860588520765
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 298 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -439.6751988530159
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 299 Step: 15000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -389.4404929727316
Took 6.342615127563477s to update distance table with 20040 states and events {None, SE([ 8 16])}
[Episode=300 Seed=18] Took 0.016733407974243164s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2])]
================================================================================
[Consolidation] Episode: 300 Step: 15000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031130313873291016s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.337860107421875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 301 Step: 15100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030269622802734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 302 Step: 15200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003041982650756836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 303 Step: 15300
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031461715698242188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 304 Step: 15400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002974271774291992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 305 Step: 15500
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031599998474121094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 306 Step: 15600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003562450408935547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 307 Step: 15700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037200450897216797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 308 Step: 15800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035965442657470703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 309 Step: 15900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.002655029296875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 310 Step: 16000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003603696823120117s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 311 Step: 16100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003569364547729492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 312 Step: 16200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035333633422851562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 313 Step: 16300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034902095794677734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 314 Step: 16400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003751516342163086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 315 Step: 16500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033981800079345703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 316 Step: 16600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003359556198120117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 317 Step: 16700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003559112548828125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 318 Step: 16800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003323078155517578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 319 Step: 16900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00267791748046875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 320 Step: 17000
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034384727478027344s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 321 Step: 17100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003733396530151367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 322 Step: 17200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003366708755493164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 323 Step: 17300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035037994384765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 324 Step: 17400
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00347137451171875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 325 Step: 17500
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003582477569580078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 326 Step: 17600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003570556640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 327 Step: 17700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003357410430908203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 328 Step: 17800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003528118133544922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 329 Step: 17900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0028612613677978516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 330 Step: 18000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034027099609375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.291534423828125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 331 Step: 18100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034134387969970703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 332 Step: 18200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003427267074584961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 333 Step: 18300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030286312103271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 334 Step: 18400
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003054380416870117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 335 Step: 18500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0029985904693603516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 336 Step: 18600
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.002434253692626953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 337 Step: 18700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032873153686523438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 338 Step: 18800
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032820701599121094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 339 Step: 18900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003079652786254883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 340 Step: 19000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031173229217529297s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 341 Step: 19100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003132343292236328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 342 Step: 19200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032515525817871094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 343 Step: 19300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003116130828857422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 344 Step: 19400
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030760765075683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 345 Step: 19500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003051280975341797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 346 Step: 19600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0023882389068603516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 347 Step: 19700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003088235855102539s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 348 Step: 19800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0030384063720703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 349 Step: 19900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2])] | Probs: [[0.31034675 0.36988075 0.31977251]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002568960189819336s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=350 Seed=18] Took 0.014466047286987305s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 350 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.1805241405964
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 351 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -349.69099049444776
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 352 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -425.20296663045883
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 353 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -427.85338847339153
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 354 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -332.7432018832769
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 355 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -436.1117655215785
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 356 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -418.0062702521682
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 357 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -399.70749916601926
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 358 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -415.9782058298588
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 359 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.6355749517679
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 360 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -443.3785907626152
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 361 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -377.8350702431053
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 362 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -446.70122399926186
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 363 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -408.5207448154688
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 364 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -372.1434969273396
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 365 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -439.5664191171527
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 366 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -390.74418822542066
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 367 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -407.11536081135273
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 368 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -427.5626695244573
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 369 Step: 20000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -410.129389335576
Accepted New Salient Event:  SE([14 14])
[DSGTrainer] Adding new SalientEvent  SE([14 14])
Took 6.178515911102295s to update distance table with 20040 states and events {SE([14 14]), None, SE([ 8 16])}
[Episode=370 Seed=18] Took 0.01146554946899414s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])]
================================================================================
[Consolidation] Episode: 370 Step: 20000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([14 14])
Creating classifier of type cnn
Created model-free option goal-option-4 with option_idx=4
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003956317901611328s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 371 Step: 20100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038881301879882812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 372 Step: 20200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003620624542236328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 373 Step: 20300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003928184509277344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 374 Step: 20400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036077499389648438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 375 Step: 20500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036766529083251953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 376 Step: 20600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031414031982421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 377 Step: 20700
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00408172607421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 378 Step: 20800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003796100616455078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 379 Step: 20900
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003810405731201172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 380 Step: 21000
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037915706634521484s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 381 Step: 21100
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003660917282104492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 382 Step: 21200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037763118743896484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 383 Step: 21300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00389862060546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 384 Step: 21400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039577484130859375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 385 Step: 21500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040433406829833984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 386 Step: 21600
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.002900838851928711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 387 Step: 21700
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037360191345214844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 388 Step: 21800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040814876556396484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 389 Step: 21900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0028073787689208984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 390 Step: 22000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038421154022216797s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 391 Step: 22100
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003709554672241211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 392 Step: 22200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0028753280639648438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 393 Step: 22300
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003625631332397461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 394 Step: 22400
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003733396530151367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 395 Step: 22500
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003694772720336914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 396 Step: 22600
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004106283187866211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 397 Step: 22700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037245750427246094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 398 Step: 22800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004135847091674805s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 399 Step: 22900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.002992391586303711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 400 Step: 23000
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038137435913085938s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 401 Step: 23100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003575563430786133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 402 Step: 23200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039017200469970703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 403 Step: 23300
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039997100830078125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 404 Step: 23400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003839731216430664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 405 Step: 23500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003911495208740234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 406 Step: 23600
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0028107166290283203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 407 Step: 23700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004017829895019531s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 408 Step: 23800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004008054733276367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 409 Step: 23900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002686023712158203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 410 Step: 24000
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037391185760498047s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 411 Step: 24100
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003949165344238281s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 412 Step: 24200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003931760787963867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 413 Step: 24300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034630298614501953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 414 Step: 24400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003749847412109375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 415 Step: 24500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040285587310791016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 416 Step: 24600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003808736801147461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 417 Step: 24700
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004116058349609375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 418 Step: 24800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003991365432739258s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 419 Step: 24900
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030333995819091797s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=420 Seed=18] Took 0.011432886123657227s to save gc logs
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 420 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -444.0379732400179
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 421 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -421.5475561292842
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 422 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -385.71734217973426
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 423 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -432.89705246314406
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 424 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -417.1331903762184
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 425 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -290.1938570927596
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 426 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.4066088180989
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 427 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -427.39778314344585
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 428 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -409.2101679742336
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 429 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -400.1722013615072
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 430 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -410.9644809290767
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 431 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -411.61696345731616
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 432 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -391.59004297852516
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 433 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -396.97295758407563
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 434 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -180.2098086992046
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 435 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -242.45176171942148
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 436 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -402.77864697854966
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 437 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -428.00223458744586
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 438 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -386.34021809790283
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x1471e8906d00>
================================================================================
[Expansion] Episode: 439 Step: 25000
================================================================================
Attempting to expand SE([ 8 16])
[RND Rollout] Reward: 0.0	IntrinsicReward: -282.37016842802404
Accepted New Salient Event:  SE([ 5 13])
[DSGTrainer] Adding new SalientEvent  SE([ 5 13])
Took 6.083435773849487s to update distance table with 20040 states and events {SE([14 14]), None, SE([ 8 16]), SE([ 5 13])}
[Episode=440 Seed=18] Took 0.02173781394958496s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 440 Step: 25000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.16890438 0.20130541 0.1740343  0.18690014 0.26885577]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[DeepSkillGraphsAgent] Creating chain from SE([ 8 16]) -> SE([ 5 13])
Creating classifier of type cnn
Created model-free option goal-option-5 with option_idx=5
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-5 on 100 transitions
Took 0.0046291351318359375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 441 Step: 25100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.16890438 0.20130541 0.1740343  0.18690014 0.26885577]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
8.834759846329689
Updated goal-option-5 on 54 transitions
Took 0.004254579544067383s to update distance table with 55 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[DeepSkillGraphsAgent] Creating chain from SE([ 5 13]) -> SE([6 4])
Creating classifier of type cnn
Created model-free option goal-option-6 with option_idx=6
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 46 transitions
Took 0.00279998779296875s to update distance table with 47 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 442 Step: 25200
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004324436187744141s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 443 Step: 25300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
17.2412309885025
Updated goal-option-5 on 100 transitions
Took 0.0047359466552734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 444 Step: 25400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0048427581787109375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 445 Step: 25500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
12.213475057056973
Updated goal-option-5 on 100 transitions
Took 0.0049588680267333984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 446 Step: 25600
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
9.6984686901172
Updated goal-option-5 on 100 transitions
Took 0.00435638427734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 447 Step: 25700
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.005178213119506836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 448 Step: 25800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
11.874538854757946
Updated goal-option-5 on 100 transitions
Took 0.004827976226806641s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 449 Step: 25900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
11.752310578570222
Updated goal-option-5 on 100 transitions
Took 0.004958152770996094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 450 Step: 26000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.380345087784987
Updated goal-option-5 on 100 transitions
Took 0.00464630126953125s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 5.0067901611328125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 451 Step: 26100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0044443607330322266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 452 Step: 26200
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0040073394775390625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 453 Step: 26300
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004140615463256836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 454 Step: 26400
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004610300064086914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 455 Step: 26500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004648447036743164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 456 Step: 26600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004914760589599609s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 457 Step: 26700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.876362710499792
Updated goal-option-5 on 100 transitions
Took 0.004875659942626953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 458 Step: 26800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004462242126464844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 459 Step: 26900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
8.050470914940039
Updated goal-option-5 on 100 transitions
Took 0.0059206485748291016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 460 Step: 27000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8184929336695106
Updated goal-option-5 on 100 transitions
Took 0.004546165466308594s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.5299530029296875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 461 Step: 27100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.228227825076492
Updated goal-option-5 on 100 transitions
Took 0.006266117095947266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 462 Step: 27200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0049037933349609375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 463 Step: 27300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
6.851158747442981
Updated goal-option-5 on 100 transitions
Took 0.0047528743743896484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 464 Step: 27400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004830121994018555s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 465 Step: 27500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.553802700837453
Updated goal-option-5 on 100 transitions
Took 0.005207061767578125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 466 Step: 27600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004376649856567383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 467 Step: 27700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004112958908081055s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 468 Step: 27800
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0044019222259521484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 469 Step: 27900
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00460362434387207s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 470 Step: 28000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.442636677705626
Updated goal-option-5 on 100 transitions
Took 0.005907297134399414s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 6.198883056640625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 471 Step: 28100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004538774490356445s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 472 Step: 28200
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.754532764703907
Updated goal-option-5 on 100 transitions
Took 0.00485992431640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 473 Step: 28300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004541635513305664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 474 Step: 28400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9978584701579716
Updated goal-option-5 on 100 transitions
Took 0.005880832672119141s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 475 Step: 28500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.0496524094873
Updated goal-option-5 on 100 transitions
Took 0.004514455795288086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 476 Step: 28600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004372596740722656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 477 Step: 28700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.13280333 0.15827907 0.13683679 0.14695273 0.42512807]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035088062286376953s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 478 Step: 28800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004637956619262695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 479 Step: 28900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004808187484741211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 480 Step: 29000
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033593177795410156s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.86102294921875e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 481 Step: 29100
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0045659542083740234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 482 Step: 29200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.640055961428344
Updated goal-option-5 on 100 transitions
Took 0.006308555603027344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 483 Step: 29300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004685401916503906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 484 Step: 29400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004652261734008789s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 485 Step: 29500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004398345947265625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 486 Step: 29600
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.094631528498112
Updated goal-option-5 on 100 transitions
Took 0.006542205810546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 487 Step: 29700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004827737808227539s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 488 Step: 29800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004660844802856445s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 489 Step: 29900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004253387451171875s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=490 Seed=18] Took 0.008611679077148438s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 490 Step: 30000
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004374027252197266s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 491 Step: 30100
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040814876556396484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 492 Step: 30200
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004931211471557617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 493 Step: 30300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.993312834168498
Updated goal-option-5 on 100 transitions
Took 0.00551915168762207s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 494 Step: 30400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0043811798095703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 495 Step: 30500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004846334457397461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 496 Step: 30600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
5.715992261154086
Updated goal-option-5 on 100 transitions
Took 0.004659891128540039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 497 Step: 30700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.12925702 0.15405247 0.13318278 0.14302859 0.44047914]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.622164859006435
Updated goal-option-5 on 100 transitions
Took 0.00422358512878418s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 498 Step: 30800
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004767179489135742s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 499 Step: 30900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.11586019 0.13808572 0.11937906 0.1282044  0.49847063]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004422426223754883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 500 Step: 31000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.11586019 0.13808572 0.11937906 0.1282044  0.49847063]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.1733884764008824
Updated goal-option-5 on 100 transitions
Took 0.004716396331787109s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 501 Step: 31100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.11586019 0.13808572 0.11937906 0.1282044  0.49847063]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.2791057699256476
Updated goal-option-5 on 85 transitions
Took 0.005191326141357422s to update distance table with 86 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[DeepSkillGraphsAgent] Creating chain from SE([ 5 13]) -> SE([6 2])
Creating classifier of type cnn
Created model-free option goal-option-7 with option_idx=7
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 15 transitions
Took 0.0009076595306396484s to update distance table with 16 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 502 Step: 31200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.11586019 0.13808572 0.11937906 0.1282044  0.49847063]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.959357234271797
Updated goal-option-5 on 100 transitions
Took 0.005631685256958008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 503 Step: 31300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.11586019 0.13808572 0.11937906 0.1282044  0.49847063]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
3.8805767543195526
Updated goal-option-5 on 30 transitions
Took 0.0013899803161621094s to update distance table with 31 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[DeepSkillGraphsAgent] Creating chain from SE([ 5 13]) -> SE([ 8 16])
Creating classifier of type cnn
Created model-free option goal-option-8 with option_idx=8
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 70 transitions
Took 0.00347900390625s to update distance table with 71 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 504 Step: 31400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00480198860168457s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 505 Step: 31500
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003957986831665039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 506 Step: 31600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.009085636916813
Updated goal-option-5 on 100 transitions
Took 0.004552125930786133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 507 Step: 31700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.038316210312544
Updated goal-option-5 on 100 transitions
Took 0.005519390106201172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 508 Step: 31800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0860465990970884
Updated goal-option-5 on 100 transitions
Took 0.005545377731323242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 509 Step: 31900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3006486984629193
Updated goal-option-5 on 100 transitions
Took 0.00555872917175293s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 510 Step: 32000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004433870315551758s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 511 Step: 32100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004854679107666016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 512 Step: 32200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004455089569091797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 513 Step: 32300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.8314290154550434
Updated goal-option-5 on 100 transitions
Took 0.0049822330474853516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 514 Step: 32400
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004619121551513672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 515 Step: 32500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003508329391479492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 516 Step: 32600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038259029388427734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 517 Step: 32700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.742443734277673
Updated goal-option-5 on 100 transitions
Took 0.005290985107421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 518 Step: 32800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.2252946203591684
Updated goal-option-5 on 100 transitions
Took 0.0053098201751708984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 519 Step: 32900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.005030155181884766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 520 Step: 33000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.005383491516113281s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 521 Step: 33100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.5862525904874794
Updated goal-option-5 on 100 transitions
Took 0.005480289459228516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 522 Step: 33200
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7658634076211643
Updated goal-option-5 on 100 transitions
Took 0.0053141117095947266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 523 Step: 33300
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.005011081695556641s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 524 Step: 33400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9751017329222444
Updated goal-option-5 on 100 transitions
Took 0.005299806594848633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 525 Step: 33500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004681825637817383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 526 Step: 33600
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004601001739501953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 527 Step: 33700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9351194113078136
Updated goal-option-5 on 100 transitions
Took 0.004851579666137695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 528 Step: 33800
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033087730407714844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 529 Step: 33900
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7981438062020714
Updated goal-option-5 on 100 transitions
Took 0.004968404769897461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 530 Step: 34000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.005406379699707031s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 531 Step: 34100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0872868619568936
Updated goal-option-5 on 100 transitions
Took 0.004965305328369141s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 532 Step: 34200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8504655235271
Updated goal-option-5 on 100 transitions
Took 0.004537105560302734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 533 Step: 34300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.6960311756845106
Updated goal-option-5 on 100 transitions
Took 0.005528688430786133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 534 Step: 34400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.005681037902832031s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 535 Step: 34500
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005261659622192383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 536 Step: 34600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.629904491947615
Updated goal-option-5 on 100 transitions
Took 0.006463050842285156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 537 Step: 34700
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004688739776611328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 538 Step: 34800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.932562301893134
Updated goal-option-5 on 100 transitions
Took 0.006821155548095703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 539 Step: 34900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039806365966796875s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=540 Seed=18] Took 0.00893259048461914s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 540 Step: 35000
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004006385803222656s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.814697265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 541 Step: 35100
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003935098648071289s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 542 Step: 35200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004913806915283203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 543 Step: 35300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004755973815917969s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 544 Step: 35400
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004138469696044922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 545 Step: 35500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035779476165771484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 546 Step: 35600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2016233059655206
Updated goal-option-5 on 100 transitions
Took 0.006399869918823242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 547 Step: 35700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.300452712933201
Updated goal-option-5 on 100 transitions
Took 0.006449460983276367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 548 Step: 35800
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004059553146362305s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 549 Step: 35900
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0046041011810302734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 550 Step: 36000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.6724984330626635
Updated goal-option-5 on 100 transitions
Took 0.0062792301177978516s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 5.7220458984375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 551 Step: 36100
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4418975984522604
Updated goal-option-5 on 100 transitions
Took 0.005905866622924805s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 552 Step: 36200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.174256486005176
Updated goal-option-5 on 100 transitions
Took 0.006713151931762695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 553 Step: 36300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038194656372070312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 554 Step: 36400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3599599330349115
Updated goal-option-5 on 100 transitions
Took 0.006739377975463867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 555 Step: 36500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032224655151367188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 556 Step: 36600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.94171970363075
Updated goal-option-5 on 100 transitions
Took 0.006315708160400391s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 557 Step: 36700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00460505485534668s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 558 Step: 36800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.393936284804258
Updated goal-option-5 on 100 transitions
Took 0.005675792694091797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 559 Step: 36900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6692487486386127
Updated goal-option-5 on 60 transitions
Took 0.002950906753540039s to update distance table with 61 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 40 transitions
Took 0.0020742416381835938s to update distance table with 41 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 560 Step: 37000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5688631213187285
Updated goal-option-5 on 62 transitions
Took 0.0029757022857666016s to update distance table with 63 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 38 transitions
Took 0.0019474029541015625s to update distance table with 39 states and events {None, SE([ 5 13])}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 561 Step: 37100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0042417049407958984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 562 Step: 37200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004376649856567383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 563 Step: 37300
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.821428001617331
Updated goal-option-5 on 91 transitions
Took 0.004885435104370117s to update distance table with 92 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 9 transitions
Took 0.0005323886871337891s to update distance table with 10 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 564 Step: 37400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.602098304324162
Updated goal-option-5 on 100 transitions
Took 0.005116462707519531s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 565 Step: 37500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0045261383056640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 566 Step: 37600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6329742346344238
Updated goal-option-5 on 100 transitions
Took 0.004798412322998047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 567 Step: 37700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00468754768371582s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 568 Step: 37800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6573555603253016
Updated goal-option-5 on 100 transitions
Took 0.005043745040893555s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 569 Step: 37900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7789285100354686
Updated goal-option-5 on 100 transitions
Took 0.0052449703216552734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 570 Step: 38000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.005194187164306641s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 4.0531158447265625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 571 Step: 38100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3516391001936268
Updated goal-option-5 on 100 transitions
Took 0.004288911819458008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 572 Step: 38200
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004450321197509766s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 573 Step: 38300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7129802134078083
Updated goal-option-5 on 100 transitions
Took 0.005587339401245117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 574 Step: 38400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8565526504626682
Updated goal-option-5 on 100 transitions
Took 0.005434274673461914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 575 Step: 38500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9552855468388148
Updated goal-option-5 on 100 transitions
Took 0.005007266998291016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 576 Step: 38600
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004934549331665039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 577 Step: 38700
================================================================================
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004477500915527344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 578 Step: 38800
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036118030548095703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 579 Step: 38900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.1461717453267837
Updated goal-option-5 on 100 transitions
Took 0.005717277526855469s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 580 Step: 39000
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004015207290649414s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.0994415283203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 581 Step: 39100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.165065439782977
Updated goal-option-5 on 100 transitions
Took 0.004770755767822266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 582 Step: 39200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3124941255112437
Updated goal-option-5 on 100 transitions
Took 0.005213260650634766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 583 Step: 39300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.054815674132051
Updated goal-option-5 on 100 transitions
Took 0.0047070980072021484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 584 Step: 39400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004392862319946289s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 585 Step: 39500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.364930339335769
Updated goal-option-5 on 100 transitions
Took 0.004976987838745117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 586 Step: 39600
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5858839987459825
Updated goal-option-5 on 100 transitions
Took 0.005136251449584961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 587 Step: 39700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5789084130361435
Updated goal-option-5 on 100 transitions
Took 0.005232095718383789s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 588 Step: 39800
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.060012331744091
Updated goal-option-5 on 100 transitions
Took 0.005231380462646484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 589 Step: 39900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6705126665543126
Updated goal-option-5 on 100 transitions
Took 0.0050694942474365234s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=590 Seed=18] Took 0.010727405548095703s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 590 Step: 40000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8915618133478496
Updated goal-option-5 on 100 transitions
Took 0.004865169525146484s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 5.4836273193359375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 591 Step: 40100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.0501159495360923
Updated goal-option-5 on 100 transitions
Took 0.004940509796142578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 592 Step: 40200
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004058122634887695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 593 Step: 40300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6239442030030862
Updated goal-option-5 on 100 transitions
Took 0.006231069564819336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 594 Step: 40400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.8696536263873031
Updated goal-option-5 on 72 transitions
Took 0.004823446273803711s to update distance table with 73 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 28 transitions
Took 0.0015881061553955078s to update distance table with 29 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 595 Step: 40500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004662275314331055s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 596 Step: 40600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0049021244049072266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 597 Step: 40700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0047643184661865234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 598 Step: 40800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.408280992860852
Updated goal-option-5 on 100 transitions
Took 0.006632328033447266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 599 Step: 40900
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004672527313232422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 600 Step: 41000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8193945607044268
Updated goal-option-5 on 100 transitions
Took 0.006400346755981445s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 6.198883056640625e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 601 Step: 41100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4647313159446285
Updated goal-option-5 on 31 transitions
Took 0.0016074180603027344s to update distance table with 32 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 69 transitions
Took 0.0035767555236816406s to update distance table with 70 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 602 Step: 41200
================================================================================
[Random] Deep skill graphs target event: SE([ 5 13])
[Random] DSG selected event SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2006, 'bonus': 0.022327214034455325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5006988084209774
Updated goal-option-5 on 100 transitions
Took 0.005604267120361328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 603 Step: 41300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.0255412626706186
Updated goal-option-5 on 100 transitions
Took 0.005605220794677734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 604 Step: 41400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004597663879394531s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 605 Step: 41500
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004835844039916992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 606 Step: 41600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8511388323813343
Updated goal-option-5 on 100 transitions
Took 0.005114555358886719s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 607 Step: 41700
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032701492309570312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 608 Step: 41800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8428709768958953
Updated goal-option-5 on 100 transitions
Took 0.005064487457275391s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 609 Step: 41900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004476070404052734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 610 Step: 42000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.53952179040902
Updated goal-option-5 on 34 transitions
Took 0.0019199848175048828s to update distance table with 35 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 66 transitions
Took 0.003309965133666992s to update distance table with 67 states and events {None, SE([ 5 13])}
Took 3.5762786865234375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 611 Step: 42100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8859585032657844
Updated goal-option-5 on 100 transitions
Took 0.0051882266998291016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 612 Step: 42200
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004564762115478516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 613 Step: 42300
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004288434982299805s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 614 Step: 42400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004665851593017578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 615 Step: 42500
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0042154788970947266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 616 Step: 42600
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004587411880493164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 617 Step: 42700
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033626556396484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 618 Step: 42800
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0042285919189453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 619 Step: 42900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5885126246933723
Updated goal-option-5 on 100 transitions
Took 0.0053386688232421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 620 Step: 43000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8431820413897269
Updated goal-option-5 on 100 transitions
Took 0.005079507827758789s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.76837158203125e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 621 Step: 43100
================================================================================
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004633665084838867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 622 Step: 43200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9245859012176545
Updated goal-option-5 on 100 transitions
Took 0.005391836166381836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 623 Step: 43300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004121065139770508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 624 Step: 43400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7678262763269863
Updated goal-option-5 on 100 transitions
Took 0.005239248275756836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 625 Step: 43500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.353487428034062
Updated goal-option-5 on 100 transitions
Took 0.005533456802368164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 626 Step: 43600
================================================================================
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0047762393951416016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 627 Step: 43700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6248324602895738
Updated goal-option-5 on 100 transitions
Took 0.0054624080657958984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 628 Step: 43800
================================================================================
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004151582717895508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 629 Step: 43900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.987226213916391
Updated goal-option-5 on 100 transitions
Took 0.005370140075683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 630 Step: 44000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4933554231074275
Updated goal-option-5 on 100 transitions
Took 0.005674600601196289s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 5.4836273193359375e-06s to add potential edges.
================================================================================
[Consolidation] Episode: 631 Step: 44100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004043102264404297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 632 Step: 44200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.419137493220778
Updated goal-option-5 on 100 transitions
Took 0.004961729049682617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 633 Step: 44300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037004947662353516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 634 Step: 44400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3979170117767836
Updated goal-option-5 on 100 transitions
Took 0.0052220821380615234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 635 Step: 44500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])] | Probs: [[0.06309995 0.07520445 0.0650164  0.06982287 0.72685635]]
[BoltzmannClosest] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([ 5 13])
Planner goal: SE([ 8 16]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
False
False
Rolling out DSC with goal vertex SE([ 5 13])
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4796097430182094
Updated goal-option-5 on 32 transitions
Creating goal-option-5-0 with parent goal-option-5
Creating classifier of type cnn
Created model-free option goal-option-5-0 with option_idx=9
Case 3: Adding edge from goal-option-5 to SE([ 5 13])
Took 0.0012578964233398438s to update distance table with 33 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 68 transitions
Took 0.0034799575805664062s to update distance table with 69 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 636 Step: 44600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004453420639038086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 637 Step: 44700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0052204132080078125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 638 Step: 44800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.487433796985668
Updated goal-option-5 on 100 transitions
Took 0.005282402038574219s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 639 Step: 44900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005023002624511719s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=640 Seed=18] Took 0.009346246719360352s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 640 Step: 45000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0053708553314208984s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.05076241493225098s to add potential edges.
================================================================================
[Consolidation] Episode: 641 Step: 45100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5144312334796777
Updated goal-option-5 on 100 transitions
Took 0.005178213119506836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 642 Step: 45200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6329735639658722
Updated goal-option-5 on 100 transitions
Took 0.0052678585052490234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 643 Step: 45300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004729509353637695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 644 Step: 45400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4071112128129013
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.005299568176269531s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 645 Step: 45500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4746050543966096
Updated goal-option-5 on 100 transitions
Took 0.006803274154663086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 646 Step: 45600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003983020782470703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 647 Step: 45700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 45700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5191442573474145
Updated goal-option-5 on 100 transitions
Took 0.0047380924224853516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 648 Step: 45800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003762960433959961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 649 Step: 45900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004024505615234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 650 Step: 46000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004205465316772461s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.010323286056518555s to add potential edges.
================================================================================
[Consolidation] Episode: 651 Step: 46100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035178661346435547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 652 Step: 46200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5299798729235496
Updated goal-option-5 on 100 transitions
Took 0.00420379638671875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 653 Step: 46300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037469863891601562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 654 Step: 46400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003751993179321289s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 655 Step: 46500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004140377044677734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 656 Step: 46600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003909111022949219s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 657 Step: 46700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036652088165283203s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 658 Step: 46800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 46800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2194369977599684
Updated goal-option-5 on 100 transitions
Took 0.005467414855957031s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 659 Step: 46900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003757953643798828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 660 Step: 47000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003787994384765625s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.010198831558227539s to add potential edges.
================================================================================
[Consolidation] Episode: 661 Step: 47100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003651857376098633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 662 Step: 47200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038480758666992188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 663 Step: 47300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003482341766357422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 664 Step: 47400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033152103424072266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 665 Step: 47500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.870072533773645
Updated goal-option-5 on 81 transitions
Took 0.004670381546020508s to update distance table with 82 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 19 transitions
Took 0.0007984638214111328s to update distance table with 20 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 666 Step: 47600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.23101377 0.27532928 0.23803005 0.2556269 ]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003737211227416992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 667 Step: 47700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2042, 'bonus': 0.022129526988628804, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.825184851155704
Updated goal-option-5 on 100 transitions
Took 0.005628347396850586s to update distance table with 101 states and events {SE([15  7]), None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 668 Step: 47800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033359527587890625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 669 Step: 47900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038204193115234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 670 Step: 48000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003206968307495117s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01094508171081543s to add potential edges.
================================================================================
[Consolidation] Episode: 671 Step: 48100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5956608400837167
Updated goal-option-5 on 100 transitions
Took 0.00428009033203125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 672 Step: 48200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035173892974853516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 673 Step: 48300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003228425979614258s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 674 Step: 48400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.388309425828204
Updated goal-option-5 on 44 transitions
Took 0.0020203590393066406s to update distance table with 45 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 56 transitions
Took 0.0023620128631591797s to update distance table with 57 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 675 Step: 48500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.531580588429257
Updated goal-option-5 on 100 transitions
Took 0.0045070648193359375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 676 Step: 48600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039958953857421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 677 Step: 48700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034949779510498047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 678 Step: 48800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004008054733276367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 679 Step: 48900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003869771957397461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 680 Step: 49000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037572383880615234s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 8.893013000488281e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 681 Step: 49100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8165899108631753
Updated goal-option-5 on 100 transitions
Took 0.005425214767456055s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 682 Step: 49200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4414201347561193
Updated goal-option-5 on 100 transitions
Took 0.0048258304595947266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 683 Step: 49300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032727718353271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 684 Step: 49400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003973484039306641s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 685 Step: 49500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5591967647550469
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.005290508270263672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 686 Step: 49600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.424998613785797
Updated goal-option-5 on 100 transitions
Took 0.004797458648681641s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 687 Step: 49700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 49700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2042, 'bonus': 0.022129526988628804, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.503188194240522
Updated goal-option-5 on 100 transitions
Took 0.005623340606689453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 688 Step: 49800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035219192504882812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 689 Step: 49900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036623477935791016s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=690 Seed=18] Took 0.009664058685302734s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 690 Step: 50000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.409079342186393
Updated goal-option-5 on 71 transitions
Took 0.0031065940856933594s to update distance table with 72 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 29 transitions
Took 0.001230478286743164s to update distance table with 30 states and events {None, SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.011548995971679688s to add potential edges.
================================================================================
[Consolidation] Episode: 691 Step: 50100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003705263137817383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 692 Step: 50200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038499832153320312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 693 Step: 50300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003633260726928711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 694 Step: 50400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034499168395996094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 695 Step: 50500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038650035858154297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 696 Step: 50600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004032611846923828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 697 Step: 50700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4487018609185718
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004811525344848633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 698 Step: 50800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038297176361083984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 699 Step: 50900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6088493028450106
Updated goal-option-5 on 100 transitions
Took 0.0056722164154052734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 700 Step: 51000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.826062354174578
Updated goal-option-5 on 100 transitions
Took 0.004453420639038086s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.014612674713134766s to add potential edges.
================================================================================
[Consolidation] Episode: 701 Step: 51100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038614273071289062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 702 Step: 51200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039615631103515625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 703 Step: 51300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003742218017578125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 704 Step: 51400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003970623016357422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 705 Step: 51500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003870248794555664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 706 Step: 51600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003792285919189453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 707 Step: 51700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.536826916909997
Updated goal-option-5 on 100 transitions
Took 0.0039484500885009766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 708 Step: 51800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003701925277709961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 709 Step: 51900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1933, 'bonus': 0.022744902159317754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 25154, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5000576102794072
Updated goal-option-5 on 53 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.002643585205078125s to update distance table with 54 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 47 transitions
Took 0.001978158950805664s to update distance table with 48 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 710 Step: 52000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5129459629890352
Updated goal-option-5 on 70 transitions
Took 0.004003286361694336s to update distance table with 71 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 30 transitions
Took 0.0012683868408203125s to update distance table with 31 states and events {None, SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.013476848602294922s to add potential edges.
================================================================================
[Consolidation] Episode: 711 Step: 52100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039064884185791016s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 712 Step: 52200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039713382720947266s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 713 Step: 52300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003681182861328125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 714 Step: 52400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003592967987060547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 715 Step: 52500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033867359161376953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 716 Step: 52600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003541707992553711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 717 Step: 52700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037822723388671875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 718 Step: 52800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2070, 'bonus': 0.0219793491131929, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6354826027729799
Updated goal-option-5 on 64 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0030143260955810547s to update distance table with 65 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 36 transitions
Took 0.0014910697937011719s to update distance table with 37 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 719 Step: 52900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036406517028808594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 720 Step: 53000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4015669346046895
Updated goal-option-5 on 94 transitions
Took 0.005341053009033203s to update distance table with 95 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 6 transitions
Took 0.0003082752227783203s to update distance table with 7 states and events {None, SE([ 5 13])}
Took 0.013638734817504883s to add potential edges.
================================================================================
[Consolidation] Episode: 721 Step: 53100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004016399383544922s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 722 Step: 53200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033826828002929688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 723 Step: 53300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003691434860229492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 724 Step: 53400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003595113754272461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 725 Step: 53500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036923885345458984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 726 Step: 53600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034742355346679688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 727 Step: 53700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7174545639378784
Updated goal-option-5 on 100 transitions
Took 0.005503177642822266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 728 Step: 53800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034532546997070312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 729 Step: 53900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003683805465698242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 730 Step: 54000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2097, 'bonus': 0.021837392736013945, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4659033130391534
Updated goal-option-5 on 100 transitions
Took 0.0054209232330322266s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.01854252815246582s to add potential edges.
================================================================================
[Consolidation] Episode: 731 Step: 54100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.399653398332817
Updated goal-option-5 on 100 transitions
Took 0.005518913269042969s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 732 Step: 54200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.668980966191265
Updated goal-option-5 on 100 transitions
Took 0.00547480583190918s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 733 Step: 54300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003987789154052734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 734 Step: 54400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003449678421020508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 735 Step: 54500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033333301544189453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 736 Step: 54600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00399017333984375s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 737 Step: 54700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2006, 'bonus': 0.022327214034455325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4067534000402035
Updated goal-option-5 on 100 transitions
Took 0.005539894104003906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 738 Step: 54800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5065207721271172
Updated goal-option-5 on 100 transitions
Took 0.0055844783782958984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 739 Step: 54900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 54900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5408159245783082
Updated goal-option-5 on 100 transitions
Took 0.004927873611450195s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=740 Seed=18] Took 0.01089024543762207s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 740 Step: 55000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0039174556732177734s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.015538930892944336s to add potential edges.
================================================================================
[Consolidation] Episode: 741 Step: 55100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003824949264526367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 742 Step: 55200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4262137047175305
Updated goal-option-5 on 100 transitions
Took 0.005150794982910156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 743 Step: 55300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 55300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2097, 'bonus': 0.021837392736013945, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.544021990530925
Updated goal-option-5 on 100 transitions
Took 0.0058209896087646484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 744 Step: 55400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00405430793762207s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 745 Step: 55500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037806034088134766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 746 Step: 55600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036487579345703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 747 Step: 55700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003397703170776367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 748 Step: 55800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003371000289916992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 749 Step: 55900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036652088165283203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 750 Step: 56000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037462711334228516s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.015987634658813477s to add potential edges.
================================================================================
[Consolidation] Episode: 751 Step: 56100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038404464721679688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 752 Step: 56200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3012518089053007
Updated goal-option-5 on 100 transitions
Took 0.004763603210449219s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 753 Step: 56300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039708614349365234s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 754 Step: 56400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036187171936035156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 755 Step: 56500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2042, 'bonus': 0.022129526988628804, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3216212421140618
Updated goal-option-5 on 13 transitions
Took 0.0005118846893310547s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.0035123825073242188s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 756 Step: 56600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4228326914518836
Updated goal-option-5 on 100 transitions
Took 0.0039997100830078125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 757 Step: 56700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2075, 'bonus': 0.021952851997938068, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50071, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7241882354376699
Updated goal-option-5 on 41 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0016930103302001953s to update distance table with 42 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 59 transitions
Took 0.0024635791778564453s to update distance table with 60 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 758 Step: 56800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003728628158569336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 759 Step: 56900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038022994995117188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 760 Step: 57000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2118, 'bonus': 0.02172886402078159, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3477560429739655
Updated goal-option-5 on 100 transitions
Took 0.00550532341003418s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.02132105827331543s to add potential edges.
================================================================================
[Consolidation] Episode: 761 Step: 57100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003993988037109375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 762 Step: 57200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 57200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3396374575145344
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004628896713256836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 763 Step: 57300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003740549087524414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 764 Step: 57400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039441585540771484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 765 Step: 57500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00398564338684082s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 766 Step: 57600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035126209259033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 767 Step: 57700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036716461181640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 768 Step: 57800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00397491455078125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 769 Step: 57900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035881996154785156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 770 Step: 58000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035893917083740234s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017625808715820312s to add potential edges.
================================================================================
[Consolidation] Episode: 771 Step: 58100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5545810165198721
Updated goal-option-5 on 100 transitions
Took 0.0055391788482666016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 772 Step: 58200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3322307836976481
Updated goal-option-5 on 100 transitions
Took 0.005520820617675781s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 773 Step: 58300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038073062896728516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 774 Step: 58400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038619041442871094s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 775 Step: 58500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6438029305484612
Updated goal-option-5 on 100 transitions
Took 0.005415439605712891s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 776 Step: 58600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003915548324584961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 777 Step: 58700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039827823638916016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 778 Step: 58800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3371245727502492
Updated goal-option-5 on 52 transitions
Took 0.0027577877044677734s to update distance table with 53 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 48 transitions
Took 0.0020494461059570312s to update distance table with 49 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 779 Step: 58900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037086009979248047s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 780 Step: 59000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035142898559570312s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01775217056274414s to add potential edges.
================================================================================
[Consolidation] Episode: 781 Step: 59100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1962, 'bonus': 0.022576182049286544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31185, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4980591188765464
Updated goal-option-5 on 22 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0009937286376953125s to update distance table with 23 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 78 transitions
Took 0.0031347274780273438s to update distance table with 79 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 782 Step: 59200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003391742706298828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 783 Step: 59300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037322044372558594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 784 Step: 59400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2118, 'bonus': 0.02172886402078159, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5013684621263945
Updated goal-option-5 on 100 transitions
Took 0.0051043033599853516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 785 Step: 59500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003300189971923828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 786 Step: 59600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032792091369628906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 787 Step: 59700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031914710998535156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 788 Step: 59800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003844738006591797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 789 Step: 59900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2119, 'bonus': 0.02172373626518906, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4412912010725727
Updated goal-option-5 on 100 transitions
Took 0.00630497932434082s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=790 Seed=18] Took 0.01821112632751465s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 790 Step: 60000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035152435302734375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017005205154418945s to add potential edges.
================================================================================
[Consolidation] Episode: 791 Step: 60100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038840770721435547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 792 Step: 60200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004105091094970703s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 793 Step: 60300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033235549926757812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 794 Step: 60400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0041790008544921875s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 795 Step: 60500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4081611369765727
Updated goal-option-5 on 100 transitions
Took 0.0056455135345458984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 796 Step: 60600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033881664276123047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 797 Step: 60700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003448009490966797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 798 Step: 60800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1985, 'bonus': 0.02244500696216168, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37062, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4010328138231518
Updated goal-option-5 on 100 transitions
Took 0.005549192428588867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 799 Step: 60900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 60900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.493686952010328
Updated goal-option-5 on 100 transitions
Took 0.005270719528198242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 800 Step: 61000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036115646362304688s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017719507217407227s to add potential edges.
================================================================================
[Consolidation] Episode: 801 Step: 61100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2070, 'bonus': 0.0219793491131929, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 48444, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4090401073927021
Updated goal-option-5 on 58 transitions
Took 0.0033712387084960938s to update distance table with 59 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 42 transitions
Took 0.0021991729736328125s to update distance table with 43 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 802 Step: 61200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033235549926757812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 803 Step: 61300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2126, 'bonus': 0.021687943336591728, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4608368883342553
Updated goal-option-5 on 100 transitions
Took 0.005503177642822266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 804 Step: 61400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003699779510498047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 805 Step: 61500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034961700439453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 806 Step: 61600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038962364196777344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 807 Step: 61700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035228729248046875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 808 Step: 61800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003864765167236328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 809 Step: 61900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2082, 'bonus': 0.021915916515945887, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2596412965925083
Updated goal-option-5 on 100 transitions
Took 0.005368232727050781s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 810 Step: 62000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034987926483154297s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017368555068969727s to add potential edges.
================================================================================
[Consolidation] Episode: 811 Step: 62100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003732442855834961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 812 Step: 62200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004587650299072266s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 813 Step: 62300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038335323333740234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 814 Step: 62400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2006, 'bonus': 0.022327214034455325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.245300183128963
Updated goal-option-5 on 100 transitions
Took 0.00565338134765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 815 Step: 62500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003376483917236328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 816 Step: 62600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034906864166259766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 817 Step: 62700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003747224807739258s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 818 Step: 62800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004011631011962891s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 819 Step: 62900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 62900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1975, 'bonus': 0.022501758018520477, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 31330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3793583910264806
Updated goal-option-5 on 100 transitions
Took 0.0048828125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 820 Step: 63000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038192272186279297s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017071247100830078s to add potential edges.
================================================================================
[Consolidation] Episode: 821 Step: 63100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004059553146362305s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 822 Step: 63200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3623424621040021
Updated goal-option-5 on 100 transitions
Took 0.005536556243896484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 823 Step: 63300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037338733673095703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 824 Step: 63400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4764615059242427
Updated goal-option-5 on 47 transitions
Took 0.002373933792114258s to update distance table with 48 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 53 transitions
Took 0.0022127628326416016s to update distance table with 54 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 825 Step: 63500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1987, 'bonus': 0.0224337081912659, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 37391, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.425274120861344
Updated goal-option-5 on 100 transitions
Took 0.0056171417236328125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 826 Step: 63600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2006, 'bonus': 0.022327214034455325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 40472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5069399354425819
Updated goal-option-5 on 100 transitions
Took 0.005730628967285156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 827 Step: 63700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003262042999267578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 828 Step: 63800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2077, 'bonus': 0.02194227995205747, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51953, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.386092721850976
Updated goal-option-5 on 100 transitions
Took 0.005127906799316406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 829 Step: 63900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003941535949707031s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 830 Step: 64000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032901763916015625s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.017833948135375977s to add potential edges.
================================================================================
[Consolidation] Episode: 831 Step: 64100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003473520278930664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 832 Step: 64200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003261089324951172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 833 Step: 64300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003940105438232422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 834 Step: 64400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003635883331298828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 835 Step: 64500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.497405335791712
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004683971405029297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 836 Step: 64600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 64600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3895201094060223
Updated goal-option-5 on 100 transitions
Took 0.0051958560943603516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 837 Step: 64700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003932952880859375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 838 Step: 64800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033676624298095703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 839 Step: 64900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003888368606567383s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
[Episode=840 Seed=18] Took 0.010232925415039062s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 840 Step: 65000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003968238830566406s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017048358917236328s to add potential edges.
================================================================================
[Consolidation] Episode: 841 Step: 65100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003931283950805664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 842 Step: 65200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5715664843087263
Updated goal-option-5 on 100 transitions
Took 0.004692792892456055s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 843 Step: 65300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036919116973876953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 844 Step: 65400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038530826568603516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 845 Step: 65500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2130, 'bonus': 0.021667569500871973, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61158, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4639376920374583
Updated goal-option-5 on 100 transitions
Took 0.005544185638427734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 846 Step: 65600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003730297088623047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 847 Step: 65700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2097, 'bonus': 0.021837392736013945, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4608078595108225
Updated goal-option-5 on 100 transitions
Took 0.004667758941650391s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 848 Step: 65800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 65800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 1978, 'bonus': 0.022484687520664393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 36960, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4381544545245017
Updated goal-option-5 on 100 transitions
Took 0.00522160530090332s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 849 Step: 65900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003863096237182617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 850 Step: 66000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2042, 'bonus': 0.022129526988628804, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.317539999329618
Updated goal-option-5 on 100 transitions
Took 0.004739046096801758s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.020929336547851562s to add potential edges.
================================================================================
[Consolidation] Episode: 851 Step: 66100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003711223602294922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 852 Step: 66200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036439895629882812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 853 Step: 66300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2119, 'bonus': 0.02172373626518906, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4046698944814944
Updated goal-option-5 on 43 transitions
Took 0.00244140625s to update distance table with 44 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 57 transitions
Took 0.0024101734161376953s to update distance table with 58 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 854 Step: 66400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003898143768310547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 855 Step: 66500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003924369812011719s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 856 Step: 66600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034236907958984375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 857 Step: 66700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2077, 'bonus': 0.02194227995205747, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51953, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4061400881853612
Updated goal-option-5 on 18 transitions
Took 0.001032114028930664s to update distance table with 19 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 82 transitions
Took 0.0034041404724121094s to update distance table with 83 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 858 Step: 66800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003833293914794922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 859 Step: 66900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3983879220497293
Updated goal-option-5 on 100 transitions
Took 0.0051424503326416016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 860 Step: 67000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2042, 'bonus': 0.022129526988628804, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2525862384893316
Updated goal-option-5 on 39 transitions
Took 0.002020597457885742s to update distance table with 40 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 61 transitions
Took 0.0025408267974853516s to update distance table with 62 states and events {None, SE([ 5 13])}
Took 0.016960859298706055s to add potential edges.
================================================================================
[Consolidation] Episode: 861 Step: 67100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032563209533691406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 862 Step: 67200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00363922119140625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 863 Step: 67300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2042, 'bonus': 0.022129526988628804, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 44532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.345814584975175
Updated goal-option-5 on 15 transitions
Took 0.0008339881896972656s to update distance table with 16 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 85 transitions
Took 0.0034439563751220703s to update distance table with 86 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 864 Step: 67400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003226041793823242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 865 Step: 67500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038259029388427734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 866 Step: 67600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5243678363102688
Updated goal-option-5 on 100 transitions
Took 0.004976749420166016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 867 Step: 67700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2213, 'bonus': 0.021257358312406823, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66343, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.691655517599118
Updated goal-option-5 on 100 transitions
Took 0.005742073059082031s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 868 Step: 67800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034623146057128906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 869 Step: 67900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004210710525512695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 870 Step: 68000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3080415783354054
Updated goal-option-5 on 100 transitions
Took 0.0048046112060546875s to update distance table with 101 states and events {SE([ 8 16])}
Took 0.02409672737121582s to add potential edges.
================================================================================
[Consolidation] Episode: 871 Step: 68100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2075, 'bonus': 0.021952851997938068, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50071, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3305270263499345
Updated goal-option-5 on 100 transitions
Took 0.0052490234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 872 Step: 68200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037827491760253906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 873 Step: 68300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033288002014160156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 874 Step: 68400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2226, 'bonus': 0.02119519516996487, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66718, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4115707617921291
Updated goal-option-5 on 100 transitions
Took 0.005688905715942383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 875 Step: 68500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2075, 'bonus': 0.021952851997938068, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 50071, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3404407289468516
Updated goal-option-5 on 100 transitions
Took 0.004642009735107422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 876 Step: 68600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003926753997802734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 877 Step: 68700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2036, 'bonus': 0.022162110358896814, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 42034, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4740747355870532
Updated goal-option-5 on 100 transitions
Took 0.005228519439697266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 878 Step: 68800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6777159863961888
Updated goal-option-5 on 100 transitions
Took 0.005189418792724609s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 879 Step: 68900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 68900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2213, 'bonus': 0.021257358312406823, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66343, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4571164469843785
Updated goal-option-5 on 100 transitions
Took 0.005257368087768555s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 880 Step: 69000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2118, 'bonus': 0.02172886402078159, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4128472640246585
Updated goal-option-5 on 100 transitions
Took 0.0055468082427978516s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.021349430084228516s to add potential edges.
================================================================================
[Consolidation] Episode: 881 Step: 69100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2025, 'bonus': 0.022222222222222223, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 41131, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3760406167811476
Updated goal-option-5 on 100 transitions
Took 0.00569605827331543s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 882 Step: 69200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2097, 'bonus': 0.021837392736013945, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3594500293143625
Updated goal-option-5 on 19 transitions
Took 0.0009715557098388672s to update distance table with 20 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 81 transitions
Took 0.003650188446044922s to update distance table with 82 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 883 Step: 69300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003621339797973633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 884 Step: 69400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2119, 'bonus': 0.02172373626518906, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3543802440054413
Updated goal-option-5 on 51 transitions
Took 0.002374410629272461s to update distance table with 52 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 49 transitions
Took 0.0020656585693359375s to update distance table with 50 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 885 Step: 69500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2255, 'bonus': 0.021058465757133063, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2990972245367807
Updated goal-option-5 on 100 transitions
Took 0.004984617233276367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 886 Step: 69600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003957509994506836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 887 Step: 69700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2230, 'bonus': 0.021176177494381335, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5763910545094397
Updated goal-option-5 on 100 transitions
Took 0.004971504211425781s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 888 Step: 69800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035533905029296875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 889 Step: 69900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034084320068359375s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=890 Seed=18] Took 0.012962818145751953s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 890 Step: 70000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036606788635253906s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.017364025115966797s to add potential edges.
================================================================================
[Consolidation] Episode: 891 Step: 70100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033838748931884766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 892 Step: 70200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00389862060546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 893 Step: 70300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036928653717041016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 894 Step: 70400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037086009979248047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 895 Step: 70500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003656148910522461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 896 Step: 70600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00393366813659668s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 897 Step: 70700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037326812744140625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 898 Step: 70800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003738880157470703s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 899 Step: 70900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 70900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2228, 'bonus': 0.021185679930351788, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3931688267259446
Updated goal-option-5 on 100 transitions
Took 0.004608631134033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 900 Step: 71000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2229, 'bonus': 0.02118092711370637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67315, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3189900444220874
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004555225372314453s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.019550323486328125s to add potential edges.
================================================================================
[Consolidation] Episode: 901 Step: 71100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032804012298583984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 902 Step: 71200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003796815872192383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 903 Step: 71300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036602020263671875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 904 Step: 71400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033655166625976562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 905 Step: 71500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003786802291870117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 906 Step: 71600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036187171936035156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 907 Step: 71700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2126, 'bonus': 0.021687943336591728, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 59122, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.472587987789457
Updated goal-option-5 on 100 transitions
Took 0.00621485710144043s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 908 Step: 71800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 71800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2213, 'bonus': 0.021257358312406823, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66343, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2820816815210216
Updated goal-option-5 on 100 transitions
Took 0.005835533142089844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 909 Step: 71900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037250518798828125s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 910 Step: 72000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003938913345336914s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.017511606216430664s to add potential edges.
================================================================================
[Consolidation] Episode: 911 Step: 72100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003924846649169922s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 912 Step: 72200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.397882160585646
Updated goal-option-5 on 87 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0037229061126708984s to update distance table with 88 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 13 transitions
Took 0.0005691051483154297s to update distance table with 14 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 913 Step: 72300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003787517547607422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 914 Step: 72400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2118, 'bonus': 0.02172886402078159, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.22575382016796
Updated goal-option-5 on 100 transitions
Took 0.004819631576538086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 915 Step: 72500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003813028335571289s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 916 Step: 72600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2255, 'bonus': 0.021058465757133063, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4819655505714204
Updated goal-option-5 on 100 transitions
Took 0.005342960357666016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 917 Step: 72700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2213, 'bonus': 0.021257358312406823, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 66343, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4668013198645669
Updated goal-option-5 on 100 transitions
Took 0.004826784133911133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 918 Step: 72800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0039806365966796875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 919 Step: 72900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036225318908691406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 920 Step: 73000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2063, 'bonus': 0.02201660678463551, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 47581, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5067705863526062
Updated goal-option-5 on 100 transitions
Took 0.004039287567138672s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01990795135498047s to add potential edges.
================================================================================
[Consolidation] Episode: 921 Step: 73100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035200119018554688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 922 Step: 73200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037114620208740234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 923 Step: 73300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003758668899536133s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 924 Step: 73400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2096, 'bonus': 0.02184260141652595, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52864, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3215865943395275
Updated goal-option-5 on 45 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0020465850830078125s to update distance table with 46 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 55 transitions
Took 0.002362489700317383s to update distance table with 56 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 925 Step: 73500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003619670867919922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 926 Step: 73600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033254623413085938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 927 Step: 73700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003574848175048828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 928 Step: 73800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2077, 'bonus': 0.02194227995205747, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 51953, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.244780918453524
Updated goal-option-5 on 70 transitions
Took 0.0034003257751464844s to update distance table with 71 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 30 transitions
Took 0.0015001296997070312s to update distance table with 31 states and events {SE([ 5 13])}
================================================================================
[Consolidation] Episode: 929 Step: 73900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036420822143554688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 930 Step: 74000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038068294525146484s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01775336265563965s to add potential edges.
================================================================================
[Consolidation] Episode: 931 Step: 74100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2119, 'bonus': 0.02172373626518906, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 56741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3109672550882991
Updated goal-option-5 on 100 transitions
Took 0.004400730133056641s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 932 Step: 74200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034482479095458984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 933 Step: 74300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038242340087890625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 934 Step: 74400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2229, 'bonus': 0.02118092711370637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67315, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4255560497102095
Updated goal-option-5 on 100 transitions
Took 0.004240274429321289s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 935 Step: 74500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2097, 'bonus': 0.021837392736013945, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 53094, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.378686061737841
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004510402679443359s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 936 Step: 74600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 74600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2272, 'bonus': 0.020979533957417227, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.363634818386844
Updated goal-option-5 on 100 transitions
Took 0.0056378841400146484s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 937 Step: 74700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003706693649291992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 938 Step: 74800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003652811050415039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 939 Step: 74900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035495758056640625s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=940 Seed=18] Took 0.009949207305908203s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 940 Step: 75000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2272, 'bonus': 0.020979533957417227, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4598765301025765
Updated goal-option-5 on 100 transitions
Took 0.005732536315917969s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.020708084106445312s to add potential edges.
================================================================================
[Consolidation] Episode: 941 Step: 75100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036084651947021484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 942 Step: 75200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00397801399230957s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 943 Step: 75300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035288333892822266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 944 Step: 75400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2123, 'bonus': 0.021703261485649127, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 58852, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2765556227682122
Updated goal-option-5 on 26 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0013799667358398438s to update distance table with 27 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 74 transitions
Took 0.003023862838745117s to update distance table with 75 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 945 Step: 75500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003936052322387695s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 946 Step: 75600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003888368606567383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 947 Step: 75700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037984848022460938s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 948 Step: 75800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2255, 'bonus': 0.021058465757133063, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3201960190540067
Updated goal-option-5 on 100 transitions
Took 0.006117820739746094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 949 Step: 75900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003972291946411133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 950 Step: 76000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035467147827148438s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01732778549194336s to add potential edges.
================================================================================
[Consolidation] Episode: 951 Step: 76100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003303050994873047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 952 Step: 76200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2082, 'bonus': 0.021915916515945887, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 52070, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3212990274987102
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0048100948333740234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 953 Step: 76300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2230, 'bonus': 0.021176177494381335, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.274985393079527
Updated goal-option-5 on 12 transitions
Took 0.0007755756378173828s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 88 transitions
Took 0.0038340091705322266s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 954 Step: 76400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2289, 'bonus': 0.020901483117353754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73870, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3119056229989938
Updated goal-option-5 on 88 transitions
Took 0.0047817230224609375s to update distance table with 89 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 12 transitions
Took 0.0005254745483398438s to update distance table with 13 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 955 Step: 76500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2264, 'bonus': 0.02101656758545993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72287, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5235136353660643
Updated goal-option-5 on 44 transitions
Took 0.0024611949920654297s to update distance table with 45 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 56 transitions
Took 0.002373933792114258s to update distance table with 57 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 956 Step: 76600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2341, 'bonus': 0.0206680399887278, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76544, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3279853293926023
Updated goal-option-5 on 100 transitions
Took 0.006579399108886719s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 957 Step: 76700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036559104919433594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 958 Step: 76800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2320, 'bonus': 0.020761369963434993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.292693172929283
Updated goal-option-5 on 30 transitions
Took 0.0012466907501220703s to update distance table with 31 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 70 transitions
Took 0.002893686294555664s to update distance table with 71 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 959 Step: 76900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2229, 'bonus': 0.02118092711370637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67315, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.436638746454305
Updated goal-option-5 on 100 transitions
Took 0.005588531494140625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 960 Step: 77000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 77000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2230, 'bonus': 0.021176177494381335, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69219, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2796223953462904
Updated goal-option-5 on 47 transitions
Took 0.0026521682739257812s to update distance table with 48 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 53 transitions
Took 0.0022597312927246094s to update distance table with 54 states and events {None, SE([ 5 13])}
Took 0.016886472702026367s to add potential edges.
================================================================================
[Consolidation] Episode: 961 Step: 77100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003856182098388672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 962 Step: 77200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036492347717285156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 963 Step: 77300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039005279541015625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 964 Step: 77400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036852359771728516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 965 Step: 77500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003237009048461914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 966 Step: 77600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036165714263916016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 967 Step: 77700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003936767578125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 968 Step: 77800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003353118896484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 969 Step: 77900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003817319869995117s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 970 Step: 78000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0040912628173828125s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.017016172409057617s to add potential edges.
================================================================================
[Consolidation] Episode: 971 Step: 78100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003490924835205078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 972 Step: 78200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2130, 'bonus': 0.021667569500871973, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 61158, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2397260486684127
Updated goal-option-5 on 85 transitions
Took 0.004930734634399414s to update distance table with 86 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 15 transitions
Took 0.0007193088531494141s to update distance table with 16 states and events {SE([ 5 13])}
================================================================================
[Consolidation] Episode: 973 Step: 78300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003555774688720703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 974 Step: 78400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034973621368408203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 975 Step: 78500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031800270080566406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 976 Step: 78600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2320, 'bonus': 0.020761369963434993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3561853974446152
Updated goal-option-5 on 100 transitions
Took 0.005291938781738281s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 977 Step: 78700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032727718353271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 978 Step: 78800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003954410552978516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 979 Step: 78900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033516883850097656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 980 Step: 79000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2204, 'bonus': 0.021300716142115247, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 63447, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3553257497286744
Updated goal-option-5 on 92 transitions
Took 0.005155324935913086s to update distance table with 93 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 8 transitions
Took 0.0003948211669921875s to update distance table with 9 states and events {SE([ 5 13])}
Took 0.015103340148925781s to add potential edges.
================================================================================
[Consolidation] Episode: 981 Step: 79100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2228, 'bonus': 0.021185679930351788, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67039, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.376373423532774
Updated goal-option-5 on 36 transitions
Took 0.001798868179321289s to update distance table with 37 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 64 transitions
Took 0.0026552677154541016s to update distance table with 65 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 982 Step: 79200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031692981719970703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 983 Step: 79300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003589153289794922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 984 Step: 79400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003536224365234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 985 Step: 79500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2264, 'bonus': 0.02101656758545993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 72287, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4023030138822135
Updated goal-option-5 on 42 transitions
Took 0.0024116039276123047s to update distance table with 43 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 58 transitions
Took 0.002490997314453125s to update distance table with 59 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 986 Step: 79600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003880023956298828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 987 Step: 79700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003916025161743164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 988 Step: 79800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2289, 'bonus': 0.020901483117353754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73870, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4295609800845301
Updated goal-option-5 on 14 transitions
Took 0.0007164478302001953s to update distance table with 15 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 86 transitions
Took 0.0039598941802978516s to update distance table with 87 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 989 Step: 79900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039031505584716797s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=990 Seed=18] Took 0.011305093765258789s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 990 Step: 80000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034427642822265625s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01727771759033203s to add potential edges.
================================================================================
[Consolidation] Episode: 991 Step: 80100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004010200500488281s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 992 Step: 80200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003993511199951172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 993 Step: 80300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2320, 'bonus': 0.020761369963434993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.302883426615841
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004019260406494141s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 994 Step: 80400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003985881805419922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 995 Step: 80500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033309459686279297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 996 Step: 80600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2229, 'bonus': 0.02118092711370637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67315, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2753526467975052
Updated goal-option-5 on 93 transitions
Took 0.004560947418212891s to update distance table with 94 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 7 transitions
Took 0.0003628730773925781s to update distance table with 8 states and events {SE([ 5 13])}
================================================================================
[Consolidation] Episode: 997 Step: 80700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2229, 'bonus': 0.02118092711370637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 67315, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3409324326114882
Updated goal-option-5 on 100 transitions
Took 0.00487518310546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 998 Step: 80800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034232139587402344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 999 Step: 80900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2289, 'bonus': 0.020901483117353754, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73870, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2988161605193362
Updated goal-option-5 on 39 transitions
Took 0.0015301704406738281s to update distance table with 40 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 61 transitions
Took 0.002545595169067383s to update distance table with 62 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1000 Step: 81000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2334, 'bonus': 0.020699009990027696, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.357969870660696
Updated goal-option-5 on 100 transitions
Took 0.005352020263671875s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.020841121673583984s to add potential edges.
================================================================================
[Consolidation] Episode: 1001 Step: 81100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037708282470703125s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1002 Step: 81200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003774881362915039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1003 Step: 81300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033724308013916016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1004 Step: 81400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035424232482910156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1005 Step: 81500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035529136657714844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1006 Step: 81600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 81600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2334, 'bonus': 0.020699009990027696, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2821951389267088
Updated goal-option-5 on 100 transitions
Took 0.003894329071044922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1007 Step: 81700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039670467376708984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1008 Step: 81800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003801584243774414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1009 Step: 81900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003429412841796875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1010 Step: 82000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004017829895019531s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.956390380859375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1011 Step: 82100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003803253173828125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1012 Step: 82200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040128231048583984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1013 Step: 82300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2338, 'bonus': 0.02068129581477602, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2847915695789112
Updated goal-option-5 on 21 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0009655952453613281s to update distance table with 22 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 79 transitions
Took 0.0032682418823242188s to update distance table with 80 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1014 Step: 82400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003492593765258789s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1015 Step: 82500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82321, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2544145076931479
Updated goal-option-5 on 100 transitions
Took 0.005461454391479492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1016 Step: 82600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036187171936035156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1017 Step: 82700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003984689712524414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1018 Step: 82800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003412961959838867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1019 Step: 82900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2341, 'bonus': 0.0206680399887278, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76544, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.30950902336365
Updated goal-option-5 on 100 transitions
Took 0.005324840545654297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1020 Step: 83000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2348, 'bonus': 0.0206372085853249, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.220046016106788
Updated goal-option-5 on 100 transitions
Took 0.005545616149902344s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.020526409149169922s to add potential edges.
================================================================================
[Consolidation] Episode: 1021 Step: 83100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032377243041992188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1022 Step: 83200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037300586700439453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1023 Step: 83300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003560781478881836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1024 Step: 83400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2348, 'bonus': 0.0206372085853249, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76830, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2961333568393167
Updated goal-option-5 on 100 transitions
Took 0.004801750183105469s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1025 Step: 83500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036721229553222656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1026 Step: 83600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038013458251953125s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1027 Step: 83700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2338, 'bonus': 0.02068129581477602, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2728716466515106
Updated goal-option-5 on 55 transitions
Took 0.0029764175415039062s to update distance table with 56 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 45 transitions
Took 0.001995563507080078s to update distance table with 46 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1028 Step: 83800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003910064697265625s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1029 Step: 83900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2255, 'bonus': 0.021058465757133063, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 69451, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2742491446406035
Updated goal-option-5 on 100 transitions
Took 0.004683256149291992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1030 Step: 84000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2334, 'bonus': 0.020699009990027696, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2211937160995523
Updated goal-option-5 on 100 transitions
Took 0.004776716232299805s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.020910978317260742s to add potential edges.
================================================================================
[Consolidation] Episode: 1031 Step: 84100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038917064666748047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1032 Step: 84200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 84200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2320, 'bonus': 0.020761369963434993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3501598297834345
Updated goal-option-5 on 100 transitions
Took 0.004444599151611328s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1033 Step: 84300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003283977508544922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1034 Step: 84400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003322124481201172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1035 Step: 84500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034584999084472656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1036 Step: 84600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003596067428588867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1037 Step: 84700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035126209259033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1038 Step: 84800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034041404724121094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1039 Step: 84900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032775402069091797s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1040 Seed=18] Took 0.009137392044067383s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1040 Step: 85000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003929615020751953s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 3.0517578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1041 Step: 85100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036203861236572266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1042 Step: 85200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038728713989257812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1043 Step: 85300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036559104919433594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1044 Step: 85400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82321, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.169593020480554
Updated goal-option-5 on 35 transitions
Took 0.001211404800415039s to update distance table with 36 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 65 transitions
Took 0.002756834030151367s to update distance table with 66 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1045 Step: 85500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036695003509521484s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1046 Step: 85600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004014730453491211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1047 Step: 85700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003832578659057617s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1048 Step: 85800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2272, 'bonus': 0.020979533957417227, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 73445, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.256304566837099
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004582643508911133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1049 Step: 85900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004123687744140625s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1050 Step: 86000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0039255619049072266s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 0.017234086990356445s to add potential edges.
================================================================================
[Consolidation] Episode: 1051 Step: 86100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003851175308227539s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1052 Step: 86200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2385, 'bonus': 0.02047650389446504, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79092, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3210907802667164
Updated goal-option-5 on 55 transitions
Took 0.002802133560180664s to update distance table with 56 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 45 transitions
Took 0.002544879913330078s to update distance table with 46 states and events {SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1053 Step: 86300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040056705474853516s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1054 Step: 86400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003710031509399414s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1055 Step: 86500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2320, 'bonus': 0.020761369963434993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 75426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3953306095925047
Updated goal-option-5 on 33 transitions
Took 0.0017898082733154297s to update distance table with 34 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 67 transitions
Took 0.002965211868286133s to update distance table with 68 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1056 Step: 86600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2338, 'bonus': 0.02068129581477602, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 76488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3097952764556773
Updated goal-option-5 on 45 transitions
Took 0.002616405487060547s to update distance table with 46 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 55 transitions
Took 0.0022411346435546875s to update distance table with 56 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1057 Step: 86700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003934144973754883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1058 Step: 86800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038318634033203125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1059 Step: 86900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038666725158691406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1060 Step: 87000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2491, 'bonus': 0.020036097492521526, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86255, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1925607134023366
Updated goal-option-5 on 9 transitions
Took 0.0005640983581542969s to update distance table with 10 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 91 transitions
Took 0.003912210464477539s to update distance table with 92 states and events {None, SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.018334388732910156s to add potential edges.
================================================================================
[Consolidation] Episode: 1061 Step: 87100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004031181335449219s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1062 Step: 87200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2394, 'bonus': 0.020437977982832194, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79136, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1612694676063922
Updated goal-option-5 on 100 transitions
Took 0.004685878753662109s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1063 Step: 87300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003958463668823242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1064 Step: 87400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036513805389404297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1065 Step: 87500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038585662841796875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1066 Step: 87600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2491, 'bonus': 0.020036097492521526, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86255, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.264760181992739
Updated goal-option-5 on 20 transitions
Took 0.000982522964477539s to update distance table with 21 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 80 transitions
Took 0.0033299922943115234s to update distance table with 81 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1067 Step: 87700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2476, 'bonus': 0.02009669677645352, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85435, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2221836686536678
Updated goal-option-5 on 100 transitions
Took 0.004015207290649414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1068 Step: 87800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2398, 'bonus': 0.020420925015338272, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2015904570403306
Updated goal-option-5 on 20 transitions
Took 0.0009562969207763672s to update distance table with 21 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 80 transitions
Took 0.0033397674560546875s to update distance table with 81 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1069 Step: 87900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040171146392822266s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1070 Step: 88000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003983974456787109s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 3.6716461181640625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1071 Step: 88100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038301944732666016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1072 Step: 88200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2369, 'bonus': 0.020545535708970802, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 78285, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.216306077647877
Updated goal-option-5 on 38 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0015206336975097656s to update distance table with 39 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 62 transitions
Took 0.0025582313537597656s to update distance table with 63 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1073 Step: 88300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037949085235595703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1074 Step: 88400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2586, 'bonus': 0.019664628205864065, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2035009131775245
Updated goal-option-5 on 100 transitions
Took 0.0051920413970947266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1075 Step: 88500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2394, 'bonus': 0.020437977982832194, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79136, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3974506700406089
Updated goal-option-5 on 100 transitions
Took 0.004950046539306641s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1076 Step: 88600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2398, 'bonus': 0.020420925015338272, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 79542, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.215106040247025
Updated goal-option-5 on 60 transitions
Took 0.0031266212463378906s to update distance table with 61 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 40 transitions
Took 0.001718759536743164s to update distance table with 41 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1077 Step: 88700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003961086273193359s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1078 Step: 88800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036630630493164062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1079 Step: 88900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2463, 'bonus': 0.02014966332712555, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2224708963760067
Updated goal-option-5 on 26 transitions
Took 0.0009202957153320312s to update distance table with 27 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 74 transitions
Took 0.0030939579010009766s to update distance table with 75 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1080 Step: 89000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2463, 'bonus': 0.02014966332712555, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3512661507258261
Updated goal-option-5 on 60 transitions
Took 0.002766132354736328s to update distance table with 61 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 40 transitions
Took 0.0017299652099609375s to update distance table with 41 states and events {None, SE([ 5 13])}
Took 0.017006635665893555s to add potential edges.
================================================================================
[Consolidation] Episode: 1081 Step: 89100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2476, 'bonus': 0.02009669677645352, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85435, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1631336047746934
Updated goal-option-5 on 100 transitions
Took 0.0052945613861083984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1082 Step: 89200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2542, 'bonus': 0.019834087593950483, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86533, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1859045976086666
Updated goal-option-5 on 100 transitions
Took 0.005196332931518555s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1083 Step: 89300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003527402877807617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1084 Step: 89400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2569, 'bonus': 0.019729584892914265, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87009, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2165820031903938
Updated goal-option-5 on 28 transitions
Took 0.001390218734741211s to update distance table with 29 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 72 transitions
Took 0.0029468536376953125s to update distance table with 73 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1085 Step: 89500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2459, 'bonus': 0.020166045169934834, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80939, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2857962659809774
Updated goal-option-5 on 18 transitions
Took 0.0008268356323242188s to update distance table with 19 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 82 transitions
Took 0.0034055709838867188s to update distance table with 83 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1086 Step: 89600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2542, 'bonus': 0.019834087593950483, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86533, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1944582751049433
Updated goal-option-5 on 100 transitions
Took 0.005238056182861328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1087 Step: 89700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003874540328979492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1088 Step: 89800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003751993179321289s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1089 Step: 89900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2568, 'bonus': 0.01973342594909646, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86645, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1048170629357932
Updated goal-option-5 on 45 transitions
Took 0.003038644790649414s to update distance table with 46 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 55 transitions
Took 0.002331972122192383s to update distance table with 56 states and events {None, SE([ 5 13])}
[Episode=1090 Seed=18] Took 0.011283636093139648s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1090 Step: 90000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004038095474243164s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.017601966857910156s to add potential edges.
================================================================================
[Consolidation] Episode: 1091 Step: 90100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2451, 'bonus': 0.020198929081169423, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80693, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1886251475115102
Updated goal-option-5 on 100 transitions
Took 0.005307435989379883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1092 Step: 90200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038590431213378906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1093 Step: 90300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2451, 'bonus': 0.020198929081169423, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 80693, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3599039396671186
Updated goal-option-5 on 100 transitions
Took 0.004441022872924805s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1094 Step: 90400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00404047966003418s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1095 Step: 90500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003882169723510742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1096 Step: 90600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003876209259033203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1097 Step: 90700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033576488494873047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1098 Step: 90800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2463, 'bonus': 0.02014966332712555, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3106748682711504
Updated goal-option-5 on 11 transitions
Took 0.0004425048828125s to update distance table with 12 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 89 transitions
Took 0.0036690235137939453s to update distance table with 90 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1099 Step: 90900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038232803344726562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1100 Step: 91000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2491, 'bonus': 0.020036097492521526, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 86255, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.166156832469209
Updated goal-option-5 on 23 transitions
Took 0.0009415149688720703s to update distance table with 24 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 77 transitions
Took 0.0031137466430664062s to update distance table with 78 states and events {None, SE([ 5 13])}
Took 3.552436828613281e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1101 Step: 91100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2606, 'bonus': 0.019589023819033338, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89945, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2140079969524318
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004128932952880859s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1102 Step: 91200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2463, 'bonus': 0.02014966332712555, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 83755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1634714224426645
Updated goal-option-5 on 50 transitions
Took 0.0018830299377441406s to update distance table with 51 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 50 transitions
Took 0.0021469593048095703s to update distance table with 51 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1103 Step: 91300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003912210464477539s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1104 Step: 91400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003888845443725586s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1105 Step: 91500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037107467651367188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1106 Step: 91600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2591, 'bonus': 0.01964564506773356, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88926, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1522317457118414
Updated goal-option-5 on 84 transitions
Took 0.005548000335693359s to update distance table with 85 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 16 transitions
Took 0.0006701946258544922s to update distance table with 17 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1107 Step: 91700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003818988800048828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1108 Step: 91800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2586, 'bonus': 0.019664628205864065, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2940865617261155
Updated goal-option-5 on 100 transitions
Took 0.004942893981933594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1109 Step: 91900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004001140594482422s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1110 Step: 92000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 92000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2460, 'bonus': 0.020161945963637795, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 82321, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1861759504485212
Updated goal-option-5 on 14 transitions
Took 0.0008106231689453125s to update distance table with 15 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 86 transitions
Took 0.0036928653717041016s to update distance table with 87 states and events {None, SE([ 5 13])}
Took 0.018352270126342773s to add potential edges.
================================================================================
[Consolidation] Episode: 1111 Step: 92100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004227399826049805s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1112 Step: 92200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 92200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2476, 'bonus': 0.02009669677645352, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 85435, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.208752554073077
Updated goal-option-5 on 13 transitions
Took 0.0007224082946777344s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 87 transitions
Took 0.003650665283203125s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1113 Step: 92300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 92300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2569, 'bonus': 0.019729584892914265, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87009, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.233638455945839
Updated goal-option-5 on 29 transitions
Took 0.0015971660614013672s to update distance table with 30 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 71 transitions
Took 0.0028028488159179688s to update distance table with 72 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1114 Step: 92400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038139820098876953s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1115 Step: 92500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 92500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2605, 'bonus': 0.019592783347677303, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89518, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2081791300270426
Updated goal-option-5 on 14 transitions
Took 0.00074005126953125s to update distance table with 15 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 86 transitions
Took 0.0036661624908447266s to update distance table with 87 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1116 Step: 92600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003731250762939453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1117 Step: 92700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034422874450683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1118 Step: 92800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003833770751953125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1119 Step: 92900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 92900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2591, 'bonus': 0.01964564506773356, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88926, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1352113030064643
Updated goal-option-5 on 21 transitions
Took 0.0009455680847167969s to update distance table with 22 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 79 transitions
Took 0.0030968189239501953s to update distance table with 80 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1120 Step: 93000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00401616096496582s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.017420053482055664s to add potential edges.
================================================================================
[Consolidation] Episode: 1121 Step: 93100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003884553909301758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1122 Step: 93200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2642, 'bonus': 0.019455105641024067, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91250, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2535616990829583
Updated goal-option-5 on 13 transitions
Took 0.0005443096160888672s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 87 transitions
Took 0.0034406185150146484s to update distance table with 88 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1123 Step: 93300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2589, 'bonus': 0.019653231723767556, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88660, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1755740370168821
Updated goal-option-5 on 15 transitions
Took 0.0006227493286132812s to update distance table with 16 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 85 transitions
Took 0.0034894943237304688s to update distance table with 86 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1124 Step: 93400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2621, 'bonus': 0.0195328893341018, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.226783443319728
Updated goal-option-5 on 61 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.002324819564819336s to update distance table with 62 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 39 transitions
Took 0.001898050308227539s to update distance table with 40 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1125 Step: 93500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00342559814453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1126 Step: 93600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037355422973632812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1127 Step: 93700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039052963256835938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1128 Step: 93800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2574, 'bonus': 0.01971041319963609, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 87820, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2523571250143217
Updated goal-option-5 on 100 transitions
Took 0.005799293518066406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1129 Step: 93900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038673877716064453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1130 Step: 94000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 94000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2586, 'bonus': 0.019664628205864065, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1650120529404566
Updated goal-option-5 on 100 transitions
Took 0.005435466766357422s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.021115541458129883s to add potential edges.
================================================================================
[Consolidation] Episode: 1131 Step: 94100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003842592239379883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1132 Step: 94200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038242340087890625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1133 Step: 94300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036420822143554688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1134 Step: 94400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 94400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2621, 'bonus': 0.0195328893341018, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1617549784223187
Updated goal-option-5 on 12 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0004913806915283203s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 88 transitions
Took 0.0035581588745117188s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1135 Step: 94500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003609180450439453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1136 Step: 94600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 94600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2595, 'bonus': 0.01963049807622355, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89060, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1419508213480118
Updated goal-option-5 on 100 transitions
Took 0.005004167556762695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1137 Step: 94700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037610530853271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1138 Step: 94800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038824081420898438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1139 Step: 94900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037374496459960938s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1140 Seed=18] Took 0.009191036224365234s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1140 Step: 95000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003951311111450195s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.017514467239379883s to add potential edges.
================================================================================
[Consolidation] Episode: 1141 Step: 95100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036063194274902344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1142 Step: 95200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003356456756591797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1143 Step: 95300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003933429718017578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1144 Step: 95400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 95400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2589, 'bonus': 0.019653231723767556, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88660, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2514847343362892
Updated goal-option-5 on 100 transitions
Took 0.004858970642089844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1145 Step: 95500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039825439453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1146 Step: 95600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038604736328125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1147 Step: 95700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003918886184692383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1148 Step: 95800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038437843322753906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1149 Step: 95900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003938198089599609s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1150 Step: 96000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 96000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2669, 'bonus': 0.01935645013576544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.096089847756287
Updated goal-option-5 on 100 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.004559993743896484s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.01954483985900879s to add potential edges.
================================================================================
[Consolidation] Episode: 1151 Step: 96100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003673553466796875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1152 Step: 96200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036258697509765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1153 Step: 96300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 96300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2639, 'bonus': 0.019466160726095222, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91023, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1420785010729955
Updated goal-option-5 on 100 transitions
Took 0.005670785903930664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1154 Step: 96400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003608226776123047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1155 Step: 96500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 96500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2586, 'bonus': 0.019664628205864065, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 88238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1131313796354083
Updated goal-option-5 on 100 transitions
Took 0.004922389984130859s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1156 Step: 96600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037946701049804688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1157 Step: 96700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 96700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2605, 'bonus': 0.019592783347677303, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89518, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1013632904049657
Updated goal-option-5 on 17 transitions
Took 0.0006992816925048828s to update distance table with 18 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 83 transitions
Took 0.005110263824462891s to update distance table with 84 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1158 Step: 96800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00351715087890625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1159 Step: 96900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040225982666015625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1160 Step: 97000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003141641616821289s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.016893863677978516s to add potential edges.
================================================================================
[Consolidation] Episode: 1161 Step: 97100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003317117691040039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1162 Step: 97200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003893136978149414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1163 Step: 97300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037004947662353516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1164 Step: 97400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003393888473510742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1165 Step: 97500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036034584045410156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1166 Step: 97600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036792755126953125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1167 Step: 97700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004052639007568359s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1168 Step: 97800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003606081008911133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1169 Step: 97900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003888368606567383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1170 Step: 98000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 98000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2606, 'bonus': 0.019589023819033338, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89945, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1811504819482932
Updated goal-option-5 on 16 transitions
Took 0.0008699893951416016s to update distance table with 17 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
Expanding goal-option-5's pessimistic classifier to include SE([ 8 16])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.004688739776611328s to update distance table with 85 states and events {None, SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.018172740936279297s to add potential edges.
================================================================================
[Consolidation] Episode: 1171 Step: 98100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 98100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2639, 'bonus': 0.019466160726095222, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91023, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.148553977286592
Updated goal-option-5 on 100 transitions
Took 0.004379987716674805s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1172 Step: 98200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 98200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2621, 'bonus': 0.0195328893341018, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 90811, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1234336020095244
Updated goal-option-5 on 14 transitions
Took 0.0005218982696533203s to update distance table with 15 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 86 transitions
Took 0.0036172866821289062s to update distance table with 87 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1173 Step: 98300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003435850143432617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1174 Step: 98400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003958463668823242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1175 Step: 98500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038301944732666016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1176 Step: 98600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003871917724609375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1177 Step: 98700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0041065216064453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1178 Step: 98800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038645267486572266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1179 Step: 98900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037398338317871094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1180 Step: 99000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004060506820678711s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.601478576660156e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1181 Step: 99100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033702850341796875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1182 Step: 99200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033884048461914062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1183 Step: 99300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003342151641845703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1184 Step: 99400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 99400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2604, 'bonus': 0.019596545041740514, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 89428, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1870078040005518
Updated goal-option-5 on 13 transitions
Took 0.0006232261657714844s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.0032927989959716797s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1185 Step: 99500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003930568695068359s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1186 Step: 99600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038352012634277344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1187 Step: 99700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 99700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2639, 'bonus': 0.019466160726095222, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91023, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.337155775162592
Updated goal-option-5 on 100 transitions
Took 0.004132986068725586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1188 Step: 99800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 99800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2727, 'bonus': 0.019149499654047535, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93461, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1206411569597619
Updated goal-option-5 on 20 transitions
Took 0.0006885528564453125s to update distance table with 21 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 80 transitions
Took 0.003276348114013672s to update distance table with 81 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1189 Step: 99900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003918886184692383s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1190 Seed=18] Took 0.010396957397460938s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1190 Step: 100000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 100000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2669, 'bonus': 0.01935645013576544, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 91684, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1943324699761375
Updated goal-option-5 on 100 transitions
Took 0.004912137985229492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.218650817871094e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1191 Step: 100100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003824949264526367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1192 Step: 100200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004098653793334961s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1193 Step: 100300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 100300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2900, 'bonus': 0.018569533817705187, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 98214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1896025640041368
Updated goal-option-5 on 12 transitions
Took 0.0005235671997070312s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 88 transitions
Took 0.003570556640625s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1194 Step: 100400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035431385040283203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1195 Step: 100500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003466367721557617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1196 Step: 100600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 100600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2947, 'bonus': 0.018420861280135682, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 100312, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.160307660978297
Updated goal-option-5 on 16 transitions
Took 0.0005767345428466797s to update distance table with 17 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 84 transitions
Took 0.0034813880920410156s to update distance table with 85 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1197 Step: 100700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038025379180908203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1198 Step: 100800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038912296295166016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1199 Step: 100900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003996372222900391s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1200 Step: 101000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2900, 'bonus': 0.018569533817705187, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 98214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1682922432396274
Updated goal-option-5 on 10 transitions
Took 0.0004267692565917969s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 90 transitions
Took 0.0035698413848876953s to update distance table with 91 states and events {None, SE([ 5 13])}
Took 3.647804260253906e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1201 Step: 101100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036830902099609375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1202 Step: 101200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003870248794555664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1203 Step: 101300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003509044647216797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1204 Step: 101400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2727, 'bonus': 0.019149499654047535, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93461, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1243568485607274
Updated goal-option-5 on 16 transitions
Took 0.0007321834564208984s to update distance table with 17 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.003534078598022461s to update distance table with 85 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1205 Step: 101500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2686, 'bonus': 0.019295098316976827, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 92329, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0624406160661983
Updated goal-option-5 on 30 transitions
Took 0.0013756752014160156s to update distance table with 31 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 70 transitions
Took 0.002969503402709961s to update distance table with 71 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1206 Step: 101600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2722, 'bonus': 0.019167079295731936, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 93213, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1964145078256996
Updated goal-option-5 on 8 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.0004818439483642578s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.004023551940917969s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1207 Step: 101700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003387451171875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1208 Step: 101800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003964662551879883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1209 Step: 101900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003793954849243164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1210 Step: 102000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00376129150390625s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.018680095672607422s to add potential edges.
================================================================================
[Consolidation] Episode: 1211 Step: 102100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003787994384765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1212 Step: 102200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2758, 'bonus': 0.019041575062365312, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 96717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1892763135849302
Updated goal-option-5 on 14 transitions
Took 0.0006394386291503906s to update distance table with 15 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 86 transitions
Took 0.0035440921783447266s to update distance table with 87 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1213 Step: 102300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2948, 'bonus': 0.018417736717093933, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 100616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1337732427958378
Updated goal-option-5 on 22 transitions
Took 0.0007436275482177734s to update distance table with 23 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 78 transitions
Took 0.0031774044036865234s to update distance table with 79 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1214 Step: 102400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2954, 'bonus': 0.018399022669872974, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1386680853478786
Updated goal-option-5 on 46 transitions
Took 0.0023047924041748047s to update distance table with 47 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 54 transitions
Took 0.002301931381225586s to update distance table with 55 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1215 Step: 102500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2757, 'bonus': 0.019045028063583717, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 94412, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1773408339371956
Updated goal-option-5 on 13 transitions
Took 0.0005459785461425781s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.0034923553466796875s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1216 Step: 102600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003510713577270508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1217 Step: 102700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003910541534423828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1218 Step: 102800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036127567291259766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1219 Step: 102900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003772735595703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1220 Step: 103000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2994, 'bonus': 0.018275703433940485, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0907018056704978
Updated goal-option-5 on 12 transitions
Took 0.0006444454193115234s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 88 transitions
Took 0.0035860538482666016s to update distance table with 89 states and events {None, SE([ 5 13])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01805734634399414s to add potential edges.
================================================================================
[Consolidation] Episode: 1221 Step: 103100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036902427673339844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1222 Step: 103200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2954, 'bonus': 0.018399022669872974, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2014597500120843
Updated goal-option-5 on 100 transitions
Took 0.004399538040161133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1223 Step: 103300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003821134567260742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1224 Step: 103400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036950111389160156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1225 Step: 103500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039751529693603516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1226 Step: 103600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2990, 'bonus': 0.018287923898986376, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1100521330539015
Updated goal-option-5 on 10 transitions
Took 0.0004611015319824219s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0035707950592041016s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1227 Step: 103700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003935813903808594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1228 Step: 103800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036482810974121094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1229 Step: 103900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037152767181396484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1230 Step: 104000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2757, 'bonus': 0.019045028063583717, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 94412, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2666659665019733
Updated goal-option-5 on 12 transitions
Took 0.000484466552734375s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 88 transitions
Took 0.003566741943359375s to update distance table with 89 states and events {None, SE([ 5 13])}
Took 2.7179718017578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1231 Step: 104100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038433074951171875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1232 Step: 104200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003657102584838867s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1233 Step: 104300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2837, 'bonus': 0.01877458439983895, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 98016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.202622683576624
Updated goal-option-5 on 22 transitions
Took 0.0006756782531738281s to update distance table with 23 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 78 transitions
Took 0.0031960010528564453s to update distance table with 79 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1234 Step: 104400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2998, 'bonus': 0.018263507434294626, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102446, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1197258123553
Updated goal-option-5 on 22 transitions
Took 0.0006346702575683594s to update distance table with 23 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 78 transitions
Took 0.003164052963256836s to update distance table with 79 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1235 Step: 104500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038928985595703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1236 Step: 104600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038988590240478516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1237 Step: 104700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003889799118041992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1238 Step: 104800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2910, 'bonus': 0.01853759994400162, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 99413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 95 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0796245463762923
Updated goal-option-5 on 8 transitions
Took 0.00040841102600097656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.0037491321563720703s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1239 Step: 104900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037424564361572266s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1240 Seed=18] Took 0.013644695281982422s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1240 Step: 105000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 105000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2994, 'bonus': 0.018275703433940485, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 96 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0240779984118162
Updated goal-option-5 on 13 transitions
Took 0.0005505084991455078s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.003699779510498047s to update distance table with 88 states and events {None, SE([ 5 13])}
Took 2.7179718017578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1241 Step: 105100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0040929317474365234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1242 Step: 105200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004027128219604492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1243 Step: 105300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 105300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3012, 'bonus': 0.01822101292697509, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1958150108973726
Updated goal-option-5 on 100 transitions
Took 0.005127429962158203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1244 Step: 105400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034241676330566406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1245 Step: 105500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037946701049804688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1246 Step: 105600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003627300262451172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1247 Step: 105700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033583641052246094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1248 Step: 105800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004125833511352539s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1249 Step: 105900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004225254058837891s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1250 Step: 106000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2994, 'bonus': 0.018275703433940485, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.080484922726949
Updated goal-option-5 on 100 transitions
Took 0.004851341247558594s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.5510787963867188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1251 Step: 106100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2994, 'bonus': 0.018275703433940485, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102322, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 97 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.114408367944565
Updated goal-option-5 on 56 transitions
Took 0.0023903846740722656s to update distance table with 57 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 44 transitions
Took 0.0019328594207763672s to update distance table with 45 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1252 Step: 106200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3024, 'bonus': 0.018184824186332698, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 98 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0621965905803472
Updated goal-option-5 on 17 transitions
Took 0.0005772113800048828s to update distance table with 18 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 83 transitions
Took 0.003442525863647461s to update distance table with 84 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1253 Step: 106300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2954, 'bonus': 0.018399022669872974, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0980602106363735
Updated goal-option-5 on 100 transitions
Took 0.004642486572265625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1254 Step: 106400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2989, 'bonus': 0.018290982847556567, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 99 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.182464166256926
Updated goal-option-5 on 25 transitions
Took 0.0012083053588867188s to update distance table with 26 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 75 transitions
Took 0.0029997825622558594s to update distance table with 76 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1255 Step: 106500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003803730010986328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1256 Step: 106600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3011, 'bonus': 0.018224038416896644, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 100 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1642449554940855
Updated goal-option-5 on 26 transitions
Took 0.0012791156768798828s to update distance table with 27 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 74 transitions
Took 0.0030455589294433594s to update distance table with 75 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1257 Step: 106700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3011, 'bonus': 0.018224038416896644, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 101 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.088600982343799
Updated goal-option-5 on 10 transitions
Took 0.00044345855712890625s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036618709564208984s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1258 Step: 106800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3007, 'bonus': 0.01823615546505513, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102513, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 102 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0508986649329428
Updated goal-option-5 on 13 transitions
Took 0.00048065185546875s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.0035202503204345703s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1259 Step: 106900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2990, 'bonus': 0.018287923898986376, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 102214, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0141847328178695
Updated goal-option-5 on 100 transitions
Took 0.004925251007080078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1260 Step: 107000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 107000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2954, 'bonus': 0.018399022669872974, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0804049182697184
Updated goal-option-5 on 100 transitions
Took 0.0044460296630859375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.574920654296875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1261 Step: 107100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003509998321533203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1262 Step: 107200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032596588134765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1263 Step: 107300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039746761322021484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1264 Step: 107400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035042762756347656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1265 Step: 107500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 107500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3011, 'bonus': 0.018224038416896644, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 103012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 103 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1121550001901632
Updated goal-option-5 on 24 transitions
Took 0.0011441707611083984s to update distance table with 25 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 76 transitions
Took 0.003064393997192383s to update distance table with 77 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1266 Step: 107600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036966800689697266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1267 Step: 107700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003644227981567383s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1268 Step: 107800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037047863006591797s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1269 Step: 107900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003679513931274414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1270 Step: 108000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 2973, 'bonus': 0.01834013572851071, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 101530, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 104 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0830295888208668
Updated goal-option-5 on 30 transitions
Took 0.0009477138519287109s to update distance table with 31 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 70 transitions
Took 0.002864360809326172s to update distance table with 71 states and events {None, SE([ 5 13])}
Took 4.1961669921875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1271 Step: 108100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031511783599853516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1272 Step: 108200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3024, 'bonus': 0.018184824186332698, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 105 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.128584888913043
Updated goal-option-5 on 16 transitions
Took 0.0005195140838623047s to update distance table with 17 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 84 transitions
Took 0.0034160614013671875s to update distance table with 85 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1273 Step: 108300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003141164779663086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1274 Step: 108400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003839254379272461s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1275 Step: 108500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3015, 'bonus': 0.018211945490271768, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104012, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 106 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0861535325557703
Updated goal-option-5 on 83 transitions
Took 0.0038814544677734375s to update distance table with 84 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 17 transitions
Took 0.0007185935974121094s to update distance table with 18 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1276 Step: 108600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3024, 'bonus': 0.018184824186332698, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 107 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0387424659623787
Updated goal-option-5 on 34 transitions
Took 0.0010180473327636719s to update distance table with 35 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 66 transitions
Took 0.002735137939453125s to update distance table with 67 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1277 Step: 108700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040493011474609375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1278 Step: 108800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038461685180664062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1279 Step: 108900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3037, 'bonus': 0.01814586201311143, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106710, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 108 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0674594800119046
Updated goal-option-5 on 10 transitions
Took 0.0004286766052246094s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 90 transitions
Took 0.003603219985961914s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1280 Step: 109000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036644935607910156s to update distance table with 101 states and events {SE([ 8 16])}
Took 2.9325485229492188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1281 Step: 109100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036535263061523438s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1282 Step: 109200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 109200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3026, 'bonus': 0.01817881366751496, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 105013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 109 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0092430852204892
Updated goal-option-5 on 38 transitions
Took 0.0016820430755615234s to update distance table with 39 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 62 transitions
Took 0.002658367156982422s to update distance table with 63 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1283 Step: 109300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039331912994384766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1284 Step: 109400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 109400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3021, 'bonus': 0.018193851153474074, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104422, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 110 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0334627504589635
Updated goal-option-5 on 18 transitions
Took 0.0008144378662109375s to update distance table with 19 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 82 transitions
Took 0.0030803680419921875s to update distance table with 83 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1285 Step: 109500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004065036773681641s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1286 Step: 109600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 109600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3033, 'bonus': 0.018157823690094776, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106217, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 111 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.051525237807638
Updated goal-option-5 on 32 transitions
Took 0.0014832019805908203s to update distance table with 33 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 68 transitions
Took 0.0027921199798583984s to update distance table with 69 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1287 Step: 109700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003161907196044922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1288 Step: 109800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003635406494140625s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1289 Step: 109900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036389827728271484s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1290 Seed=18] Took 0.011611223220825195s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1290 Step: 110000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036275386810302734s to update distance table with 101 states and events {SE([ 8 16])}
Took 2.86102294921875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1291 Step: 110100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3024, 'bonus': 0.018184824186332698, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 112 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0859468089823692
Updated goal-option-5 on 11 transitions
Took 0.0004467964172363281s to update distance table with 12 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 89 transitions
Took 0.0033936500549316406s to update distance table with 90 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1292 Step: 110200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3066, 'bonus': 0.018059841095769247, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 109238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 113 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.016936573600629
Updated goal-option-5 on 10 transitions
Took 0.00042724609375s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036096572875976562s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1293 Step: 110300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032258033752441406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1294 Step: 110400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3021, 'bonus': 0.018193851153474074, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 104422, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 114 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0722725571033362
Updated goal-option-5 on 13 transitions
Took 0.0005052089691162109s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.0035381317138671875s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1295 Step: 110500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033075809478759766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1296 Step: 110600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00391387939453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1297 Step: 110700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037784576416015625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1298 Step: 110800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3052, 'bonus': 0.018101215356399913, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 106813, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 115 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.122441695767008
Updated goal-option-5 on 12 transitions
Took 0.0004999637603759766s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 88 transitions
Took 0.003648042678833008s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1299 Step: 110900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3026, 'bonus': 0.01817881366751496, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 105013, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0687107738782788
Updated goal-option-5 on 100 transitions
Took 0.004656314849853516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1300 Step: 111000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00402069091796875s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.220008850097656e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1301 Step: 111100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3066, 'bonus': 0.018059841095769247, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 109238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 116 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.018167646240956
Updated goal-option-5 on 26 transitions
Took 0.0010066032409667969s to update distance table with 27 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 74 transitions
Took 0.002888202667236328s to update distance table with 75 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1302 Step: 111200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3053, 'bonus': 0.01809825061715205, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 107524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 117 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0314233865137108
Updated goal-option-5 on 86 transitions
Took 0.003968477249145508s to update distance table with 87 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 14 transitions
Took 0.0005979537963867188s to update distance table with 15 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1303 Step: 111300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038862228393554688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1304 Step: 111400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003603696823120117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1305 Step: 111500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003601551055908203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1306 Step: 111600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038640499114990234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1307 Step: 111700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3064, 'bonus': 0.018065734338248103, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 118 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.070528932261294
Updated goal-option-5 on 30 transitions
Took 0.0014166831970214844s to update distance table with 31 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 70 transitions
Took 0.002876758575439453s to update distance table with 71 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1308 Step: 111800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3118, 'bonus': 0.017908612711114453, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111286, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 119 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0686336499749969
Updated goal-option-5 on 27 transitions
Took 0.0014691352844238281s to update distance table with 28 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 73 transitions
Took 0.0031316280364990234s to update distance table with 74 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1309 Step: 111900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004074573516845703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1310 Step: 112000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004271268844604492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.765655517578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1311 Step: 112100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033698081970214844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1312 Step: 112200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003659963607788086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1313 Step: 112300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003638029098510742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1314 Step: 112400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003954887390136719s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1315 Step: 112500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.002984762191772461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1316 Step: 112600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 112600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3120, 'bonus': 0.017902871850985824, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 120 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0892612387197913
Updated goal-option-5 on 12 transitions
Took 0.0004572868347167969s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 88 transitions
Took 0.003534078598022461s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1317 Step: 112700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 112700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3089, 'bonus': 0.017992480714263844, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110210, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 121 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0010739165703628
Updated goal-option-5 on 15 transitions
Took 0.0004971027374267578s to update distance table with 16 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 85 transitions
Took 0.0033817291259765625s to update distance table with 86 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1318 Step: 112800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 112800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3058, 'bonus': 0.018083448741266828, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108030, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 122 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.093633204655558
Updated goal-option-5 on 12 transitions
Took 0.000457763671875s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 88 transitions
Took 0.003306865692138672s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1319 Step: 112900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038940906524658203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1320 Step: 113000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003168344497680664s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.9802322387695312e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1321 Step: 113100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3064, 'bonus': 0.018065734338248103, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.077526977571329
Updated goal-option-5 on 100 transitions
Took 0.004642009735107422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1322 Step: 113200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038645267486572266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1323 Step: 113300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3092, 'bonus': 0.01798375003164016, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110413, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9962344284553254
Updated goal-option-5 on 100 transitions
Took 0.004740476608276367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1324 Step: 113400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3083, 'bonus': 0.018009980294390843, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110111, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 123 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1068662449355118
Updated goal-option-5 on 10 transitions
Took 0.0004258155822753906s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036764144897460938s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1325 Step: 113500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003854036331176758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1326 Step: 113600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3094, 'bonus': 0.017977936632415488, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110812, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 124 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0905100340196843
Updated goal-option-5 on 10 transitions
Took 0.00042748451232910156s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 90 transitions
Took 0.004005908966064453s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1327 Step: 113700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003935575485229492s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1328 Step: 113800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038797855377197266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1329 Step: 113900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003557443618774414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1330 Step: 114000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00400996208190918s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.956390380859375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1331 Step: 114100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004017353057861328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1332 Step: 114200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 114200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3064, 'bonus': 0.018065734338248103, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 108634, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 125 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0465845591329832
Updated goal-option-5 on 12 transitions
Took 0.0005311965942382812s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 88 transitions
Took 0.003574371337890625s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1333 Step: 114300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003721952438354492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1334 Step: 114400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036339759826660156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1335 Step: 114500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038862228393554688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1336 Step: 114600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003877878189086914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1337 Step: 114700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 114700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3127, 'bonus': 0.017882822232191637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 112715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0704817627357621
Updated goal-option-5 on 100 transitions
Took 0.004815101623535156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1338 Step: 114800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 114800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3127, 'bonus': 0.017882822232191637, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 112715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 126 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.011711493559033
Updated goal-option-5 on 10 transitions
Took 0.000518798828125s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 90 transitions
Took 0.0038912296295166016s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1339 Step: 114900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003659486770629883s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1340 Seed=18] Took 0.009524106979370117s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1340 Step: 115000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004108428955078125s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.7670135498046875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1341 Step: 115100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0042285919189453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1342 Step: 115200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00405573844909668s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1343 Step: 115300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038826465606689453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1344 Step: 115400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 115400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3178, 'bonus': 0.017738751654443555, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 114212, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1173765366804513
Updated goal-option-5 on 100 transitions
Took 0.004839181900024414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1345 Step: 115500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003317117691040039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1346 Step: 115600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033888816833496094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1347 Step: 115700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 115700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3089, 'bonus': 0.017992480714263844, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 110210, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 127 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9678547482541267
Updated goal-option-5 on 15 transitions
Took 0.0006401538848876953s to update distance table with 16 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 85 transitions
Took 0.0037550926208496094s to update distance table with 86 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1348 Step: 115800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003926277160644531s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1349 Step: 115900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003832578659057617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1350 Step: 116000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036830902099609375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.86102294921875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1351 Step: 116100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004055976867675781s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1352 Step: 116200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037889480590820312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1353 Step: 116300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 116300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3066, 'bonus': 0.018059841095769247, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 109238, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 128 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9977996908367784
Updated goal-option-5 on 10 transitions
Took 0.0004260540008544922s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036966800689697266s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1354 Step: 116400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034151077270507812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1355 Step: 116500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033693313598632812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1356 Step: 116600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004004716873168945s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1357 Step: 116700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 116700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3120, 'bonus': 0.017902871850985824, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 129 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.027176699395907
Updated goal-option-5 on 61 transitions
Took 0.002841949462890625s to update distance table with 62 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 39 transitions
Took 0.0017032623291015625s to update distance table with 40 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1358 Step: 116800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 116800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3105, 'bonus': 0.017946063401938852, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111126, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 130 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9576493499142927
Updated goal-option-5 on 10 transitions
Took 0.0004298686981201172s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.003673553466796875s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1359 Step: 116900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003592252731323242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1360 Step: 117000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033919811248779297s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.600120544433594e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1361 Step: 117100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003721952438354492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1362 Step: 117200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 117200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3144, 'bonus': 0.01783440937516054, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 131 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0385966472401063
Updated goal-option-5 on 27 transitions
Took 0.001247406005859375s to update distance table with 28 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 73 transitions
Took 0.0030379295349121094s to update distance table with 74 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1363 Step: 117300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037212371826171875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1364 Step: 117400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 117400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3131, 'bonus': 0.017871395507553855, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0766491235348217
Updated goal-option-5 on 100 transitions
Took 0.0045316219329833984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1365 Step: 117500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003990650177001953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1366 Step: 117600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.005032539367675781s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1367 Step: 117700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00394439697265625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1368 Step: 117800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036821365356445312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1369 Step: 117900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 117900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3120, 'bonus': 0.017902871850985824, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 111827, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 132 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9696802069121139
Updated goal-option-5 on 44 transitions
Took 0.0020787715911865234s to update distance table with 45 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 56 transitions
Took 0.0023910999298095703s to update distance table with 57 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1370 Step: 118000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036454200744628906s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.600120544433594e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1371 Step: 118100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 118100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3186, 'bonus': 0.017716466781757798, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 116761, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 133 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.056506294028025
Updated goal-option-5 on 29 transitions
Took 0.0014643669128417969s to update distance table with 30 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 71 transitions
Took 0.0031032562255859375s to update distance table with 72 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1372 Step: 118200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003642559051513672s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1373 Step: 118300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038194656372070312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1374 Step: 118400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003815889358520508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1375 Step: 118500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003401041030883789s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1376 Step: 118600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 118600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3206, 'bonus': 0.017661119983645744, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 117944, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 134 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0080584850021985
Updated goal-option-5 on 10 transitions
Took 0.00046133995056152344s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.00370025634765625s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1377 Step: 118700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004032611846923828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1378 Step: 118800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038008689880371094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1379 Step: 118900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003943681716918945s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1380 Step: 119000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037450790405273438s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.695487976074219e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1381 Step: 119100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033452510833740234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1382 Step: 119200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3183, 'bonus': 0.0177248137630368, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 115715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 135 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1522300375635428
Updated goal-option-5 on 52 transitions
Took 0.0025615692138671875s to update distance table with 53 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 48 transitions
Took 0.0019969940185546875s to update distance table with 49 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1383 Step: 119300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003966569900512695s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1384 Step: 119400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3131, 'bonus': 0.017871395507553855, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 113410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 136 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9674388732830849
Updated goal-option-5 on 72 transitions
Took 0.003420591354370117s to update distance table with 73 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 28 transitions
Took 0.0011162757873535156s to update distance table with 29 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1385 Step: 119500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003198862075805664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1386 Step: 119600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3201, 'bonus': 0.01767490804100673, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 116810, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 137 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0399199799885825
Updated goal-option-5 on 50 transitions
Took 0.003976106643676758s to update distance table with 51 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 50 transitions
Took 0.0020554065704345703s to update distance table with 51 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1387 Step: 119700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003926277160644531s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1388 Step: 119800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3179, 'bonus': 0.017735961445750802, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 114810, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 138 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.038031626726694
Updated goal-option-5 on 10 transitions
Took 0.0004730224609375s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 90 transitions
Took 0.0036916732788085938s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1389 Step: 119900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3219, 'bonus': 0.017625421500471306, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 118610, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 139 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0397262285050657
Updated goal-option-5 on 57 transitions
Took 0.002689361572265625s to update distance table with 58 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 43 transitions
Took 0.001809835433959961s to update distance table with 44 states and events {None, SE([ 5 13])}
[Episode=1390 Seed=18] Took 0.013303041458129883s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1390 Step: 120000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003808736801147461s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.9087066650390625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1391 Step: 120100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003150463104248047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1392 Step: 120200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035436153411865234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1393 Step: 120300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 120300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3204, 'bonus': 0.017666631333439334, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 117227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 140 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0128454729117484
Updated goal-option-5 on 28 transitions
Took 0.0013239383697509766s to update distance table with 29 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 72 transitions
Took 0.0029449462890625s to update distance table with 73 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1394 Step: 120400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003139495849609375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1395 Step: 120500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003711700439453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1396 Step: 120600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037453174591064453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1397 Step: 120700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037157535552978516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1398 Step: 120800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003995656967163086s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1399 Step: 120900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037147998809814453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1400 Step: 121000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 121000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3247, 'bonus': 0.01754926191550154, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119957, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 141 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.03676306624962
Updated goal-option-5 on 10 transitions
Took 0.00043582916259765625s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.003611326217651367s to update distance table with 91 states and events {None, SE([ 5 13])}
Took 3.5762786865234375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1401 Step: 121100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034401416778564453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1402 Step: 121200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003228425979614258s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1403 Step: 121300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003514528274536133s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1404 Step: 121400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031816959381103516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1405 Step: 121500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004030942916870117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1406 Step: 121600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 121600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3184, 'bonus': 0.017722030125208395, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 116310, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 142 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1340729965846572
Updated goal-option-5 on 10 transitions
Took 0.00043082237243652344s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.003630399703979492s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1407 Step: 121700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 121700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3247, 'bonus': 0.01754926191550154, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119957, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 143 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9783991472432256
Updated goal-option-5 on 11 transitions
Took 0.0004439353942871094s to update distance table with 12 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 89 transitions
Took 0.0037527084350585938s to update distance table with 90 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1408 Step: 121800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003955841064453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1409 Step: 121900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003587007522583008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1410 Step: 122000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003948211669921875s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.8371810913085938e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1411 Step: 122100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 122100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3239, 'bonus': 0.01757092099429725, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9859411381299535
Updated goal-option-5 on 100 transitions
Took 0.0048596858978271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1412 Step: 122200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033025741577148438s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1413 Step: 122300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003226757049560547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1414 Step: 122400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003639698028564453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1415 Step: 122500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003567934036254883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1416 Step: 122600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 122600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3204, 'bonus': 0.017666631333439334, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 117227, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 144 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1077466304398105
Updated goal-option-5 on 10 transitions
Took 0.0004394054412841797s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 90 transitions
Took 0.00373077392578125s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1417 Step: 122700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003887176513671875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1418 Step: 122800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003597259521484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1419 Step: 122900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037620067596435547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1420 Step: 123000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038771629333496094s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 3.552436828613281e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1421 Step: 123100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004016399383544922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1422 Step: 123200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3217, 'bonus': 0.017630899487083906, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 118129, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 145 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0558055797725123
Updated goal-option-5 on 13 transitions
Took 0.00048232078552246094s to update distance table with 14 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 87 transitions
Took 0.0036830902099609375s to update distance table with 88 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1423 Step: 123300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003953695297241211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1424 Step: 123400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3183, 'bonus': 0.0177248137630368, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 115715, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 146 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.025353913183193
Updated goal-option-5 on 10 transitions
Took 0.00047469139099121094s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 90 transitions
Took 0.003755331039428711s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1425 Step: 123500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3265, 'bonus': 0.01750082037018273, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 121711, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 147 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9362798398246571
Updated goal-option-5 on 11 transitions
Took 0.0004851818084716797s to update distance table with 12 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 89 transitions
Took 0.004019498825073242s to update distance table with 90 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1426 Step: 123600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3255, 'bonus': 0.017527682734987296, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 121010, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 148 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9841340339394224
Updated goal-option-5 on 12 transitions
Took 0.00045180320739746094s to update distance table with 13 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 88 transitions
Took 0.0035762786865234375s to update distance table with 89 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1427 Step: 123700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038421154022216797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1428 Step: 123800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034551620483398438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1429 Step: 123900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3360, 'bonus': 0.017251638983558856, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123612, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 149 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9378575257759717
Updated goal-option-5 on 11 transitions
Took 0.0004782676696777344s to update distance table with 12 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 89 transitions
Took 0.0035486221313476562s to update distance table with 90 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1430 Step: 124000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035445690155029297s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.00543212890625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1431 Step: 124100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039942264556884766s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1432 Step: 124200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 124200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3237, 'bonus': 0.017576348305930706, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119472, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 150 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.043517809859442
Updated goal-option-5 on 10 transitions
Took 0.00042510032653808594s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0033485889434814453s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1433 Step: 124300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038878917694091797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1434 Step: 124400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003907442092895508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1435 Step: 124500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 124500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3265, 'bonus': 0.01750082037018273, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 121711, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 151 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9393533207577095
Updated goal-option-5 on 10 transitions
Took 0.0004267692565917969s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036034584045410156s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1436 Step: 124600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032739639282226562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1437 Step: 124700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034351348876953125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1438 Step: 124800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004179954528808594s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1439 Step: 124900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00379180908203125s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
[Episode=1440 Seed=18] Took 0.013181447982788086s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1440 Step: 125000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003662109375s to update distance table with 101 states and events {SE([ 8 16])}
Took 3.266334533691406e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1441 Step: 125100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035114288330078125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1442 Step: 125200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 125200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 124510, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 152 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.951384654839026
Updated goal-option-5 on 10 transitions
Took 0.00047707557678222656s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036830902099609375s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1443 Step: 125300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003937721252441406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1444 Step: 125400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 125400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3225, 'bonus': 0.017609018126512475, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119252, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 153 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9554654692630216
Updated goal-option-5 on 88 transitions
Took 0.004538774490356445s to update distance table with 89 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 12 transitions
Took 0.0005941390991210938s to update distance table with 13 states and events {SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1445 Step: 125500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 125500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3416, 'bonus': 0.017109647770728872, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 125488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 154 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9386940401213373
Updated goal-option-5 on 11 transitions
Took 0.0004918575286865234s to update distance table with 12 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 89 transitions
Took 0.0035991668701171875s to update distance table with 90 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1446 Step: 125600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003955364227294922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1447 Step: 125700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003314971923828125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1448 Step: 125800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003666400909423828s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1449 Step: 125900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003812074661254883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1450 Step: 126000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3323, 'bonus': 0.017347417443674195, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 155 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9561739596939053
Updated goal-option-5 on 10 transitions
Took 0.0004889965057373047s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 90 transitions
Took 0.0038099288940429688s to update distance table with 91 states and events {SE([ 8 16]), None, SE([ 5 13])}
Took 3.719329833984375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1451 Step: 126100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037984848022460938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1452 Step: 126200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003857135772705078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1453 Step: 126300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3239, 'bonus': 0.01757092099429725, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 119650, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 156 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9671597198003069
Updated goal-option-5 on 10 transitions
Took 0.00043773651123046875s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036182403564453125s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1454 Step: 126400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003785848617553711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1455 Step: 126500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003756999969482422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1456 Step: 126600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035865306854248047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1457 Step: 126700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037076473236083984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1458 Step: 126800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3307, 'bonus': 0.01738933213465966, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 157 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.975409000931364
Updated goal-option-5 on 10 transitions
Took 0.0004322528839111328s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0036339759826660156s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1459 Step: 126900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3431, 'bonus': 0.017072205940667412, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126010, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 158 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9996225328927233
Updated goal-option-5 on 10 transitions
Took 0.0004470348358154297s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.003758668899536133s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1460 Step: 127000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 127000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3360, 'bonus': 0.017251638983558856, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123612, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 159 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0276201989661942
Updated goal-option-5 on 10 transitions
Took 0.0004680156707763672s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 90 transitions
Took 0.003663301467895508s to update distance table with 91 states and events {None, SE([ 5 13])}
Took 2.8848648071289062e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1461 Step: 127100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003975868225097656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1462 Step: 127200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004026889801025391s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1463 Step: 127300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 127300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3434, 'bonus': 0.017064747028519057, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126810, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 160 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9718078466592938
Updated goal-option-5 on 10 transitions
Took 0.0004661083221435547s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.00363922119140625s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1464 Step: 127400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040166378021240234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1465 Step: 127500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037202835083007812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1466 Step: 127600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003936767578125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1467 Step: 127700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003962039947509766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1468 Step: 127800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036466121673583984s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1469 Step: 127900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040051937103271484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1470 Step: 128000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037784576416015625s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.482269287109375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1471 Step: 128100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3360, 'bonus': 0.017251638983558856, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123612, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 161 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.031489716329325
Updated goal-option-5 on 10 transitions
Took 0.0004298686981201172s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 90 transitions
Took 0.0036444664001464844s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1472 Step: 128200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3431, 'bonus': 0.017072205940667412, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126010, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 162 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9709236943266042
Updated goal-option-5 on 10 transitions
Took 0.00043201446533203125s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.00357818603515625s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1473 Step: 128300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003840923309326172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1474 Step: 128400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 124510, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 163 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1178191945825058
Updated goal-option-5 on 10 transitions
Took 0.00043511390686035156s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 90 transitions
Took 0.0037436485290527344s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1475 Step: 128500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003474712371826172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1476 Step: 128600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039675235748291016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1477 Step: 128700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3307, 'bonus': 0.01738933213465966, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 164 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9575984136966659
Updated goal-option-5 on 56 transitions
Took 0.0026743412017822266s to update distance table with 57 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 44 transitions
Took 0.0017948150634765625s to update distance table with 45 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1478 Step: 128800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3379, 'bonus': 0.017203067924632873, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 124510, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 165 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0139426402075735
Updated goal-option-5 on 8 transitions
Took 0.00040268898010253906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.003744363784790039s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1479 Step: 128900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3478, 'bonus': 0.016956460837017517, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128110, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 166 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0000687348047892
Updated goal-option-5 on 8 transitions
Took 0.0004210472106933594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.0037424564361572266s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1480 Step: 129000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037717819213867188s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.9325485229492188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1481 Step: 129100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038514137268066406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1482 Step: 129200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036058425903320312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1483 Step: 129300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003874540328979492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1484 Step: 129400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036759376525878906s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1485 Step: 129500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039327144622802734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1486 Step: 129600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035042762756347656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1487 Step: 129700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003371000289916992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1488 Step: 129800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033371448516845703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1489 Step: 129900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 129900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3416, 'bonus': 0.017109647770728872, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 125488, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 167 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9586137079993883
Updated goal-option-5 on 8 transitions
Took 0.000408172607421875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.0037610530853271484s to update distance table with 93 states and events {None, SE([ 5 13])}
[Episode=1490 Seed=18] Took 0.009746789932250977s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1490 Step: 130000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038437843322753906s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.790855407714844e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1491 Step: 130100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 130100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3502, 'bonus': 0.01689825771046658, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 129908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 168 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0158213946620622
Updated goal-option-5 on 8 transitions
Took 0.0004048347473144531s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.003697633743286133s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1492 Step: 130200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 130200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3372, 'bonus': 0.017220914757957267, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 123911, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 169 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.029827215289324
Updated goal-option-5 on 8 transitions
Took 0.0004203319549560547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.0035812854766845703s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1493 Step: 130300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003445863723754883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1494 Step: 130400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003489971160888672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1495 Step: 130500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039479732513427734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1496 Step: 130600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037178993225097656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1497 Step: 130700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003877878189086914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1498 Step: 130800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003799915313720703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1499 Step: 130900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004022836685180664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1500 Step: 131000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 131000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3502, 'bonus': 0.01689825771046658, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 129908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 170 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9689096695410754
Updated goal-option-5 on 8 transitions
Took 0.0004405975341796875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.003742694854736328s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 2.8848648071289062e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1501 Step: 131100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037326812744140625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1502 Step: 131200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036468505859375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1503 Step: 131300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039501190185546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1504 Step: 131400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004027366638183594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1505 Step: 131500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037088394165039062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1506 Step: 131600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039865970611572266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1507 Step: 131700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003108978271484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1508 Step: 131800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003719806671142578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1509 Step: 131900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 131900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3481, 'bonus': 0.01694915254237288, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 171 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0112134708576177
Updated goal-option-5 on 8 transitions
Took 0.0004069805145263672s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.003567218780517578s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1510 Step: 132000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003835916519165039s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.8133392333984375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1511 Step: 132100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003927946090698242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1512 Step: 132200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037660598754882812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1513 Step: 132300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004039287567138672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1514 Step: 132400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003890514373779297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1515 Step: 132500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003787994384765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1516 Step: 132600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3429, 'bonus': 0.017077183985952, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 125511, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 172 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9917874056029605
Updated goal-option-5 on 8 transitions
Took 0.00042557716369628906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-8 on 92 transitions
Took 0.0037627220153808594s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1517 Step: 132700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003854990005493164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1518 Step: 132800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3434, 'bonus': 0.017064747028519057, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 126810, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 173 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8986120029076797
Updated goal-option-5 on 8 transitions
Took 0.0004057884216308594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 92 transitions
Took 0.0037691593170166016s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1519 Step: 132900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3507, 'bonus': 0.01688620732191951, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 130108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 174 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.956978714739184
Updated goal-option-5 on 8 transitions
Took 0.0004069805145263672s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.5591520922310602
Updated goal-option-8 on 83 transitions
Took 0.004128456115722656s to update distance table with 84 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3468, 'bonus': 0.01698089027028311, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 127310, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 175 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8923868939336653
Updated goal-option-5 on 8 transitions
Took 0.0003979206085205078s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 1 transitions
Took 0.00012183189392089844s to update distance table with 2 states and events {SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1520 Step: 133000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3552, 'bonus': 0.016778901380350607, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132999, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 176 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9542272961281877
Updated goal-option-5 on 8 transitions
Took 0.00040340423583984375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.437172107204297
Updated goal-option-8 on 92 transitions
Took 0.004601001739501953s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 3.1948089599609375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1521 Step: 133100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038950443267822266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1522 Step: 133200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003859996795654297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1523 Step: 133300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038094520568847656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1524 Step: 133400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003542184829711914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1525 Step: 133500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036613941192626953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1526 Step: 133600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038259029388427734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1527 Step: 133700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036802291870117188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1528 Step: 133800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003805398941040039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1529 Step: 133900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 177 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9393909166908329
Updated goal-option-5 on 8 transitions
Took 0.0004093647003173828s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9354275480472345
Updated goal-option-8 on 92 transitions
Took 0.0045070648193359375s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1530 Step: 134000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003477811813354492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.956390380859375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1531 Step: 134100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 134100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3520, 'bonus': 0.016854996561581053, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 131008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 178 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9864559662586968
Updated goal-option-5 on 8 transitions
Took 0.00042557716369628906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0902204005364093
Updated goal-option-8 on 92 transitions
Took 0.00452733039855957s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1532 Step: 134200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 134200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3478, 'bonus': 0.016956460837017517, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 128110, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 179 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.00472714832772
Updated goal-option-5 on 8 transitions
Took 0.0004444122314453125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.630096132395777
Updated goal-option-8 on 92 transitions
Took 0.005091667175292969s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1533 Step: 134300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0040051937103271484s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1534 Step: 134400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 134400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3556, 'bonus': 0.016769461772638442, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 180 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9357237994237236
Updated goal-option-5 on 8 transitions
Took 0.00043773651123046875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.325903722429629
Updated goal-option-8 on 92 transitions
Took 0.0045528411865234375s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1535 Step: 134500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037844181060791016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1536 Step: 134600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037450790405273438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1537 Step: 134700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038983821868896484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1538 Step: 134800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003534555435180664s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1539 Step: 134900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003801107406616211s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1540 Seed=18] Took 0.009863853454589844s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1540 Step: 135000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3502, 'bonus': 0.01689825771046658, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 129908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 181 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9700439337187658
Updated goal-option-5 on 8 transitions
Took 0.0004627704620361328s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7311656259035786
Updated goal-option-8 on 92 transitions
Took 0.005060672760009766s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 3.218650817871094e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1541 Step: 135100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3502, 'bonus': 0.01689825771046658, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 129908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 182 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0179992504639201
Updated goal-option-5 on 8 transitions
Took 0.00040793418884277344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.0036737918853759766s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1542 Step: 135200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003811359405517578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1543 Step: 135300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3587, 'bonus': 0.016696841006065288, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 183 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9439267642820628
Updated goal-option-5 on 8 transitions
Took 0.00038933753967285156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.4652718049386824
Updated goal-option-8 on 92 transitions
Took 0.004530668258666992s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1544 Step: 135400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3520, 'bonus': 0.016854996561581053, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 131008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 184 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9387763868464102
Updated goal-option-5 on 10 transitions
Took 0.0004229545593261719s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 90 transitions
Took 0.0036978721618652344s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1545 Step: 135500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003553152084350586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1546 Step: 135600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004080057144165039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1547 Step: 135700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032682418823242188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1548 Step: 135800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037994384765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1549 Step: 135900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003599882125854492s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1550 Step: 136000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 136000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3569, 'bonus': 0.0167388927220441, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 134408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 185 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9213262956604185
Updated goal-option-5 on 8 transitions
Took 0.00046324729919433594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.551529992550476
Updated goal-option-8 on 92 transitions
Took 0.004568815231323242s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 2.9325485229492188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1551 Step: 136100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038604736328125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1552 Step: 136200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037047863006591797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1553 Step: 136300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003907203674316406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1554 Step: 136400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038475990295410156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1555 Step: 136500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 136500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3556, 'bonus': 0.016769461772638442, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 186 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0132227643480098
Updated goal-option-5 on 10 transitions
Took 0.00046563148498535156s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 90 transitions
Took 0.003583669662475586s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1556 Step: 136600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038063526153564453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1557 Step: 136700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037729740142822266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1558 Step: 136800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037043094635009766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1559 Step: 136900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037093162536621094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1560 Step: 137000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035619735717773438s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.0531158447265625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1561 Step: 137100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3520, 'bonus': 0.016854996561581053, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 131008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 187 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9279184301576439
Updated goal-option-5 on 8 transitions
Took 0.00041103363037109375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9305636718034949
Updated goal-option-8 on 92 transitions
Took 0.0045392513275146484s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1562 Step: 137200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3556, 'bonus': 0.016769461772638442, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 188 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9498935875376929
Updated goal-option-5 on 8 transitions
Took 0.0006544589996337891s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.6512061953297805
Updated goal-option-8 on 92 transitions
Took 0.004603862762451172s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1563 Step: 137300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035009384155273438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1564 Step: 137400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3572, 'bonus': 0.016731862035256367, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 189 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8973501186712567
Updated goal-option-5 on 8 transitions
Took 0.0005118846893310547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.295998517513111
Updated goal-option-8 on 92 transitions
Took 0.005091428756713867s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1565 Step: 137500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3572, 'bonus': 0.016731862035256367, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 190 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.891234028856665
Updated goal-option-5 on 8 transitions
Took 0.00042557716369628906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.097998455177084
Updated goal-option-8 on 92 transitions
Took 0.00456547737121582s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1566 Step: 137600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032618045806884766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1567 Step: 137700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038247108459472656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1568 Step: 137800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3533, 'bonus': 0.016823958224413904, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 191 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9945939614234635
Updated goal-option-5 on 10 transitions
Took 0.0004696846008300781s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 90 transitions
Took 0.0035867691040039062s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1569 Step: 137900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3533, 'bonus': 0.016823958224413904, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 192 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9561183371647136
Updated goal-option-5 on 8 transitions
Took 0.00041222572326660156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8886167113907673
Updated goal-option-8 on 92 transitions
Took 0.004569292068481445s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1570 Step: 138000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003981828689575195s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.4809112548828125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1571 Step: 138100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003710508346557617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1572 Step: 138200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3617, 'bonus': 0.01662745363976212, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 193 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9153185289089136
Updated goal-option-5 on 8 transitions
Took 0.0004563331604003906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.8860392029966384
Updated goal-option-8 on 92 transitions
Took 0.004614591598510742s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1573 Step: 138300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003672361373901367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1574 Step: 138400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3603, 'bonus': 0.016659726559488115, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 194 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0466968312361853
Updated goal-option-5 on 8 transitions
Took 0.0004940032958984375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.6576943188177586
Updated goal-option-8 on 92 transitions
Took 0.004579782485961914s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1575 Step: 138500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3554, 'bonus': 0.016774179584455692, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 133008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 195 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9185919796007478
Updated goal-option-5 on 8 transitions
Took 0.0004038810729980469s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.6335604043821697
Updated goal-option-8 on 92 transitions
Took 0.004533290863037109s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1576 Step: 138600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004018545150756836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1577 Step: 138700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003543853759765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1578 Step: 138800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003957986831665039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1579 Step: 138900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3597, 'bonus': 0.01667361545440517, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 136510, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 196 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9168223610053908
Updated goal-option-5 on 10 transitions
Took 0.0004763603210449219s to update distance table with 11 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.998792079258491
Updated goal-option-8 on 90 transitions
Took 0.004446983337402344s to update distance table with 91 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1580 Step: 139000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 139000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3562, 'bonus': 0.016755332185712266, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 134108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 197 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9366965731171373
Updated goal-option-5 on 8 transitions
Took 0.00040268898010253906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3070376839542734
Updated goal-option-8 on 92 transitions
Took 0.004525423049926758s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 4.124641418457031e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1581 Step: 139100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035719871520996094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1582 Step: 139200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003943204879760742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1583 Step: 139300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003977060317993164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1584 Step: 139400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038995742797851562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1585 Step: 139500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004105329513549805s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1586 Step: 139600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003498077392578125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1587 Step: 139700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 139700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3625, 'bonus': 0.016609095970747993, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 198 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8985084996309155
Updated goal-option-5 on 8 transitions
Took 0.0004374980926513672s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.0037572383880615234s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1588 Step: 139800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038652420043945312s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1589 Step: 139900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033571720123291016s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1590 Seed=18] Took 0.012205839157104492s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1590 Step: 140000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036084651947021484s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.9325485229492188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1591 Step: 140100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3627, 'bonus': 0.01660451604622393, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138910, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 199 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9014120215489193
Updated goal-option-5 on 8 transitions
Took 0.00043320655822753906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.681617636371542
Updated goal-option-8 on 92 transitions
Took 0.004613637924194336s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1592 Step: 140200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038754940032958984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1593 Step: 140300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3599, 'bonus': 0.016668981963846228, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 200 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9223402587323895
Updated goal-option-5 on 8 transitions
Took 0.0004956722259521484s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
4.034904789126882
Updated goal-option-8 on 92 transitions
Took 0.005143880844116211s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1594 Step: 140400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3595, 'bonus': 0.016678252811038963, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 135410, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 201 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8526211741969076
Updated goal-option-5 on 8 transitions
Took 0.00040149688720703125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
2.1107545161630843
Updated goal-option-8 on 22 transitions
Took 0.0011136531829833984s to update distance table with 23 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 70 transitions
Took 0.0019333362579345703s to update distance table with 71 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1595 Step: 140500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003847837448120117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1596 Step: 140600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003899097442626953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1597 Step: 140700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3604, 'bonus': 0.01665741511631924, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137810, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 202 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.927116301642161
Updated goal-option-5 on 8 transitions
Took 0.00040650367736816406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7445659190937908
Updated goal-option-8 on 92 transitions
Took 0.004595041275024414s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1598 Step: 140800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3596, 'bonus': 0.016675933649126753, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 136008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 203 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9298581960838105
Updated goal-option-5 on 8 transitions
Took 0.0004107952117919922s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.005381107330322266s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1599 Step: 140900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003329038619995117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1600 Step: 141000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003855466842651367s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.4332275390625e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1601 Step: 141100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004075050354003906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1602 Step: 141200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034656524658203125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1603 Step: 141300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 141300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3622, 'bonus': 0.016615972968891307, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 204 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9616909856752803
Updated goal-option-5 on 8 transitions
Took 0.00045180320739746094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9161489851723448
Updated goal-option-8 on 92 transitions
Took 0.005182027816772461s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1604 Step: 141400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031692981719970703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1605 Step: 141500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003300189971923828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1606 Step: 141600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 141600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3618, 'bonus': 0.01662515560179388, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 205 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9057273203895116
Updated goal-option-5 on 8 transitions
Took 0.0004162788391113281s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.5459118694230605
Updated goal-option-8 on 92 transitions
Took 0.0045316219329833984s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1607 Step: 141700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00403141975402832s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1608 Step: 141800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003550291061401367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1609 Step: 141900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036940574645996094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1610 Step: 142000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038640499114990234s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 3.838539123535156e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1611 Step: 142100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035195350646972656s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1612 Step: 142200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003164052963256836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1613 Step: 142300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035088062286376953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1614 Step: 142400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003889799118041992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1615 Step: 142500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003787517547607422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1616 Step: 142600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038061141967773438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1617 Step: 142700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003806591033935547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1618 Step: 142800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 142800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3600, 'bonus': 0.016666666666666666, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 206 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8537393935257569
Updated goal-option-5 on 8 transitions
Took 0.00043463706970214844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.0037603378295898438s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1619 Step: 142900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037322044372558594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1620 Step: 143000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3601, 'bonus': 0.016664352333993333, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 207 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9231950177086724
Updated goal-option-5 on 8 transitions
Took 0.00040411949157714844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.623899439873616
Updated goal-option-8 on 92 transitions
Took 0.004623889923095703s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 5.1021575927734375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1621 Step: 143100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3618, 'bonus': 0.01662515560179388, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 138208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 208 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9267019497217336
Updated goal-option-5 on 8 transitions
Took 0.00040459632873535156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.0037653446197509766s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1622 Step: 143200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3662, 'bonus': 0.016524975718631645, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 142808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 209 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9072899119159942
Updated goal-option-5 on 8 transitions
Took 0.00040912628173828125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.67398647562338
Updated goal-option-8 on 92 transitions
Took 0.0049664974212646484s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1623 Step: 143300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003793478012084961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1624 Step: 143400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037119388580322266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1625 Step: 143500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036072731018066406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1626 Step: 143600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3662, 'bonus': 0.016524975718631645, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 142808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 210 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0010167523812692
Updated goal-option-5 on 8 transitions
Took 0.00041604042053222656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.003699064254760742s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1627 Step: 143700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00386810302734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1628 Step: 143800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3617, 'bonus': 0.01662745363976212, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 137908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 211 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8507966934359027
Updated goal-option-5 on 8 transitions
Took 0.0004222393035888672s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9196909220722052
Updated goal-option-8 on 92 transitions
Took 0.004561662673950195s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1629 Step: 143900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3664, 'bonus': 0.016520465011377244, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 212 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9394346447383692
Updated goal-option-5 on 8 transitions
Took 0.0004360675811767578s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.527690080743424
Updated goal-option-8 on 92 transitions
Took 0.005138397216796875s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1630 Step: 144000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004092693328857422s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.933906555175781e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1631 Step: 144100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 144100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3670, 'bonus': 0.016506955020011944, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 213 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8836280206579173
Updated goal-option-5 on 8 transitions
Took 0.00040411949157714844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9065626566993727
Updated goal-option-8 on 92 transitions
Took 0.004525184631347656s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1632 Step: 144200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039000511169433594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1633 Step: 144300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0039141178131103516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1634 Step: 144400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0030241012573242188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1635 Step: 144500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 144500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3669, 'bonus': 0.016509204383655284, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 214 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9173766338902384
Updated goal-option-5 on 8 transitions
Took 0.00043654441833496094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.004082202911376953s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1636 Step: 144600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004015922546386719s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1637 Step: 144700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003863096237182617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1638 Step: 144800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 144800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3672, 'bonus': 0.01650245904961124, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 215 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0278817540619365
Updated goal-option-5 on 8 transitions
Took 0.0004520416259765625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.999240204676127
Updated goal-option-8 on 92 transitions
Took 0.005001544952392578s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1639 Step: 144900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004276275634765625s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1640 Seed=18] Took 0.010391950607299805s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1640 Step: 145000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3637, 'bonus': 0.016581673118850265, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 216 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9264705629196651
Updated goal-option-5 on 8 transitions
Took 0.0004494190216064453s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.9145442406994497
Updated goal-option-8 on 92 transitions
Took 0.005162954330444336s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 3.0994415283203125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1641 Step: 145100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3665, 'bonus': 0.016518211042472374, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 217 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9301018543560685
Updated goal-option-5 on 8 transitions
Took 0.00041294097900390625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.969446385555811
Updated goal-option-8 on 92 transitions
Took 0.0045282840728759766s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1642 Step: 145200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3677, 'bonus': 0.016491235176280154, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 144108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 218 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8853107360059286
Updated goal-option-5 on 8 transitions
Took 0.0004050731658935547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3226145870965307
Updated goal-option-8 on 92 transitions
Took 0.0045642852783203125s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1643 Step: 145300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3639, 'bonus': 0.016577115836060096, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 219 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8798880240874549
Updated goal-option-5 on 8 transitions
Took 0.0004367828369140625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.1843014176632134
Updated goal-option-8 on 92 transitions
Took 0.0045108795166015625s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1644 Step: 145400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3710, 'bonus': 0.01641772758257796, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 220 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0841877317328672
Updated goal-option-5 on 8 transitions
Took 0.0004363059997558594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.0037546157836914062s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1645 Step: 145500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037992000579833984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1646 Step: 145600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3669, 'bonus': 0.016509204383655284, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 221 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.944719808648126
Updated goal-option-5 on 8 transitions
Took 0.00040268898010253906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.185445403562351
Updated goal-option-8 on 92 transitions
Took 0.0044803619384765625s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1647 Step: 145700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3716, 'bonus': 0.016404467873119666, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 222 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.03710792262196
Updated goal-option-5 on 8 transitions
Took 0.0004150867462158203s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 92 transitions
Took 0.003770112991333008s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1648 Step: 145800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3717, 'bonus': 0.016402261043504094, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 223 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9329833064223502
Updated goal-option-5 on 8 transitions
Took 0.00040149688720703125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.175788708745002
Updated goal-option-8 on 92 transitions
Took 0.004585742950439453s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1649 Step: 145900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3710, 'bonus': 0.01641772758257796, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 224 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9192998302834373
Updated goal-option-5 on 8 transitions
Took 0.0004019737243652344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0235778019047452
Updated goal-option-8 on 92 transitions
Took 0.004498720169067383s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1650 Step: 146000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035936832427978516s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.504753112792969e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1651 Step: 146100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3710, 'bonus': 0.01641772758257796, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 225 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9630378624340435
Updated goal-option-5 on 8 transitions
Took 0.00040078163146972656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8098174137008927
Updated goal-option-8 on 92 transitions
Took 0.00455927848815918s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1652 Step: 146200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3670, 'bonus': 0.016506955020011944, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 226 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8874909549894131
Updated goal-option-5 on 8 transitions
Deleting edge from SE([ 5 13]) to goal-option-5
Took 0.00040841102600097656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.7297353056860256
Updated goal-option-8 on 92 transitions
Took 0.004541158676147461s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1653 Step: 146300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034132003784179688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1654 Step: 146400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003438711166381836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1655 Step: 146500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.00376129150390625s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1656 Step: 146600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3713, 'bonus': 0.01641109371029585, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 227 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8501945461840988
Updated goal-option-5 on 8 transitions
Took 0.0004928112030029297s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0232074509319573
Updated goal-option-8 on 92 transitions
Took 0.004577159881591797s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1657 Step: 146700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3716, 'bonus': 0.016404467873119666, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 228 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9081624045767076
Updated goal-option-5 on 8 transitions
Took 0.00047469139099121094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.2990065773729795
Updated goal-option-8 on 92 transitions
Took 0.004540920257568359s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1658 Step: 146800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3675, 'bonus': 0.016495721976846452, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 229 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9535873775489817
Updated goal-option-5 on 8 transitions
Took 0.0005199909210205078s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.534899173413894
Updated goal-option-8 on 92 transitions
Took 0.0045511722564697266s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1659 Step: 146900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003928184509277344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1660 Step: 147000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036957263946533203s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from SE([ 5 13]) to goal-option-5
Took 0.01734638214111328s to add potential edges.
================================================================================
[Consolidation] Episode: 1661 Step: 147100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003901958465576172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1662 Step: 147200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003763437271118164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1663 Step: 147300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003751516342163086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1664 Step: 147400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003465414047241211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1665 Step: 147500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035767555236816406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1666 Step: 147600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033349990844726562s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1667 Step: 147700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3702, 'bonus': 0.01643545731515533, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 230 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8977797621526779
Updated goal-option-5 on 8 transitions
Took 0.0004038810729980469s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.326155348199914
Updated goal-option-8 on 92 transitions
Took 0.004597902297973633s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1668 Step: 147800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3672, 'bonus': 0.01650245904961124, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 143808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 231 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9193172984398328
Updated goal-option-5 on 8 transitions
Took 0.00040030479431152344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 92 transitions
Took 0.003807544708251953s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1669 Step: 147900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3679, 'bonus': 0.01648675203492335, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 144508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 232 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8694248390327411
Updated goal-option-5 on 8 transitions
Took 0.00040268898010253906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3909743002310782
Updated goal-option-8 on 92 transitions
Took 0.004601240158081055s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1670 Step: 148000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003875255584716797s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.86102294921875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1671 Step: 148100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033240318298339844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1672 Step: 148200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003719329833984375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1673 Step: 148300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037522315979003906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1674 Step: 148400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 148400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3736, 'bonus': 0.01636049977509221, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 233 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8922826758539989
Updated goal-option-5 on 8 transitions
Took 0.00040340423583984375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.0037589073181152344s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1675 Step: 148500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036363601684570312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1676 Step: 148600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003693819046020508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1677 Step: 148700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003551006317138672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1678 Step: 148800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032875537872314453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1679 Step: 148900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 148900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3741, 'bonus': 0.016349562879842853, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 234 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9001532515233248
Updated goal-option-5 on 8 transitions
Took 0.0004248619079589844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.0934645215262986
Updated goal-option-8 on 92 transitions
Took 0.004603147506713867s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1680 Step: 149000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037839412689208984s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.7418136596679688e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1681 Step: 149100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003304004669189453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1682 Step: 149200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003686666488647461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1683 Step: 149300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 149300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3721, 'bonus': 0.01639344262295082, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 235 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9378121509909413
Updated goal-option-5 on 8 transitions
Took 0.0004050731658935547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.6710052344637614
Updated goal-option-8 on 92 transitions
Took 0.004542350769042969s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1684 Step: 149400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003756284713745117s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1685 Step: 149500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003857135772705078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1686 Step: 149600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003517627716064453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1687 Step: 149700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003731966018676758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1688 Step: 149800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003714323043823242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1689 Step: 149900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 149900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3716, 'bonus': 0.016404467873119666, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 236 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9057331304630862
Updated goal-option-5 on 8 transitions
Took 0.0004088878631591797s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.258982403422715
Updated goal-option-8 on 92 transitions
Took 0.004511356353759766s to update distance table with 93 states and events {None, SE([ 5 13])}
[Episode=1690 Seed=18] Took 0.010776042938232422s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1690 Step: 150000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 150000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3723, 'bonus': 0.01638903874305324, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 237 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8940859147339184
Updated goal-option-5 on 8 transitions
Took 0.0004088878631591797s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.3526916011819137
Updated goal-option-8 on 92 transitions
Took 0.004490375518798828s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 3.0994415283203125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1691 Step: 150100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003988027572631836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1692 Step: 150200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003199338912963867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1693 Step: 150300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036323070526123047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1694 Step: 150400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036902427673339844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1695 Step: 150500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0039033889770507812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1696 Step: 150600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 150600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3765, 'bonus': 0.016297369409447485, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 149908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 238 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.865830089949252
Updated goal-option-5 on 8 transitions
Took 0.00040602684020996094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.460564191776717
Updated goal-option-8 on 92 transitions
Took 0.00455164909362793s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1697 Step: 150700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004294633865356445s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1698 Step: 150800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003434896469116211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1699 Step: 150900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003892183303833008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1700 Step: 151000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037908554077148438s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.86102294921875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1701 Step: 151100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037059783935546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1702 Step: 151200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003336668014526367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1703 Step: 151300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 151300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3713, 'bonus': 0.01641109371029585, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 239 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8555222493474691
Updated goal-option-5 on 8 transitions
Took 0.00040721893310546875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.1032630122835414
Updated goal-option-8 on 92 transitions
Took 0.004488706588745117s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1704 Step: 151400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004053831100463867s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1705 Step: 151500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031576156616210938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1706 Step: 151600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003809690475463867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1707 Step: 151700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032422542572021484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1708 Step: 151800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 151800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3736, 'bonus': 0.01636049977509221, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 240 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8775569584583917
Updated goal-option-5 on 8 transitions
Took 0.0004863739013671875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.4192619919625233
Updated goal-option-8 on 92 transitions
Took 0.004556417465209961s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1709 Step: 151900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 151900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3716, 'bonus': 0.016404467873119666, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 241 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8591144740999391
Updated goal-option-5 on 8 transitions
Took 0.000400543212890625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.9263823310532016
Updated goal-option-8 on 92 transitions
Took 0.0046122074127197266s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1710 Step: 152000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003612518310546875s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.6226043701171875e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1711 Step: 152100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003602266311645508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1712 Step: 152200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 152200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3719, 'bonus': 0.016397850054841973, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 145808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 242 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8875954052381236
Updated goal-option-5 on 8 transitions
Took 0.0004055500030517578s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.859924350319543
Updated goal-option-8 on 92 transitions
Took 0.004597187042236328s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1713 Step: 152300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032875537872314453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1714 Step: 152400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036296844482421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1715 Step: 152500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 152500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3723, 'bonus': 0.01638903874305324, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 243 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8545245236643702
Updated goal-option-5 on 8 transitions
Took 0.0004062652587890625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
3.0736873431127125
Updated goal-option-8 on 92 transitions
Took 0.004488229751586914s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1716 Step: 152600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037450790405273438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1717 Step: 152700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0031583309173583984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1718 Step: 152800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00394892692565918s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1719 Step: 152900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036847591400146484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1720 Step: 153000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033037662506103516s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.5762786865234375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1721 Step: 153100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3743, 'bonus': 0.01634519425908889, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 244 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8969727644445635
Updated goal-option-5 on 8 transitions
Took 0.00040531158447265625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8125502957777744
Updated goal-option-8 on 92 transitions
Took 0.00455021858215332s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1722 Step: 153200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3730, 'bonus': 0.016373653066597823, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 245 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9437749658690558
Updated goal-option-5 on 8 transitions
Took 0.00045800209045410156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.263658327148145
Updated goal-option-8 on 92 transitions
Took 0.005070924758911133s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1723 Step: 153300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3823, 'bonus': 0.01617327052797354, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 246 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8829217766201686
Updated goal-option-5 on 8 transitions
Took 0.000453948974609375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.504826015957138
Updated goal-option-8 on 92 transitions
Took 0.005075693130493164s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1724 Step: 153400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038030147552490234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1725 Step: 153500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003958225250244141s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1726 Step: 153600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3731, 'bonus': 0.016371458648164514, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 146708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 247 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8480548205829802
Updated goal-option-5 on 8 transitions
Took 0.00041961669921875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7239210525516384
Updated goal-option-8 on 92 transitions
Took 0.004587888717651367s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1727 Step: 153700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003718137741088867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1728 Step: 153800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003839254379272461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1729 Step: 153900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003662109375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1730 Step: 154000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0040073394775390625s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.8133392333984375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1731 Step: 154100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.004010677337646484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1732 Step: 154200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003791332244873047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1733 Step: 154300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 154300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3767, 'bonus': 0.016293042482672843, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 150008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 248 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9578175335480384
Updated goal-option-5 on 8 transitions
Took 0.0004031658172607422s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8447088412305712
Updated goal-option-8 on 92 transitions
Took 0.00449681282043457s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1734 Step: 154400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036916732788085938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1735 Step: 154500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003419160842895508s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1736 Step: 154600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036497116088867188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1737 Step: 154700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003838062286376953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1738 Step: 154800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 154800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3741, 'bonus': 0.016349562879842853, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 249 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8555412065657978
Updated goal-option-5 on 8 transitions
Took 0.00039958953857421875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.003476858139038086s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1739 Step: 154900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035958290100097656s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1740 Seed=18] Took 0.009682893753051758s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1740 Step: 155000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035905838012695312s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.7179718017578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1741 Step: 155100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037758350372314453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1742 Step: 155200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035212039947509766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1743 Step: 155300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036246776580810547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1744 Step: 155400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003779172897338867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1745 Step: 155500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003698110580444336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1746 Step: 155600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 155600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3765, 'bonus': 0.016297369409447485, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 149908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 250 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.864223377295169
Updated goal-option-5 on 8 transitions
Took 0.00040721893310546875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.20678961914648
Updated goal-option-8 on 92 transitions
Took 0.0051364898681640625s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1747 Step: 155700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 155700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3743, 'bonus': 0.01634519425908889, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 147808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 251 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9047096068495604
Updated goal-option-5 on 8 transitions
Took 0.0004856586456298828s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 92 transitions
Took 0.003997087478637695s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1748 Step: 155800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034351348876953125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1749 Step: 155900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004122734069824219s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1750 Step: 156000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003844022750854492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.076957702636719e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1751 Step: 156100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003853321075439453s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1752 Step: 156200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004184722900390625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1753 Step: 156300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003513336181640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1754 Step: 156400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037653446197509766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1755 Step: 156500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037140846252441406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1756 Step: 156600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0040891170501708984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1757 Step: 156700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 156700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3790, 'bonus': 0.0162435292576479, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 151308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 252 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9875586731459505
Updated goal-option-5 on 8 transitions
Took 0.00043511390686035156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 92 transitions
Took 0.003797769546508789s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1758 Step: 156800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 156800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3810, 'bonus': 0.01620083922520836, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 151808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 253 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.936380558964725
Updated goal-option-5 on 8 transitions
Took 0.0004355907440185547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 92 transitions
Took 0.003722667694091797s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1759 Step: 156900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 156900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3852, 'bonus': 0.016112274817427726, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 156708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 254 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9287168943640705
Updated goal-option-5 on 8 transitions
Took 0.00044727325439453125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.766865680698208
Updated goal-option-8 on 92 transitions
Took 0.004534244537353516s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
================================================================================
[Consolidation] Episode: 1760 Step: 157000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036187171936035156s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.719329833984375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1761 Step: 157100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3790, 'bonus': 0.0162435292576479, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 151308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 255 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8812837657339946
Updated goal-option-5 on 8 transitions
Took 0.0004019737243652344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([14 14])
[Random] DSG selected event SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 5 13]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 5 13] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 92 transitions
Took 0.003564119338989258s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1762 Step: 157200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003313779830932617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1763 Step: 157300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3827, 'bonus': 0.01616481612565617, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 256 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9132934424913289
Updated goal-option-5 on 8 transitions
Took 0.00040793418884277344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.405950373748336
Updated goal-option-8 on 92 transitions
Took 0.00462794303894043s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1764 Step: 157400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003284454345703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1765 Step: 157500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3822, 'bonus': 0.016175386202065652, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 152508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 257 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.825696277159332
Updated goal-option-5 on 8 transitions
Took 0.0004062652587890625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 92 transitions
Took 0.003863811492919922s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1766 Step: 157600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037670135498046875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1767 Step: 157700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030090808868408203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1768 Step: 157800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003301858901977539s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1769 Step: 157900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3863, 'bonus': 0.016089318388051083, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 156908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 258 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9249297519787798
Updated goal-option-5 on 8 transitions
Took 0.0004024505615234375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.802905654473209
Updated goal-option-8 on 92 transitions
Took 0.0049207210540771484s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1770 Step: 158000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003182649612426758s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.886222839355469e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1771 Step: 158100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003834247589111328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1772 Step: 158200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004014253616333008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1773 Step: 158300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033698081970214844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1774 Step: 158400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033926963806152344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1775 Step: 158500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00372314453125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1776 Step: 158600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003601551055908203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1777 Step: 158700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038633346557617188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1778 Step: 158800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003517627716064453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1779 Step: 158900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035729408264160156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1780 Step: 159000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003599882125854492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 4.029273986816406e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1781 Step: 159100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0032660961151123047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1782 Step: 159200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036656856536865234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1783 Step: 159300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033462047576904297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1784 Step: 159400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 159400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3827, 'bonus': 0.01616481612565617, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 259 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9045812488353396
Updated goal-option-5 on 8 transitions
Took 0.00041937828063964844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5063799485477205
Updated goal-option-8 on 92 transitions
Took 0.004536151885986328s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1785 Step: 159500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036034584045410156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1786 Step: 159600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037789344787597656s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1787 Step: 159700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037450790405273438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1788 Step: 159800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 159800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3866, 'bonus': 0.01608307455427813, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 260 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9060300336968771
Updated goal-option-5 on 8 transitions
Took 0.00042247772216796875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.609677795273962
Updated goal-option-8 on 92 transitions
Took 0.004664897918701172s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1789 Step: 159900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003206968307495117s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1790 Seed=18] Took 0.010144472122192383s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1790 Step: 160000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3833, 'bonus': 0.01615215934480992, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 155708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 261 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8197081493069763
Updated goal-option-5 on 8 transitions
Took 0.0004050731658935547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8914183605338601
Updated goal-option-8 on 92 transitions
Took 0.00475621223449707s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 3.266334533691406e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1791 Step: 160100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003614664077758789s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1792 Step: 160200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3828, 'bonus': 0.0161627045958809, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 154308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 262 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8460243299509743
Updated goal-option-5 on 8 transitions
Took 0.00039958953857421875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.658246931398975
Updated goal-option-8 on 92 transitions
Took 0.004584312438964844s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1793 Step: 160300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003190279006958008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1794 Step: 160400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032219886779785156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1795 Step: 160500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034055709838867188s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1796 Step: 160600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036132335662841797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1797 Step: 160700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003368377685546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1798 Step: 160800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032033920288085938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1799 Step: 160900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3827, 'bonus': 0.01616481612565617, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 153608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 263 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8128816370881579
Updated goal-option-5 on 8 transitions
Took 0.000423431396484375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3236556385560314
Updated goal-option-8 on 92 transitions
Took 0.004587888717651367s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1800 Step: 161000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003721952438354492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.765655517578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1801 Step: 161100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035047531127929688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1802 Step: 161200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004046916961669922s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1803 Step: 161300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037093162536621094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1804 Step: 161400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0040454864501953125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1805 Step: 161500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 161500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3833, 'bonus': 0.01615215934480992, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 155708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 264 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8485431995357423
Updated goal-option-5 on 8 transitions
Took 0.00044536590576171875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.325821526264314
Updated goal-option-8 on 92 transitions
Took 0.0052204132080078125s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1806 Step: 161600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 161600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3906, 'bonus': 0.01600051202457731, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 265 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8223693658739833
Updated goal-option-5 on 8 transitions
Took 0.00040340423583984375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3623386555353845
Updated goal-option-8 on 92 transitions
Took 0.004635334014892578s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1807 Step: 161700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 161700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3911, 'bonus': 0.015990280862955328, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 266 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8386372523306304
Updated goal-option-5 on 8 transitions
Took 0.0004794597625732422s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6517166083213521
Updated goal-option-8 on 92 transitions
Took 0.00537562370300293s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1808 Step: 161800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003736257553100586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1809 Step: 161900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 161900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3911, 'bonus': 0.015990280862955328, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 267 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9084745390171651
Updated goal-option-5 on 8 transitions
Took 0.0003998279571533203s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6653940343716453
Updated goal-option-8 on 92 transitions
Took 0.0045430660247802734s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1810 Step: 162000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0033991336822509766s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.1948089599609375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1811 Step: 162100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3906, 'bonus': 0.01600051202457731, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 268 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8301179370933905
Updated goal-option-5 on 8 transitions
Took 0.00048542022705078125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 92 transitions
Took 0.003982067108154297s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1812 Step: 162200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003835439682006836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1813 Step: 162300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003529787063598633s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1814 Step: 162400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003856658935546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1815 Step: 162500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3829, 'bonus': 0.016160593893345503, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 154808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 269 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8327876020194892
Updated goal-option-5 on 8 transitions
Took 0.00042128562927246094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3686288574509868
Updated goal-option-8 on 92 transitions
Took 0.005403995513916016s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1816 Step: 162600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003619670867919922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1817 Step: 162700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3946, 'bonus': 0.01591920808366894, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 161608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 270 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8295258398081425
Updated goal-option-5 on 8 transitions
Took 0.00048732757568359375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.003734111785888672s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1818 Step: 162800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036306381225585938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1819 Step: 162900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003378152847290039s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1820 Step: 163000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003691434860229492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.457069396972656e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1821 Step: 163100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003583669662475586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1822 Step: 163200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3881, 'bonus': 0.016051964057894892, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 271 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8646918232177033
Updated goal-option-5 on 8 transitions
Took 0.00043487548828125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.0038712024688720703s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1823 Step: 163300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3866, 'bonus': 0.01608307455427813, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 272 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8815680193744502
Updated goal-option-5 on 8 transitions
Took 0.00040721893310546875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.0720882943496295
Updated goal-option-8 on 92 transitions
Took 0.004567146301269531s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1824 Step: 163400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3956, 'bonus': 0.015899075018722335, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 273 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8476716379697358
Updated goal-option-5 on 8 transitions
Took 0.0004076957702636719s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.9528033599527765
Updated goal-option-8 on 18 transitions
Took 0.0009238719940185547s to update distance table with 19 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 74 transitions
Took 0.002989530563354492s to update distance table with 75 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1825 Step: 163500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003292083740234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1826 Step: 163600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038356781005859375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1827 Step: 163700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003766775131225586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1828 Step: 163800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003106832504272461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1829 Step: 163900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003620624542236328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1830 Step: 164000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0031075477600097656s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.409385681152344e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1831 Step: 164100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3947, 'bonus': 0.015917191334679576, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 161708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 274 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9005773519940776
Updated goal-option-5 on 8 transitions
Took 0.00043582916259765625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5498283161621471
Updated goal-option-8 on 92 transitions
Took 0.004932880401611328s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1832 Step: 164200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035293102264404297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1833 Step: 164300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3897, 'bonus': 0.01601897771107376, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 159408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 275 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8328661749537072
Updated goal-option-5 on 8 transitions
Took 0.00043702125549316406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.595074470184051
Updated goal-option-8 on 92 transitions
Took 0.005400896072387695s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1834 Step: 164400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033528804779052734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1835 Step: 164500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003557443618774414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1836 Step: 164600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3881, 'bonus': 0.016051964057894892, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 276 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8535203468449851
Updated goal-option-5 on 8 transitions
Took 0.00039649009704589844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4745037798593013
Updated goal-option-8 on 92 transitions
Took 0.004498720169067383s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1837 Step: 164700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003650188446044922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1838 Step: 164800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4008, 'bonus': 0.015795600590164088, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 277 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8443188121571348
Updated goal-option-5 on 8 transitions
Took 0.0004067420959472656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([15  7])
[Random] DSG selected event SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 5 13]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 5 13] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 92 transitions
Took 0.0035448074340820312s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1839 Step: 164900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3956, 'bonus': 0.015899075018722335, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 278 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8256712476598139
Updated goal-option-5 on 8 transitions
Took 0.00041103363037109375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.054430318356904
Updated goal-option-8 on 92 transitions
Took 0.004645109176635742s to update distance table with 93 states and events {None, SE([ 5 13])}
[Episode=1840 Seed=18] Took 0.012414693832397461s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1840 Step: 165000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3909, 'bonus': 0.015994370971952505, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 279 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8993080071942456
Updated goal-option-5 on 8 transitions
Took 0.0004138946533203125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
2.345865744938899
Updated goal-option-8 on 92 transitions
Took 0.004652500152587891s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 0.00010013580322265625s to add potential edges.
================================================================================
[Consolidation] Episode: 1841 Step: 165100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037069320678710938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1842 Step: 165200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003714323043823242s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1843 Step: 165300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003929615020751953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1844 Step: 165400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034685134887695312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1845 Step: 165500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003739595413208008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1846 Step: 165600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036339759826660156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1847 Step: 165700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033986568450927734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1848 Step: 165800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003781557083129883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1849 Step: 165900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3909, 'bonus': 0.015994370971952505, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 160208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 280 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8340619215880757
Updated goal-option-5 on 8 transitions
Took 0.0004048347473144531s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7383669866903204
Updated goal-option-8 on 92 transitions
Took 0.00455927848815918s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1850 Step: 166000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003334522247314453s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.5510787963867188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1851 Step: 166100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037851333618164062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1852 Step: 166200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034704208374023438s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1853 Step: 166300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4015, 'bonus': 0.01578182506843426, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 281 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8918698061424405
Updated goal-option-5 on 8 transitions
Took 0.0004703998565673828s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6716083467385232
Updated goal-option-8 on 22 transitions
Took 0.0012912750244140625s to update distance table with 23 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 70 transitions
Took 0.0028867721557617188s to update distance table with 71 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1854 Step: 166400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4021, 'bonus': 0.015770046120355822, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 282 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8184298791769725
Updated goal-option-5 on 8 transitions
Took 0.0004811286926269531s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.529644538626079
Updated goal-option-8 on 29 transitions
Took 0.0018930435180664062s to update distance table with 30 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 63 transitions
Took 0.0024738311767578125s to update distance table with 64 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1855 Step: 166500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003577709197998047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1856 Step: 166600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038912296295166016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1857 Step: 166700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003910064697265625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1858 Step: 166800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4011, 'bonus': 0.01578969237952532, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 283 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8449355768727177
Updated goal-option-5 on 8 transitions
Took 0.0003960132598876953s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1802198359724088
Updated goal-option-8 on 55 transitions
Took 0.0029485225677490234s to update distance table with 56 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 35820, 'bonus': 0.005283688541235345, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4011, 'bonus': 0.01578969237952532, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 284 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8500749260501635
Updated goal-option-5 on 9 transitions
Took 0.000415802001953125s to update distance table with 10 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35794, 'bonus': 0.005285607172352227, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166437, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.182956927600585
Updated goal-option-8 on 8 transitions
Took 0.0005116462707519531s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 35823, 'bonus': 0.005283467295143451, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4023, 'bonus': 0.015766125661346737, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 285 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8315078969293319
Updated goal-option-5 on 8 transitions
Took 0.0004215240478515625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35794, 'bonus': 0.005285607172352227, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166437, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7473263027770403
Updated goal-option-8 on 12 transitions
Took 0.0007929801940917969s to update distance table with 13 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1859 Step: 166900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033419132232666016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1860 Step: 167000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003744363784790039s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.719329833984375e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1861 Step: 167100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0031404495239257812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1862 Step: 167200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036177635192871094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1863 Step: 167300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034666061401367188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1864 Step: 167400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034041404724121094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1865 Step: 167500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034232139587402344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1866 Step: 167600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036139488220214844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1867 Step: 167700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003382444381713867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1868 Step: 167800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003640413284301758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1869 Step: 167900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00395512580871582s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1870 Step: 168000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003445148468017578s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.8848648071289062e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1871 Step: 168100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035080909729003906s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1872 Step: 168200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003583669662475586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1873 Step: 168300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 168300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3979, 'bonus': 0.015853057338939592, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 286 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7888967536454454
Updated goal-option-5 on 8 transitions
Took 0.00040459632873535156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.7793581858247993
Updated goal-option-8 on 92 transitions
Took 0.0051631927490234375s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1874 Step: 168400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0040781497955322266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1875 Step: 168500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 168500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4015, 'bonus': 0.01578182506843426, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 287 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8583430902850081
Updated goal-option-5 on 8 transitions
Took 0.00040411949157714844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.8452483410445275
Updated goal-option-8 on 92 transitions
Took 0.004977226257324219s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1876 Step: 168600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036592483520507812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1877 Step: 168700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003123044967651367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1878 Step: 168800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003742218017578125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1879 Step: 168900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037183761596679688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1880 Step: 169000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003528594970703125s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 3.695487976074219e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1881 Step: 169100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 3974, 'bonus': 0.015863027189204314, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 162508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 288 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8315672407104474
Updated goal-option-5 on 8 transitions
Took 0.0004355907440185547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2669723776003823
Updated goal-option-8 on 92 transitions
Took 0.005272388458251953s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1882 Step: 169200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4021, 'bonus': 0.015770046120355822, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 289 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8360521071388524
Updated goal-option-5 on 8 transitions
Took 0.00041484832763671875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4644156686178154
Updated goal-option-8 on 92 transitions
Took 0.005052328109741211s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1883 Step: 169300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4015, 'bonus': 0.01578182506843426, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 165008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 290 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9197193353022776
Updated goal-option-5 on 8 transitions
Took 0.00041484832763671875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.6846509286203437
Updated goal-option-8 on 92 transitions
Took 0.005036115646362305s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1884 Step: 169400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003958463668823242s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1885 Step: 169500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034303665161132812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1886 Step: 169600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030663013458251953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1887 Step: 169700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035419464111328125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1888 Step: 169800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4023, 'bonus': 0.015766125661346737, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 291 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8523883579797632
Updated goal-option-5 on 8 transitions
Took 0.0004420280456542969s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 2])
[Random] DSG selected event SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 5 13]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 5 13] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 92 transitions
Took 0.0035223960876464844s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1889 Step: 169900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003765106201171875s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1890 Seed=18] Took 0.00903940200805664s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1890 Step: 170000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036079883575439453s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.5510787963867188e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1891 Step: 170100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0032105445861816406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1892 Step: 170200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003342151641845703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1893 Step: 170300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003356456756591797s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1894 Step: 170400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038204193115234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1895 Step: 170500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4057, 'bonus': 0.01569992205008053, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 168508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 292 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.957286044964469
Updated goal-option-5 on 8 transitions
Took 0.0004410743713378906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35823, 'bonus': 0.005283467295143451, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 9 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2027016093079719
Updated goal-option-8 on 9 transitions
Took 0.0006952285766601562s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 83 transitions
Took 0.0027544498443603516s to update distance table with 84 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1896 Step: 170600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4009, 'bonus': 0.01579363044976476, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 293 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7890855675349856
Updated goal-option-5 on 8 transitions
Took 0.0004019737243652344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3321327199864257
Updated goal-option-8 on 92 transitions
Took 0.004914999008178711s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1897 Step: 170700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4011, 'bonus': 0.01578969237952532, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 294 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8730841528670288
Updated goal-option-5 on 8 transitions
Took 0.00040602684020996094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35820, 'bonus': 0.005283688541235345, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.153192703510659
Updated goal-option-8 on 92 transitions
Took 0.0049588680267333984s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1898 Step: 170800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003178119659423828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1899 Step: 170900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4009, 'bonus': 0.01579363044976476, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 295 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.810332312296938
Updated goal-option-5 on 8 transitions
Took 0.0004067420959472656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35788, 'bonus': 0.005286050230275497, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4855092948347954
Updated goal-option-8 on 92 transitions
Took 0.004929304122924805s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1900 Step: 171000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039293766021728516s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 2.7179718017578125e-05s to add potential edges.
================================================================================
[Consolidation] Episode: 1901 Step: 171100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4011, 'bonus': 0.01578969237952532, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 164908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 296 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8017429897099165
Updated goal-option-5 on 8 transitions
Took 0.0004096031188964844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3124136913156073
Updated goal-option-8 on 92 transitions
Took 0.005333662033081055s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1902 Step: 171200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003053426742553711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1903 Step: 171300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4030, 'bonus': 0.015752427045264396, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166888, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 297 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9108732096111781
Updated goal-option-5 on 8 transitions
Took 0.0004279613494873047s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2436723698369494
Updated goal-option-8 on 92 transitions
Took 0.005274534225463867s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1904 Step: 171400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036802291870117188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1905 Step: 171500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4099, 'bonus': 0.015619281095398016, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 298 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9117375448281869
Updated goal-option-5 on 8 transitions
Took 0.0004439353942871094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([6 4])
[Random] DSG selected event SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 5 13]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 5 13] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 92 transitions
Took 0.0038290023803710938s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1906 Step: 171600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4026, 'bonus': 0.015760250451281974, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 299 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7888676951539693
Updated goal-option-5 on 8 transitions
Took 0.0003993511199951172s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3384826404348746
Updated goal-option-8 on 92 transitions
Took 0.0048558712005615234s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1907 Step: 171700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003251314163208008s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1908 Step: 171800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003654956817626953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1909 Step: 171900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4092, 'bonus': 0.01563263498701806, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 300 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8963324655062745
Updated goal-option-5 on 8 transitions
Took 0.0004000663757324219s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5807075001526802
Updated goal-option-8 on 92 transitions
Took 0.0052874088287353516s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1910 Step: 172000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4097, 'bonus': 0.015623093000542114, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 301 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.820658915707106
Updated goal-option-5 on 8 transitions
Took 0.0004417896270751953s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36235, 'bonus': 0.005253344325675983, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170517, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 10 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.7006021670749145
Updated goal-option-8 on 8 transitions
Creating goal-option-8-0 with parent goal-option-8
Creating classifier of type cnn
Created model-free option goal-option-8-0 with option_idx=10
Case 3: Adding edge from goal-option-8 to SE([ 8 16])
Adding edge from goal-option-8 to goal-option-5
Took 0.0004475116729736328s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0031137466430664062s to update distance table with 85 states and events {None, SE([ 8 16])}
Adding edge from SE([ 8 16]) to goal-option-5
Adding edge from SE([ 8 16]) to goal-option-8
Took 0.12595701217651367s to add potential edges.
================================================================================
[Consolidation] Episode: 1911 Step: 172100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038003921508789062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1912 Step: 172200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4105, 'bonus': 0.015607862099528717, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 302 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8690136647117911
Updated goal-option-5 on 8 transitions
Took 0.0003993511199951172s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4129, 'bonus': 0.015562435288367494, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.4384870114668507
Updated goal-option-8 on 92 transitions
Took 0.0045430660247802734s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1913 Step: 172300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4101, 'bonus': 0.015615471979112765, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 303 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8168266408461013
Updated goal-option-5 on 8 transitions
Took 0.0003979206085205078s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 1 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 9 transitions
Rolling out goal-option-8, from [ 1 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5979643730975874
Updated goal-option-8 on 83 transitions
Took 0.0058939456939697266s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1914 Step: 172400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033478736877441406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1915 Step: 172500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4062, 'bonus': 0.015690256395005604, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 304 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8460783673218235
Updated goal-option-5 on 8 transitions
Took 0.00039649009704589844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4131, 'bonus': 0.015558667600311219, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.5503836973402814
Updated goal-option-8 on 92 transitions
Took 0.004558086395263672s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1916 Step: 172600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036063194274902344s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1917 Step: 172700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035066604614257812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1918 Step: 172800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003545999526977539s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1919 Step: 172900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4086, 'bonus': 0.015644108482131068, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 305 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8046478961895697
Updated goal-option-5 on 8 transitions
Took 0.0003974437713623047s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 2 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 4 transitions
Rolling out goal-option-8, from [ 5 15] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 11 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2403718967698425
Updated goal-option-8 on 10 transitions
Took 0.0007801055908203125s to update distance table with 15 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 78 transitions
Took 0.002843141555786133s to update distance table with 79 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1920 Step: 173000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036504268646240234s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.10358452796936035s to add potential edges.
================================================================================
[Consolidation] Episode: 1921 Step: 173100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036270618438720703s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1922 Step: 173200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003393888473510742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1923 Step: 173300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4132, 'bonus': 0.015556784782176378, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 306 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8157633820493869
Updated goal-option-5 on 8 transitions
Took 0.0004019737243652344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4139, 'bonus': 0.01554362416667488, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 12 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.317449846957186
Updated goal-option-8 on 8 transitions
Took 0.0004436969757080078s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 36556, 'bonus': 0.005230228533552358, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4101, 'bonus': 0.015615471979112765, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 307 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8126520525444957
Updated goal-option-5 on 8 transitions
Took 0.00046253204345703125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 3 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 1 transitions
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36441, 'bonus': 0.005238474773996224, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2349683015305442
Updated goal-option-8 on 75 transitions
Took 0.00413060188293457s to update distance table with 77 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1924 Step: 173400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4097, 'bonus': 0.015623093000542114, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 308 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8268261466759678
Updated goal-option-5 on 8 transitions
Took 0.0004563331604003906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4143, 'bonus': 0.015536118794838617, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 13 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.608808911671219
Updated goal-option-8 on 13 transitions
Took 0.0007946491241455078s to update distance table with 14 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 79 transitions
Took 0.002824068069458008s to update distance table with 80 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1925 Step: 173500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4086, 'bonus': 0.015644108482131068, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 309 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7982789602301535
Updated goal-option-5 on 8 transitions
Took 0.00045299530029296875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4146, 'bonus': 0.015530496895325855, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35487, 'bonus': 0.005308420977746082, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 163426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2201935939840707
Updated goal-option-8 on 92 transitions
Took 0.005116462707519531s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1926 Step: 173600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.004242420196533203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1927 Step: 173700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003664255142211914s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1928 Step: 173800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4064, 'bonus': 0.015686395128453965, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 169308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 310 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8281375101035523
Updated goal-option-5 on 8 transitions
Took 0.00045609474182128906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4148, 'bonus': 0.015526752351113423, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32884, 'bonus': 0.005514519543875155, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 140430, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 14 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2215526073691687
Updated goal-option-8 on 9 transitions
Took 0.0005431175231933594s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 83 transitions
Took 0.003348827362060547s to update distance table with 84 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1929 Step: 173900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0039157867431640625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1930 Step: 174000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.00394892692565918s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.12618494033813477s to add potential edges.
================================================================================
[Consolidation] Episode: 1931 Step: 174100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038526058197021484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1932 Step: 174200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4129, 'bonus': 0.015562435288367494, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 311 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8333528019966335
Updated goal-option-5 on 8 transitions
Took 0.0004038810729980469s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4150, 'bonus': 0.015523010514126658, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36559, 'bonus': 0.005230013935129194, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173421, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3433785346023634
Updated goal-option-8 on 92 transitions
Took 0.0045223236083984375s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1933 Step: 174300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003958225250244141s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1934 Step: 174400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4146, 'bonus': 0.015530496895325855, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 312 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.809782189709363
Updated goal-option-5 on 8 transitions
Took 0.0004010200500488281s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4152, 'bonus': 0.01551927138110502, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 34623, 'bonus': 0.005374247364166262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': True, 'terminated': False, 'needs_reset': True, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 157000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 15 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6171428965592867
Updated goal-option-8 on 10 transitions
Took 0.0005369186401367188s to update distance table with 11 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 36654, 'bonus': 0.005223231951210958, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4139, 'bonus': 0.01554362416667488, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 313 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8206545559004841
Updated goal-option-5 on 8 transitions
Took 0.00039696693420410156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4154, 'bonus': 0.01551553494879347, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 16 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.6197865960393953
Updated goal-option-8 on 52 transitions
Took 0.002609729766845703s to update distance table with 53 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 22 transitions
Took 0.0007879734039306641s to update distance table with 23 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1935 Step: 174500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033648014068603516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1936 Step: 174600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037326812744140625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1937 Step: 174700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003720521926879883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1938 Step: 174800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003733396530151367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1939 Step: 174900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4099, 'bonus': 0.015619281095398016, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 314 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8255481529839891
Updated goal-option-5 on 8 transitions
Took 0.0004029273986816406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4156, 'bonus': 0.01551180121394244, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36362, 'bonus': 0.005244162235828522, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 17 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.3529737273415836
Updated goal-option-8 on 9 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 83 transitions
Took 0.00322723388671875s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
[Episode=1940 Seed=18] Took 0.010005950927734375s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1940 Step: 175000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003693819046020508s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.10403180122375488s to add potential edges.
================================================================================
[Consolidation] Episode: 1941 Step: 175100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 175100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4103, 'bonus': 0.015611665648287395, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 315 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8868880139724614
Updated goal-option-5 on 8 transitions
Took 0.0004017353057861328s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 4 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 4 transitions
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 18 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.238759397027734
Updated goal-option-8 on 8 transitions
Took 0.0007550716400146484s to update distance table with 13 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 80 transitions
Took 0.003117084503173828s to update distance table with 81 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1942 Step: 175200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037994384765625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1943 Step: 175300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034873485565185547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1944 Step: 175400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 175400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4127, 'bonus': 0.015566205714900918, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 316 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7785020293730341
Updated goal-option-5 on 8 transitions
Took 0.00039887428283691406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4163, 'bonus': 0.015498754337678151, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 175408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0542090573612395
Updated goal-option-8 on 92 transitions
Took 0.004525661468505859s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1945 Step: 175500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036733150482177734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1946 Step: 175600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0034117698669433594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1947 Step: 175700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036864280700683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1948 Step: 175800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037794113159179688s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1949 Step: 175900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037877559661865234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1950 Step: 176000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4143, 'bonus': 0.015536118794838617, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 317 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8274695707631503
Updated goal-option-5 on 8 transitions
Took 0.00040721893310546875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4166, 'bonus': 0.015493172888242845, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36691, 'bonus': 0.0052205976767490374, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174917, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.3181110533585525
Updated goal-option-8 on 92 transitions
Took 0.004618167877197266s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 0.11508345603942871s to add potential edges.
================================================================================
[Consolidation] Episode: 1951 Step: 176100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4154, 'bonus': 0.01551553494879347, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 318 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.791283341768005
Updated goal-option-5 on 8 transitions
Took 0.00040531158447265625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[Random] Deep skill graphs target event: SE([ 8 16])
[Random] DSG selected event SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 5 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 3 transitions
Rolling out goal-option-8, from [ 5 15] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 19 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.4874588806622364
Updated goal-option-8 on 5 transitions
Took 0.0005383491516113281s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 84 transitions
Took 0.0026476383209228516s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1952 Step: 176200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038907527923583984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1953 Step: 176300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035598278045654297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1954 Step: 176400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4156, 'bonus': 0.01551180121394244, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 319 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8508288491961439
Updated goal-option-5 on 8 transitions
Took 0.0004220008850097656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 6 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 2 transitions
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35788, 'bonus': 0.005286050230275497, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166330, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.280505339808479
Updated goal-option-8 on 90 transitions
Took 0.0052013397216796875s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1955 Step: 176500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0031709671020507812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1956 Step: 176600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4125, 'bonus': 0.015569978883230457, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 171908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 320 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8027351750128896
Updated goal-option-5 on 8 transitions
Took 0.00040531158447265625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4175, 'bonus': 0.015476464650682737, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35823, 'bonus': 0.005283467295143451, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 20 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.357530096657906
Updated goal-option-8 on 64 transitions
Deleting edge from SE([ 8 16]) to goal-option-8
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 28 transitions
Took 0.003869295120239258s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1957 Step: 176700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4169, 'bonus': 0.015487597464483503, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 321 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8217760330641646
Updated goal-option-5 on 8 transitions
Took 0.0004794597625732422s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4178, 'bonus': 0.015470907239054392, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 32373, 'bonus': 0.005557871818135057, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 132991, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 21 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.2189206818308234
Updated goal-option-8 on 15 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 77 transitions
Took 0.0031642913818359375s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1958 Step: 176800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003731966018676758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1959 Step: 176900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4171, 'bonus': 0.015483883857556962, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 322 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8232496558136121
Updated goal-option-5 on 8 transitions
Took 0.0004138946533203125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4181, 'bonus': 0.015465355809927969, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35794, 'bonus': 0.005285607172352227, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166437, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0404837464573147
Updated goal-option-8 on 92 transitions
Took 0.004622459411621094s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1960 Step: 177000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003693819046020508s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.12317848205566406s to add potential edges.
================================================================================
[Consolidation] Episode: 1961 Step: 177100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004011392593383789s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1962 Step: 177200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038797855377197266s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1963 Step: 177300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036797523498535156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1964 Step: 177400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036954879760742188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1965 Step: 177500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003679990768432617s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1966 Step: 177600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4148, 'bonus': 0.015526752351113423, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 323 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8314052604333372
Updated goal-option-5 on 8 transitions
Took 0.0004150867462158203s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 7 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 3 transitions
Rolling out goal-option-8, from [ 5 14] targeting {'count': 36235, 'bonus': 0.005253344325675983, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 170517, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 22 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.030517053489362
Updated goal-option-8 on 29 transitions
Took 0.0019381046295166016s to update distance table with 33 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 60 transitions
Took 0.0017533302307128906s to update distance table with 61 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1967 Step: 177700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003551006317138672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1968 Step: 177800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4154, 'bonus': 0.01551553494879347, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174426, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 324 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8390142416223005
Updated goal-option-5 on 8 transitions
Took 0.0004305839538574219s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4188, 'bonus': 0.015452425680385325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35823, 'bonus': 0.005283467295143451, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 23 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.160749877775092
Updated goal-option-8 on 17 transitions
Took 0.0009348392486572266s to update distance table with 18 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 36968, 'bonus': 0.00520100201755229, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4171, 'bonus': 0.015483883857556962, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 325 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8374665148511077
Updated goal-option-5 on 8 transitions
Took 0.0004363059997558594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[1.00000000e+00 1.92874989e-22 1.92874989e-22 1.92874989e-22
  1.95877337e-22]]
[BoltzmannClosest] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Revised planner goal vertex to SE([ 5 13]) and dsc goal vertex to SE([ 8 16])
Planner goal: SE([ 5 13]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
False
False
Rolling out DSC with goal vertex SE([ 8 16])
Rolling out goal-option-8-0, from [ 5 13] targeting {'player_x': 8, 'player_y': 16, 'inventory': '00000000', 'room_number': 1, 'dead': False, 'falling': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8-0 reached term set 8 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
Updated goal-option-8-0 on 9 transitions
Rolling out goal-option-8, from [ 5 15] targeting {'count': 36656, 'bonus': 0.0052230894560341854, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 24 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1376909687457204
Updated goal-option-8 on 5 transitions
Took 0.0008385181427001953s to update distance table with 15 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 53 transitions
Took 0.0016946792602539062s to update distance table with 54 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1969 Step: 177900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4171, 'bonus': 0.015483883857556962, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 326 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8343262207688706
Updated goal-option-5 on 8 transitions
Took 0.0004291534423828125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
Expanding goal-option-8's pessimistic classifier to include SE([ 5 13])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4207, 'bonus': 0.015417492434686497, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36362, 'bonus': 0.005244162235828522, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 25 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0360935249732954
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 84 transitions
Took 0.002866506576538086s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1970 Step: 178000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036933422088623047s to update distance table with 101 states and events {None, SE([ 8 16])}
Adding edge from goal-option-5 to goal-option-8
Adding edge from SE([ 5 13]) to goal-option-8
Adding edge from SE([ 8 16]) to goal-option-8
Took 0.08711385726928711s to add potential edges.
================================================================================
[Consolidation] Episode: 1971 Step: 178100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 178100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4146, 'bonus': 0.015530496895325855, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 327 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7590722081516729
Updated goal-option-5 on 8 transitions
Took 0.0004684925079345703s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4209, 'bonus': 0.015413829017161887, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 178108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36654, 'bonus': 0.005223231951210958, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1975871018151725
Updated goal-option-8 on 92 transitions
Took 0.0046002864837646484s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1972 Step: 178200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036385059356689453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1973 Step: 178300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 178300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4143, 'bonus': 0.015536118794838617, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 328 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7874048204221512
Updated goal-option-5 on 8 transitions
Took 0.00047135353088378906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4210, 'bonus': 0.015411998287418845, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 178308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35823, 'bonus': 0.005283467295143451, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166880, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 26 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.07044533767676
Updated goal-option-8 on 9 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 83 transitions
Took 0.0034875869750976562s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1974 Step: 178400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034492015838623047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1975 Step: 178500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003949880599975586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1976 Step: 178600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036029815673828125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1977 Step: 178700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035448074340820312s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1978 Step: 178800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0030019283294677734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1979 Step: 178900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003911733627319336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1980 Step: 179000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4146, 'bonus': 0.015530496895325855, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 329 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7776484233425807
Updated goal-option-5 on 8 transitions
Took 0.0004782676696777344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4212, 'bonus': 0.015408338784034142, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36656, 'bonus': 0.0052230894560341854, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2424002683548885
Updated goal-option-8 on 92 transitions
Took 0.004654884338378906s to update distance table with 93 states and events {None, SE([ 5 13])}
Took 0.0021855831146240234s to add potential edges.
================================================================================
[Consolidation] Episode: 1981 Step: 179100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038309097290039062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1982 Step: 179200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003263235092163086s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1983 Step: 179300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003484487533569336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1984 Step: 179400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4178, 'bonus': 0.015470907239054392, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 330 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8429442212138837
Updated goal-option-5 on 8 transitions
Took 0.0004496574401855469s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4213, 'bonus': 0.015406510009618582, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 35820, 'bonus': 0.005283688541235345, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 166863, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0000371428596935
Updated goal-option-8 on 92 transitions
Took 0.004708528518676758s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1985 Step: 179500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038404464721679688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1986 Step: 179600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003609895706176758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1987 Step: 179700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037288665771484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1988 Step: 179800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4166, 'bonus': 0.015493172888242845, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 331 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.828968380780781
Updated goal-option-5 on 8 transitions
Took 0.00043010711669921875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4219, 'bonus': 0.015395551020673125, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36556, 'bonus': 0.005230228533552358, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0849982686097817
Updated goal-option-8 on 92 transitions
Took 0.004622936248779297s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1989 Step: 179900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.00400853157043457s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=1990 Seed=18] Took 0.009967327117919922s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 1990 Step: 180000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4212, 'bonus': 0.015408338784034142, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 332 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8106692750456829
Updated goal-option-5 on 8 transitions
Took 0.00042319297790527344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4223, 'bonus': 0.015388258006990242, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37046, 'bonus': 0.005195523802355777, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 178317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 27 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0830376837200741
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0038497447967529297s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
Took 0.0016865730285644531s to add potential edges.
================================================================================
[Consolidation] Episode: 1991 Step: 180100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003912687301635742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1992 Step: 180200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4212, 'bonus': 0.015408338784034142, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 333 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8298864565645728
Updated goal-option-5 on 8 transitions
Took 0.00048232078552246094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4225, 'bonus': 0.015384615384615385, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36860, 'bonus': 0.005208615926498857, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176723, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0040866569831235
Updated goal-option-8 on 92 transitions
Took 0.0052089691162109375s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1993 Step: 180300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4188, 'bonus': 0.015452425680385325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 334 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8302262441668073
Updated goal-option-5 on 8 transitions
Took 0.00042939186096191406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4228, 'bonus': 0.015379156298021624, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36654, 'bonus': 0.005223231951210958, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174418, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 28 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1270603186012282
Updated goal-option-8 on 34 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 58 transitions
Took 0.003341197967529297s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1994 Step: 180400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0030524730682373047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1995 Step: 180500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036630630493164062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1996 Step: 180600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0038492679595947266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 1997 Step: 180700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4213, 'bonus': 0.015406510009618582, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 335 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8057066219768444
Updated goal-option-5 on 8 transitions
Took 0.0004677772521972656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4230, 'bonus': 0.015375520133814751, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36987, 'bonus': 0.005199665984185419, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177916, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 29 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.052369291628941
Updated goal-option-8 on 10 transitions
Took 0.0005364418029785156s to update distance table with 11 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 37370, 'bonus': 0.005172952029550125, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180718, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4223, 'bonus': 0.015388258006990242, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 336 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.787841056074415
Updated goal-option-5 on 8 transitions
Took 0.00043129920959472656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4232, 'bonus': 0.015371886547533641, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36441, 'bonus': 0.005238474773996224, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 172922, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.945671270635643
Updated goal-option-8 on 74 transitions
Took 0.003893136978149414s to update distance table with 75 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1998 Step: 180800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4219, 'bonus': 0.015395551020673125, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 337 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8857315763283236
Updated goal-option-5 on 8 transitions
Took 0.00043320655822753906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4235, 'bonus': 0.015366440995063938, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36970, 'bonus': 0.005200861333961262, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177847, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 30 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0254717997725933
Updated goal-option-8 on 9 transitions
Took 0.0005142688751220703s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 37373, 'bonus': 0.005172744404158359, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4188, 'bonus': 0.015452425680385325, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 338 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8156750536244699
Updated goal-option-5 on 8 transitions
Took 0.0004215240478515625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4238, 'bonus': 0.015361001225823307, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36968, 'bonus': 0.00520100201755229, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 31 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.024854816832636
Updated goal-option-8 on 9 transitions
Took 0.0005085468292236328s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 37375, 'bonus': 0.005172606001118717, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180834, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4228, 'bonus': 0.015379156298021624, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 339 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8351156787787678
Updated goal-option-5 on 8 transitions
Took 0.0004608631134033203s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4241, 'bonus': 0.015355567229582588, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180842, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36987, 'bonus': 0.005199665984185419, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177916, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 32 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9509861056392225
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 50 transitions
Took 0.0021963119506835938s to update distance table with 59 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 1999 Step: 180900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003425121307373047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2000 Step: 181000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034694671630859375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.0018651485443115234s to add potential edges.
================================================================================
[Consolidation] Episode: 2001 Step: 181100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0040400028228759766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2002 Step: 181200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003657102584838867s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2003 Step: 181300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003662586212158203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2004 Step: 181400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4213, 'bonus': 0.015406510009618582, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 340 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8846007252356349
Updated goal-option-5 on 8 transitions
Took 0.00042438507080078125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4243, 'bonus': 0.015351947767604297, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36709, 'bonus': 0.005219317578129058, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 175120, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.2323989620432723
Updated goal-option-8 on 92 transitions
Took 0.004586219787597656s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2005 Step: 181500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035398006439208984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2006 Step: 181600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4241, 'bonus': 0.015355567229582588, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180842, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 341 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9257435709148556
Updated goal-option-5 on 8 transitions
Took 0.0033152103424072266s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4246, 'bonus': 0.01534652337036732, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37373, 'bonus': 0.005172744404158359, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.0332045667115446
Updated goal-option-8 on 92 transitions
Took 0.004664421081542969s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2007 Step: 181700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4238, 'bonus': 0.015361001225823307, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 342 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8017115729170161
Updated goal-option-5 on 8 transitions
Took 0.0004410743713378906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4248, 'bonus': 0.015342910298305389, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37296, 'bonus': 0.005178081383343334, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180342, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 33 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1234629864169763
Updated goal-option-8 on 9 transitions
Took 0.0005102157592773438s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 83 transitions
Took 0.0029587745666503906s to update distance table with 84 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2008 Step: 181800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036344528198242188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2009 Step: 181900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003980159759521484s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2010 Step: 182000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037775039672851562s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.004030942916870117s to add potential edges.
================================================================================
[Consolidation] Episode: 2011 Step: 182100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4248, 'bonus': 0.015342910298305389, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 343 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8461112712596629
Updated goal-option-5 on 8 transitions
Took 0.0004162788391113281s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4251, 'bonus': 0.015337495471844778, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36600, 'bonus': 0.005227083734893167, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 173817, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.9338868893962453
Updated goal-option-8 on 92 transitions
Took 0.004630088806152344s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2012 Step: 182200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035293102264404297s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2013 Step: 182300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037407875061035156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2014 Step: 182400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0030548572540283203s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2015 Step: 182500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4230, 'bonus': 0.015375520133814751, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 344 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7716085518167602
Updated goal-option-5 on 8 transitions
Took 0.00041675567626953125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4253, 'bonus': 0.0153338887709197, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36656, 'bonus': 0.0052230894560341854, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 174478, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 34 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1047735216014516
Updated goal-option-8 on 8 transitions
Took 0.000446319580078125s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 37535, 'bonus': 0.005161569624227366, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4223, 'bonus': 0.015388258006990242, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 345 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8032485142135792
Updated goal-option-5 on 8 transitions
Took 0.0004222393035888672s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4255, 'bonus': 0.015330284613208399, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36853, 'bonus': 0.005209110575242474, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176672, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 35 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9780158774321318
Updated goal-option-8 on 11 transitions
Took 0.0006077289581298828s to update distance table with 12 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 65 transitions
Took 0.002370119094848633s to update distance table with 66 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2016 Step: 182600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4212, 'bonus': 0.015408338784034142, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 346 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7655664335051887
Updated goal-option-5 on 8 transitions
Took 0.0004570484161376953s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4260, 'bonus': 0.01532128532589739, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36930, 'bonus': 0.005203677176795586, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177640, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
1.1324801994280553
Updated goal-option-8 on 92 transitions
Took 0.004660367965698242s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2017 Step: 182700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4253, 'bonus': 0.0153338887709197, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 347 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7552253034180055
Updated goal-option-5 on 8 transitions
Took 0.00041747093200683594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4263, 'bonus': 0.01531589335482564, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37296, 'bonus': 0.005178081383343334, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180342, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 36 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9315253081458449
Updated goal-option-8 on 31 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 61 transitions
Took 0.003440380096435547s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2018 Step: 182800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003740072250366211s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2019 Step: 182900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4263, 'bonus': 0.01531589335482564, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 348 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8309737167302753
Updated goal-option-5 on 8 transitions
Took 0.00045800209045410156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4265, 'bonus': 0.015312301868469587, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36773, 'bonus': 0.00521477373085751, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 176116, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 37 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1596016829885218
Updated goal-option-8 on 23 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 69 transitions
Took 0.003087282180786133s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2020 Step: 183000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003538370132446289s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.0020089149475097656s to add potential edges.
================================================================================
[Consolidation] Episode: 2021 Step: 183100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003450155258178711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2022 Step: 183200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003914594650268555s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2023 Step: 183300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003903627395629883s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2024 Step: 183400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0035479068756103516s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2025 Step: 183500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032815933227539062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2026 Step: 183600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4212, 'bonus': 0.015408338784034142, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 179008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 349 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7307315773410329
Updated goal-option-5 on 8 transitions
Took 0.00043392181396484375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4266, 'bonus': 0.01531050707248751, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36987, 'bonus': 0.005199665984185419, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177916, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 38 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9415814542730279
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0033888816833496094s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2027 Step: 183700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003681659698486328s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2028 Step: 183800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003704547882080078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2029 Step: 183900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4241, 'bonus': 0.015355567229582588, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180842, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 350 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7472462253867421
Updated goal-option-5 on 8 transitions
Took 0.0004093647003173828s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4268, 'bonus': 0.015306919373065674, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37537, 'bonus': 0.0051614321162118315, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182535, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 39 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1056077195411678
Updated goal-option-8 on 8 transitions
Took 0.00048279762268066406s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0029997825622558594s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2030 Step: 184000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4238, 'bonus': 0.015361001225823307, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 351 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7549032114063398
Updated goal-option-5 on 8 transitions
Took 0.00044989585876464844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4270, 'bonus': 0.015303334194570998, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37377, 'bonus': 0.005172467609187904, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180850, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 40 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0721551352900114
Updated goal-option-8 on 8 transitions
Took 0.0004343986511230469s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 37657, 'bonus': 0.005153201693271035, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4270, 'bonus': 0.015303334194570998, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 352 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.755908389779402
Updated goal-option-5 on 8 transitions
Took 0.00041031837463378906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4272, 'bonus': 0.015299751534052615, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184024, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37634, 'bonus': 0.005154776141051782, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 41 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0471973596857198
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 68 transitions
Took 0.0028848648071289062s to update distance table with 77 states and events {SE([ 8 16]), None, SE([ 5 13])}
Took 0.0019495487213134766s to add potential edges.
================================================================================
[Consolidation] Episode: 2031 Step: 184100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036890506744384766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2032 Step: 184200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4255, 'bonus': 0.015330284613208399, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 353 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8071524186978914
Updated goal-option-5 on 8 transitions
Took 0.0004792213439941406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4274, 'bonus': 0.015296171388564487, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37551, 'bonus': 0.005160469867723185, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182931, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 42 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8356902620513506
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 84 transitions
Took 0.0034685134887695312s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2033 Step: 184300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4248, 'bonus': 0.015342910298305389, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 354 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7826404865816828
Updated goal-option-5 on 8 transitions
Took 0.0004215240478515625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4276, 'bonus': 0.0152925937551654, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 36987, 'bonus': 0.005199665984185419, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 177916, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 43 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7938568321414602
Updated goal-option-8 on 9 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 83 transitions
Took 0.0035948753356933594s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2034 Step: 184400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4232, 'bonus': 0.015371886547533641, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180726, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 355 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8314148657330461
Updated goal-option-5 on 8 transitions
Took 0.0004634857177734375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4279, 'bonus': 0.015287232008811677, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37678, 'bonus': 0.005151765413232271, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 44 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9405342173921952
Updated goal-option-8 on 8 transitions
Took 0.0004582405090332031s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.003024578094482422s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2035 Step: 184500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4255, 'bonus': 0.015330284613208399, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 356 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8444486112379929
Updated goal-option-5 on 8 transitions
Took 0.0004048347473144531s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4281, 'bonus': 0.015283660642798961, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37535, 'bonus': 0.005161569624227366, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 45 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.053145941528496
Updated goal-option-8 on 8 transitions
Took 0.00044989585876464844s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.003151416778564453s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2036 Step: 184600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4266, 'bonus': 0.01531050707248751, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 357 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8535108210430259
Updated goal-option-5 on 8 transitions
Took 0.0004189014434814453s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4283, 'bonus': 0.01528009177861889, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37377, 'bonus': 0.005172467609187904, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180850, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 46 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0656123262183543
Updated goal-option-8 on 8 transitions
Took 0.0004849433898925781s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0031070709228515625s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2037 Step: 184700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003719806671142578s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2038 Step: 184800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4238, 'bonus': 0.015361001225823307, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 180825, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 358 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8225993334714855
Updated goal-option-5 on 8 transitions
Took 0.0004105567932128906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4285, 'bonus': 0.015276525413351826, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37544, 'bonus': 0.005160950924689053, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182739, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.8765717407232952
Updated goal-option-8 on 92 transitions
Took 0.004651546478271484s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2039 Step: 184900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003650665283203125s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=2040 Seed=18] Took 0.009523630142211914s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 2040 Step: 185000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4283, 'bonus': 0.01528009177861889, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 359 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8116485312935852
Updated goal-option-5 on 8 transitions
Took 0.0004553794860839844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4287, 'bonus': 0.015272961544082902, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37657, 'bonus': 0.005153201693271035, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184016, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 47 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1019824694550626
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.003262758255004883s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
Took 0.002197742462158203s to add potential edges.
================================================================================
[Consolidation] Episode: 2041 Step: 185100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003366708755493164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2042 Step: 185200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4281, 'bonus': 0.015283660642798961, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 360 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7951207461452031
Updated goal-option-5 on 8 transitions
Took 0.0004150867462158203s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4289, 'bonus': 0.01526940016790202, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37698, 'bonus': 0.005150398643406601, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 48 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.922757256077453
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.003391265869140625s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2043 Step: 185300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035703182220458984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2044 Step: 185400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4281, 'bonus': 0.015283660642798961, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 361 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7801631256999958
Updated goal-option-5 on 8 transitions
Took 0.00042748451232910156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4291, 'bonus': 0.015265841281903815, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37535, 'bonus': 0.005161569624227366, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 49 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9382979875706366
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.0036873817443847656s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2045 Step: 185500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0038805007934570312s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2046 Step: 185600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003976106643676758s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2047 Step: 185700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037446022033691406s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2048 Step: 185800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038874149322509766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2049 Step: 185900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0033109188079833984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2050 Step: 186000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003612518310546875s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.002124786376953125s to add potential edges.
================================================================================
[Consolidation] Episode: 2051 Step: 186100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4253, 'bonus': 0.0153338887709197, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 362 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7700599274391654
Updated goal-option-5 on 8 transitions
Took 0.00041031837463378906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4302, 'bonus': 0.015246311791544941, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37535, 'bonus': 0.005161569624227366, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 182516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 50 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8928546056304808
Updated goal-option-8 on 9 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 83 transitions
Took 0.0036478042602539062s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2052 Step: 186200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033605098724365234s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2053 Step: 186300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4270, 'bonus': 0.015303334194570998, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 363 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8919942018921775
Updated goal-option-5 on 8 transitions
Took 0.0004477500915527344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4305, 'bonus': 0.015240998561973753, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37460, 'bonus': 0.005166734121691368, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 181717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 51 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8587926516024217
Updated goal-option-8 on 9 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 83 transitions
Took 0.003236055374145508s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2054 Step: 186400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003971576690673828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2055 Step: 186500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4276, 'bonus': 0.0152925937551654, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 364 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8141460705058007
Updated goal-option-5 on 8 transitions
Took 0.0004184246063232422s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4308, 'bonus': 0.01523569088340013, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37775, 'bonus': 0.0051451467175583875, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 52 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9649662852546994
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.002991199493408203s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2056 Step: 186600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037698745727539062s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2057 Step: 186700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.00359344482421875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2058 Step: 186800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003673076629638672s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2059 Step: 186900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036737918853759766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2060 Step: 187000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0038259029388427734s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.002527952194213867s to add potential edges.
================================================================================
[Consolidation] Episode: 2061 Step: 187100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036878585815429688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2062 Step: 187200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003851175308227539s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2063 Step: 187300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003808736801147461s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2064 Step: 187400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4283, 'bonus': 0.01528009177861889, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 365 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7895871160081273
Updated goal-option-5 on 8 transitions
Took 0.00041484832763671875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4310, 'bonus': 0.015232155510134434, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37648, 'bonus': 0.005153817609704591, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183916, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 53 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0181721782732578
Updated goal-option-8 on 8 transitions
Took 0.0004603862762451172s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38006, 'bonus': 0.0051294868169242044, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4276, 'bonus': 0.0152925937551654, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 366 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7171763207429821
Updated goal-option-5 on 8 transitions
Took 0.00043320655822753906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4312, 'bonus': 0.015228622596829316, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37634, 'bonus': 0.005154776141051782, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 54 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0115189556754702
Updated goal-option-8 on 8 transitions
Took 0.0005021095275878906s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 68 transitions
Took 0.0025000572204589844s to update distance table with 69 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2065 Step: 187500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003408193588256836s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2066 Step: 187600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4266, 'bonus': 0.01531050707248751, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 183608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 367 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7451570547671627
Updated goal-option-5 on 8 transitions
Took 0.00041794776916503906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4314, 'bonus': 0.01522509214063331, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37665, 'bonus': 0.0051526543973352025, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 55 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0618769777180905
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.0033369064331054688s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2067 Step: 187700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4276, 'bonus': 0.0152925937551654, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 368 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7848462029241682
Updated goal-option-5 on 8 transitions
Took 0.0004131793975830078s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4316, 'bonus': 0.015221564138699574, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37861, 'bonus': 0.005139299880778806, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186117, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 56 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9451279935496805
Updated goal-option-8 on 9 transitions
Took 0.0005078315734863281s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38048, 'bonus': 0.0051266548949691374, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4274, 'bonus': 0.015296171388564487, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 369 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8686320876284701
Updated goal-option-5 on 8 transitions
Took 0.0004482269287109375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4319, 'bonus': 0.015216276731324616, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187725, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38008, 'bonus': 0.005129351857065813, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 57 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9956456427387176
Updated goal-option-8 on 8 transitions
Took 0.00044465065002441406s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38050, 'bonus': 0.005126520158510161, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187733, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4291, 'bonus': 0.015265841281903815, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 370 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7629093976766224
Updated goal-option-5 on 8 transitions
Took 0.00041222572326660156s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4321, 'bonus': 0.01521275485262189, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187741, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37806, 'bonus': 0.005143036837405854, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 58 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8877136464931978
Updated goal-option-8 on 9 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 50 transitions
Took 0.002218484878540039s to update distance table with 60 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2068 Step: 187800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.004065275192260742s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2069 Step: 187900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037190914154052734s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2070 Step: 188000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003954172134399414s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.0026557445526123047s to add potential edges.
================================================================================
[Consolidation] Episode: 2071 Step: 188100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003329753875732422s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2072 Step: 188200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0037212371826171875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2073 Step: 188300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003935813903808594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2074 Step: 188400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003850698471069336s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2075 Step: 188500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4314, 'bonus': 0.01522509214063331, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 371 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7453439761455177
Updated goal-option-5 on 8 transitions
Took 0.00041413307189941406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4324, 'bonus': 0.015207476616811839, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38048, 'bonus': 0.0051266548949691374, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187717, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 59 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.996023374622585
Updated goal-option-8 on 8 transitions
Took 0.00043702125549316406s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38102, 'bonus': 0.005123020735063669, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4324, 'bonus': 0.015207476616811839, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 372 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8275178943190452
Updated goal-option-5 on 8 transitions
Took 0.0004172325134277344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4326, 'bonus': 0.015203960843648032, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188524, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37944, 'bonus': 0.0051336758636141445, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 60 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8525475084744549
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 68 transitions
Took 0.0028848648071289062s to update distance table with 77 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2076 Step: 188600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0039730072021484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2077 Step: 188700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038509368896484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2078 Step: 188800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003582477569580078s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2079 Step: 188900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036983489990234375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2080 Step: 189000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003905057907104492s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.0023288726806640625s to add potential edges.
================================================================================
[Consolidation] Episode: 2081 Step: 189100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003535747528076172s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2082 Step: 189200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4279, 'bonus': 0.015287232008811677, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 184408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 373 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7827846486484055
Updated goal-option-5 on 8 transitions
Took 0.00044083595275878906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4328, 'bonus': 0.015200447507762041, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37861, 'bonus': 0.005139299880778806, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186117, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 61 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8772477440208579
Updated goal-option-8 on 8 transitions
Took 0.00047206878662109375s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.003314971923828125s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2083 Step: 189300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036678314208984375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2084 Step: 189400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4287, 'bonus': 0.015272961544082902, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 374 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7700732169073943
Updated goal-option-5 on 8 transitions
Took 0.00040340423583984375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 37919, 'bonus': 0.005135367901241785, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186317, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
0.7988034532306519
Updated goal-option-8 on 92 transitions
Took 0.004538059234619141s to update distance table with 93 states and events {None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2085 Step: 189500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0039520263671875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2086 Step: 189600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4312, 'bonus': 0.015228622596829316, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 375 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7273862551535125
Updated goal-option-5 on 8 transitions
Took 0.000408172607421875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4332, 'bonus': 0.0151934281365691, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38102, 'bonus': 0.005123020735063669, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 62 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8669094479943906
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.003122091293334961s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2087 Step: 189700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.003727436065673828s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2088 Step: 189800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0034568309783935547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2089 Step: 189900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034117698669433594s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=2090 Seed=18] Took 0.010123968124389648s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 2090 Step: 190000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036492347717285156s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 0.0026237964630126953s to add potential edges.
================================================================================
[Consolidation] Episode: 2091 Step: 190100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003360748291015625s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2092 Step: 190200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003938436508178711s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2093 Step: 190300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4291, 'bonus': 0.015265841281903815, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 376 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7595179576176636
Updated goal-option-5 on 8 transitions
Took 0.0004107952117919922s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4336, 'bonus': 0.015186418480769674, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38050, 'bonus': 0.005126520158510161, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187733, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 63 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8740183589335279
Updated goal-option-8 on 8 transitions
Took 0.00047659873962402344s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38288, 'bonus': 0.005110561976028001, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4310, 'bonus': 0.015232155510134434, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 377 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7427377557234994
Updated goal-option-5 on 8 transitions
Took 0.0004611015319824219s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4338, 'bonus': 0.015182917289142565, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38052, 'bonus': 0.005126385432673876, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187750, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 64 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0238718863685798
Updated goal-option-8 on 8 transitions
Took 0.00044274330139160156s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 68 transitions
Took 0.0025081634521484375s to update distance table with 69 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2094 Step: 190400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0036339759826660156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2095 Step: 190500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036444664001464844s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2096 Step: 190600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003623485565185547s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2097 Step: 190700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003397703170776367s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2098 Step: 190800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4302, 'bonus': 0.015246311791544941, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 378 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7526495105842539
Updated goal-option-5 on 8 transitions
Took 0.0004513263702392578s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4340, 'bonus': 0.015179418517972906, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38288, 'bonus': 0.005110561976028001, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190316, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 65 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8740320750970505
Updated goal-option-8 on 8 transitions
Took 0.0004394054412841797s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0030968189239501953s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2099 Step: 190900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035669803619384766s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2100 Step: 191000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003088712692260742s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.0022046566009521484s to add potential edges.
================================================================================
[Consolidation] Episode: 2101 Step: 191100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4289, 'bonus': 0.01526940016790202, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 185208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 379 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7728407239472425
Updated goal-option-5 on 8 transitions
Took 0.0004487037658691406s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4342, 'bonus': 0.015175922164473119, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38052, 'bonus': 0.005126385432673876, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187750, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 66 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9034128245371004
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.003494739532470703s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2102 Step: 191200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4338, 'bonus': 0.015182917289142565, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 380 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8169412520406949
Updated goal-option-5 on 8 transitions
Took 0.0004096031188964844s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4344, 'bonus': 0.015172428225860112, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38102, 'bonus': 0.005123020735063669, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188516, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 67 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7301417740331501
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.003427743911743164s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2103 Step: 191300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032377243041992188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2104 Step: 191400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4328, 'bonus': 0.015200447507762041, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 381 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7841580997909396
Updated goal-option-5 on 8 transitions
Took 0.0004591941833496094s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4346, 'bonus': 0.01516893669935528, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38041, 'bonus': 0.005127126556249417, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 68 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9843609717094086
Updated goal-option-8 on 31 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 61 transitions
Took 0.0034418106079101562s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2105 Step: 191500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003701925277709961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2106 Step: 191600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035915374755859375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2107 Step: 191700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003615140914916992s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2108 Step: 191800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4302, 'bonus': 0.015246311791544941, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 186108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 382 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.723328168254898
Updated goal-option-5 on 8 transitions
Took 0.0004584789276123047s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4348, 'bonus': 0.015165447582184487, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38006, 'bonus': 0.0051294868169242044, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 69 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8841770408533999
Updated goal-option-8 on 8 transitions
Took 0.00048422813415527344s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 84 transitions
Took 0.0032851696014404297s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2109 Step: 191900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0034029483795166016s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2110 Step: 192000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4344, 'bonus': 0.015172428225860112, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 383 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7831227472270598
Updated goal-option-5 on 8 transitions
Took 0.0004191398620605469s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4350, 'bonus': 0.015161960871578069, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38426, 'bonus': 0.005101376894398813, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191116, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 70 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7724945974065184
Updated goal-option-8 on 8 transitions
Took 0.0004410743713378906s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0030214786529541016s to update distance table with 85 states and events {None, SE([ 8 16])}
Took 0.002348661422729492s to add potential edges.
================================================================================
[Consolidation] Episode: 2111 Step: 192100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033397674560546875s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2112 Step: 192200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0036766529083251953s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2113 Step: 192300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034151077270507812s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2114 Step: 192400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4344, 'bonus': 0.015172428225860112, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 384 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8159333900701551
Updated goal-option-5 on 8 transitions
Took 0.00040793418884277344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4352, 'bonus': 0.01515847656477081, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38006, 'bonus': 0.0051294868169242044, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 71 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8242410320711855
Updated goal-option-8 on 8 transitions
Took 0.00043010711669921875s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38594, 'bonus': 0.005090261617155619, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4336, 'bonus': 0.015186418480769674, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 385 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7591438540235651
Updated goal-option-5 on 8 transitions
Took 0.00042629241943359375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4354, 'bonus': 0.015154994659001947, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192424, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38174, 'bonus': 0.005118187188897259, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189616, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 72 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8628510471024157
Updated goal-option-8 on 8 transitions
Took 0.00043463706970214844s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38596, 'bonus': 0.005090129729717498, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192432, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4350, 'bonus': 0.015161960871578069, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 386 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7913661382319847
Updated goal-option-5 on 8 transitions
Took 0.0004169940948486328s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4356, 'bonus': 0.015151515151515152, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192440, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38359, 'bonus': 0.00510583012745629, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 73 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8099157138717873
Updated goal-option-8 on 8 transitions
Took 0.0004322528839111328s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 52 transitions
Took 0.0017828941345214844s to update distance table with 53 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2115 Step: 192500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003853321075439453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2116 Step: 192600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003999233245849609s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2117 Step: 192700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4330, 'bonus': 0.015196936606339122, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 387 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7721153507123723
Updated goal-option-5 on 8 transitions
Took 0.0004622936248779297s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4358, 'bonus': 0.015148038039558517, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38359, 'bonus': 0.00510583012745629, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 74 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0075996607012252
Updated goal-option-8 on 8 transitions
Took 0.0004329681396484375s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38611, 'bonus': 0.005089140900589986, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192716, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4348, 'bonus': 0.015165447582184487, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 388 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7080893890859093
Updated goal-option-5 on 8 transitions
Took 0.00041556358337402344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4360, 'bonus': 0.015144563320384568, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38594, 'bonus': 0.005090261617155619, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192416, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 75 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9739073627069254
Updated goal-option-8 on 8 transitions
Took 0.0004391670227050781s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'count': 38613, 'bonus': 0.0050890091002429114, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192732, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4332, 'bonus': 0.0151934281365691, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 189608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 389 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7793104839603803
Updated goal-option-5 on 8 transitions
Took 0.0004172325134277344s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4362, 'bonus': 0.015141090991250224, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192740, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38426, 'bonus': 0.005101376894398813, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191116, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 76 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.884445030092191
Updated goal-option-8 on 15 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 45 transitions
Took 0.0022690296173095703s to update distance table with 61 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2118 Step: 192800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036487579345703125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2119 Step: 192900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003736257553100586s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2120 Step: 193000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037827491760253906s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
Took 0.002630949020385742s to add potential edges.
================================================================================
[Consolidation] Episode: 2121 Step: 193100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4338, 'bonus': 0.015182917289142565, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190324, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 390 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7519231168324487
Updated goal-option-5 on 8 transitions
Took 0.0004508495330810547s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4368, 'bonus': 0.015130688316720061, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38050, 'bonus': 0.005126520158510161, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 187733, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 77 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.027597167258728
Updated goal-option-8 on 8 transitions
Took 0.0004329681396484375s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0030760765075683594s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2122 Step: 193200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4342, 'bonus': 0.015175922164473119, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 391 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7716834199707411
Updated goal-option-5 on 8 transitions
Took 0.00041675567626953125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4370, 'bonus': 0.01512722552040129, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38290, 'bonus': 0.005110428504398001, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190332, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 78 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9417687549212953
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0030069351196289062s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2123 Step: 193300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.004033327102661133s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2124 Step: 193400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003981590270996094s to update distance table with 101 states and events {None, SE([ 8 16]), SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2125 Step: 193500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0035102367401123047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2126 Step: 193600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036864280700683594s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2127 Step: 193700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4336, 'bonus': 0.015186418480769674, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 190308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 392 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7319036680776616
Updated goal-option-5 on 8 transitions
Took 0.0004382133483886719s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4380, 'bonus': 0.015109947130387486, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38613, 'bonus': 0.0050890091002429114, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192732, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 79 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8706783531494361
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.003857135772705078s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2128 Step: 193800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003732919692993164s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2129 Step: 193900
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193900, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4346, 'bonus': 0.01516893669935528, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 393 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7560156019403443
Updated goal-option-5 on 8 transitions
Took 0.00040841102600097656s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4395, 'bonus': 0.015084140199287575, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193908, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38104, 'bonus': 0.005122886284928223, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 188532, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 80 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.1292471621451923
Updated goal-option-8 on 8 transitions
Took 0.000446319580078125s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.0031485557556152344s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2130 Step: 194000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032112598419189453s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.002138376235961914s to add potential edges.
================================================================================
[Consolidation] Episode: 2131 Step: 194100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036771297454833984s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2132 Step: 194200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4356, 'bonus': 0.015151515151515152, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192440, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 394 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.732333132295809
Updated goal-option-5 on 8 transitions
Took 0.00041484832763671875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38710, 'bonus': 0.005082629049748715, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193916, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 81 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
1.0703907068386427
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0030705928802490234s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2133 Step: 194300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0036635398864746094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2134 Step: 194400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0035660266876220703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2135 Step: 194500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4352, 'bonus': 0.01515847656477081, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 395 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.754404713432272
Updated goal-option-5 on 8 transitions
Took 0.0004162788391113281s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (5, 13) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
True
False
[Planner] Rolling out from {'count': 4399, 'bonus': 0.015077280653594389, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38615, 'bonus': 0.00508887731013554, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 82 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8110888566999727
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.003409147262573242s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2136 Step: 194600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4342, 'bonus': 0.015175922164473119, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 396 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7312484900087188
Updated goal-option-5 on 8 transitions
Took 0.00045013427734375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4401, 'bonus': 0.015073854388204487, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38611, 'bonus': 0.005089140900589986, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192716, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 83 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9465432961882015
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0033943653106689453s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2137 Step: 194700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0036690235137939453s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2138 Step: 194800
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194800, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4362, 'bonus': 0.015141090991250224, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192740, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 397 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8035800280809263
Updated goal-option-5 on 8 transitions
Took 0.0004062652587890625s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4403, 'bonus': 0.015070430457578103, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194808, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38430, 'bonus': 0.005101111398190333, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 84 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7568000324618877
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.003651142120361328s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2139 Step: 194900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.003905057907104492s to update distance table with 101 states and events {None, SE([ 8 16])}
[Episode=2140 Seed=18] Took 0.011545658111572266s to save gc logs
[SE([ 8 16]), SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14]), SE([ 5 13])]
================================================================================
[Consolidation] Episode: 2140 Step: 195000
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0032958984375s to update distance table with 101 states and events {None, SE([ 8 16])}
Took 0.002096891403198242s to add potential edges.
================================================================================
[Consolidation] Episode: 2141 Step: 195100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0032835006713867188s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2142 Step: 195200
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195200, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 398 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7816399738083506
Updated goal-option-5 on 8 transitions
Took 0.0004177093505859375s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4405, 'bonus': 0.015067008859064805, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38703, 'bonus': 0.005083088662631126, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193716, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 85 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9014916818005593
Updated goal-option-8 on 8 transitions
Took 0.0004467964172363281s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0030472278594970703s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2143 Step: 195300
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195300, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4346, 'bonus': 0.01516893669935528, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 399 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8121519522690509
Updated goal-option-5 on 8 transitions
Took 0.0004658699035644531s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4407, 'bonus': 0.01506358959001838, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195308, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38598, 'bonus': 0.005089997852530359, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 86 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8768624413961321
Updated goal-option-8 on 9 transitions
Took 0.0004863739013671875s to update distance table with 10 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 83 transitions
Took 0.0029375553131103516s to update distance table with 84 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2144 Step: 195400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0037086009979248047s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2145 Step: 195500
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195500, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4368, 'bonus': 0.015130688316720061, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 400 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7486207618347221
Updated goal-option-5 on 8 transitions
Took 0.00040912628173828125s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4409, 'bonus': 0.015060172647796806, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195508, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38658, 'bonus': 0.00508604629704572, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 87 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8771107962690959
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0034215450286865234s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2146 Step: 195600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4362, 'bonus': 0.015141090991250224, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192740, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 401 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7806145328120343
Updated goal-option-5 on 8 transitions
Took 0.00044798851013183594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4411, 'bonus': 0.01505675802976226, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38479, 'bonus': 0.005097862430135215, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 191816, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 88 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9754162050068665
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.0033423900604248047s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2147 Step: 195700
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037069320678710938s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2148 Step: 195800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0034589767456054688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2149 Step: 195900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.0031931400299072266s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2150 Step: 196000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4356, 'bonus': 0.015151515151515152, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192440, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 402 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7413584988880103
Updated goal-option-5 on 8 transitions
Took 0.0004410743713378906s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4413, 'bonus': 0.015053345733281098, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38611, 'bonus': 0.005089140900589986, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192716, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 89 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7768272120167579
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.0035431385040283203s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
Took 0.002134561538696289s to add potential edges.
================================================================================
[Consolidation] Episode: 2151 Step: 196100
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003802776336669922s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2152 Step: 196200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.0033583641052246094s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2153 Step: 196300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 100 transitions
Took 0.003509521484375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2154 Step: 196400
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196400, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4360, 'bonus': 0.015144563320384568, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192724, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 403 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7502680752300911
Updated goal-option-5 on 8 transitions
Took 0.0004153251647949219s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (5, 13) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
True
False
[Planner] Rolling out from {'count': 4415, 'bonus': 0.015049935755723864, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38598, 'bonus': 0.005089997852530359, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192448, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 90 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8122008252412586
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 84 transitions
Took 0.0031380653381347656s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2155 Step: 196500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0038814544677734375s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2156 Step: 196600
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0033435821533203125s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2157 Step: 196700
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196700, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4352, 'bonus': 0.01515847656477081, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192408, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 404 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7857378608916002
Updated goal-option-5 on 8 transitions
Took 0.00041961669921875s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4417, 'bonus': 0.015046528094465257, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196708, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38613, 'bonus': 0.0050890091002429114, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192732, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 91 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.9538886332973252
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 84 transitions
Took 0.003614187240600586s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
================================================================================
[Consolidation] Episode: 2158 Step: 196800
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.005742788314819336s to update distance table with 101 states and events {SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2159 Step: 196900
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.003854513168334961s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2160 Step: 197000
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197000, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4370, 'bonus': 0.01512722552040129, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 193208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 405 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7120951592403909
Updated goal-option-5 on 8 transitions
Took 0.00041747093200683594s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (5, 13) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
True
False
[Planner] Rolling out from {'count': 4419, 'bonus': 0.01504312274688414, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38891, 'bonus': 0.0050707878945675374, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 195216, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 92 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7217652908073432
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 84 transitions
Took 0.003263711929321289s to update distance table with 93 states and events {SE([ 8 16]), None, SE([ 5 13])}
Took 0.0022459030151367188s to add potential edges.
================================================================================
[Consolidation] Episode: 2161 Step: 197100
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197100, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4397, 'bonus': 0.01508070925640246, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 194208, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 406 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7275101147872814
Updated goal-option-5 on 8 transitions
Took 0.0015475749969482422s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
[CompetenceConnected] DSG selected event: SE([ 8 16])
[Graph Consolidation] From (5, 13) to [ 8 16]
Planner goal: SE([ 8 16]), DSC goal: SE([ 8 16]) and Goal: SE([ 8 16])
True
False
[Planner] Rolling out from {'count': 4421, 'bonus': 0.015039719710363528, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197108, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 38615, 'bonus': 0.00508887731013554, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 192755, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 93 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.8733886866843901
Updated goal-option-8 on 8 transitions
Took 0.00045299530029296875s to update distance table with 9 states and events {SE([ 8 16]), None, SE([ 5 13])}
DSG successfully reached SE([ 8 16])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([15  7])
[Graph Consolidation] From (8, 16) to [15  7]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([15  7])
Planner goal: SE([ 8 16]), DSC goal: SE([15  7]) and Goal: SE([15  7])
False
False
Rolling out DSC with goal vertex SE([15  7])
Rolling out goal-option-2, from [ 8 16] targeting {'player_pos': (15, 7), 'player_x': 15, 'player_y': 7, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-2 on 84 transitions
Took 0.0029621124267578125s to update distance table with 85 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2162 Step: 197200
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 4])
[Graph Consolidation] From (8, 16) to [6 4]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 4])
Planner goal: SE([ 8 16]), DSC goal: SE([6 4]) and Goal: SE([6 4])
False
False
Rolling out DSC with goal vertex SE([6 4])
Rolling out goal-option-1, from [ 8 16] targeting {'player_pos': (6, 4), 'player_x': 6, 'player_y': 4, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-1 on 100 transitions
Took 0.0037186145782470703s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2163 Step: 197300
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0035119056701660156s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2164 Step: 197400
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([14 14])
[Graph Consolidation] From (8, 16) to [14 14]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([14 14])
Planner goal: SE([ 8 16]), DSC goal: SE([14 14]) and Goal: SE([14 14])
False
False
Rolling out DSC with goal vertex SE([14 14])
Rolling out goal-option-4, from [ 8 16] targeting {'player_pos': (14, 14), 'player_x': 14, 'player_y': 14, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-4 on 100 transitions
Took 0.002977609634399414s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2165 Step: 197500
================================================================================
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.3773031  0.22295157 0.19274802 0.20699731]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (8, 16) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
[-trajReplay] Replaying negative trajectory with positive relabel
Updated goal-option-3 on 100 transitions
Took 0.0037488937377929688s to update distance table with 101 states and events {None, SE([ 8 16])}
================================================================================
[Consolidation] Episode: 2166 Step: 197600
================================================================================
[CompetenceConnected] DSG selected event: SE([ 5 13])
[Graph Consolidation] From (8, 16) to [ 5 13]
Planner goal: SE([ 5 13]), DSC goal: SE([ 5 13]) and Goal: SE([ 5 13])
True
False
[Planner] Rolling out from {'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197600, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 5 13])
Got plan [goal-option-5] and chose to execute goal-option-5
Rolling out goal-option-5, from [ 8 16] targeting {'count': 4413, 'bonus': 0.015053345733281098, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 196008, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-5 reached term set 407 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7881664351363113
Updated goal-option-5 on 8 transitions
Took 0.0005230903625488281s to update distance table with 9 states and events {None, SE([ 8 16]), SE([ 5 13])}
DSG successfully reached SE([ 5 13])
Unconnected Events: [SE([15  7]), SE([6 4]), SE([6 2]), SE([14 14])] | Probs: [[0.24903088 0.24903088 0.24903088 0.25290737]]
[BoltzmannClosest] DSG selected event: SE([6 2])
[Graph Consolidation] From (5, 13) to [6 2]
Revised planner goal vertex to SE([ 8 16]) and dsc goal vertex to SE([6 2])
Planner goal: SE([ 8 16]), DSC goal: SE([6 2]) and Goal: SE([6 2])
True
False
[Planner] Rolling out from {'count': 4423, 'bonus': 0.015036318982290579, 'player_pos': (5, 13), 'player_x': 5, 'player_y': 13, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197608, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False} targeting SE([ 8 16])
Got plan [goal-option-8] and chose to execute goal-option-8
Rolling out goal-option-8, from [ 5 13] targeting {'count': 39251, 'bonus': 0.005047480352547459, 'player_pos': (8, 16), 'player_x': 8, 'player_y': 16, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 197116, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
goal-option-8 reached term set 94 times.
[+SalientEventTrajReplay] Replaying positive trajectory with *positive* original goal
0.7966867523202548
Updated goal-option-8 on 8 transitions
False
False
Rolling out DSC with goal vertex SE([6 2])
Rolling out goal-option-3, from [ 8 16] targeting {'player_pos': (6, 2), 'player_x': 6, 'player_y': 2, 'room_number': 1, 'jumping': 0, 'dead': 0, 'falling': 0, 'uncontrollable': False, 'truncated': False, 'terminated': False, 'needs_reset': False, 'buggy_state': 0, 'inventory': '00000000', 'timestep': 0, 'has_key': False, 'door_open': False, 'left_door_open': False, 'right_door_open': False}
